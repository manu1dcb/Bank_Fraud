{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b836d3ce",
   "metadata": {},
   "source": [
    "### Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c189c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import scipy.stats as ss\n",
    "import sklearn\n",
    "import category_encoders as ce\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier)\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay,\n",
    "                             classification_report, auc, silhouette_score, recall_score, precision_score, \n",
    "                             make_scorer, fbeta_score, f1_score, precision_recall_curve, accuracy_score)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import scikitplot as skplt\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09b175",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c850c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = pd.read_csv(\"../data/Base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e351ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede meter pipeline aquí\n",
    "X_train0 = pd.read_csv(\"../data/X_train0.csv\")\n",
    "X_train0 = X_train0.drop('Unnamed: 0', axis=1)\n",
    "X_train1 = pd.read_csv(\"../data/X_train1.csv\")\n",
    "X_train1 = X_train1.drop('Unnamed: 0', axis=1)\n",
    "X_val = pd.read_csv(\"../data/X_validacion.csv\")\n",
    "X_val = X_val.drop('Unnamed: 0', axis=1)\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\")\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "y_train0 = pd.read_csv(\"../data/y_train0.csv\")\n",
    "y_train0 = y_train0.drop('Unnamed: 0', axis=1)\n",
    "y_train1 = pd.read_csv(\"../data/y_train1.csv\")\n",
    "y_train1 = y_train1.drop('Unnamed: 0', axis=1)\n",
    "y_val = pd.read_csv(\"../data/y_validacion.csv\")\n",
    "y_val = y_val.drop('Unnamed: 0', axis=1)\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\")\n",
    "y_test = y_test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d746c1",
   "metadata": {},
   "source": [
    "## Selección de threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467bf9f9",
   "metadata": {},
   "source": [
    "Elegimos el threshold óptimo para maximizar el F2 score, es decir, el Fscore con beta igual a dos, para cada modelo. De esta forma, damos prioridad a la exhaustividad, ya que en este problema es preferible dar un falso positivo que un falso positivo, porque lo importante es detectar la mayor cantidad posible de fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3e4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6683, number of negative: 33415\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 40098, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB:\n",
      "   Mejor F2-score: 0.207\n",
      "   Mejor Threshold: 0.990\n",
      "\n",
      "LogisticRegression:\n",
      "   Mejor F2-score: 0.261\n",
      "   Mejor Threshold: 0.495\n",
      "\n",
      "XGBClassifier:\n",
      "   Mejor F2-score: 0.288\n",
      "   Mejor Threshold: 0.535\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "   Mejor F2-score: 0.145\n",
      "   Mejor Threshold: 0.000\n",
      "\n",
      "RandomForestClassifier:\n",
      "   Mejor F2-score: 0.278\n",
      "   Mejor Threshold: 0.465\n",
      "\n",
      "AdaBoostClassifier:\n",
      "   Mejor F2-score: 0.263\n",
      "   Mejor Threshold: 0.505\n",
      "\n",
      "GradientBoostingClassifier:\n",
      "   Mejor F2-score: 0.302\n",
      "   Mejor Threshold: 0.495\n",
      "\n",
      "LGBMClassifier:\n",
      "   Mejor F2-score: 0.302\n",
      "   Mejor Threshold: 0.545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que ya tienes tus datos de entrenamiento y validación: X_train, X_val, y_train, y_val\n",
    "\n",
    "# Define your thresholds\n",
    "thresholds = np.linspace(0, 1, 100)  # You can adjust the range and number of thresholds\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LGBMClassifier()\n",
    "]\n",
    "\n",
    "# Inicializa una lista para almacenar los resultados de F2-score y thresholds\n",
    "f2_scores = []\n",
    "beta = 2  # Puedes ajustar este valor según tus preferencias\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    \n",
    "    # Crea un pipeline con el clasificador\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train1, y_train1)\n",
    "    \n",
    "    # Obtén las probabilidades de las clases\n",
    "    y_prob = pipe.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Inicializa listas para almacenar los resultados de F2-score para cada threshold\n",
    "    f2_scores_classifier = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Aplica el threshold a las predicciones\n",
    "        y_pred = (y_prob > threshold).astype(int)\n",
    "        \n",
    "        # Calcula el F2-score\n",
    "        f2 = fbeta_score(y_val, y_pred, beta=beta)\n",
    "        f2_scores_classifier.append(f2)\n",
    "    \n",
    "    # Encuentra el mejor F2-score y su correspondiente threshold\n",
    "    best_f2_score = max(f2_scores_classifier)\n",
    "    best_threshold = thresholds[f2_scores_classifier.index(best_f2_score)]\n",
    "    \n",
    "    # Almacena los resultados\n",
    "    f2_scores.append({\n",
    "        'classifier': classifier_name,\n",
    "        'best_f2_score': best_f2_score,\n",
    "        'best_threshold': best_threshold\n",
    "    })\n",
    "\n",
    "    # Grafica la curva de precision-recall\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_prob)\n",
    "    plt.plot(recall, precision, label=classifier_name)\n",
    "\n",
    "# Muestra la leyenda y etiquetas del gráfico\n",
    "plt.legend()\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall para Diferentes Clasificadores')\n",
    "plt.show()\n",
    "\n",
    "# Muestra el mejor F2-score y threshold para cada clasificador\n",
    "for result in f2_scores:\n",
    "    print(f\"{result['classifier']}:\")\n",
    "    print(f\"   Mejor F2-score: {result['best_f2_score']:.3f}\")\n",
    "    print(f\"   Mejor Threshold: {result['best_threshold']:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb3677",
   "metadata": {},
   "source": [
    "Nos quedamos con el Threshold de 0.525 porque es el que mejor métrica nos da utilizando el LGBM Clasiffier. Con ese threshold, pasamos a comparar todos los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c755d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "Model Score: 0.838\n",
      "F-2 Score: 0.169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    197860\n",
      "           1       0.04      0.65      0.08      2140\n",
      "\n",
      "    accuracy                           0.84    200000\n",
      "   macro avg       0.52      0.75      0.50    200000\n",
      "weighted avg       0.99      0.84      0.90    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Model Score: 0.957\n",
      "F-2 Score: 0.260\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197860\n",
      "           1       0.11      0.38      0.18      2140\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.55      0.68      0.58    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model Score: 0.948\n",
      "F-2 Score: 0.287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    197860\n",
      "           1       0.11      0.49      0.18      2140\n",
      "\n",
      "    accuracy                           0.95    200000\n",
      "   macro avg       0.55      0.72      0.58    200000\n",
      "weighted avg       0.98      0.95      0.97    200000\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model Score: 0.875\n",
      "F-2 Score: 0.143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    197860\n",
      "           1       0.04      0.45      0.07      2140\n",
      "\n",
      "    accuracy                           0.88    200000\n",
      "   macro avg       0.52      0.66      0.50    200000\n",
      "weighted avg       0.98      0.88      0.92    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Model Score: 0.964\n",
      "F-2 Score: 0.273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197860\n",
      "           1       0.13      0.37      0.20      2140\n",
      "\n",
      "    accuracy                           0.97    200000\n",
      "   macro avg       0.56      0.67      0.59    200000\n",
      "weighted avg       0.98      0.97      0.98    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "Model Score: 0.954\n",
      "F-2 Score: 0.004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    197860\n",
      "           1       0.75      0.00      0.01      2140\n",
      "\n",
      "    accuracy                           0.99    200000\n",
      "   macro avg       0.87      0.50      0.50    200000\n",
      "weighted avg       0.99      0.99      0.98    200000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Model Score: 0.961\n",
      "F-2 Score: 0.299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197860\n",
      "           1       0.14      0.43      0.21      2140\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.56      0.70      0.59    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 6683, number of negative: 33415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 40098, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n",
      "Model Score: 0.954\n",
      "F-2 Score: 0.300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    197860\n",
      "           1       0.12      0.47      0.20      2140\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.56      0.72      0.59    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LGBMClassifier()\n",
    "]\n",
    "\n",
    "beta = 2\n",
    "threshold = 0.525  # Nuevo umbral\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train1, y_train1)\n",
    "    \n",
    "    # Obtener las probabilidades de las clases\n",
    "    y_prob = pipe.predict_proba(X_val)\n",
    "    \n",
    "    # Aplicar el nuevo umbral a las predicciones\n",
    "    y_pred = (y_prob[:, 1] > threshold).astype(int)\n",
    "    \n",
    "    # Calcula el model score\n",
    "    model_score = pipe.score(X_val, y_val)\n",
    "    \n",
    "    # Calcular f-beta score\n",
    "    f_beta = fbeta_score(y_val, y_pred, beta=beta)\n",
    "\n",
    "    \n",
    "    print(f\"{classifier.__class__.__name__}\")\n",
    "    print(f\"Model Score: {model_score:.3f}\")\n",
    "    print(f\"F-{beta} Score: {f_beta:.3f}\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13496dff",
   "metadata": {},
   "source": [
    "## Hacemos undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6647737",
   "metadata": {},
   "source": [
    "Una vez confirmado que elegimos el model LGBM, volvemos al train0 para renombrarlos como train2 haciendo un undersampling del total de la muestra. Ahora elegimos cual la mejor estrategia de remuestreo para entrenar el modelo. Lo hacemos mediante validación cruzada de x_train0 e y_train0, los cuales, una vez tengamos el valor elegido, serán balanceados de tal forma que los pasaremos a x_train2 e y_train2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc4f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_train0, y_train0, test_size=0.2, stratify=y_train0, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e539513c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.05 - F2 Score on Validation Set: 0.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.10 - F2 Score on Validation Set: 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.15 - F2 Score on Validation Set: 0.2697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.20 - F2 Score on Validation Set: 0.2771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.25 - F2 Score on Validation Set: 0.2774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.30 - F2 Score on Validation Set: 0.2705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.35 - F2 Score on Validation Set: 0.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.40 - F2 Score on Validation Set: 0.2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.45 - F2 Score on Validation Set: 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.50 - F2 Score on Validation Set: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.55 - F2 Score on Validation Set: 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.60 - F2 Score on Validation Set: 0.2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.65 - F2 Score on Validation Set: 0.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.70 - F2 Score on Validation Set: 0.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.75 - F2 Score on Validation Set: 0.1937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.80 - F2 Score on Validation Set: 0.1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.85 - F2 Score on Validation Set: 0.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.90 - F2 Score on Validation Set: 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.95 - F2 Score on Validation Set: 0.1729\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Supongamos que X_train3 es tu conjunto de entrenamiento y X_val es tu conjunto de validación\n",
    "\n",
    "# 1. Divide el conjunto de entrenamiento en entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define las tasas de undersampling que deseas probar (de 0.05 en 0.05)\n",
    "undersampling_rates = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "# 3. Itera sobre las tasas de undersampling\n",
    "for rate in undersampling_rates:\n",
    "    # 4. Aplica RandomUnderSampler con la tasa actual\n",
    "    rus = RandomUnderSampler(sampling_strategy=rate, random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 5. Entrena un clasificador (por ejemplo, RandomForest) con los datos undersampled\n",
    "    clf = RandomForestClassifier(random_state=69)\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # 6. Realiza predicciones en el conjunto de validación\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    # 7. Calcula y muestra el F2-score\n",
    "    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "    print(f\"Undersampling Rate: {rate:.2f} - F2 Score on Validation Set: {f2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ef158",
   "metadata": {},
   "source": [
    "El F2-Score más alto nos da en 0.2. Para ser más exhaustivos, comprobamos yendo de 0.01 en 0.01 (en vez de de 0.1 en 0.1), para buscar el remuestreo óptimo que maximice esta métrica. Aquí veremos que este es 0.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3896c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 71100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 78210, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.090909 -> initscore=-2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "Undersampling Rate: 0.100 - F2 Score on Validation Set: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 64636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 71746, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099100 -> initscore=-2.207269\n",
      "[LightGBM] [Info] Start training from score -2.207269\n",
      "Undersampling Rate: 0.110 - F2 Score on Validation Set: 0.2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 59250\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 66360, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.107143 -> initscore=-2.120264\n",
      "[LightGBM] [Info] Start training from score -2.120264\n",
      "Undersampling Rate: 0.120 - F2 Score on Validation Set: 0.2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 54692\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 61802, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115045 -> initscore=-2.040215\n",
      "[LightGBM] [Info] Start training from score -2.040215\n",
      "Undersampling Rate: 0.130 - F2 Score on Validation Set: 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 50785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 57895, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122809 -> initscore=-1.966099\n",
      "[LightGBM] [Info] Start training from score -1.966099\n",
      "Undersampling Rate: 0.140 - F2 Score on Validation Set: 0.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 47400\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 54510, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.130435 -> initscore=-1.897120\n",
      "[LightGBM] [Info] Start training from score -1.897120\n",
      "Undersampling Rate: 0.150 - F2 Score on Validation Set: 0.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 44437\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 51547, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137932 -> initscore=-1.832570\n",
      "[LightGBM] [Info] Start training from score -1.832570\n",
      "Undersampling Rate: 0.160 - F2 Score on Validation Set: 0.3019\n",
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 41823\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 48933, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.145301 -> initscore=-1.771944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -1.771944\n",
      "Undersampling Rate: 0.170 - F2 Score on Validation Set: 0.3014\n",
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 39500\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 46610, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152542 -> initscore=-1.714798\n",
      "[LightGBM] [Info] Start training from score -1.714798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.180 - F2 Score on Validation Set: 0.2991\n",
      "[LightGBM] [Info] Number of positive: 7110, number of negative: 37421\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 44531, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.159664 -> initscore=-1.660730\n",
      "[LightGBM] [Info] Start training from score -1.660730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Rate: 0.190 - F2 Score on Validation Set: 0.2935\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Divide el conjunto de entrenamiento en entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define las tasas de undersampling que deseas probar (de 0.001 en 0.001 entre 0.1 y 0.2)\n",
    "undersampling_rates = np.arange(0.10, 0.20, 0.01)\n",
    "\n",
    "# Almacena los resultados\n",
    "undersampling_results = []\n",
    "f2_scores = []\n",
    "\n",
    "# 3. Itera sobre las tasas de undersampling\n",
    "for rate in undersampling_rates:\n",
    "    # 4. Aplica RandomUnderSampler con la tasa actual\n",
    "    rus = RandomUnderSampler(sampling_strategy=rate, random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 5. Entrena un clasificador (por ejemplo, LGBMClassifier) con los datos undersampled\n",
    "    clf = LGBMClassifier(random_state=69)\n",
    "    clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # 6. Realiza predicciones en el conjunto de validación\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    # 7. Calcula y almacena el F2-score\n",
    "    f2 = fbeta_score(y_val, y_pred, beta=2)\n",
    "    undersampling_results.append(rate)\n",
    "    f2_scores.append(f2)\n",
    "    print(f\"Undersampling Rate: {rate:.3f} - F2 Score on Validation Set: {f2:.4f}\")\n",
    "\n",
    "# Grafica los resultados\n",
    "plt.plot(undersampling_results, f2_scores, marker='o')\n",
    "plt.xlabel('Undersampling Rate')\n",
    "plt.ylabel('F2 Score on Validation Set')\n",
    "plt.title('Undersampling Rate vs F2 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb4913",
   "metadata": {},
   "source": [
    "Hacemos undersampling con 0.16 como estrategia de remuestreo. De esta forma, optimizamos el F2-Score, que es la métrica en la que estamos fijando nuestra atención. Como hemos comprobado a la hora de elaborar el modelo, cuanto mayor sea el sampling strategy a partir de 0.16, a pesar de que la F2-Score decrece, la captación de verdaderos positivos aumenta. Pero como la investigación de cada caso también tiene un coste y, utilizando la métrica F2Score ya estamos priorizando el recall sobre la precisión, decidimos quedarnos aquí. De otra forma, la cantidad de falsos positivos sería muy grande en comparación con los verdaderos positivos que recogeríamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e899902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes del undersampling - X_train: (40098, 40) y_train: (40098, 1)\n",
      "Después del undersampling - X_train_resampled: (63966, 40) y_train_resampled: (63966, 1)\n"
     ]
    }
   ],
   "source": [
    "# Para reducir tiempos de computación a la hora de ejecutar un problema con un millón de instancias, y para elegir el modelo\n",
    "# a utilizar, realizamos undersampling. Ahora el dataset se nos queda en un 60% de entrenamiento que estará rebalanceado,\n",
    "# y una validación y test que permanecen vírgenes.\n",
    "# Siempre utilizamos el mismo random_state para los splits\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Definir el undersampler con la proporción deseada\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.16, random_state=69)\n",
    "\n",
    "# Aplicar undersampling a X_train e y_train\n",
    "X_train2, y_train2 = undersampler.fit_resample(X_train0, y_train0)\n",
    "\n",
    "# Ver las formas antes y después del undersampling\n",
    "print(\"Antes del undersampling - X_train:\", X_train1.shape, \"y_train:\", y_train1.shape)\n",
    "print(\"Después del undersampling - X_train_resampled:\", X_train2.shape, \"y_train_resampled:\", y_train2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0a804",
   "metadata": {},
   "source": [
    "## Buscamos hiperparámetros con LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef2fd6",
   "metadata": {},
   "source": [
    "A la hora de buscar los hiperparámetros, como scorer objetivo hemos elegido que se maximice el f2score, lo que hará que el modelo optimice esta métrica, que es especialmente sensible con la búsqueda de positivos en detrimento de la búsqueda de negativos y de evitar falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515c02d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4014\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5882, number of negative: 36762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4015\n",
      "[LightGBM] [Info] Number of data points in the train set: 42644, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 8823, number of negative: 55143\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4016\n",
      "[LightGBM] [Info] Number of data points in the train set: 63966, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137933 -> initscore=-1.832568\n",
      "[LightGBM] [Info] Start training from score -1.832568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2-score en datos de prueba: 0.307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    197794\n",
      "           1       0.13      0.46      0.21      2206\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.56      0.71      0.59    200000\n",
      "weighted avg       0.98      0.96      0.97    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo LGBMClassifier\n",
    "lgbm_model = LGBMClassifier(random_state=69)\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Definir la métrica a optimizar (F2-score)\n",
    "scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm_model, param_grid=param_grid, scoring=scorer, cv=3)\n",
    "\n",
    "# Ajustar el modelo\n",
    "grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_lgbm_model = grid_search.best_estimator_\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Imprimir el F2-score del mejor modelo en los datos de entrenamiento\n",
    "y_pred = best_lgbm_model.predict(X_test)\n",
    "f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"F2-score en datos de prueba: {f2_score:.3f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b871b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = best_lgbm_model.predict_proba(X_test)\n",
    "y_pred_prob = y_pred_prob[:,1] #para transformarlo en un array de 1d y que lo coja el predictor de la curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add24c9",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee390a5",
   "metadata": {},
   "source": [
    "#### Accuracy del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27e0249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = accuracy_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6d6da",
   "metadata": {},
   "source": [
    "El modelo acierta en 96 de cada 100 casos. Esta métrica no mejora la del modelo base (que al haber un 99,1% de negativos, en el caso de que se den todos los casos como negativos, se tendría un 99,1% de acierto). Sin embargo, no es relevante porque es mucho más importante detectar un verdadero positivo que un verdadero negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443e530",
   "metadata": {},
   "source": [
    "#### Curva ROC y AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a9de0",
   "metadata": {},
   "source": [
    "La curva ROC nos indica el número de verdaderos positivos que vamos a tener y el coste que tiene esto en falsos positivos. El punto deseado se debería encontrar moderadamente más arriba del punto álgido de la curva, ya que así priorizaríamos predecir más verdaderos, que es lo interesante. Además, el area bajo la curva es de 0.895, lo cual, según las fuentes consultadas, es una buena métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc832e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_prob = [0 for _ in range(len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a37e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.8931321840737423\n"
     ]
    }
   ],
   "source": [
    "r_auc = roc_auc_score(y_test, t_prob)\n",
    "print(r_auc)\n",
    "\n",
    "f_auc_prob = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f_auc_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa6d84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_r_auc, tpr_r_auc, _ = roc_curve(y_test, t_prob)\n",
    "fpr_f_auc_prob, tpr_f_auc_prob, _ = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5b0f01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_f_auc_prob, tpr_f_auc_prob, linestyle='-', label='prediction prob (AUROC = %0.2f)' % f_auc_prob)\n",
    "\n",
    "plt.plot(fpr_r_auc, tpr_r_auc, linestyle='--', label='base prob (AUROC = %0.2f)' % r_auc)\n",
    "\n",
    "\n",
    "\n",
    "#Title\n",
    "plt.title('ROC Plot')\n",
    "\n",
    "#Axis labels\n",
    "plt.xlabel('False Positive Rates')\n",
    "plt.ylabel('True Positive Rates')\n",
    "\n",
    "#Show legend\n",
    "plt.legend()\n",
    "\n",
    "#Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509919c9",
   "metadata": {},
   "source": [
    "#### Curva de ganancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72909fe",
   "metadata": {},
   "source": [
    "Al ser un dataset tan desbalanceado es muy probable que la curva de ganancia esté alejada de la diagonal (si solo hubiera un positivo, muy probablemente con examinar el 1% de instancias con más probabilidad de haber cometido fraude ya habríamos conseguido detectar el 100% de los positivos). En este caso, examinando 20% de los casos más probables, detectaríamos más del 80% de los fraudes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0b342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "#Probabilidad de que froud_bool=1\n",
    "y_pred_prob=best_lgbm_model.predict_proba(X_test) #lo vuelvo a ejecutar porque aquí hay que tener el array completo, en 2D, no como para la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38975aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_cumulative_gain(y_test, y_pred_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53f261",
   "metadata": {},
   "source": [
    "#### Curva Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c49bb",
   "metadata": {},
   "source": [
    "Para la detección del fraude, el modelo mejora cuantiosamente lo que obtendríamos intentando encontrar aleatoriamente fraude.\n",
    "En el caso de Fraud Bool positivo, la mayoría se cogen entre 85 y 90 veces mejor con el modelo que de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcbc3ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_lift_curve(y_test, y_pred_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5d1a0",
   "metadata": {},
   "source": [
    "### Curvas de precisión-sensitividad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711232cf",
   "metadata": {},
   "source": [
    "#### F-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6a1d8",
   "metadata": {},
   "source": [
    "Con el F-Score encontramos la precisión y la sensitividad del modelo. En el caso del F1-Score pondera ambas por igual (es decir, es tan grave errar en un falso positivo como en un falso negativo. Sin embargo, como en este problema lo que intentamos es detectar los positivos principalmente, creemos que la sensitividad o recall es mucho más importante que la precisión. Por tanto, hemos hecho un F2-Score, que ha sido la métrica que hemos intentado optimizar en todo momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f668b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20504508155202109"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed321afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3068712474983322"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.fbeta_score(y_test, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fcb908",
   "metadata": {},
   "source": [
    "#### Matriz de confusión absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503dd44",
   "metadata": {},
   "source": [
    "De 200.000 instancias que tiene la parte de Test, hemos predicho 7.113 positivos. Con esa predicción hemos evitado un 46% del total de fraudes (1.016). Hay numerosos puntos del dataset en los que podíamos haber cambiado parámetros para detectar más de un 46% del fraude, pero ello hubiera supuesto un coste enorme de falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6652f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "y_pred_LGBM = best_lgbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1189344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[191141,   6653],\n",
       "       [  1194,   1012]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = confusion_matrix(y_test, y_pred_LGBM)#, labels=valores_unicos)\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3136c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_display = ConfusionMatrixDisplay(confusion_matrix=mc, display_labels = ['no fraude', 'fraude']) #display_labels debe ir en el orden en el que van valores_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2369415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2df901202e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee17eb",
   "metadata": {},
   "source": [
    "#### Matriz de confusión relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a63c0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = confusion_matrix(y_test, y_pred_LGBM)\n",
    "mc_rel = mc / mc.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ef21aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2df901a4af0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc_rel = mc / mc.sum(axis=1)[:, np.newaxis]\n",
    "mc_rel_display = ConfusionMatrixDisplay(confusion_matrix=mc_rel, display_labels = ['no fraude', 'fraude'])\n",
    "mc_rel_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000fc17",
   "metadata": {},
   "source": [
    "## Explicabilidad: SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a717848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align='center'><img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAdxJREFUeNq0Vt1Rg0AQJjcpgBJiBWIFkgoMFYhPPAIVECogPuYpdJBYgXQQrMCUkA50V7+d2ZwXuXPGm9khHLu3f9+3l1nkWNvtNqfHLgpfQ1EUS3tz5nAQ0+NIsiAZSc6eDlI8M3J00B/mDuUKDk6kfOebAgW3pkdD0pFcODGW4gKKvOrAUm04MA4QDt1OEIXU9hDigfS5rC1eS5T90gltck1Xrizo257kgySZcNRzgCSxCvgiE9nckPJo2b/B2AcEkk2OwL8bD8gmOKR1GPbaCUqxEgTq0tLvgb6zfo7+DgYGkkWL2tqLDV4RSITfbHPPfJKIrWz4nJQTMPAWA7IbD6imcNaDeDfgk+4No+wZr40BL3g9eQJJCFqRQ54KiSt72lsLpE3o3MCBSxDuq4yOckU2hKXRuwBH3OyMR4g1UpyTYw6mlmBqNdUXRM1NfyF5EPI6JkcpIDBIX8jX6DR/6ckAZJ0wEAdLR8DEk6OfC1Pp8BKo6TQIwPJbvJ6toK5lmuvJoRtfK6Ym1iRYIarRo2UyYHvRN5qpakR3yoizWrouoyuXXQqI185LCw07op5ZyCRGL99h24InP0e9xdQukEKVmhzrqZuRIfwISB//cP3Wk3f8f/yR+BRgAHu00HjLcEQBAAAAAElFTkSuQmCC' /></div><script charset='utf-8'>/*! For license information please see bundle.js.LICENSE.txt */\n",
       "(()=>{var e={486:function(e,t,n){var r;e=n.nmd(e),function(){var a,i=\"Expected a function\",o=\"__lodash_hash_undefined__\",u=\"__lodash_placeholder__\",l=32,s=128,c=1/0,f=9007199254740991,p=NaN,d=4294967295,h=[[\"ary\",s],[\"bind\",1],[\"bindKey\",2],[\"curry\",8],[\"curryRight\",16],[\"flip\",512],[\"partial\",l],[\"partialRight\",64],[\"rearg\",256]],v=\"[object Arguments]\",g=\"[object Array]\",y=\"[object Boolean]\",m=\"[object Date]\",b=\"[object Error]\",_=\"[object Function]\",w=\"[object GeneratorFunction]\",x=\"[object Map]\",k=\"[object Number]\",S=\"[object Object]\",E=\"[object Promise]\",C=\"[object RegExp]\",T=\"[object Set]\",M=\"[object String]\",N=\"[object Symbol]\",P=\"[object WeakMap]\",z=\"[object ArrayBuffer]\",L=\"[object DataView]\",O=\"[object Float32Array]\",A=\"[object Float64Array]\",F=\"[object Int8Array]\",D=\"[object Int16Array]\",R=\"[object Int32Array]\",j=\"[object Uint8Array]\",U=\"[object Uint8ClampedArray]\",I=\"[object Uint16Array]\",$=\"[object Uint32Array]\",B=/\\b__p \\+= '';/g,W=/\\b(__p \\+=) '' \\+/g,V=/(__e\\(.*?\\)|\\b__t\\)) \\+\\n'';/g,H=/&(?:amp|lt|gt|quot|#39);/g,q=/[&<>\"']/g,Q=RegExp(H.source),Y=RegExp(q.source),G=/<%-([\\s\\S]+?)%>/g,K=/<%([\\s\\S]+?)%>/g,Z=/<%=([\\s\\S]+?)%>/g,X=/\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,J=/^\\w*$/,ee=/[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g,te=/[\\\\^$.*+?()[\\]{}|]/g,ne=RegExp(te.source),re=/^\\s+/,ae=/\\s/,ie=/\\{(?:\\n\\/\\* \\[wrapped with .+\\] \\*\\/)?\\n?/,oe=/\\{\\n\\/\\* \\[wrapped with (.+)\\] \\*/,ue=/,? & /,le=/[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g,se=/[()=,{}\\[\\]\\/\\s]/,ce=/\\\\(\\\\)?/g,fe=/\\$\\{([^\\\\}]*(?:\\\\.[^\\\\}]*)*)\\}/g,pe=/\\w*$/,de=/^[-+]0x[0-9a-f]+$/i,he=/^0b[01]+$/i,ve=/^\\[object .+?Constructor\\]$/,ge=/^0o[0-7]+$/i,ye=/^(?:0|[1-9]\\d*)$/,me=/[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g,be=/($^)/,_e=/['\\n\\r\\u2028\\u2029\\\\]/g,we=\"\\\\ud800-\\\\udfff\",xe=\"\\\\u0300-\\\\u036f\\\\ufe20-\\\\ufe2f\\\\u20d0-\\\\u20ff\",ke=\"\\\\u2700-\\\\u27bf\",Se=\"a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff\",Ee=\"A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde\",Ce=\"\\\\ufe0e\\\\ufe0f\",Te=\"\\\\xac\\\\xb1\\\\xd7\\\\xf7\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf\\\\u2000-\\\\u206f \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000\",Me=\"[\"+we+\"]\",Ne=\"[\"+Te+\"]\",Pe=\"[\"+xe+\"]\",ze=\"\\\\d+\",Le=\"[\"+ke+\"]\",Oe=\"[\"+Se+\"]\",Ae=\"[^\"+we+Te+ze+ke+Se+Ee+\"]\",Fe=\"\\\\ud83c[\\\\udffb-\\\\udfff]\",De=\"[^\"+we+\"]\",Re=\"(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}\",je=\"[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]\",Ue=\"[\"+Ee+\"]\",Ie=\"\\\\u200d\",$e=\"(?:\"+Oe+\"|\"+Ae+\")\",Be=\"(?:\"+Ue+\"|\"+Ae+\")\",We=\"(?:['’](?:d|ll|m|re|s|t|ve))?\",Ve=\"(?:['’](?:D|LL|M|RE|S|T|VE))?\",He=\"(?:\"+Pe+\"|\"+Fe+\")?\",qe=\"[\"+Ce+\"]?\",Qe=qe+He+\"(?:\"+Ie+\"(?:\"+[De,Re,je].join(\"|\")+\")\"+qe+He+\")*\",Ye=\"(?:\"+[Le,Re,je].join(\"|\")+\")\"+Qe,Ge=\"(?:\"+[De+Pe+\"?\",Pe,Re,je,Me].join(\"|\")+\")\",Ke=RegExp(\"['’]\",\"g\"),Ze=RegExp(Pe,\"g\"),Xe=RegExp(Fe+\"(?=\"+Fe+\")|\"+Ge+Qe,\"g\"),Je=RegExp([Ue+\"?\"+Oe+\"+\"+We+\"(?=\"+[Ne,Ue,\"$\"].join(\"|\")+\")\",Be+\"+\"+Ve+\"(?=\"+[Ne,Ue+$e,\"$\"].join(\"|\")+\")\",Ue+\"?\"+$e+\"+\"+We,Ue+\"+\"+Ve,\"\\\\d*(?:1ST|2ND|3RD|(?![123])\\\\dTH)(?=\\\\b|[a-z_])\",\"\\\\d*(?:1st|2nd|3rd|(?![123])\\\\dth)(?=\\\\b|[A-Z_])\",ze,Ye].join(\"|\"),\"g\"),et=RegExp(\"[\"+Ie+we+xe+Ce+\"]\"),tt=/[a-z][A-Z]|[A-Z]{2}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/,nt=[\"Array\",\"Buffer\",\"DataView\",\"Date\",\"Error\",\"Float32Array\",\"Float64Array\",\"Function\",\"Int8Array\",\"Int16Array\",\"Int32Array\",\"Map\",\"Math\",\"Object\",\"Promise\",\"RegExp\",\"Set\",\"String\",\"Symbol\",\"TypeError\",\"Uint8Array\",\"Uint8ClampedArray\",\"Uint16Array\",\"Uint32Array\",\"WeakMap\",\"_\",\"clearTimeout\",\"isFinite\",\"parseInt\",\"setTimeout\"],rt=-1,at={};at[O]=at[A]=at[F]=at[D]=at[R]=at[j]=at[U]=at[I]=at[$]=!0,at[v]=at[g]=at[z]=at[y]=at[L]=at[m]=at[b]=at[_]=at[x]=at[k]=at[S]=at[C]=at[T]=at[M]=at[P]=!1;var it={};it[v]=it[g]=it[z]=it[L]=it[y]=it[m]=it[O]=it[A]=it[F]=it[D]=it[R]=it[x]=it[k]=it[S]=it[C]=it[T]=it[M]=it[N]=it[j]=it[U]=it[I]=it[$]=!0,it[b]=it[_]=it[P]=!1;var ot={\"\\\\\":\"\\\\\",\"'\":\"'\",\"\\n\":\"n\",\"\\r\":\"r\",\"\\u2028\":\"u2028\",\"\\u2029\":\"u2029\"},ut=parseFloat,lt=parseInt,st=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,ct=\"object\"==typeof self&&self&&self.Object===Object&&self,ft=st||ct||Function(\"return this\")(),pt=t&&!t.nodeType&&t,dt=pt&&e&&!e.nodeType&&e,ht=dt&&dt.exports===pt,vt=ht&&st.process,gt=function(){try{return dt&&dt.require&&dt.require(\"util\").types||vt&&vt.binding&&vt.binding(\"util\")}catch(e){}}(),yt=gt&&gt.isArrayBuffer,mt=gt&&gt.isDate,bt=gt&&gt.isMap,_t=gt&&gt.isRegExp,wt=gt&&gt.isSet,xt=gt&&gt.isTypedArray;function kt(e,t,n){switch(n.length){case 0:return e.call(t);case 1:return e.call(t,n[0]);case 2:return e.call(t,n[0],n[1]);case 3:return e.call(t,n[0],n[1],n[2])}return e.apply(t,n)}function St(e,t,n,r){for(var a=-1,i=null==e?0:e.length;++a<i;){var o=e[a];t(r,o,n(o),e)}return r}function Et(e,t){for(var n=-1,r=null==e?0:e.length;++n<r&&!1!==t(e[n],n,e););return e}function Ct(e,t){for(var n=null==e?0:e.length;n--&&!1!==t(e[n],n,e););return e}function Tt(e,t){for(var n=-1,r=null==e?0:e.length;++n<r;)if(!t(e[n],n,e))return!1;return!0}function Mt(e,t){for(var n=-1,r=null==e?0:e.length,a=0,i=[];++n<r;){var o=e[n];t(o,n,e)&&(i[a++]=o)}return i}function Nt(e,t){return!(null==e||!e.length)&&Ut(e,t,0)>-1}function Pt(e,t,n){for(var r=-1,a=null==e?0:e.length;++r<a;)if(n(t,e[r]))return!0;return!1}function zt(e,t){for(var n=-1,r=null==e?0:e.length,a=Array(r);++n<r;)a[n]=t(e[n],n,e);return a}function Lt(e,t){for(var n=-1,r=t.length,a=e.length;++n<r;)e[a+n]=t[n];return e}function Ot(e,t,n,r){var a=-1,i=null==e?0:e.length;for(r&&i&&(n=e[++a]);++a<i;)n=t(n,e[a],a,e);return n}function At(e,t,n,r){var a=null==e?0:e.length;for(r&&a&&(n=e[--a]);a--;)n=t(n,e[a],a,e);return n}function Ft(e,t){for(var n=-1,r=null==e?0:e.length;++n<r;)if(t(e[n],n,e))return!0;return!1}var Dt=Wt(\"length\");function Rt(e,t,n){var r;return n(e,(function(e,n,a){if(t(e,n,a))return r=n,!1})),r}function jt(e,t,n,r){for(var a=e.length,i=n+(r?1:-1);r?i--:++i<a;)if(t(e[i],i,e))return i;return-1}function Ut(e,t,n){return t==t?function(e,t,n){for(var r=n-1,a=e.length;++r<a;)if(e[r]===t)return r;return-1}(e,t,n):jt(e,$t,n)}function It(e,t,n,r){for(var a=n-1,i=e.length;++a<i;)if(r(e[a],t))return a;return-1}function $t(e){return e!=e}function Bt(e,t){var n=null==e?0:e.length;return n?qt(e,t)/n:p}function Wt(e){return function(t){return null==t?a:t[e]}}function Vt(e){return function(t){return null==e?a:e[t]}}function Ht(e,t,n,r,a){return a(e,(function(e,a,i){n=r?(r=!1,e):t(n,e,a,i)})),n}function qt(e,t){for(var n,r=-1,i=e.length;++r<i;){var o=t(e[r]);o!==a&&(n=n===a?o:n+o)}return n}function Qt(e,t){for(var n=-1,r=Array(e);++n<e;)r[n]=t(n);return r}function Yt(e){return e?e.slice(0,pn(e)+1).replace(re,\"\"):e}function Gt(e){return function(t){return e(t)}}function Kt(e,t){return zt(t,(function(t){return e[t]}))}function Zt(e,t){return e.has(t)}function Xt(e,t){for(var n=-1,r=e.length;++n<r&&Ut(t,e[n],0)>-1;);return n}function Jt(e,t){for(var n=e.length;n--&&Ut(t,e[n],0)>-1;);return n}var en=Vt({À:\"A\",Á:\"A\",Â:\"A\",Ã:\"A\",Ä:\"A\",Å:\"A\",à:\"a\",á:\"a\",â:\"a\",ã:\"a\",ä:\"a\",å:\"a\",Ç:\"C\",ç:\"c\",Ð:\"D\",ð:\"d\",È:\"E\",É:\"E\",Ê:\"E\",Ë:\"E\",è:\"e\",é:\"e\",ê:\"e\",ë:\"e\",Ì:\"I\",Í:\"I\",Î:\"I\",Ï:\"I\",ì:\"i\",í:\"i\",î:\"i\",ï:\"i\",Ñ:\"N\",ñ:\"n\",Ò:\"O\",Ó:\"O\",Ô:\"O\",Õ:\"O\",Ö:\"O\",Ø:\"O\",ò:\"o\",ó:\"o\",ô:\"o\",õ:\"o\",ö:\"o\",ø:\"o\",Ù:\"U\",Ú:\"U\",Û:\"U\",Ü:\"U\",ù:\"u\",ú:\"u\",û:\"u\",ü:\"u\",Ý:\"Y\",ý:\"y\",ÿ:\"y\",Æ:\"Ae\",æ:\"ae\",Þ:\"Th\",þ:\"th\",ß:\"ss\",Ā:\"A\",Ă:\"A\",Ą:\"A\",ā:\"a\",ă:\"a\",ą:\"a\",Ć:\"C\",Ĉ:\"C\",Ċ:\"C\",Č:\"C\",ć:\"c\",ĉ:\"c\",ċ:\"c\",č:\"c\",Ď:\"D\",Đ:\"D\",ď:\"d\",đ:\"d\",Ē:\"E\",Ĕ:\"E\",Ė:\"E\",Ę:\"E\",Ě:\"E\",ē:\"e\",ĕ:\"e\",ė:\"e\",ę:\"e\",ě:\"e\",Ĝ:\"G\",Ğ:\"G\",Ġ:\"G\",Ģ:\"G\",ĝ:\"g\",ğ:\"g\",ġ:\"g\",ģ:\"g\",Ĥ:\"H\",Ħ:\"H\",ĥ:\"h\",ħ:\"h\",Ĩ:\"I\",Ī:\"I\",Ĭ:\"I\",Į:\"I\",İ:\"I\",ĩ:\"i\",ī:\"i\",ĭ:\"i\",į:\"i\",ı:\"i\",Ĵ:\"J\",ĵ:\"j\",Ķ:\"K\",ķ:\"k\",ĸ:\"k\",Ĺ:\"L\",Ļ:\"L\",Ľ:\"L\",Ŀ:\"L\",Ł:\"L\",ĺ:\"l\",ļ:\"l\",ľ:\"l\",ŀ:\"l\",ł:\"l\",Ń:\"N\",Ņ:\"N\",Ň:\"N\",Ŋ:\"N\",ń:\"n\",ņ:\"n\",ň:\"n\",ŋ:\"n\",Ō:\"O\",Ŏ:\"O\",Ő:\"O\",ō:\"o\",ŏ:\"o\",ő:\"o\",Ŕ:\"R\",Ŗ:\"R\",Ř:\"R\",ŕ:\"r\",ŗ:\"r\",ř:\"r\",Ś:\"S\",Ŝ:\"S\",Ş:\"S\",Š:\"S\",ś:\"s\",ŝ:\"s\",ş:\"s\",š:\"s\",Ţ:\"T\",Ť:\"T\",Ŧ:\"T\",ţ:\"t\",ť:\"t\",ŧ:\"t\",Ũ:\"U\",Ū:\"U\",Ŭ:\"U\",Ů:\"U\",Ű:\"U\",Ų:\"U\",ũ:\"u\",ū:\"u\",ŭ:\"u\",ů:\"u\",ű:\"u\",ų:\"u\",Ŵ:\"W\",ŵ:\"w\",Ŷ:\"Y\",ŷ:\"y\",Ÿ:\"Y\",Ź:\"Z\",Ż:\"Z\",Ž:\"Z\",ź:\"z\",ż:\"z\",ž:\"z\",Ĳ:\"IJ\",ĳ:\"ij\",Œ:\"Oe\",œ:\"oe\",ŉ:\"'n\",ſ:\"s\"}),tn=Vt({\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#39;\"});function nn(e){return\"\\\\\"+ot[e]}function rn(e){return et.test(e)}function an(e){var t=-1,n=Array(e.size);return e.forEach((function(e,r){n[++t]=[r,e]})),n}function on(e,t){return function(n){return e(t(n))}}function un(e,t){for(var n=-1,r=e.length,a=0,i=[];++n<r;){var o=e[n];o!==t&&o!==u||(e[n]=u,i[a++]=n)}return i}function ln(e){var t=-1,n=Array(e.size);return e.forEach((function(e){n[++t]=e})),n}function sn(e){var t=-1,n=Array(e.size);return e.forEach((function(e){n[++t]=[e,e]})),n}function cn(e){return rn(e)?function(e){for(var t=Xe.lastIndex=0;Xe.test(e);)++t;return t}(e):Dt(e)}function fn(e){return rn(e)?function(e){return e.match(Xe)||[]}(e):function(e){return e.split(\"\")}(e)}function pn(e){for(var t=e.length;t--&&ae.test(e.charAt(t)););return t}var dn=Vt({\"&amp;\":\"&\",\"&lt;\":\"<\",\"&gt;\":\">\",\"&quot;\":'\"',\"&#39;\":\"'\"}),hn=function e(t){var n,r=(t=null==t?ft:hn.defaults(ft.Object(),t,hn.pick(ft,nt))).Array,ae=t.Date,we=t.Error,xe=t.Function,ke=t.Math,Se=t.Object,Ee=t.RegExp,Ce=t.String,Te=t.TypeError,Me=r.prototype,Ne=xe.prototype,Pe=Se.prototype,ze=t[\"__core-js_shared__\"],Le=Ne.toString,Oe=Pe.hasOwnProperty,Ae=0,Fe=(n=/[^.]+$/.exec(ze&&ze.keys&&ze.keys.IE_PROTO||\"\"))?\"Symbol(src)_1.\"+n:\"\",De=Pe.toString,Re=Le.call(Se),je=ft._,Ue=Ee(\"^\"+Le.call(Oe).replace(te,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\"),Ie=ht?t.Buffer:a,$e=t.Symbol,Be=t.Uint8Array,We=Ie?Ie.allocUnsafe:a,Ve=on(Se.getPrototypeOf,Se),He=Se.create,qe=Pe.propertyIsEnumerable,Qe=Me.splice,Ye=$e?$e.isConcatSpreadable:a,Ge=$e?$e.iterator:a,Xe=$e?$e.toStringTag:a,et=function(){try{var e=li(Se,\"defineProperty\");return e({},\"\",{}),e}catch(e){}}(),ot=t.clearTimeout!==ft.clearTimeout&&t.clearTimeout,st=ae&&ae.now!==ft.Date.now&&ae.now,ct=t.setTimeout!==ft.setTimeout&&t.setTimeout,pt=ke.ceil,dt=ke.floor,vt=Se.getOwnPropertySymbols,gt=Ie?Ie.isBuffer:a,Dt=t.isFinite,Vt=Me.join,vn=on(Se.keys,Se),gn=ke.max,yn=ke.min,mn=ae.now,bn=t.parseInt,_n=ke.random,wn=Me.reverse,xn=li(t,\"DataView\"),kn=li(t,\"Map\"),Sn=li(t,\"Promise\"),En=li(t,\"Set\"),Cn=li(t,\"WeakMap\"),Tn=li(Se,\"create\"),Mn=Cn&&new Cn,Nn={},Pn=Di(xn),zn=Di(kn),Ln=Di(Sn),On=Di(En),An=Di(Cn),Fn=$e?$e.prototype:a,Dn=Fn?Fn.valueOf:a,Rn=Fn?Fn.toString:a;function jn(e){if(eu(e)&&!Wo(e)&&!(e instanceof Bn)){if(e instanceof $n)return e;if(Oe.call(e,\"__wrapped__\"))return Ri(e)}return new $n(e)}var Un=function(){function e(){}return function(t){if(!Jo(t))return{};if(He)return He(t);e.prototype=t;var n=new e;return e.prototype=a,n}}();function In(){}function $n(e,t){this.__wrapped__=e,this.__actions__=[],this.__chain__=!!t,this.__index__=0,this.__values__=a}function Bn(e){this.__wrapped__=e,this.__actions__=[],this.__dir__=1,this.__filtered__=!1,this.__iteratees__=[],this.__takeCount__=d,this.__views__=[]}function Wn(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}function Vn(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}function Hn(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}function qn(e){var t=-1,n=null==e?0:e.length;for(this.__data__=new Hn;++t<n;)this.add(e[t])}function Qn(e){var t=this.__data__=new Vn(e);this.size=t.size}function Yn(e,t){var n=Wo(e),r=!n&&Bo(e),a=!n&&!r&&Qo(e),i=!n&&!r&&!a&&lu(e),o=n||r||a||i,u=o?Qt(e.length,Ce):[],l=u.length;for(var s in e)!t&&!Oe.call(e,s)||o&&(\"length\"==s||a&&(\"offset\"==s||\"parent\"==s)||i&&(\"buffer\"==s||\"byteLength\"==s||\"byteOffset\"==s)||vi(s,l))||u.push(s);return u}function Gn(e){var t=e.length;return t?e[Hr(0,t-1)]:a}function Kn(e,t){return zi(Ca(e),ir(t,0,e.length))}function Zn(e){return zi(Ca(e))}function Xn(e,t,n){(n!==a&&!Uo(e[t],n)||n===a&&!(t in e))&&rr(e,t,n)}function Jn(e,t,n){var r=e[t];Oe.call(e,t)&&Uo(r,n)&&(n!==a||t in e)||rr(e,t,n)}function er(e,t){for(var n=e.length;n--;)if(Uo(e[n][0],t))return n;return-1}function tr(e,t,n,r){return cr(e,(function(e,a,i){t(r,e,n(e),i)})),r}function nr(e,t){return e&&Ta(t,Pu(t),e)}function rr(e,t,n){\"__proto__\"==t&&et?et(e,t,{configurable:!0,enumerable:!0,value:n,writable:!0}):e[t]=n}function ar(e,t){for(var n=-1,i=t.length,o=r(i),u=null==e;++n<i;)o[n]=u?a:Eu(e,t[n]);return o}function ir(e,t,n){return e==e&&(n!==a&&(e=e<=n?e:n),t!==a&&(e=e>=t?e:t)),e}function or(e,t,n,r,i,o){var u,l=1&t,s=2&t,c=4&t;if(n&&(u=i?n(e,r,i,o):n(e)),u!==a)return u;if(!Jo(e))return e;var f=Wo(e);if(f){if(u=function(e){var t=e.length,n=new e.constructor(t);return t&&\"string\"==typeof e[0]&&Oe.call(e,\"index\")&&(n.index=e.index,n.input=e.input),n}(e),!l)return Ca(e,u)}else{var p=fi(e),d=p==_||p==w;if(Qo(e))return _a(e,l);if(p==S||p==v||d&&!i){if(u=s||d?{}:di(e),!l)return s?function(e,t){return Ta(e,ci(e),t)}(e,function(e,t){return e&&Ta(t,zu(t),e)}(u,e)):function(e,t){return Ta(e,si(e),t)}(e,nr(u,e))}else{if(!it[p])return i?e:{};u=function(e,t,n){var r,a=e.constructor;switch(t){case z:return wa(e);case y:case m:return new a(+e);case L:return function(e,t){var n=t?wa(e.buffer):e.buffer;return new e.constructor(n,e.byteOffset,e.byteLength)}(e,n);case O:case A:case F:case D:case R:case j:case U:case I:case $:return xa(e,n);case x:return new a;case k:case M:return new a(e);case C:return function(e){var t=new e.constructor(e.source,pe.exec(e));return t.lastIndex=e.lastIndex,t}(e);case T:return new a;case N:return r=e,Dn?Se(Dn.call(r)):{}}}(e,p,l)}}o||(o=new Qn);var h=o.get(e);if(h)return h;o.set(e,u),iu(e)?e.forEach((function(r){u.add(or(r,t,n,r,e,o))})):tu(e)&&e.forEach((function(r,a){u.set(a,or(r,t,n,a,e,o))}));var g=f?a:(c?s?ti:ei:s?zu:Pu)(e);return Et(g||e,(function(r,a){g&&(r=e[a=r]),Jn(u,a,or(r,t,n,a,e,o))})),u}function ur(e,t,n){var r=n.length;if(null==e)return!r;for(e=Se(e);r--;){var i=n[r],o=t[i],u=e[i];if(u===a&&!(i in e)||!o(u))return!1}return!0}function lr(e,t,n){if(\"function\"!=typeof e)throw new Te(i);return Ti((function(){e.apply(a,n)}),t)}function sr(e,t,n,r){var a=-1,i=Nt,o=!0,u=e.length,l=[],s=t.length;if(!u)return l;n&&(t=zt(t,Gt(n))),r?(i=Pt,o=!1):t.length>=200&&(i=Zt,o=!1,t=new qn(t));e:for(;++a<u;){var c=e[a],f=null==n?c:n(c);if(c=r||0!==c?c:0,o&&f==f){for(var p=s;p--;)if(t[p]===f)continue e;l.push(c)}else i(t,f,r)||l.push(c)}return l}jn.templateSettings={escape:G,evaluate:K,interpolate:Z,variable:\"\",imports:{_:jn}},jn.prototype=In.prototype,jn.prototype.constructor=jn,$n.prototype=Un(In.prototype),$n.prototype.constructor=$n,Bn.prototype=Un(In.prototype),Bn.prototype.constructor=Bn,Wn.prototype.clear=function(){this.__data__=Tn?Tn(null):{},this.size=0},Wn.prototype.delete=function(e){var t=this.has(e)&&delete this.__data__[e];return this.size-=t?1:0,t},Wn.prototype.get=function(e){var t=this.__data__;if(Tn){var n=t[e];return n===o?a:n}return Oe.call(t,e)?t[e]:a},Wn.prototype.has=function(e){var t=this.__data__;return Tn?t[e]!==a:Oe.call(t,e)},Wn.prototype.set=function(e,t){var n=this.__data__;return this.size+=this.has(e)?0:1,n[e]=Tn&&t===a?o:t,this},Vn.prototype.clear=function(){this.__data__=[],this.size=0},Vn.prototype.delete=function(e){var t=this.__data__,n=er(t,e);return!(n<0||(n==t.length-1?t.pop():Qe.call(t,n,1),--this.size,0))},Vn.prototype.get=function(e){var t=this.__data__,n=er(t,e);return n<0?a:t[n][1]},Vn.prototype.has=function(e){return er(this.__data__,e)>-1},Vn.prototype.set=function(e,t){var n=this.__data__,r=er(n,e);return r<0?(++this.size,n.push([e,t])):n[r][1]=t,this},Hn.prototype.clear=function(){this.size=0,this.__data__={hash:new Wn,map:new(kn||Vn),string:new Wn}},Hn.prototype.delete=function(e){var t=oi(this,e).delete(e);return this.size-=t?1:0,t},Hn.prototype.get=function(e){return oi(this,e).get(e)},Hn.prototype.has=function(e){return oi(this,e).has(e)},Hn.prototype.set=function(e,t){var n=oi(this,e),r=n.size;return n.set(e,t),this.size+=n.size==r?0:1,this},qn.prototype.add=qn.prototype.push=function(e){return this.__data__.set(e,o),this},qn.prototype.has=function(e){return this.__data__.has(e)},Qn.prototype.clear=function(){this.__data__=new Vn,this.size=0},Qn.prototype.delete=function(e){var t=this.__data__,n=t.delete(e);return this.size=t.size,n},Qn.prototype.get=function(e){return this.__data__.get(e)},Qn.prototype.has=function(e){return this.__data__.has(e)},Qn.prototype.set=function(e,t){var n=this.__data__;if(n instanceof Vn){var r=n.__data__;if(!kn||r.length<199)return r.push([e,t]),this.size=++n.size,this;n=this.__data__=new Hn(r)}return n.set(e,t),this.size=n.size,this};var cr=Pa(mr),fr=Pa(br,!0);function pr(e,t){var n=!0;return cr(e,(function(e,r,a){return n=!!t(e,r,a)})),n}function dr(e,t,n){for(var r=-1,i=e.length;++r<i;){var o=e[r],u=t(o);if(null!=u&&(l===a?u==u&&!uu(u):n(u,l)))var l=u,s=o}return s}function hr(e,t){var n=[];return cr(e,(function(e,r,a){t(e,r,a)&&n.push(e)})),n}function vr(e,t,n,r,a){var i=-1,o=e.length;for(n||(n=hi),a||(a=[]);++i<o;){var u=e[i];t>0&&n(u)?t>1?vr(u,t-1,n,r,a):Lt(a,u):r||(a[a.length]=u)}return a}var gr=za(),yr=za(!0);function mr(e,t){return e&&gr(e,t,Pu)}function br(e,t){return e&&yr(e,t,Pu)}function _r(e,t){return Mt(t,(function(t){return Ko(e[t])}))}function wr(e,t){for(var n=0,r=(t=ga(t,e)).length;null!=e&&n<r;)e=e[Fi(t[n++])];return n&&n==r?e:a}function xr(e,t,n){var r=t(e);return Wo(e)?r:Lt(r,n(e))}function kr(e){return null==e?e===a?\"[object Undefined]\":\"[object Null]\":Xe&&Xe in Se(e)?function(e){var t=Oe.call(e,Xe),n=e[Xe];try{e[Xe]=a;var r=!0}catch(e){}var i=De.call(e);return r&&(t?e[Xe]=n:delete e[Xe]),i}(e):function(e){return De.call(e)}(e)}function Sr(e,t){return e>t}function Er(e,t){return null!=e&&Oe.call(e,t)}function Cr(e,t){return null!=e&&t in Se(e)}function Tr(e,t,n){for(var i=n?Pt:Nt,o=e[0].length,u=e.length,l=u,s=r(u),c=1/0,f=[];l--;){var p=e[l];l&&t&&(p=zt(p,Gt(t))),c=yn(p.length,c),s[l]=!n&&(t||o>=120&&p.length>=120)?new qn(l&&p):a}p=e[0];var d=-1,h=s[0];e:for(;++d<o&&f.length<c;){var v=p[d],g=t?t(v):v;if(v=n||0!==v?v:0,!(h?Zt(h,g):i(f,g,n))){for(l=u;--l;){var y=s[l];if(!(y?Zt(y,g):i(e[l],g,n)))continue e}h&&h.push(g),f.push(v)}}return f}function Mr(e,t,n){var r=null==(e=Si(e,t=ga(t,e)))?e:e[Fi(Yi(t))];return null==r?a:kt(r,e,n)}function Nr(e){return eu(e)&&kr(e)==v}function Pr(e,t,n,r,i){return e===t||(null==e||null==t||!eu(e)&&!eu(t)?e!=e&&t!=t:function(e,t,n,r,i,o){var u=Wo(e),l=Wo(t),s=u?g:fi(e),c=l?g:fi(t),f=(s=s==v?S:s)==S,p=(c=c==v?S:c)==S,d=s==c;if(d&&Qo(e)){if(!Qo(t))return!1;u=!0,f=!1}if(d&&!f)return o||(o=new Qn),u||lu(e)?Xa(e,t,n,r,i,o):function(e,t,n,r,a,i,o){switch(n){case L:if(e.byteLength!=t.byteLength||e.byteOffset!=t.byteOffset)return!1;e=e.buffer,t=t.buffer;case z:return!(e.byteLength!=t.byteLength||!i(new Be(e),new Be(t)));case y:case m:case k:return Uo(+e,+t);case b:return e.name==t.name&&e.message==t.message;case C:case M:return e==t+\"\";case x:var u=an;case T:var l=1&r;if(u||(u=ln),e.size!=t.size&&!l)return!1;var s=o.get(e);if(s)return s==t;r|=2,o.set(e,t);var c=Xa(u(e),u(t),r,a,i,o);return o.delete(e),c;case N:if(Dn)return Dn.call(e)==Dn.call(t)}return!1}(e,t,s,n,r,i,o);if(!(1&n)){var h=f&&Oe.call(e,\"__wrapped__\"),_=p&&Oe.call(t,\"__wrapped__\");if(h||_){var w=h?e.value():e,E=_?t.value():t;return o||(o=new Qn),i(w,E,n,r,o)}}return!!d&&(o||(o=new Qn),function(e,t,n,r,i,o){var u=1&n,l=ei(e),s=l.length;if(s!=ei(t).length&&!u)return!1;for(var c=s;c--;){var f=l[c];if(!(u?f in t:Oe.call(t,f)))return!1}var p=o.get(e),d=o.get(t);if(p&&d)return p==t&&d==e;var h=!0;o.set(e,t),o.set(t,e);for(var v=u;++c<s;){var g=e[f=l[c]],y=t[f];if(r)var m=u?r(y,g,f,t,e,o):r(g,y,f,e,t,o);if(!(m===a?g===y||i(g,y,n,r,o):m)){h=!1;break}v||(v=\"constructor\"==f)}if(h&&!v){var b=e.constructor,_=t.constructor;b==_||!(\"constructor\"in e)||!(\"constructor\"in t)||\"function\"==typeof b&&b instanceof b&&\"function\"==typeof _&&_ instanceof _||(h=!1)}return o.delete(e),o.delete(t),h}(e,t,n,r,i,o))}(e,t,n,r,Pr,i))}function zr(e,t,n,r){var i=n.length,o=i,u=!r;if(null==e)return!o;for(e=Se(e);i--;){var l=n[i];if(u&&l[2]?l[1]!==e[l[0]]:!(l[0]in e))return!1}for(;++i<o;){var s=(l=n[i])[0],c=e[s],f=l[1];if(u&&l[2]){if(c===a&&!(s in e))return!1}else{var p=new Qn;if(r)var d=r(c,f,s,e,t,p);if(!(d===a?Pr(f,c,3,r,p):d))return!1}}return!0}function Lr(e){return!(!Jo(e)||(t=e,Fe&&Fe in t))&&(Ko(e)?Ue:ve).test(Di(e));var t}function Or(e){return\"function\"==typeof e?e:null==e?nl:\"object\"==typeof e?Wo(e)?jr(e[0],e[1]):Rr(e):fl(e)}function Ar(e){if(!_i(e))return vn(e);var t=[];for(var n in Se(e))Oe.call(e,n)&&\"constructor\"!=n&&t.push(n);return t}function Fr(e,t){return e<t}function Dr(e,t){var n=-1,a=Ho(e)?r(e.length):[];return cr(e,(function(e,r,i){a[++n]=t(e,r,i)})),a}function Rr(e){var t=ui(e);return 1==t.length&&t[0][2]?xi(t[0][0],t[0][1]):function(n){return n===e||zr(n,e,t)}}function jr(e,t){return yi(e)&&wi(t)?xi(Fi(e),t):function(n){var r=Eu(n,e);return r===a&&r===t?Cu(n,e):Pr(t,r,3)}}function Ur(e,t,n,r,i){e!==t&&gr(t,(function(o,u){if(i||(i=new Qn),Jo(o))!function(e,t,n,r,i,o,u){var l=Ei(e,n),s=Ei(t,n),c=u.get(s);if(c)Xn(e,n,c);else{var f=o?o(l,s,n+\"\",e,t,u):a,p=f===a;if(p){var d=Wo(s),h=!d&&Qo(s),v=!d&&!h&&lu(s);f=s,d||h||v?Wo(l)?f=l:qo(l)?f=Ca(l):h?(p=!1,f=_a(s,!0)):v?(p=!1,f=xa(s,!0)):f=[]:ru(s)||Bo(s)?(f=l,Bo(l)?f=gu(l):Jo(l)&&!Ko(l)||(f=di(s))):p=!1}p&&(u.set(s,f),i(f,s,r,o,u),u.delete(s)),Xn(e,n,f)}}(e,t,u,n,Ur,r,i);else{var l=r?r(Ei(e,u),o,u+\"\",e,t,i):a;l===a&&(l=o),Xn(e,u,l)}}),zu)}function Ir(e,t){var n=e.length;if(n)return vi(t+=t<0?n:0,n)?e[t]:a}function $r(e,t,n){t=t.length?zt(t,(function(e){return Wo(e)?function(t){return wr(t,1===e.length?e[0]:e)}:e})):[nl];var r=-1;t=zt(t,Gt(ii()));var a=Dr(e,(function(e,n,a){var i=zt(t,(function(t){return t(e)}));return{criteria:i,index:++r,value:e}}));return function(e,t){var r=e.length;for(e.sort((function(e,t){return function(e,t,n){for(var r=-1,a=e.criteria,i=t.criteria,o=a.length,u=n.length;++r<o;){var l=ka(a[r],i[r]);if(l)return r>=u?l:l*(\"desc\"==n[r]?-1:1)}return e.index-t.index}(e,t,n)}));r--;)e[r]=e[r].value;return e}(a)}function Br(e,t,n){for(var r=-1,a=t.length,i={};++r<a;){var o=t[r],u=wr(e,o);n(u,o)&&Kr(i,ga(o,e),u)}return i}function Wr(e,t,n,r){var a=r?It:Ut,i=-1,o=t.length,u=e;for(e===t&&(t=Ca(t)),n&&(u=zt(e,Gt(n)));++i<o;)for(var l=0,s=t[i],c=n?n(s):s;(l=a(u,c,l,r))>-1;)u!==e&&Qe.call(u,l,1),Qe.call(e,l,1);return e}function Vr(e,t){for(var n=e?t.length:0,r=n-1;n--;){var a=t[n];if(n==r||a!==i){var i=a;vi(a)?Qe.call(e,a,1):la(e,a)}}return e}function Hr(e,t){return e+dt(_n()*(t-e+1))}function qr(e,t){var n=\"\";if(!e||t<1||t>f)return n;do{t%2&&(n+=e),(t=dt(t/2))&&(e+=e)}while(t);return n}function Qr(e,t){return Mi(ki(e,t,nl),e+\"\")}function Yr(e){return Gn(Uu(e))}function Gr(e,t){var n=Uu(e);return zi(n,ir(t,0,n.length))}function Kr(e,t,n,r){if(!Jo(e))return e;for(var i=-1,o=(t=ga(t,e)).length,u=o-1,l=e;null!=l&&++i<o;){var s=Fi(t[i]),c=n;if(\"__proto__\"===s||\"constructor\"===s||\"prototype\"===s)return e;if(i!=u){var f=l[s];(c=r?r(f,s,l):a)===a&&(c=Jo(f)?f:vi(t[i+1])?[]:{})}Jn(l,s,c),l=l[s]}return e}var Zr=Mn?function(e,t){return Mn.set(e,t),e}:nl,Xr=et?function(e,t){return et(e,\"toString\",{configurable:!0,enumerable:!1,value:Ju(t),writable:!0})}:nl;function Jr(e){return zi(Uu(e))}function ea(e,t,n){var a=-1,i=e.length;t<0&&(t=-t>i?0:i+t),(n=n>i?i:n)<0&&(n+=i),i=t>n?0:n-t>>>0,t>>>=0;for(var o=r(i);++a<i;)o[a]=e[a+t];return o}function ta(e,t){var n;return cr(e,(function(e,r,a){return!(n=t(e,r,a))})),!!n}function na(e,t,n){var r=0,a=null==e?r:e.length;if(\"number\"==typeof t&&t==t&&a<=2147483647){for(;r<a;){var i=r+a>>>1,o=e[i];null!==o&&!uu(o)&&(n?o<=t:o<t)?r=i+1:a=i}return a}return ra(e,t,nl,n)}function ra(e,t,n,r){var i=0,o=null==e?0:e.length;if(0===o)return 0;for(var u=(t=n(t))!=t,l=null===t,s=uu(t),c=t===a;i<o;){var f=dt((i+o)/2),p=n(e[f]),d=p!==a,h=null===p,v=p==p,g=uu(p);if(u)var y=r||v;else y=c?v&&(r||d):l?v&&d&&(r||!h):s?v&&d&&!h&&(r||!g):!h&&!g&&(r?p<=t:p<t);y?i=f+1:o=f}return yn(o,4294967294)}function aa(e,t){for(var n=-1,r=e.length,a=0,i=[];++n<r;){var o=e[n],u=t?t(o):o;if(!n||!Uo(u,l)){var l=u;i[a++]=0===o?0:o}}return i}function ia(e){return\"number\"==typeof e?e:uu(e)?p:+e}function oa(e){if(\"string\"==typeof e)return e;if(Wo(e))return zt(e,oa)+\"\";if(uu(e))return Rn?Rn.call(e):\"\";var t=e+\"\";return\"0\"==t&&1/e==-1/0?\"-0\":t}function ua(e,t,n){var r=-1,a=Nt,i=e.length,o=!0,u=[],l=u;if(n)o=!1,a=Pt;else if(i>=200){var s=t?null:qa(e);if(s)return ln(s);o=!1,a=Zt,l=new qn}else l=t?[]:u;e:for(;++r<i;){var c=e[r],f=t?t(c):c;if(c=n||0!==c?c:0,o&&f==f){for(var p=l.length;p--;)if(l[p]===f)continue e;t&&l.push(f),u.push(c)}else a(l,f,n)||(l!==u&&l.push(f),u.push(c))}return u}function la(e,t){return null==(e=Si(e,t=ga(t,e)))||delete e[Fi(Yi(t))]}function sa(e,t,n,r){return Kr(e,t,n(wr(e,t)),r)}function ca(e,t,n,r){for(var a=e.length,i=r?a:-1;(r?i--:++i<a)&&t(e[i],i,e););return n?ea(e,r?0:i,r?i+1:a):ea(e,r?i+1:0,r?a:i)}function fa(e,t){var n=e;return n instanceof Bn&&(n=n.value()),Ot(t,(function(e,t){return t.func.apply(t.thisArg,Lt([e],t.args))}),n)}function pa(e,t,n){var a=e.length;if(a<2)return a?ua(e[0]):[];for(var i=-1,o=r(a);++i<a;)for(var u=e[i],l=-1;++l<a;)l!=i&&(o[i]=sr(o[i]||u,e[l],t,n));return ua(vr(o,1),t,n)}function da(e,t,n){for(var r=-1,i=e.length,o=t.length,u={};++r<i;){var l=r<o?t[r]:a;n(u,e[r],l)}return u}function ha(e){return qo(e)?e:[]}function va(e){return\"function\"==typeof e?e:nl}function ga(e,t){return Wo(e)?e:yi(e,t)?[e]:Ai(yu(e))}var ya=Qr;function ma(e,t,n){var r=e.length;return n=n===a?r:n,!t&&n>=r?e:ea(e,t,n)}var ba=ot||function(e){return ft.clearTimeout(e)};function _a(e,t){if(t)return e.slice();var n=e.length,r=We?We(n):new e.constructor(n);return e.copy(r),r}function wa(e){var t=new e.constructor(e.byteLength);return new Be(t).set(new Be(e)),t}function xa(e,t){var n=t?wa(e.buffer):e.buffer;return new e.constructor(n,e.byteOffset,e.length)}function ka(e,t){if(e!==t){var n=e!==a,r=null===e,i=e==e,o=uu(e),u=t!==a,l=null===t,s=t==t,c=uu(t);if(!l&&!c&&!o&&e>t||o&&u&&s&&!l&&!c||r&&u&&s||!n&&s||!i)return 1;if(!r&&!o&&!c&&e<t||c&&n&&i&&!r&&!o||l&&n&&i||!u&&i||!s)return-1}return 0}function Sa(e,t,n,a){for(var i=-1,o=e.length,u=n.length,l=-1,s=t.length,c=gn(o-u,0),f=r(s+c),p=!a;++l<s;)f[l]=t[l];for(;++i<u;)(p||i<o)&&(f[n[i]]=e[i]);for(;c--;)f[l++]=e[i++];return f}function Ea(e,t,n,a){for(var i=-1,o=e.length,u=-1,l=n.length,s=-1,c=t.length,f=gn(o-l,0),p=r(f+c),d=!a;++i<f;)p[i]=e[i];for(var h=i;++s<c;)p[h+s]=t[s];for(;++u<l;)(d||i<o)&&(p[h+n[u]]=e[i++]);return p}function Ca(e,t){var n=-1,a=e.length;for(t||(t=r(a));++n<a;)t[n]=e[n];return t}function Ta(e,t,n,r){var i=!n;n||(n={});for(var o=-1,u=t.length;++o<u;){var l=t[o],s=r?r(n[l],e[l],l,n,e):a;s===a&&(s=e[l]),i?rr(n,l,s):Jn(n,l,s)}return n}function Ma(e,t){return function(n,r){var a=Wo(n)?St:tr,i=t?t():{};return a(n,e,ii(r,2),i)}}function Na(e){return Qr((function(t,n){var r=-1,i=n.length,o=i>1?n[i-1]:a,u=i>2?n[2]:a;for(o=e.length>3&&\"function\"==typeof o?(i--,o):a,u&&gi(n[0],n[1],u)&&(o=i<3?a:o,i=1),t=Se(t);++r<i;){var l=n[r];l&&e(t,l,r,o)}return t}))}function Pa(e,t){return function(n,r){if(null==n)return n;if(!Ho(n))return e(n,r);for(var a=n.length,i=t?a:-1,o=Se(n);(t?i--:++i<a)&&!1!==r(o[i],i,o););return n}}function za(e){return function(t,n,r){for(var a=-1,i=Se(t),o=r(t),u=o.length;u--;){var l=o[e?u:++a];if(!1===n(i[l],l,i))break}return t}}function La(e){return function(t){var n=rn(t=yu(t))?fn(t):a,r=n?n[0]:t.charAt(0),i=n?ma(n,1).join(\"\"):t.slice(1);return r[e]()+i}}function Oa(e){return function(t){return Ot(Ku(Bu(t).replace(Ke,\"\")),e,\"\")}}function Aa(e){return function(){var t=arguments;switch(t.length){case 0:return new e;case 1:return new e(t[0]);case 2:return new e(t[0],t[1]);case 3:return new e(t[0],t[1],t[2]);case 4:return new e(t[0],t[1],t[2],t[3]);case 5:return new e(t[0],t[1],t[2],t[3],t[4]);case 6:return new e(t[0],t[1],t[2],t[3],t[4],t[5]);case 7:return new e(t[0],t[1],t[2],t[3],t[4],t[5],t[6])}var n=Un(e.prototype),r=e.apply(n,t);return Jo(r)?r:n}}function Fa(e){return function(t,n,r){var i=Se(t);if(!Ho(t)){var o=ii(n,3);t=Pu(t),n=function(e){return o(i[e],e,i)}}var u=e(t,n,r);return u>-1?i[o?t[u]:u]:a}}function Da(e){return Ja((function(t){var n=t.length,r=n,o=$n.prototype.thru;for(e&&t.reverse();r--;){var u=t[r];if(\"function\"!=typeof u)throw new Te(i);if(o&&!l&&\"wrapper\"==ri(u))var l=new $n([],!0)}for(r=l?r:n;++r<n;){var s=ri(u=t[r]),c=\"wrapper\"==s?ni(u):a;l=c&&mi(c[0])&&424==c[1]&&!c[4].length&&1==c[9]?l[ri(c[0])].apply(l,c[3]):1==u.length&&mi(u)?l[s]():l.thru(u)}return function(){var e=arguments,r=e[0];if(l&&1==e.length&&Wo(r))return l.plant(r).value();for(var a=0,i=n?t[a].apply(this,e):r;++a<n;)i=t[a].call(this,i);return i}}))}function Ra(e,t,n,i,o,u,l,c,f,p){var d=t&s,h=1&t,v=2&t,g=24&t,y=512&t,m=v?a:Aa(e);return function s(){for(var b=arguments.length,_=r(b),w=b;w--;)_[w]=arguments[w];if(g)var x=ai(s),k=function(e,t){for(var n=e.length,r=0;n--;)e[n]===t&&++r;return r}(_,x);if(i&&(_=Sa(_,i,o,g)),u&&(_=Ea(_,u,l,g)),b-=k,g&&b<p){var S=un(_,x);return Va(e,t,Ra,s.placeholder,n,_,S,c,f,p-b)}var E=h?n:this,C=v?E[e]:e;return b=_.length,c?_=function(e,t){for(var n=e.length,r=yn(t.length,n),i=Ca(e);r--;){var o=t[r];e[r]=vi(o,n)?i[o]:a}return e}(_,c):y&&b>1&&_.reverse(),d&&f<b&&(_.length=f),this&&this!==ft&&this instanceof s&&(C=m||Aa(C)),C.apply(E,_)}}function ja(e,t){return function(n,r){return function(e,t,n,r){return mr(e,(function(e,a,i){t(r,n(e),a,i)})),r}(n,e,t(r),{})}}function Ua(e,t){return function(n,r){var i;if(n===a&&r===a)return t;if(n!==a&&(i=n),r!==a){if(i===a)return r;\"string\"==typeof n||\"string\"==typeof r?(n=oa(n),r=oa(r)):(n=ia(n),r=ia(r)),i=e(n,r)}return i}}function Ia(e){return Ja((function(t){return t=zt(t,Gt(ii())),Qr((function(n){var r=this;return e(t,(function(e){return kt(e,r,n)}))}))}))}function $a(e,t){var n=(t=t===a?\" \":oa(t)).length;if(n<2)return n?qr(t,e):t;var r=qr(t,pt(e/cn(t)));return rn(t)?ma(fn(r),0,e).join(\"\"):r.slice(0,e)}function Ba(e){return function(t,n,i){return i&&\"number\"!=typeof i&&gi(t,n,i)&&(n=i=a),t=pu(t),n===a?(n=t,t=0):n=pu(n),function(e,t,n,a){for(var i=-1,o=gn(pt((t-e)/(n||1)),0),u=r(o);o--;)u[a?o:++i]=e,e+=n;return u}(t,n,i=i===a?t<n?1:-1:pu(i),e)}}function Wa(e){return function(t,n){return\"string\"==typeof t&&\"string\"==typeof n||(t=vu(t),n=vu(n)),e(t,n)}}function Va(e,t,n,r,i,o,u,s,c,f){var p=8&t;t|=p?l:64,4&(t&=~(p?64:l))||(t&=-4);var d=[e,t,i,p?o:a,p?u:a,p?a:o,p?a:u,s,c,f],h=n.apply(a,d);return mi(e)&&Ci(h,d),h.placeholder=r,Ni(h,e,t)}function Ha(e){var t=ke[e];return function(e,n){if(e=vu(e),(n=null==n?0:yn(du(n),292))&&Dt(e)){var r=(yu(e)+\"e\").split(\"e\");return+((r=(yu(t(r[0]+\"e\"+(+r[1]+n)))+\"e\").split(\"e\"))[0]+\"e\"+(+r[1]-n))}return t(e)}}var qa=En&&1/ln(new En([,-0]))[1]==c?function(e){return new En(e)}:ul;function Qa(e){return function(t){var n=fi(t);return n==x?an(t):n==T?sn(t):function(e,t){return zt(t,(function(t){return[t,e[t]]}))}(t,e(t))}}function Ya(e,t,n,o,c,f,p,d){var h=2&t;if(!h&&\"function\"!=typeof e)throw new Te(i);var v=o?o.length:0;if(v||(t&=-97,o=c=a),p=p===a?p:gn(du(p),0),d=d===a?d:du(d),v-=c?c.length:0,64&t){var g=o,y=c;o=c=a}var m=h?a:ni(e),b=[e,t,n,o,c,g,y,f,p,d];if(m&&function(e,t){var n=e[1],r=t[1],a=n|r,i=a<131,o=r==s&&8==n||r==s&&256==n&&e[7].length<=t[8]||384==r&&t[7].length<=t[8]&&8==n;if(!i&&!o)return e;1&r&&(e[2]=t[2],a|=1&n?0:4);var l=t[3];if(l){var c=e[3];e[3]=c?Sa(c,l,t[4]):l,e[4]=c?un(e[3],u):t[4]}(l=t[5])&&(c=e[5],e[5]=c?Ea(c,l,t[6]):l,e[6]=c?un(e[5],u):t[6]),(l=t[7])&&(e[7]=l),r&s&&(e[8]=null==e[8]?t[8]:yn(e[8],t[8])),null==e[9]&&(e[9]=t[9]),e[0]=t[0],e[1]=a}(b,m),e=b[0],t=b[1],n=b[2],o=b[3],c=b[4],!(d=b[9]=b[9]===a?h?0:e.length:gn(b[9]-v,0))&&24&t&&(t&=-25),t&&1!=t)_=8==t||16==t?function(e,t,n){var i=Aa(e);return function o(){for(var u=arguments.length,l=r(u),s=u,c=ai(o);s--;)l[s]=arguments[s];var f=u<3&&l[0]!==c&&l[u-1]!==c?[]:un(l,c);return(u-=f.length)<n?Va(e,t,Ra,o.placeholder,a,l,f,a,a,n-u):kt(this&&this!==ft&&this instanceof o?i:e,this,l)}}(e,t,d):t!=l&&33!=t||c.length?Ra.apply(a,b):function(e,t,n,a){var i=1&t,o=Aa(e);return function t(){for(var u=-1,l=arguments.length,s=-1,c=a.length,f=r(c+l),p=this&&this!==ft&&this instanceof t?o:e;++s<c;)f[s]=a[s];for(;l--;)f[s++]=arguments[++u];return kt(p,i?n:this,f)}}(e,t,n,o);else var _=function(e,t,n){var r=1&t,a=Aa(e);return function t(){return(this&&this!==ft&&this instanceof t?a:e).apply(r?n:this,arguments)}}(e,t,n);return Ni((m?Zr:Ci)(_,b),e,t)}function Ga(e,t,n,r){return e===a||Uo(e,Pe[n])&&!Oe.call(r,n)?t:e}function Ka(e,t,n,r,i,o){return Jo(e)&&Jo(t)&&(o.set(t,e),Ur(e,t,a,Ka,o),o.delete(t)),e}function Za(e){return ru(e)?a:e}function Xa(e,t,n,r,i,o){var u=1&n,l=e.length,s=t.length;if(l!=s&&!(u&&s>l))return!1;var c=o.get(e),f=o.get(t);if(c&&f)return c==t&&f==e;var p=-1,d=!0,h=2&n?new qn:a;for(o.set(e,t),o.set(t,e);++p<l;){var v=e[p],g=t[p];if(r)var y=u?r(g,v,p,t,e,o):r(v,g,p,e,t,o);if(y!==a){if(y)continue;d=!1;break}if(h){if(!Ft(t,(function(e,t){if(!Zt(h,t)&&(v===e||i(v,e,n,r,o)))return h.push(t)}))){d=!1;break}}else if(v!==g&&!i(v,g,n,r,o)){d=!1;break}}return o.delete(e),o.delete(t),d}function Ja(e){return Mi(ki(e,a,Wi),e+\"\")}function ei(e){return xr(e,Pu,si)}function ti(e){return xr(e,zu,ci)}var ni=Mn?function(e){return Mn.get(e)}:ul;function ri(e){for(var t=e.name+\"\",n=Nn[t],r=Oe.call(Nn,t)?n.length:0;r--;){var a=n[r],i=a.func;if(null==i||i==e)return a.name}return t}function ai(e){return(Oe.call(jn,\"placeholder\")?jn:e).placeholder}function ii(){var e=jn.iteratee||rl;return e=e===rl?Or:e,arguments.length?e(arguments[0],arguments[1]):e}function oi(e,t){var n,r,a=e.__data__;return(\"string\"==(r=typeof(n=t))||\"number\"==r||\"symbol\"==r||\"boolean\"==r?\"__proto__\"!==n:null===n)?a[\"string\"==typeof t?\"string\":\"hash\"]:a.map}function ui(e){for(var t=Pu(e),n=t.length;n--;){var r=t[n],a=e[r];t[n]=[r,a,wi(a)]}return t}function li(e,t){var n=function(e,t){return null==e?a:e[t]}(e,t);return Lr(n)?n:a}var si=vt?function(e){return null==e?[]:(e=Se(e),Mt(vt(e),(function(t){return qe.call(e,t)})))}:hl,ci=vt?function(e){for(var t=[];e;)Lt(t,si(e)),e=Ve(e);return t}:hl,fi=kr;function pi(e,t,n){for(var r=-1,a=(t=ga(t,e)).length,i=!1;++r<a;){var o=Fi(t[r]);if(!(i=null!=e&&n(e,o)))break;e=e[o]}return i||++r!=a?i:!!(a=null==e?0:e.length)&&Xo(a)&&vi(o,a)&&(Wo(e)||Bo(e))}function di(e){return\"function\"!=typeof e.constructor||_i(e)?{}:Un(Ve(e))}function hi(e){return Wo(e)||Bo(e)||!!(Ye&&e&&e[Ye])}function vi(e,t){var n=typeof e;return!!(t=null==t?f:t)&&(\"number\"==n||\"symbol\"!=n&&ye.test(e))&&e>-1&&e%1==0&&e<t}function gi(e,t,n){if(!Jo(n))return!1;var r=typeof t;return!!(\"number\"==r?Ho(n)&&vi(t,n.length):\"string\"==r&&t in n)&&Uo(n[t],e)}function yi(e,t){if(Wo(e))return!1;var n=typeof e;return!(\"number\"!=n&&\"symbol\"!=n&&\"boolean\"!=n&&null!=e&&!uu(e))||J.test(e)||!X.test(e)||null!=t&&e in Se(t)}function mi(e){var t=ri(e),n=jn[t];if(\"function\"!=typeof n||!(t in Bn.prototype))return!1;if(e===n)return!0;var r=ni(n);return!!r&&e===r[0]}(xn&&fi(new xn(new ArrayBuffer(1)))!=L||kn&&fi(new kn)!=x||Sn&&fi(Sn.resolve())!=E||En&&fi(new En)!=T||Cn&&fi(new Cn)!=P)&&(fi=function(e){var t=kr(e),n=t==S?e.constructor:a,r=n?Di(n):\"\";if(r)switch(r){case Pn:return L;case zn:return x;case Ln:return E;case On:return T;case An:return P}return t});var bi=ze?Ko:vl;function _i(e){var t=e&&e.constructor;return e===(\"function\"==typeof t&&t.prototype||Pe)}function wi(e){return e==e&&!Jo(e)}function xi(e,t){return function(n){return null!=n&&n[e]===t&&(t!==a||e in Se(n))}}function ki(e,t,n){return t=gn(t===a?e.length-1:t,0),function(){for(var a=arguments,i=-1,o=gn(a.length-t,0),u=r(o);++i<o;)u[i]=a[t+i];i=-1;for(var l=r(t+1);++i<t;)l[i]=a[i];return l[t]=n(u),kt(e,this,l)}}function Si(e,t){return t.length<2?e:wr(e,ea(t,0,-1))}function Ei(e,t){if((\"constructor\"!==t||\"function\"!=typeof e[t])&&\"__proto__\"!=t)return e[t]}var Ci=Pi(Zr),Ti=ct||function(e,t){return ft.setTimeout(e,t)},Mi=Pi(Xr);function Ni(e,t,n){var r=t+\"\";return Mi(e,function(e,t){var n=t.length;if(!n)return e;var r=n-1;return t[r]=(n>1?\"& \":\"\")+t[r],t=t.join(n>2?\", \":\" \"),e.replace(ie,\"{\\n/* [wrapped with \"+t+\"] */\\n\")}(r,function(e,t){return Et(h,(function(n){var r=\"_.\"+n[0];t&n[1]&&!Nt(e,r)&&e.push(r)})),e.sort()}(function(e){var t=e.match(oe);return t?t[1].split(ue):[]}(r),n)))}function Pi(e){var t=0,n=0;return function(){var r=mn(),i=16-(r-n);if(n=r,i>0){if(++t>=800)return arguments[0]}else t=0;return e.apply(a,arguments)}}function zi(e,t){var n=-1,r=e.length,i=r-1;for(t=t===a?r:t;++n<t;){var o=Hr(n,i),u=e[o];e[o]=e[n],e[n]=u}return e.length=t,e}var Li,Oi,Ai=(Li=Oo((function(e){var t=[];return 46===e.charCodeAt(0)&&t.push(\"\"),e.replace(ee,(function(e,n,r,a){t.push(r?a.replace(ce,\"$1\"):n||e)})),t}),(function(e){return 500===Oi.size&&Oi.clear(),e})),Oi=Li.cache,Li);function Fi(e){if(\"string\"==typeof e||uu(e))return e;var t=e+\"\";return\"0\"==t&&1/e==-1/0?\"-0\":t}function Di(e){if(null!=e){try{return Le.call(e)}catch(e){}try{return e+\"\"}catch(e){}}return\"\"}function Ri(e){if(e instanceof Bn)return e.clone();var t=new $n(e.__wrapped__,e.__chain__);return t.__actions__=Ca(e.__actions__),t.__index__=e.__index__,t.__values__=e.__values__,t}var ji=Qr((function(e,t){return qo(e)?sr(e,vr(t,1,qo,!0)):[]})),Ui=Qr((function(e,t){var n=Yi(t);return qo(n)&&(n=a),qo(e)?sr(e,vr(t,1,qo,!0),ii(n,2)):[]})),Ii=Qr((function(e,t){var n=Yi(t);return qo(n)&&(n=a),qo(e)?sr(e,vr(t,1,qo,!0),a,n):[]}));function $i(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var a=null==n?0:du(n);return a<0&&(a=gn(r+a,0)),jt(e,ii(t,3),a)}function Bi(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var i=r-1;return n!==a&&(i=du(n),i=n<0?gn(r+i,0):yn(i,r-1)),jt(e,ii(t,3),i,!0)}function Wi(e){return null!=e&&e.length?vr(e,1):[]}function Vi(e){return e&&e.length?e[0]:a}var Hi=Qr((function(e){var t=zt(e,ha);return t.length&&t[0]===e[0]?Tr(t):[]})),qi=Qr((function(e){var t=Yi(e),n=zt(e,ha);return t===Yi(n)?t=a:n.pop(),n.length&&n[0]===e[0]?Tr(n,ii(t,2)):[]})),Qi=Qr((function(e){var t=Yi(e),n=zt(e,ha);return(t=\"function\"==typeof t?t:a)&&n.pop(),n.length&&n[0]===e[0]?Tr(n,a,t):[]}));function Yi(e){var t=null==e?0:e.length;return t?e[t-1]:a}var Gi=Qr(Ki);function Ki(e,t){return e&&e.length&&t&&t.length?Wr(e,t):e}var Zi=Ja((function(e,t){var n=null==e?0:e.length,r=ar(e,t);return Vr(e,zt(t,(function(e){return vi(e,n)?+e:e})).sort(ka)),r}));function Xi(e){return null==e?e:wn.call(e)}var Ji=Qr((function(e){return ua(vr(e,1,qo,!0))})),eo=Qr((function(e){var t=Yi(e);return qo(t)&&(t=a),ua(vr(e,1,qo,!0),ii(t,2))})),to=Qr((function(e){var t=Yi(e);return t=\"function\"==typeof t?t:a,ua(vr(e,1,qo,!0),a,t)}));function no(e){if(!e||!e.length)return[];var t=0;return e=Mt(e,(function(e){if(qo(e))return t=gn(e.length,t),!0})),Qt(t,(function(t){return zt(e,Wt(t))}))}function ro(e,t){if(!e||!e.length)return[];var n=no(e);return null==t?n:zt(n,(function(e){return kt(t,a,e)}))}var ao=Qr((function(e,t){return qo(e)?sr(e,t):[]})),io=Qr((function(e){return pa(Mt(e,qo))})),oo=Qr((function(e){var t=Yi(e);return qo(t)&&(t=a),pa(Mt(e,qo),ii(t,2))})),uo=Qr((function(e){var t=Yi(e);return t=\"function\"==typeof t?t:a,pa(Mt(e,qo),a,t)})),lo=Qr(no),so=Qr((function(e){var t=e.length,n=t>1?e[t-1]:a;return n=\"function\"==typeof n?(e.pop(),n):a,ro(e,n)}));function co(e){var t=jn(e);return t.__chain__=!0,t}function fo(e,t){return t(e)}var po=Ja((function(e){var t=e.length,n=t?e[0]:0,r=this.__wrapped__,i=function(t){return ar(t,e)};return!(t>1||this.__actions__.length)&&r instanceof Bn&&vi(n)?((r=r.slice(n,+n+(t?1:0))).__actions__.push({func:fo,args:[i],thisArg:a}),new $n(r,this.__chain__).thru((function(e){return t&&!e.length&&e.push(a),e}))):this.thru(i)})),ho=Ma((function(e,t,n){Oe.call(e,n)?++e[n]:rr(e,n,1)})),vo=Fa($i),go=Fa(Bi);function yo(e,t){return(Wo(e)?Et:cr)(e,ii(t,3))}function mo(e,t){return(Wo(e)?Ct:fr)(e,ii(t,3))}var bo=Ma((function(e,t,n){Oe.call(e,n)?e[n].push(t):rr(e,n,[t])})),_o=Qr((function(e,t,n){var a=-1,i=\"function\"==typeof t,o=Ho(e)?r(e.length):[];return cr(e,(function(e){o[++a]=i?kt(t,e,n):Mr(e,t,n)})),o})),wo=Ma((function(e,t,n){rr(e,n,t)}));function xo(e,t){return(Wo(e)?zt:Dr)(e,ii(t,3))}var ko=Ma((function(e,t,n){e[n?0:1].push(t)}),(function(){return[[],[]]})),So=Qr((function(e,t){if(null==e)return[];var n=t.length;return n>1&&gi(e,t[0],t[1])?t=[]:n>2&&gi(t[0],t[1],t[2])&&(t=[t[0]]),$r(e,vr(t,1),[])})),Eo=st||function(){return ft.Date.now()};function Co(e,t,n){return t=n?a:t,t=e&&null==t?e.length:t,Ya(e,s,a,a,a,a,t)}function To(e,t){var n;if(\"function\"!=typeof t)throw new Te(i);return e=du(e),function(){return--e>0&&(n=t.apply(this,arguments)),e<=1&&(t=a),n}}var Mo=Qr((function(e,t,n){var r=1;if(n.length){var a=un(n,ai(Mo));r|=l}return Ya(e,r,t,n,a)})),No=Qr((function(e,t,n){var r=3;if(n.length){var a=un(n,ai(No));r|=l}return Ya(t,r,e,n,a)}));function Po(e,t,n){var r,o,u,l,s,c,f=0,p=!1,d=!1,h=!0;if(\"function\"!=typeof e)throw new Te(i);function v(t){var n=r,i=o;return r=o=a,f=t,l=e.apply(i,n)}function g(e){var n=e-c;return c===a||n>=t||n<0||d&&e-f>=u}function y(){var e=Eo();if(g(e))return m(e);s=Ti(y,function(e){var n=t-(e-c);return d?yn(n,u-(e-f)):n}(e))}function m(e){return s=a,h&&r?v(e):(r=o=a,l)}function b(){var e=Eo(),n=g(e);if(r=arguments,o=this,c=e,n){if(s===a)return function(e){return f=e,s=Ti(y,t),p?v(e):l}(c);if(d)return ba(s),s=Ti(y,t),v(c)}return s===a&&(s=Ti(y,t)),l}return t=vu(t)||0,Jo(n)&&(p=!!n.leading,u=(d=\"maxWait\"in n)?gn(vu(n.maxWait)||0,t):u,h=\"trailing\"in n?!!n.trailing:h),b.cancel=function(){s!==a&&ba(s),f=0,r=c=o=s=a},b.flush=function(){return s===a?l:m(Eo())},b}var zo=Qr((function(e,t){return lr(e,1,t)})),Lo=Qr((function(e,t,n){return lr(e,vu(t)||0,n)}));function Oo(e,t){if(\"function\"!=typeof e||null!=t&&\"function\"!=typeof t)throw new Te(i);var n=function(){var r=arguments,a=t?t.apply(this,r):r[0],i=n.cache;if(i.has(a))return i.get(a);var o=e.apply(this,r);return n.cache=i.set(a,o)||i,o};return n.cache=new(Oo.Cache||Hn),n}function Ao(e){if(\"function\"!=typeof e)throw new Te(i);return function(){var t=arguments;switch(t.length){case 0:return!e.call(this);case 1:return!e.call(this,t[0]);case 2:return!e.call(this,t[0],t[1]);case 3:return!e.call(this,t[0],t[1],t[2])}return!e.apply(this,t)}}Oo.Cache=Hn;var Fo=ya((function(e,t){var n=(t=1==t.length&&Wo(t[0])?zt(t[0],Gt(ii())):zt(vr(t,1),Gt(ii()))).length;return Qr((function(r){for(var a=-1,i=yn(r.length,n);++a<i;)r[a]=t[a].call(this,r[a]);return kt(e,this,r)}))})),Do=Qr((function(e,t){var n=un(t,ai(Do));return Ya(e,l,a,t,n)})),Ro=Qr((function(e,t){var n=un(t,ai(Ro));return Ya(e,64,a,t,n)})),jo=Ja((function(e,t){return Ya(e,256,a,a,a,t)}));function Uo(e,t){return e===t||e!=e&&t!=t}var Io=Wa(Sr),$o=Wa((function(e,t){return e>=t})),Bo=Nr(function(){return arguments}())?Nr:function(e){return eu(e)&&Oe.call(e,\"callee\")&&!qe.call(e,\"callee\")},Wo=r.isArray,Vo=yt?Gt(yt):function(e){return eu(e)&&kr(e)==z};function Ho(e){return null!=e&&Xo(e.length)&&!Ko(e)}function qo(e){return eu(e)&&Ho(e)}var Qo=gt||vl,Yo=mt?Gt(mt):function(e){return eu(e)&&kr(e)==m};function Go(e){if(!eu(e))return!1;var t=kr(e);return t==b||\"[object DOMException]\"==t||\"string\"==typeof e.message&&\"string\"==typeof e.name&&!ru(e)}function Ko(e){if(!Jo(e))return!1;var t=kr(e);return t==_||t==w||\"[object AsyncFunction]\"==t||\"[object Proxy]\"==t}function Zo(e){return\"number\"==typeof e&&e==du(e)}function Xo(e){return\"number\"==typeof e&&e>-1&&e%1==0&&e<=f}function Jo(e){var t=typeof e;return null!=e&&(\"object\"==t||\"function\"==t)}function eu(e){return null!=e&&\"object\"==typeof e}var tu=bt?Gt(bt):function(e){return eu(e)&&fi(e)==x};function nu(e){return\"number\"==typeof e||eu(e)&&kr(e)==k}function ru(e){if(!eu(e)||kr(e)!=S)return!1;var t=Ve(e);if(null===t)return!0;var n=Oe.call(t,\"constructor\")&&t.constructor;return\"function\"==typeof n&&n instanceof n&&Le.call(n)==Re}var au=_t?Gt(_t):function(e){return eu(e)&&kr(e)==C},iu=wt?Gt(wt):function(e){return eu(e)&&fi(e)==T};function ou(e){return\"string\"==typeof e||!Wo(e)&&eu(e)&&kr(e)==M}function uu(e){return\"symbol\"==typeof e||eu(e)&&kr(e)==N}var lu=xt?Gt(xt):function(e){return eu(e)&&Xo(e.length)&&!!at[kr(e)]},su=Wa(Fr),cu=Wa((function(e,t){return e<=t}));function fu(e){if(!e)return[];if(Ho(e))return ou(e)?fn(e):Ca(e);if(Ge&&e[Ge])return function(e){for(var t,n=[];!(t=e.next()).done;)n.push(t.value);return n}(e[Ge]());var t=fi(e);return(t==x?an:t==T?ln:Uu)(e)}function pu(e){return e?(e=vu(e))===c||e===-1/0?17976931348623157e292*(e<0?-1:1):e==e?e:0:0===e?e:0}function du(e){var t=pu(e),n=t%1;return t==t?n?t-n:t:0}function hu(e){return e?ir(du(e),0,d):0}function vu(e){if(\"number\"==typeof e)return e;if(uu(e))return p;if(Jo(e)){var t=\"function\"==typeof e.valueOf?e.valueOf():e;e=Jo(t)?t+\"\":t}if(\"string\"!=typeof e)return 0===e?e:+e;e=Yt(e);var n=he.test(e);return n||ge.test(e)?lt(e.slice(2),n?2:8):de.test(e)?p:+e}function gu(e){return Ta(e,zu(e))}function yu(e){return null==e?\"\":oa(e)}var mu=Na((function(e,t){if(_i(t)||Ho(t))Ta(t,Pu(t),e);else for(var n in t)Oe.call(t,n)&&Jn(e,n,t[n])})),bu=Na((function(e,t){Ta(t,zu(t),e)})),_u=Na((function(e,t,n,r){Ta(t,zu(t),e,r)})),wu=Na((function(e,t,n,r){Ta(t,Pu(t),e,r)})),xu=Ja(ar),ku=Qr((function(e,t){e=Se(e);var n=-1,r=t.length,i=r>2?t[2]:a;for(i&&gi(t[0],t[1],i)&&(r=1);++n<r;)for(var o=t[n],u=zu(o),l=-1,s=u.length;++l<s;){var c=u[l],f=e[c];(f===a||Uo(f,Pe[c])&&!Oe.call(e,c))&&(e[c]=o[c])}return e})),Su=Qr((function(e){return e.push(a,Ka),kt(Ou,a,e)}));function Eu(e,t,n){var r=null==e?a:wr(e,t);return r===a?n:r}function Cu(e,t){return null!=e&&pi(e,t,Cr)}var Tu=ja((function(e,t,n){null!=t&&\"function\"!=typeof t.toString&&(t=De.call(t)),e[t]=n}),Ju(nl)),Mu=ja((function(e,t,n){null!=t&&\"function\"!=typeof t.toString&&(t=De.call(t)),Oe.call(e,t)?e[t].push(n):e[t]=[n]}),ii),Nu=Qr(Mr);function Pu(e){return Ho(e)?Yn(e):Ar(e)}function zu(e){return Ho(e)?Yn(e,!0):function(e){if(!Jo(e))return function(e){var t=[];if(null!=e)for(var n in Se(e))t.push(n);return t}(e);var t=_i(e),n=[];for(var r in e)(\"constructor\"!=r||!t&&Oe.call(e,r))&&n.push(r);return n}(e)}var Lu=Na((function(e,t,n){Ur(e,t,n)})),Ou=Na((function(e,t,n,r){Ur(e,t,n,r)})),Au=Ja((function(e,t){var n={};if(null==e)return n;var r=!1;t=zt(t,(function(t){return t=ga(t,e),r||(r=t.length>1),t})),Ta(e,ti(e),n),r&&(n=or(n,7,Za));for(var a=t.length;a--;)la(n,t[a]);return n})),Fu=Ja((function(e,t){return null==e?{}:function(e,t){return Br(e,t,(function(t,n){return Cu(e,n)}))}(e,t)}));function Du(e,t){if(null==e)return{};var n=zt(ti(e),(function(e){return[e]}));return t=ii(t),Br(e,n,(function(e,n){return t(e,n[0])}))}var Ru=Qa(Pu),ju=Qa(zu);function Uu(e){return null==e?[]:Kt(e,Pu(e))}var Iu=Oa((function(e,t,n){return t=t.toLowerCase(),e+(n?$u(t):t)}));function $u(e){return Gu(yu(e).toLowerCase())}function Bu(e){return(e=yu(e))&&e.replace(me,en).replace(Ze,\"\")}var Wu=Oa((function(e,t,n){return e+(n?\"-\":\"\")+t.toLowerCase()})),Vu=Oa((function(e,t,n){return e+(n?\" \":\"\")+t.toLowerCase()})),Hu=La(\"toLowerCase\"),qu=Oa((function(e,t,n){return e+(n?\"_\":\"\")+t.toLowerCase()})),Qu=Oa((function(e,t,n){return e+(n?\" \":\"\")+Gu(t)})),Yu=Oa((function(e,t,n){return e+(n?\" \":\"\")+t.toUpperCase()})),Gu=La(\"toUpperCase\");function Ku(e,t,n){return e=yu(e),(t=n?a:t)===a?function(e){return tt.test(e)}(e)?function(e){return e.match(Je)||[]}(e):function(e){return e.match(le)||[]}(e):e.match(t)||[]}var Zu=Qr((function(e,t){try{return kt(e,a,t)}catch(e){return Go(e)?e:new we(e)}})),Xu=Ja((function(e,t){return Et(t,(function(t){t=Fi(t),rr(e,t,Mo(e[t],e))})),e}));function Ju(e){return function(){return e}}var el=Da(),tl=Da(!0);function nl(e){return e}function rl(e){return Or(\"function\"==typeof e?e:or(e,1))}var al=Qr((function(e,t){return function(n){return Mr(n,e,t)}})),il=Qr((function(e,t){return function(n){return Mr(e,n,t)}}));function ol(e,t,n){var r=Pu(t),a=_r(t,r);null!=n||Jo(t)&&(a.length||!r.length)||(n=t,t=e,e=this,a=_r(t,Pu(t)));var i=!(Jo(n)&&\"chain\"in n&&!n.chain),o=Ko(e);return Et(a,(function(n){var r=t[n];e[n]=r,o&&(e.prototype[n]=function(){var t=this.__chain__;if(i||t){var n=e(this.__wrapped__);return(n.__actions__=Ca(this.__actions__)).push({func:r,args:arguments,thisArg:e}),n.__chain__=t,n}return r.apply(e,Lt([this.value()],arguments))})})),e}function ul(){}var ll=Ia(zt),sl=Ia(Tt),cl=Ia(Ft);function fl(e){return yi(e)?Wt(Fi(e)):function(e){return function(t){return wr(t,e)}}(e)}var pl=Ba(),dl=Ba(!0);function hl(){return[]}function vl(){return!1}var gl,yl=Ua((function(e,t){return e+t}),0),ml=Ha(\"ceil\"),bl=Ua((function(e,t){return e/t}),1),_l=Ha(\"floor\"),wl=Ua((function(e,t){return e*t}),1),xl=Ha(\"round\"),kl=Ua((function(e,t){return e-t}),0);return jn.after=function(e,t){if(\"function\"!=typeof t)throw new Te(i);return e=du(e),function(){if(--e<1)return t.apply(this,arguments)}},jn.ary=Co,jn.assign=mu,jn.assignIn=bu,jn.assignInWith=_u,jn.assignWith=wu,jn.at=xu,jn.before=To,jn.bind=Mo,jn.bindAll=Xu,jn.bindKey=No,jn.castArray=function(){if(!arguments.length)return[];var e=arguments[0];return Wo(e)?e:[e]},jn.chain=co,jn.chunk=function(e,t,n){t=(n?gi(e,t,n):t===a)?1:gn(du(t),0);var i=null==e?0:e.length;if(!i||t<1)return[];for(var o=0,u=0,l=r(pt(i/t));o<i;)l[u++]=ea(e,o,o+=t);return l},jn.compact=function(e){for(var t=-1,n=null==e?0:e.length,r=0,a=[];++t<n;){var i=e[t];i&&(a[r++]=i)}return a},jn.concat=function(){var e=arguments.length;if(!e)return[];for(var t=r(e-1),n=arguments[0],a=e;a--;)t[a-1]=arguments[a];return Lt(Wo(n)?Ca(n):[n],vr(t,1))},jn.cond=function(e){var t=null==e?0:e.length,n=ii();return e=t?zt(e,(function(e){if(\"function\"!=typeof e[1])throw new Te(i);return[n(e[0]),e[1]]})):[],Qr((function(n){for(var r=-1;++r<t;){var a=e[r];if(kt(a[0],this,n))return kt(a[1],this,n)}}))},jn.conforms=function(e){return function(e){var t=Pu(e);return function(n){return ur(n,e,t)}}(or(e,1))},jn.constant=Ju,jn.countBy=ho,jn.create=function(e,t){var n=Un(e);return null==t?n:nr(n,t)},jn.curry=function e(t,n,r){var i=Ya(t,8,a,a,a,a,a,n=r?a:n);return i.placeholder=e.placeholder,i},jn.curryRight=function e(t,n,r){var i=Ya(t,16,a,a,a,a,a,n=r?a:n);return i.placeholder=e.placeholder,i},jn.debounce=Po,jn.defaults=ku,jn.defaultsDeep=Su,jn.defer=zo,jn.delay=Lo,jn.difference=ji,jn.differenceBy=Ui,jn.differenceWith=Ii,jn.drop=function(e,t,n){var r=null==e?0:e.length;return r?ea(e,(t=n||t===a?1:du(t))<0?0:t,r):[]},jn.dropRight=function(e,t,n){var r=null==e?0:e.length;return r?ea(e,0,(t=r-(t=n||t===a?1:du(t)))<0?0:t):[]},jn.dropRightWhile=function(e,t){return e&&e.length?ca(e,ii(t,3),!0,!0):[]},jn.dropWhile=function(e,t){return e&&e.length?ca(e,ii(t,3),!0):[]},jn.fill=function(e,t,n,r){var i=null==e?0:e.length;return i?(n&&\"number\"!=typeof n&&gi(e,t,n)&&(n=0,r=i),function(e,t,n,r){var i=e.length;for((n=du(n))<0&&(n=-n>i?0:i+n),(r=r===a||r>i?i:du(r))<0&&(r+=i),r=n>r?0:hu(r);n<r;)e[n++]=t;return e}(e,t,n,r)):[]},jn.filter=function(e,t){return(Wo(e)?Mt:hr)(e,ii(t,3))},jn.flatMap=function(e,t){return vr(xo(e,t),1)},jn.flatMapDeep=function(e,t){return vr(xo(e,t),c)},jn.flatMapDepth=function(e,t,n){return n=n===a?1:du(n),vr(xo(e,t),n)},jn.flatten=Wi,jn.flattenDeep=function(e){return null!=e&&e.length?vr(e,c):[]},jn.flattenDepth=function(e,t){return null!=e&&e.length?vr(e,t=t===a?1:du(t)):[]},jn.flip=function(e){return Ya(e,512)},jn.flow=el,jn.flowRight=tl,jn.fromPairs=function(e){for(var t=-1,n=null==e?0:e.length,r={};++t<n;){var a=e[t];r[a[0]]=a[1]}return r},jn.functions=function(e){return null==e?[]:_r(e,Pu(e))},jn.functionsIn=function(e){return null==e?[]:_r(e,zu(e))},jn.groupBy=bo,jn.initial=function(e){return null!=e&&e.length?ea(e,0,-1):[]},jn.intersection=Hi,jn.intersectionBy=qi,jn.intersectionWith=Qi,jn.invert=Tu,jn.invertBy=Mu,jn.invokeMap=_o,jn.iteratee=rl,jn.keyBy=wo,jn.keys=Pu,jn.keysIn=zu,jn.map=xo,jn.mapKeys=function(e,t){var n={};return t=ii(t,3),mr(e,(function(e,r,a){rr(n,t(e,r,a),e)})),n},jn.mapValues=function(e,t){var n={};return t=ii(t,3),mr(e,(function(e,r,a){rr(n,r,t(e,r,a))})),n},jn.matches=function(e){return Rr(or(e,1))},jn.matchesProperty=function(e,t){return jr(e,or(t,1))},jn.memoize=Oo,jn.merge=Lu,jn.mergeWith=Ou,jn.method=al,jn.methodOf=il,jn.mixin=ol,jn.negate=Ao,jn.nthArg=function(e){return e=du(e),Qr((function(t){return Ir(t,e)}))},jn.omit=Au,jn.omitBy=function(e,t){return Du(e,Ao(ii(t)))},jn.once=function(e){return To(2,e)},jn.orderBy=function(e,t,n,r){return null==e?[]:(Wo(t)||(t=null==t?[]:[t]),Wo(n=r?a:n)||(n=null==n?[]:[n]),$r(e,t,n))},jn.over=ll,jn.overArgs=Fo,jn.overEvery=sl,jn.overSome=cl,jn.partial=Do,jn.partialRight=Ro,jn.partition=ko,jn.pick=Fu,jn.pickBy=Du,jn.property=fl,jn.propertyOf=function(e){return function(t){return null==e?a:wr(e,t)}},jn.pull=Gi,jn.pullAll=Ki,jn.pullAllBy=function(e,t,n){return e&&e.length&&t&&t.length?Wr(e,t,ii(n,2)):e},jn.pullAllWith=function(e,t,n){return e&&e.length&&t&&t.length?Wr(e,t,a,n):e},jn.pullAt=Zi,jn.range=pl,jn.rangeRight=dl,jn.rearg=jo,jn.reject=function(e,t){return(Wo(e)?Mt:hr)(e,Ao(ii(t,3)))},jn.remove=function(e,t){var n=[];if(!e||!e.length)return n;var r=-1,a=[],i=e.length;for(t=ii(t,3);++r<i;){var o=e[r];t(o,r,e)&&(n.push(o),a.push(r))}return Vr(e,a),n},jn.rest=function(e,t){if(\"function\"!=typeof e)throw new Te(i);return Qr(e,t=t===a?t:du(t))},jn.reverse=Xi,jn.sampleSize=function(e,t,n){return t=(n?gi(e,t,n):t===a)?1:du(t),(Wo(e)?Kn:Gr)(e,t)},jn.set=function(e,t,n){return null==e?e:Kr(e,t,n)},jn.setWith=function(e,t,n,r){return r=\"function\"==typeof r?r:a,null==e?e:Kr(e,t,n,r)},jn.shuffle=function(e){return(Wo(e)?Zn:Jr)(e)},jn.slice=function(e,t,n){var r=null==e?0:e.length;return r?(n&&\"number\"!=typeof n&&gi(e,t,n)?(t=0,n=r):(t=null==t?0:du(t),n=n===a?r:du(n)),ea(e,t,n)):[]},jn.sortBy=So,jn.sortedUniq=function(e){return e&&e.length?aa(e):[]},jn.sortedUniqBy=function(e,t){return e&&e.length?aa(e,ii(t,2)):[]},jn.split=function(e,t,n){return n&&\"number\"!=typeof n&&gi(e,t,n)&&(t=n=a),(n=n===a?d:n>>>0)?(e=yu(e))&&(\"string\"==typeof t||null!=t&&!au(t))&&!(t=oa(t))&&rn(e)?ma(fn(e),0,n):e.split(t,n):[]},jn.spread=function(e,t){if(\"function\"!=typeof e)throw new Te(i);return t=null==t?0:gn(du(t),0),Qr((function(n){var r=n[t],a=ma(n,0,t);return r&&Lt(a,r),kt(e,this,a)}))},jn.tail=function(e){var t=null==e?0:e.length;return t?ea(e,1,t):[]},jn.take=function(e,t,n){return e&&e.length?ea(e,0,(t=n||t===a?1:du(t))<0?0:t):[]},jn.takeRight=function(e,t,n){var r=null==e?0:e.length;return r?ea(e,(t=r-(t=n||t===a?1:du(t)))<0?0:t,r):[]},jn.takeRightWhile=function(e,t){return e&&e.length?ca(e,ii(t,3),!1,!0):[]},jn.takeWhile=function(e,t){return e&&e.length?ca(e,ii(t,3)):[]},jn.tap=function(e,t){return t(e),e},jn.throttle=function(e,t,n){var r=!0,a=!0;if(\"function\"!=typeof e)throw new Te(i);return Jo(n)&&(r=\"leading\"in n?!!n.leading:r,a=\"trailing\"in n?!!n.trailing:a),Po(e,t,{leading:r,maxWait:t,trailing:a})},jn.thru=fo,jn.toArray=fu,jn.toPairs=Ru,jn.toPairsIn=ju,jn.toPath=function(e){return Wo(e)?zt(e,Fi):uu(e)?[e]:Ca(Ai(yu(e)))},jn.toPlainObject=gu,jn.transform=function(e,t,n){var r=Wo(e),a=r||Qo(e)||lu(e);if(t=ii(t,4),null==n){var i=e&&e.constructor;n=a?r?new i:[]:Jo(e)&&Ko(i)?Un(Ve(e)):{}}return(a?Et:mr)(e,(function(e,r,a){return t(n,e,r,a)})),n},jn.unary=function(e){return Co(e,1)},jn.union=Ji,jn.unionBy=eo,jn.unionWith=to,jn.uniq=function(e){return e&&e.length?ua(e):[]},jn.uniqBy=function(e,t){return e&&e.length?ua(e,ii(t,2)):[]},jn.uniqWith=function(e,t){return t=\"function\"==typeof t?t:a,e&&e.length?ua(e,a,t):[]},jn.unset=function(e,t){return null==e||la(e,t)},jn.unzip=no,jn.unzipWith=ro,jn.update=function(e,t,n){return null==e?e:sa(e,t,va(n))},jn.updateWith=function(e,t,n,r){return r=\"function\"==typeof r?r:a,null==e?e:sa(e,t,va(n),r)},jn.values=Uu,jn.valuesIn=function(e){return null==e?[]:Kt(e,zu(e))},jn.without=ao,jn.words=Ku,jn.wrap=function(e,t){return Do(va(t),e)},jn.xor=io,jn.xorBy=oo,jn.xorWith=uo,jn.zip=lo,jn.zipObject=function(e,t){return da(e||[],t||[],Jn)},jn.zipObjectDeep=function(e,t){return da(e||[],t||[],Kr)},jn.zipWith=so,jn.entries=Ru,jn.entriesIn=ju,jn.extend=bu,jn.extendWith=_u,ol(jn,jn),jn.add=yl,jn.attempt=Zu,jn.camelCase=Iu,jn.capitalize=$u,jn.ceil=ml,jn.clamp=function(e,t,n){return n===a&&(n=t,t=a),n!==a&&(n=(n=vu(n))==n?n:0),t!==a&&(t=(t=vu(t))==t?t:0),ir(vu(e),t,n)},jn.clone=function(e){return or(e,4)},jn.cloneDeep=function(e){return or(e,5)},jn.cloneDeepWith=function(e,t){return or(e,5,t=\"function\"==typeof t?t:a)},jn.cloneWith=function(e,t){return or(e,4,t=\"function\"==typeof t?t:a)},jn.conformsTo=function(e,t){return null==t||ur(e,t,Pu(t))},jn.deburr=Bu,jn.defaultTo=function(e,t){return null==e||e!=e?t:e},jn.divide=bl,jn.endsWith=function(e,t,n){e=yu(e),t=oa(t);var r=e.length,i=n=n===a?r:ir(du(n),0,r);return(n-=t.length)>=0&&e.slice(n,i)==t},jn.eq=Uo,jn.escape=function(e){return(e=yu(e))&&Y.test(e)?e.replace(q,tn):e},jn.escapeRegExp=function(e){return(e=yu(e))&&ne.test(e)?e.replace(te,\"\\\\$&\"):e},jn.every=function(e,t,n){var r=Wo(e)?Tt:pr;return n&&gi(e,t,n)&&(t=a),r(e,ii(t,3))},jn.find=vo,jn.findIndex=$i,jn.findKey=function(e,t){return Rt(e,ii(t,3),mr)},jn.findLast=go,jn.findLastIndex=Bi,jn.findLastKey=function(e,t){return Rt(e,ii(t,3),br)},jn.floor=_l,jn.forEach=yo,jn.forEachRight=mo,jn.forIn=function(e,t){return null==e?e:gr(e,ii(t,3),zu)},jn.forInRight=function(e,t){return null==e?e:yr(e,ii(t,3),zu)},jn.forOwn=function(e,t){return e&&mr(e,ii(t,3))},jn.forOwnRight=function(e,t){return e&&br(e,ii(t,3))},jn.get=Eu,jn.gt=Io,jn.gte=$o,jn.has=function(e,t){return null!=e&&pi(e,t,Er)},jn.hasIn=Cu,jn.head=Vi,jn.identity=nl,jn.includes=function(e,t,n,r){e=Ho(e)?e:Uu(e),n=n&&!r?du(n):0;var a=e.length;return n<0&&(n=gn(a+n,0)),ou(e)?n<=a&&e.indexOf(t,n)>-1:!!a&&Ut(e,t,n)>-1},jn.indexOf=function(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var a=null==n?0:du(n);return a<0&&(a=gn(r+a,0)),Ut(e,t,a)},jn.inRange=function(e,t,n){return t=pu(t),n===a?(n=t,t=0):n=pu(n),function(e,t,n){return e>=yn(t,n)&&e<gn(t,n)}(e=vu(e),t,n)},jn.invoke=Nu,jn.isArguments=Bo,jn.isArray=Wo,jn.isArrayBuffer=Vo,jn.isArrayLike=Ho,jn.isArrayLikeObject=qo,jn.isBoolean=function(e){return!0===e||!1===e||eu(e)&&kr(e)==y},jn.isBuffer=Qo,jn.isDate=Yo,jn.isElement=function(e){return eu(e)&&1===e.nodeType&&!ru(e)},jn.isEmpty=function(e){if(null==e)return!0;if(Ho(e)&&(Wo(e)||\"string\"==typeof e||\"function\"==typeof e.splice||Qo(e)||lu(e)||Bo(e)))return!e.length;var t=fi(e);if(t==x||t==T)return!e.size;if(_i(e))return!Ar(e).length;for(var n in e)if(Oe.call(e,n))return!1;return!0},jn.isEqual=function(e,t){return Pr(e,t)},jn.isEqualWith=function(e,t,n){var r=(n=\"function\"==typeof n?n:a)?n(e,t):a;return r===a?Pr(e,t,a,n):!!r},jn.isError=Go,jn.isFinite=function(e){return\"number\"==typeof e&&Dt(e)},jn.isFunction=Ko,jn.isInteger=Zo,jn.isLength=Xo,jn.isMap=tu,jn.isMatch=function(e,t){return e===t||zr(e,t,ui(t))},jn.isMatchWith=function(e,t,n){return n=\"function\"==typeof n?n:a,zr(e,t,ui(t),n)},jn.isNaN=function(e){return nu(e)&&e!=+e},jn.isNative=function(e){if(bi(e))throw new we(\"Unsupported core-js use. Try https://npms.io/search?q=ponyfill.\");return Lr(e)},jn.isNil=function(e){return null==e},jn.isNull=function(e){return null===e},jn.isNumber=nu,jn.isObject=Jo,jn.isObjectLike=eu,jn.isPlainObject=ru,jn.isRegExp=au,jn.isSafeInteger=function(e){return Zo(e)&&e>=-9007199254740991&&e<=f},jn.isSet=iu,jn.isString=ou,jn.isSymbol=uu,jn.isTypedArray=lu,jn.isUndefined=function(e){return e===a},jn.isWeakMap=function(e){return eu(e)&&fi(e)==P},jn.isWeakSet=function(e){return eu(e)&&\"[object WeakSet]\"==kr(e)},jn.join=function(e,t){return null==e?\"\":Vt.call(e,t)},jn.kebabCase=Wu,jn.last=Yi,jn.lastIndexOf=function(e,t,n){var r=null==e?0:e.length;if(!r)return-1;var i=r;return n!==a&&(i=(i=du(n))<0?gn(r+i,0):yn(i,r-1)),t==t?function(e,t,n){for(var r=n+1;r--;)if(e[r]===t)return r;return r}(e,t,i):jt(e,$t,i,!0)},jn.lowerCase=Vu,jn.lowerFirst=Hu,jn.lt=su,jn.lte=cu,jn.max=function(e){return e&&e.length?dr(e,nl,Sr):a},jn.maxBy=function(e,t){return e&&e.length?dr(e,ii(t,2),Sr):a},jn.mean=function(e){return Bt(e,nl)},jn.meanBy=function(e,t){return Bt(e,ii(t,2))},jn.min=function(e){return e&&e.length?dr(e,nl,Fr):a},jn.minBy=function(e,t){return e&&e.length?dr(e,ii(t,2),Fr):a},jn.stubArray=hl,jn.stubFalse=vl,jn.stubObject=function(){return{}},jn.stubString=function(){return\"\"},jn.stubTrue=function(){return!0},jn.multiply=wl,jn.nth=function(e,t){return e&&e.length?Ir(e,du(t)):a},jn.noConflict=function(){return ft._===this&&(ft._=je),this},jn.noop=ul,jn.now=Eo,jn.pad=function(e,t,n){e=yu(e);var r=(t=du(t))?cn(e):0;if(!t||r>=t)return e;var a=(t-r)/2;return $a(dt(a),n)+e+$a(pt(a),n)},jn.padEnd=function(e,t,n){e=yu(e);var r=(t=du(t))?cn(e):0;return t&&r<t?e+$a(t-r,n):e},jn.padStart=function(e,t,n){e=yu(e);var r=(t=du(t))?cn(e):0;return t&&r<t?$a(t-r,n)+e:e},jn.parseInt=function(e,t,n){return n||null==t?t=0:t&&(t=+t),bn(yu(e).replace(re,\"\"),t||0)},jn.random=function(e,t,n){if(n&&\"boolean\"!=typeof n&&gi(e,t,n)&&(t=n=a),n===a&&(\"boolean\"==typeof t?(n=t,t=a):\"boolean\"==typeof e&&(n=e,e=a)),e===a&&t===a?(e=0,t=1):(e=pu(e),t===a?(t=e,e=0):t=pu(t)),e>t){var r=e;e=t,t=r}if(n||e%1||t%1){var i=_n();return yn(e+i*(t-e+ut(\"1e-\"+((i+\"\").length-1))),t)}return Hr(e,t)},jn.reduce=function(e,t,n){var r=Wo(e)?Ot:Ht,a=arguments.length<3;return r(e,ii(t,4),n,a,cr)},jn.reduceRight=function(e,t,n){var r=Wo(e)?At:Ht,a=arguments.length<3;return r(e,ii(t,4),n,a,fr)},jn.repeat=function(e,t,n){return t=(n?gi(e,t,n):t===a)?1:du(t),qr(yu(e),t)},jn.replace=function(){var e=arguments,t=yu(e[0]);return e.length<3?t:t.replace(e[1],e[2])},jn.result=function(e,t,n){var r=-1,i=(t=ga(t,e)).length;for(i||(i=1,e=a);++r<i;){var o=null==e?a:e[Fi(t[r])];o===a&&(r=i,o=n),e=Ko(o)?o.call(e):o}return e},jn.round=xl,jn.runInContext=e,jn.sample=function(e){return(Wo(e)?Gn:Yr)(e)},jn.size=function(e){if(null==e)return 0;if(Ho(e))return ou(e)?cn(e):e.length;var t=fi(e);return t==x||t==T?e.size:Ar(e).length},jn.snakeCase=qu,jn.some=function(e,t,n){var r=Wo(e)?Ft:ta;return n&&gi(e,t,n)&&(t=a),r(e,ii(t,3))},jn.sortedIndex=function(e,t){return na(e,t)},jn.sortedIndexBy=function(e,t,n){return ra(e,t,ii(n,2))},jn.sortedIndexOf=function(e,t){var n=null==e?0:e.length;if(n){var r=na(e,t);if(r<n&&Uo(e[r],t))return r}return-1},jn.sortedLastIndex=function(e,t){return na(e,t,!0)},jn.sortedLastIndexBy=function(e,t,n){return ra(e,t,ii(n,2),!0)},jn.sortedLastIndexOf=function(e,t){if(null!=e&&e.length){var n=na(e,t,!0)-1;if(Uo(e[n],t))return n}return-1},jn.startCase=Qu,jn.startsWith=function(e,t,n){return e=yu(e),n=null==n?0:ir(du(n),0,e.length),t=oa(t),e.slice(n,n+t.length)==t},jn.subtract=kl,jn.sum=function(e){return e&&e.length?qt(e,nl):0},jn.sumBy=function(e,t){return e&&e.length?qt(e,ii(t,2)):0},jn.template=function(e,t,n){var r=jn.templateSettings;n&&gi(e,t,n)&&(t=a),e=yu(e),t=_u({},t,r,Ga);var i,o,u=_u({},t.imports,r.imports,Ga),l=Pu(u),s=Kt(u,l),c=0,f=t.interpolate||be,p=\"__p += '\",d=Ee((t.escape||be).source+\"|\"+f.source+\"|\"+(f===Z?fe:be).source+\"|\"+(t.evaluate||be).source+\"|$\",\"g\"),h=\"//# sourceURL=\"+(Oe.call(t,\"sourceURL\")?(t.sourceURL+\"\").replace(/\\s/g,\" \"):\"lodash.templateSources[\"+ ++rt+\"]\")+\"\\n\";e.replace(d,(function(t,n,r,a,u,l){return r||(r=a),p+=e.slice(c,l).replace(_e,nn),n&&(i=!0,p+=\"' +\\n__e(\"+n+\") +\\n'\"),u&&(o=!0,p+=\"';\\n\"+u+\";\\n__p += '\"),r&&(p+=\"' +\\n((__t = (\"+r+\")) == null ? '' : __t) +\\n'\"),c=l+t.length,t})),p+=\"';\\n\";var v=Oe.call(t,\"variable\")&&t.variable;if(v){if(se.test(v))throw new we(\"Invalid `variable` option passed into `_.template`\")}else p=\"with (obj) {\\n\"+p+\"\\n}\\n\";p=(o?p.replace(B,\"\"):p).replace(W,\"$1\").replace(V,\"$1;\"),p=\"function(\"+(v||\"obj\")+\") {\\n\"+(v?\"\":\"obj || (obj = {});\\n\")+\"var __t, __p = ''\"+(i?\", __e = _.escape\":\"\")+(o?\", __j = Array.prototype.join;\\nfunction print() { __p += __j.call(arguments, '') }\\n\":\";\\n\")+p+\"return __p\\n}\";var g=Zu((function(){return xe(l,h+\"return \"+p).apply(a,s)}));if(g.source=p,Go(g))throw g;return g},jn.times=function(e,t){if((e=du(e))<1||e>f)return[];var n=d,r=yn(e,d);t=ii(t),e-=d;for(var a=Qt(r,t);++n<e;)t(n);return a},jn.toFinite=pu,jn.toInteger=du,jn.toLength=hu,jn.toLower=function(e){return yu(e).toLowerCase()},jn.toNumber=vu,jn.toSafeInteger=function(e){return e?ir(du(e),-9007199254740991,f):0===e?e:0},jn.toString=yu,jn.toUpper=function(e){return yu(e).toUpperCase()},jn.trim=function(e,t,n){if((e=yu(e))&&(n||t===a))return Yt(e);if(!e||!(t=oa(t)))return e;var r=fn(e),i=fn(t);return ma(r,Xt(r,i),Jt(r,i)+1).join(\"\")},jn.trimEnd=function(e,t,n){if((e=yu(e))&&(n||t===a))return e.slice(0,pn(e)+1);if(!e||!(t=oa(t)))return e;var r=fn(e);return ma(r,0,Jt(r,fn(t))+1).join(\"\")},jn.trimStart=function(e,t,n){if((e=yu(e))&&(n||t===a))return e.replace(re,\"\");if(!e||!(t=oa(t)))return e;var r=fn(e);return ma(r,Xt(r,fn(t))).join(\"\")},jn.truncate=function(e,t){var n=30,r=\"...\";if(Jo(t)){var i=\"separator\"in t?t.separator:i;n=\"length\"in t?du(t.length):n,r=\"omission\"in t?oa(t.omission):r}var o=(e=yu(e)).length;if(rn(e)){var u=fn(e);o=u.length}if(n>=o)return e;var l=n-cn(r);if(l<1)return r;var s=u?ma(u,0,l).join(\"\"):e.slice(0,l);if(i===a)return s+r;if(u&&(l+=s.length-l),au(i)){if(e.slice(l).search(i)){var c,f=s;for(i.global||(i=Ee(i.source,yu(pe.exec(i))+\"g\")),i.lastIndex=0;c=i.exec(f);)var p=c.index;s=s.slice(0,p===a?l:p)}}else if(e.indexOf(oa(i),l)!=l){var d=s.lastIndexOf(i);d>-1&&(s=s.slice(0,d))}return s+r},jn.unescape=function(e){return(e=yu(e))&&Q.test(e)?e.replace(H,dn):e},jn.uniqueId=function(e){var t=++Ae;return yu(e)+t},jn.upperCase=Yu,jn.upperFirst=Gu,jn.each=yo,jn.eachRight=mo,jn.first=Vi,ol(jn,(gl={},mr(jn,(function(e,t){Oe.call(jn.prototype,t)||(gl[t]=e)})),gl),{chain:!1}),jn.VERSION=\"4.17.21\",Et([\"bind\",\"bindKey\",\"curry\",\"curryRight\",\"partial\",\"partialRight\"],(function(e){jn[e].placeholder=jn})),Et([\"drop\",\"take\"],(function(e,t){Bn.prototype[e]=function(n){n=n===a?1:gn(du(n),0);var r=this.__filtered__&&!t?new Bn(this):this.clone();return r.__filtered__?r.__takeCount__=yn(n,r.__takeCount__):r.__views__.push({size:yn(n,d),type:e+(r.__dir__<0?\"Right\":\"\")}),r},Bn.prototype[e+\"Right\"]=function(t){return this.reverse()[e](t).reverse()}})),Et([\"filter\",\"map\",\"takeWhile\"],(function(e,t){var n=t+1,r=1==n||3==n;Bn.prototype[e]=function(e){var t=this.clone();return t.__iteratees__.push({iteratee:ii(e,3),type:n}),t.__filtered__=t.__filtered__||r,t}})),Et([\"head\",\"last\"],(function(e,t){var n=\"take\"+(t?\"Right\":\"\");Bn.prototype[e]=function(){return this[n](1).value()[0]}})),Et([\"initial\",\"tail\"],(function(e,t){var n=\"drop\"+(t?\"\":\"Right\");Bn.prototype[e]=function(){return this.__filtered__?new Bn(this):this[n](1)}})),Bn.prototype.compact=function(){return this.filter(nl)},Bn.prototype.find=function(e){return this.filter(e).head()},Bn.prototype.findLast=function(e){return this.reverse().find(e)},Bn.prototype.invokeMap=Qr((function(e,t){return\"function\"==typeof e?new Bn(this):this.map((function(n){return Mr(n,e,t)}))})),Bn.prototype.reject=function(e){return this.filter(Ao(ii(e)))},Bn.prototype.slice=function(e,t){e=du(e);var n=this;return n.__filtered__&&(e>0||t<0)?new Bn(n):(e<0?n=n.takeRight(-e):e&&(n=n.drop(e)),t!==a&&(n=(t=du(t))<0?n.dropRight(-t):n.take(t-e)),n)},Bn.prototype.takeRightWhile=function(e){return this.reverse().takeWhile(e).reverse()},Bn.prototype.toArray=function(){return this.take(d)},mr(Bn.prototype,(function(e,t){var n=/^(?:filter|find|map|reject)|While$/.test(t),r=/^(?:head|last)$/.test(t),i=jn[r?\"take\"+(\"last\"==t?\"Right\":\"\"):t],o=r||/^find/.test(t);i&&(jn.prototype[t]=function(){var t=this.__wrapped__,u=r?[1]:arguments,l=t instanceof Bn,s=u[0],c=l||Wo(t),f=function(e){var t=i.apply(jn,Lt([e],u));return r&&p?t[0]:t};c&&n&&\"function\"==typeof s&&1!=s.length&&(l=c=!1);var p=this.__chain__,d=!!this.__actions__.length,h=o&&!p,v=l&&!d;if(!o&&c){t=v?t:new Bn(this);var g=e.apply(t,u);return g.__actions__.push({func:fo,args:[f],thisArg:a}),new $n(g,p)}return h&&v?e.apply(this,u):(g=this.thru(f),h?r?g.value()[0]:g.value():g)})})),Et([\"pop\",\"push\",\"shift\",\"sort\",\"splice\",\"unshift\"],(function(e){var t=Me[e],n=/^(?:push|sort|unshift)$/.test(e)?\"tap\":\"thru\",r=/^(?:pop|shift)$/.test(e);jn.prototype[e]=function(){var e=arguments;if(r&&!this.__chain__){var a=this.value();return t.apply(Wo(a)?a:[],e)}return this[n]((function(n){return t.apply(Wo(n)?n:[],e)}))}})),mr(Bn.prototype,(function(e,t){var n=jn[t];if(n){var r=n.name+\"\";Oe.call(Nn,r)||(Nn[r]=[]),Nn[r].push({name:t,func:n})}})),Nn[Ra(a,2).name]=[{name:\"wrapper\",func:a}],Bn.prototype.clone=function(){var e=new Bn(this.__wrapped__);return e.__actions__=Ca(this.__actions__),e.__dir__=this.__dir__,e.__filtered__=this.__filtered__,e.__iteratees__=Ca(this.__iteratees__),e.__takeCount__=this.__takeCount__,e.__views__=Ca(this.__views__),e},Bn.prototype.reverse=function(){if(this.__filtered__){var e=new Bn(this);e.__dir__=-1,e.__filtered__=!0}else(e=this.clone()).__dir__*=-1;return e},Bn.prototype.value=function(){var e=this.__wrapped__.value(),t=this.__dir__,n=Wo(e),r=t<0,a=n?e.length:0,i=function(e,t,n){for(var r=-1,a=n.length;++r<a;){var i=n[r],o=i.size;switch(i.type){case\"drop\":e+=o;break;case\"dropRight\":t-=o;break;case\"take\":t=yn(t,e+o);break;case\"takeRight\":e=gn(e,t-o)}}return{start:e,end:t}}(0,a,this.__views__),o=i.start,u=i.end,l=u-o,s=r?u:o-1,c=this.__iteratees__,f=c.length,p=0,d=yn(l,this.__takeCount__);if(!n||!r&&a==l&&d==l)return fa(e,this.__actions__);var h=[];e:for(;l--&&p<d;){for(var v=-1,g=e[s+=t];++v<f;){var y=c[v],m=y.iteratee,b=y.type,_=m(g);if(2==b)g=_;else if(!_){if(1==b)continue e;break e}}h[p++]=g}return h},jn.prototype.at=po,jn.prototype.chain=function(){return co(this)},jn.prototype.commit=function(){return new $n(this.value(),this.__chain__)},jn.prototype.next=function(){this.__values__===a&&(this.__values__=fu(this.value()));var e=this.__index__>=this.__values__.length;return{done:e,value:e?a:this.__values__[this.__index__++]}},jn.prototype.plant=function(e){for(var t,n=this;n instanceof In;){var r=Ri(n);r.__index__=0,r.__values__=a,t?i.__wrapped__=r:t=r;var i=r;n=n.__wrapped__}return i.__wrapped__=e,t},jn.prototype.reverse=function(){var e=this.__wrapped__;if(e instanceof Bn){var t=e;return this.__actions__.length&&(t=new Bn(this)),(t=t.reverse()).__actions__.push({func:fo,args:[Xi],thisArg:a}),new $n(t,this.__chain__)}return this.thru(Xi)},jn.prototype.toJSON=jn.prototype.valueOf=jn.prototype.value=function(){return fa(this.__wrapped__,this.__actions__)},jn.prototype.first=jn.prototype.head,Ge&&(jn.prototype[Ge]=function(){return this}),jn}();ft._=hn,(r=function(){return hn}.call(t,n,t,e))===a||(e.exports=r)}.call(this)},448:(e,t,n)=>{\"use strict\";var r=n(294),a=n(840);function i(e){for(var t=\"https://reactjs.org/docs/error-decoder.html?invariant=\"+e,n=1;n<arguments.length;n++)t+=\"&args[]=\"+encodeURIComponent(arguments[n]);return\"Minified React error #\"+e+\"; visit \"+t+\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\"}var o=new Set,u={};function l(e,t){s(e,t),s(e+\"Capture\",t)}function s(e,t){for(u[e]=t,e=0;e<t.length;e++)o.add(t[e])}var c=!(\"undefined\"==typeof window||void 0===window.document||void 0===window.document.createElement),f=Object.prototype.hasOwnProperty,p=/^[:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$/,d={},h={};function v(e,t,n,r,a,i,o){this.acceptsBooleans=2===t||3===t||4===t,this.attributeName=r,this.attributeNamespace=a,this.mustUseProperty=n,this.propertyName=e,this.type=t,this.sanitizeURL=i,this.removeEmptyString=o}var g={};\"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style\".split(\" \").forEach((function(e){g[e]=new v(e,0,!1,e,null,!1,!1)})),[[\"acceptCharset\",\"accept-charset\"],[\"className\",\"class\"],[\"htmlFor\",\"for\"],[\"httpEquiv\",\"http-equiv\"]].forEach((function(e){var t=e[0];g[t]=new v(t,1,!1,e[1],null,!1,!1)})),[\"contentEditable\",\"draggable\",\"spellCheck\",\"value\"].forEach((function(e){g[e]=new v(e,2,!1,e.toLowerCase(),null,!1,!1)})),[\"autoReverse\",\"externalResourcesRequired\",\"focusable\",\"preserveAlpha\"].forEach((function(e){g[e]=new v(e,2,!1,e,null,!1,!1)})),\"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope\".split(\" \").forEach((function(e){g[e]=new v(e,3,!1,e.toLowerCase(),null,!1,!1)})),[\"checked\",\"multiple\",\"muted\",\"selected\"].forEach((function(e){g[e]=new v(e,3,!0,e,null,!1,!1)})),[\"capture\",\"download\"].forEach((function(e){g[e]=new v(e,4,!1,e,null,!1,!1)})),[\"cols\",\"rows\",\"size\",\"span\"].forEach((function(e){g[e]=new v(e,6,!1,e,null,!1,!1)})),[\"rowSpan\",\"start\"].forEach((function(e){g[e]=new v(e,5,!1,e.toLowerCase(),null,!1,!1)}));var y=/[\\-:]([a-z])/g;function m(e){return e[1].toUpperCase()}function b(e,t,n,r){var a=g.hasOwnProperty(t)?g[t]:null;(null!==a?0!==a.type:r||!(2<t.length)||\"o\"!==t[0]&&\"O\"!==t[0]||\"n\"!==t[1]&&\"N\"!==t[1])&&(function(e,t,n,r){if(null==t||function(e,t,n,r){if(null!==n&&0===n.type)return!1;switch(typeof t){case\"function\":case\"symbol\":return!0;case\"boolean\":return!r&&(null!==n?!n.acceptsBooleans:\"data-\"!==(e=e.toLowerCase().slice(0,5))&&\"aria-\"!==e);default:return!1}}(e,t,n,r))return!0;if(r)return!1;if(null!==n)switch(n.type){case 3:return!t;case 4:return!1===t;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}(t,n,a,r)&&(n=null),r||null===a?function(e){return!!f.call(h,e)||!f.call(d,e)&&(p.test(e)?h[e]=!0:(d[e]=!0,!1))}(t)&&(null===n?e.removeAttribute(t):e.setAttribute(t,\"\"+n)):a.mustUseProperty?e[a.propertyName]=null===n?3!==a.type&&\"\":n:(t=a.attributeName,r=a.attributeNamespace,null===n?e.removeAttribute(t):(n=3===(a=a.type)||4===a&&!0===n?\"\":\"\"+n,r?e.setAttributeNS(r,t,n):e.setAttribute(t,n))))}\"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height\".split(\" \").forEach((function(e){var t=e.replace(y,m);g[t]=new v(t,1,!1,e,null,!1,!1)})),\"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type\".split(\" \").forEach((function(e){var t=e.replace(y,m);g[t]=new v(t,1,!1,e,\"http://www.w3.org/1999/xlink\",!1,!1)})),[\"xml:base\",\"xml:lang\",\"xml:space\"].forEach((function(e){var t=e.replace(y,m);g[t]=new v(t,1,!1,e,\"http://www.w3.org/XML/1998/namespace\",!1,!1)})),[\"tabIndex\",\"crossOrigin\"].forEach((function(e){g[e]=new v(e,1,!1,e.toLowerCase(),null,!1,!1)})),g.xlinkHref=new v(\"xlinkHref\",1,!1,\"xlink:href\",\"http://www.w3.org/1999/xlink\",!0,!1),[\"src\",\"href\",\"action\",\"formAction\"].forEach((function(e){g[e]=new v(e,1,!1,e.toLowerCase(),null,!0,!0)}));var _=r.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,w=Symbol.for(\"react.element\"),x=Symbol.for(\"react.portal\"),k=Symbol.for(\"react.fragment\"),S=Symbol.for(\"react.strict_mode\"),E=Symbol.for(\"react.profiler\"),C=Symbol.for(\"react.provider\"),T=Symbol.for(\"react.context\"),M=Symbol.for(\"react.forward_ref\"),N=Symbol.for(\"react.suspense\"),P=Symbol.for(\"react.suspense_list\"),z=Symbol.for(\"react.memo\"),L=Symbol.for(\"react.lazy\");Symbol.for(\"react.scope\"),Symbol.for(\"react.debug_trace_mode\");var O=Symbol.for(\"react.offscreen\");Symbol.for(\"react.legacy_hidden\"),Symbol.for(\"react.cache\"),Symbol.for(\"react.tracing_marker\");var A=Symbol.iterator;function F(e){return null===e||\"object\"!=typeof e?null:\"function\"==typeof(e=A&&e[A]||e[\"@@iterator\"])?e:null}var D,R=Object.assign;function j(e){if(void 0===D)try{throw Error()}catch(e){var t=e.stack.trim().match(/\\n( *(at )?)/);D=t&&t[1]||\"\"}return\"\\n\"+D+e}var U=!1;function I(e,t){if(!e||U)return\"\";U=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,\"props\",{set:function(){throw Error()}}),\"object\"==typeof Reflect&&Reflect.construct){try{Reflect.construct(t,[])}catch(e){var r=e}Reflect.construct(e,[],t)}else{try{t.call()}catch(e){r=e}e.call(t.prototype)}else{try{throw Error()}catch(e){r=e}e()}}catch(t){if(t&&r&&\"string\"==typeof t.stack){for(var a=t.stack.split(\"\\n\"),i=r.stack.split(\"\\n\"),o=a.length-1,u=i.length-1;1<=o&&0<=u&&a[o]!==i[u];)u--;for(;1<=o&&0<=u;o--,u--)if(a[o]!==i[u]){if(1!==o||1!==u)do{if(o--,0>--u||a[o]!==i[u]){var l=\"\\n\"+a[o].replace(\" at new \",\" at \");return e.displayName&&l.includes(\"<anonymous>\")&&(l=l.replace(\"<anonymous>\",e.displayName)),l}}while(1<=o&&0<=u);break}}}finally{U=!1,Error.prepareStackTrace=n}return(e=e?e.displayName||e.name:\"\")?j(e):\"\"}function $(e){switch(e.tag){case 5:return j(e.type);case 16:return j(\"Lazy\");case 13:return j(\"Suspense\");case 19:return j(\"SuspenseList\");case 0:case 2:case 15:return I(e.type,!1);case 11:return I(e.type.render,!1);case 1:return I(e.type,!0);default:return\"\"}}function B(e){if(null==e)return null;if(\"function\"==typeof e)return e.displayName||e.name||null;if(\"string\"==typeof e)return e;switch(e){case k:return\"Fragment\";case x:return\"Portal\";case E:return\"Profiler\";case S:return\"StrictMode\";case N:return\"Suspense\";case P:return\"SuspenseList\"}if(\"object\"==typeof e)switch(e.$$typeof){case T:return(e.displayName||\"Context\")+\".Consumer\";case C:return(e._context.displayName||\"Context\")+\".Provider\";case M:var t=e.render;return(e=e.displayName)||(e=\"\"!==(e=t.displayName||t.name||\"\")?\"ForwardRef(\"+e+\")\":\"ForwardRef\"),e;case z:return null!==(t=e.displayName||null)?t:B(e.type)||\"Memo\";case L:t=e._payload,e=e._init;try{return B(e(t))}catch(e){}}return null}function W(e){var t=e.type;switch(e.tag){case 24:return\"Cache\";case 9:return(t.displayName||\"Context\")+\".Consumer\";case 10:return(t._context.displayName||\"Context\")+\".Provider\";case 18:return\"DehydratedFragment\";case 11:return e=(e=t.render).displayName||e.name||\"\",t.displayName||(\"\"!==e?\"ForwardRef(\"+e+\")\":\"ForwardRef\");case 7:return\"Fragment\";case 5:return t;case 4:return\"Portal\";case 3:return\"Root\";case 6:return\"Text\";case 16:return B(t);case 8:return t===S?\"StrictMode\":\"Mode\";case 22:return\"Offscreen\";case 12:return\"Profiler\";case 21:return\"Scope\";case 13:return\"Suspense\";case 19:return\"SuspenseList\";case 25:return\"TracingMarker\";case 1:case 0:case 17:case 2:case 14:case 15:if(\"function\"==typeof t)return t.displayName||t.name||null;if(\"string\"==typeof t)return t}return null}function V(e){switch(typeof e){case\"boolean\":case\"number\":case\"string\":case\"undefined\":case\"object\":return e;default:return\"\"}}function H(e){var t=e.type;return(e=e.nodeName)&&\"input\"===e.toLowerCase()&&(\"checkbox\"===t||\"radio\"===t)}function q(e){e._valueTracker||(e._valueTracker=function(e){var t=H(e)?\"checked\":\"value\",n=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),r=\"\"+e[t];if(!e.hasOwnProperty(t)&&void 0!==n&&\"function\"==typeof n.get&&\"function\"==typeof n.set){var a=n.get,i=n.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return a.call(this)},set:function(e){r=\"\"+e,i.call(this,e)}}),Object.defineProperty(e,t,{enumerable:n.enumerable}),{getValue:function(){return r},setValue:function(e){r=\"\"+e},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}(e))}function Q(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),r=\"\";return e&&(r=H(e)?e.checked?\"true\":\"false\":e.value),(e=r)!==n&&(t.setValue(e),!0)}function Y(e){if(void 0===(e=e||(\"undefined\"!=typeof document?document:void 0)))return null;try{return e.activeElement||e.body}catch(t){return e.body}}function G(e,t){var n=t.checked;return R({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=n?n:e._wrapperState.initialChecked})}function K(e,t){var n=null==t.defaultValue?\"\":t.defaultValue,r=null!=t.checked?t.checked:t.defaultChecked;n=V(null!=t.value?t.value:n),e._wrapperState={initialChecked:r,initialValue:n,controlled:\"checkbox\"===t.type||\"radio\"===t.type?null!=t.checked:null!=t.value}}function Z(e,t){null!=(t=t.checked)&&b(e,\"checked\",t,!1)}function X(e,t){Z(e,t);var n=V(t.value),r=t.type;if(null!=n)\"number\"===r?(0===n&&\"\"===e.value||e.value!=n)&&(e.value=\"\"+n):e.value!==\"\"+n&&(e.value=\"\"+n);else if(\"submit\"===r||\"reset\"===r)return void e.removeAttribute(\"value\");t.hasOwnProperty(\"value\")?ee(e,t.type,n):t.hasOwnProperty(\"defaultValue\")&&ee(e,t.type,V(t.defaultValue)),null==t.checked&&null!=t.defaultChecked&&(e.defaultChecked=!!t.defaultChecked)}function J(e,t,n){if(t.hasOwnProperty(\"value\")||t.hasOwnProperty(\"defaultValue\")){var r=t.type;if(!(\"submit\"!==r&&\"reset\"!==r||void 0!==t.value&&null!==t.value))return;t=\"\"+e._wrapperState.initialValue,n||t===e.value||(e.value=t),e.defaultValue=t}\"\"!==(n=e.name)&&(e.name=\"\"),e.defaultChecked=!!e._wrapperState.initialChecked,\"\"!==n&&(e.name=n)}function ee(e,t,n){\"number\"===t&&Y(e.ownerDocument)===e||(null==n?e.defaultValue=\"\"+e._wrapperState.initialValue:e.defaultValue!==\"\"+n&&(e.defaultValue=\"\"+n))}var te=Array.isArray;function ne(e,t,n,r){if(e=e.options,t){t={};for(var a=0;a<n.length;a++)t[\"$\"+n[a]]=!0;for(n=0;n<e.length;n++)a=t.hasOwnProperty(\"$\"+e[n].value),e[n].selected!==a&&(e[n].selected=a),a&&r&&(e[n].defaultSelected=!0)}else{for(n=\"\"+V(n),t=null,a=0;a<e.length;a++){if(e[a].value===n)return e[a].selected=!0,void(r&&(e[a].defaultSelected=!0));null!==t||e[a].disabled||(t=e[a])}null!==t&&(t.selected=!0)}}function re(e,t){if(null!=t.dangerouslySetInnerHTML)throw Error(i(91));return R({},t,{value:void 0,defaultValue:void 0,children:\"\"+e._wrapperState.initialValue})}function ae(e,t){var n=t.value;if(null==n){if(n=t.children,t=t.defaultValue,null!=n){if(null!=t)throw Error(i(92));if(te(n)){if(1<n.length)throw Error(i(93));n=n[0]}t=n}null==t&&(t=\"\"),n=t}e._wrapperState={initialValue:V(n)}}function ie(e,t){var n=V(t.value),r=V(t.defaultValue);null!=n&&((n=\"\"+n)!==e.value&&(e.value=n),null==t.defaultValue&&e.defaultValue!==n&&(e.defaultValue=n)),null!=r&&(e.defaultValue=\"\"+r)}function oe(e){var t=e.textContent;t===e._wrapperState.initialValue&&\"\"!==t&&null!==t&&(e.value=t)}function ue(e){switch(e){case\"svg\":return\"http://www.w3.org/2000/svg\";case\"math\":return\"http://www.w3.org/1998/Math/MathML\";default:return\"http://www.w3.org/1999/xhtml\"}}function le(e,t){return null==e||\"http://www.w3.org/1999/xhtml\"===e?ue(t):\"http://www.w3.org/2000/svg\"===e&&\"foreignObject\"===t?\"http://www.w3.org/1999/xhtml\":e}var se,ce,fe=(ce=function(e,t){if(\"http://www.w3.org/2000/svg\"!==e.namespaceURI||\"innerHTML\"in e)e.innerHTML=t;else{for((se=se||document.createElement(\"div\")).innerHTML=\"<svg>\"+t.valueOf().toString()+\"</svg>\",t=se.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}},\"undefined\"!=typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,t,n,r){MSApp.execUnsafeLocalFunction((function(){return ce(e,t)}))}:ce);function pe(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&3===n.nodeType)return void(n.nodeValue=t)}e.textContent=t}var de={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},he=[\"Webkit\",\"ms\",\"Moz\",\"O\"];function ve(e,t,n){return null==t||\"boolean\"==typeof t||\"\"===t?\"\":n||\"number\"!=typeof t||0===t||de.hasOwnProperty(e)&&de[e]?(\"\"+t).trim():t+\"px\"}function ge(e,t){for(var n in e=e.style,t)if(t.hasOwnProperty(n)){var r=0===n.indexOf(\"--\"),a=ve(n,t[n],r);\"float\"===n&&(n=\"cssFloat\"),r?e.setProperty(n,a):e[n]=a}}Object.keys(de).forEach((function(e){he.forEach((function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),de[t]=de[e]}))}));var ye=R({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function me(e,t){if(t){if(ye[e]&&(null!=t.children||null!=t.dangerouslySetInnerHTML))throw Error(i(137,e));if(null!=t.dangerouslySetInnerHTML){if(null!=t.children)throw Error(i(60));if(\"object\"!=typeof t.dangerouslySetInnerHTML||!(\"__html\"in t.dangerouslySetInnerHTML))throw Error(i(61))}if(null!=t.style&&\"object\"!=typeof t.style)throw Error(i(62))}}function be(e,t){if(-1===e.indexOf(\"-\"))return\"string\"==typeof t.is;switch(e){case\"annotation-xml\":case\"color-profile\":case\"font-face\":case\"font-face-src\":case\"font-face-uri\":case\"font-face-format\":case\"font-face-name\":case\"missing-glyph\":return!1;default:return!0}}var _e=null;function we(e){return(e=e.target||e.srcElement||window).correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}var xe=null,ke=null,Se=null;function Ee(e){if(e=ba(e)){if(\"function\"!=typeof xe)throw Error(i(280));var t=e.stateNode;t&&(t=wa(t),xe(e.stateNode,e.type,t))}}function Ce(e){ke?Se?Se.push(e):Se=[e]:ke=e}function Te(){if(ke){var e=ke,t=Se;if(Se=ke=null,Ee(e),t)for(e=0;e<t.length;e++)Ee(t[e])}}function Me(e,t){return e(t)}function Ne(){}var Pe=!1;function ze(e,t,n){if(Pe)return e(t,n);Pe=!0;try{return Me(e,t,n)}finally{Pe=!1,(null!==ke||null!==Se)&&(Ne(),Te())}}function Le(e,t){var n=e.stateNode;if(null===n)return null;var r=wa(n);if(null===r)return null;n=r[t];e:switch(t){case\"onClick\":case\"onClickCapture\":case\"onDoubleClick\":case\"onDoubleClickCapture\":case\"onMouseDown\":case\"onMouseDownCapture\":case\"onMouseMove\":case\"onMouseMoveCapture\":case\"onMouseUp\":case\"onMouseUpCapture\":case\"onMouseEnter\":(r=!r.disabled)||(r=!(\"button\"===(e=e.type)||\"input\"===e||\"select\"===e||\"textarea\"===e)),e=!r;break e;default:e=!1}if(e)return null;if(n&&\"function\"!=typeof n)throw Error(i(231,t,typeof n));return n}var Oe=!1;if(c)try{var Ae={};Object.defineProperty(Ae,\"passive\",{get:function(){Oe=!0}}),window.addEventListener(\"test\",Ae,Ae),window.removeEventListener(\"test\",Ae,Ae)}catch(ce){Oe=!1}function Fe(e,t,n,r,a,i,o,u,l){var s=Array.prototype.slice.call(arguments,3);try{t.apply(n,s)}catch(e){this.onError(e)}}var De=!1,Re=null,je=!1,Ue=null,Ie={onError:function(e){De=!0,Re=e}};function $e(e,t,n,r,a,i,o,u,l){De=!1,Re=null,Fe.apply(Ie,arguments)}function Be(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do{0!=(4098&(t=e).flags)&&(n=t.return),e=t.return}while(e)}return 3===t.tag?n:null}function We(e){if(13===e.tag){var t=e.memoizedState;if(null===t&&null!==(e=e.alternate)&&(t=e.memoizedState),null!==t)return t.dehydrated}return null}function Ve(e){if(Be(e)!==e)throw Error(i(188))}function He(e){return null!==(e=function(e){var t=e.alternate;if(!t){if(null===(t=Be(e)))throw Error(i(188));return t!==e?null:e}for(var n=e,r=t;;){var a=n.return;if(null===a)break;var o=a.alternate;if(null===o){if(null!==(r=a.return)){n=r;continue}break}if(a.child===o.child){for(o=a.child;o;){if(o===n)return Ve(a),e;if(o===r)return Ve(a),t;o=o.sibling}throw Error(i(188))}if(n.return!==r.return)n=a,r=o;else{for(var u=!1,l=a.child;l;){if(l===n){u=!0,n=a,r=o;break}if(l===r){u=!0,r=a,n=o;break}l=l.sibling}if(!u){for(l=o.child;l;){if(l===n){u=!0,n=o,r=a;break}if(l===r){u=!0,r=o,n=a;break}l=l.sibling}if(!u)throw Error(i(189))}}if(n.alternate!==r)throw Error(i(190))}if(3!==n.tag)throw Error(i(188));return n.stateNode.current===n?e:t}(e))?qe(e):null}function qe(e){if(5===e.tag||6===e.tag)return e;for(e=e.child;null!==e;){var t=qe(e);if(null!==t)return t;e=e.sibling}return null}var Qe=a.unstable_scheduleCallback,Ye=a.unstable_cancelCallback,Ge=a.unstable_shouldYield,Ke=a.unstable_requestPaint,Ze=a.unstable_now,Xe=a.unstable_getCurrentPriorityLevel,Je=a.unstable_ImmediatePriority,et=a.unstable_UserBlockingPriority,tt=a.unstable_NormalPriority,nt=a.unstable_LowPriority,rt=a.unstable_IdlePriority,at=null,it=null,ot=Math.clz32?Math.clz32:function(e){return 0===(e>>>=0)?32:31-(ut(e)/lt|0)|0},ut=Math.log,lt=Math.LN2,st=64,ct=4194304;function ft(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return 4194240&e;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return 130023424&e;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function pt(e,t){var n=e.pendingLanes;if(0===n)return 0;var r=0,a=e.suspendedLanes,i=e.pingedLanes,o=268435455&n;if(0!==o){var u=o&~a;0!==u?r=ft(u):0!=(i&=o)&&(r=ft(i))}else 0!=(o=n&~a)?r=ft(o):0!==i&&(r=ft(i));if(0===r)return 0;if(0!==t&&t!==r&&0==(t&a)&&((a=r&-r)>=(i=t&-t)||16===a&&0!=(4194240&i)))return t;if(0!=(4&r)&&(r|=16&n),0!==(t=e.entangledLanes))for(e=e.entanglements,t&=r;0<t;)a=1<<(n=31-ot(t)),r|=e[n],t&=~a;return r}function dt(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;default:return-1}}function ht(e){return 0!=(e=-1073741825&e.pendingLanes)?e:1073741824&e?1073741824:0}function vt(){var e=st;return 0==(4194240&(st<<=1))&&(st=64),e}function gt(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function yt(e,t,n){e.pendingLanes|=t,536870912!==t&&(e.suspendedLanes=0,e.pingedLanes=0),(e=e.eventTimes)[t=31-ot(t)]=n}function mt(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var r=31-ot(n),a=1<<r;a&t|e[r]&t&&(e[r]|=t),n&=~a}}var bt=0;function _t(e){return 1<(e&=-e)?4<e?0!=(268435455&e)?16:536870912:4:1}var wt,xt,kt,St,Et,Ct=!1,Tt=[],Mt=null,Nt=null,Pt=null,zt=new Map,Lt=new Map,Ot=[],At=\"mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit\".split(\" \");function Ft(e,t){switch(e){case\"focusin\":case\"focusout\":Mt=null;break;case\"dragenter\":case\"dragleave\":Nt=null;break;case\"mouseover\":case\"mouseout\":Pt=null;break;case\"pointerover\":case\"pointerout\":zt.delete(t.pointerId);break;case\"gotpointercapture\":case\"lostpointercapture\":Lt.delete(t.pointerId)}}function Dt(e,t,n,r,a,i){return null===e||e.nativeEvent!==i?(e={blockedOn:t,domEventName:n,eventSystemFlags:r,nativeEvent:i,targetContainers:[a]},null!==t&&null!==(t=ba(t))&&xt(t),e):(e.eventSystemFlags|=r,t=e.targetContainers,null!==a&&-1===t.indexOf(a)&&t.push(a),e)}function Rt(e){var t=ma(e.target);if(null!==t){var n=Be(t);if(null!==n)if(13===(t=n.tag)){if(null!==(t=We(n)))return e.blockedOn=t,void Et(e.priority,(function(){kt(n)}))}else if(3===t&&n.stateNode.current.memoizedState.isDehydrated)return void(e.blockedOn=3===n.tag?n.stateNode.containerInfo:null)}e.blockedOn=null}function jt(e){if(null!==e.blockedOn)return!1;for(var t=e.targetContainers;0<t.length;){var n=Gt(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(null!==n)return null!==(t=ba(n))&&xt(t),e.blockedOn=n,!1;var r=new(n=e.nativeEvent).constructor(n.type,n);_e=r,n.target.dispatchEvent(r),_e=null,t.shift()}return!0}function Ut(e,t,n){jt(e)&&n.delete(t)}function It(){Ct=!1,null!==Mt&&jt(Mt)&&(Mt=null),null!==Nt&&jt(Nt)&&(Nt=null),null!==Pt&&jt(Pt)&&(Pt=null),zt.forEach(Ut),Lt.forEach(Ut)}function $t(e,t){e.blockedOn===t&&(e.blockedOn=null,Ct||(Ct=!0,a.unstable_scheduleCallback(a.unstable_NormalPriority,It)))}function Bt(e){function t(t){return $t(t,e)}if(0<Tt.length){$t(Tt[0],e);for(var n=1;n<Tt.length;n++){var r=Tt[n];r.blockedOn===e&&(r.blockedOn=null)}}for(null!==Mt&&$t(Mt,e),null!==Nt&&$t(Nt,e),null!==Pt&&$t(Pt,e),zt.forEach(t),Lt.forEach(t),n=0;n<Ot.length;n++)(r=Ot[n]).blockedOn===e&&(r.blockedOn=null);for(;0<Ot.length&&null===(n=Ot[0]).blockedOn;)Rt(n),null===n.blockedOn&&Ot.shift()}var Wt=_.ReactCurrentBatchConfig,Vt=!0;function Ht(e,t,n,r){var a=bt,i=Wt.transition;Wt.transition=null;try{bt=1,Qt(e,t,n,r)}finally{bt=a,Wt.transition=i}}function qt(e,t,n,r){var a=bt,i=Wt.transition;Wt.transition=null;try{bt=4,Qt(e,t,n,r)}finally{bt=a,Wt.transition=i}}function Qt(e,t,n,r){if(Vt){var a=Gt(e,t,n,r);if(null===a)Vr(e,t,r,Yt,n),Ft(e,r);else if(function(e,t,n,r,a){switch(t){case\"focusin\":return Mt=Dt(Mt,e,t,n,r,a),!0;case\"dragenter\":return Nt=Dt(Nt,e,t,n,r,a),!0;case\"mouseover\":return Pt=Dt(Pt,e,t,n,r,a),!0;case\"pointerover\":var i=a.pointerId;return zt.set(i,Dt(zt.get(i)||null,e,t,n,r,a)),!0;case\"gotpointercapture\":return i=a.pointerId,Lt.set(i,Dt(Lt.get(i)||null,e,t,n,r,a)),!0}return!1}(a,e,t,n,r))r.stopPropagation();else if(Ft(e,r),4&t&&-1<At.indexOf(e)){for(;null!==a;){var i=ba(a);if(null!==i&&wt(i),null===(i=Gt(e,t,n,r))&&Vr(e,t,r,Yt,n),i===a)break;a=i}null!==a&&r.stopPropagation()}else Vr(e,t,r,null,n)}}var Yt=null;function Gt(e,t,n,r){if(Yt=null,null!==(e=ma(e=we(r))))if(null===(t=Be(e)))e=null;else if(13===(n=t.tag)){if(null!==(e=We(t)))return e;e=null}else if(3===n){if(t.stateNode.current.memoizedState.isDehydrated)return 3===t.tag?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Yt=e,null}function Kt(e){switch(e){case\"cancel\":case\"click\":case\"close\":case\"contextmenu\":case\"copy\":case\"cut\":case\"auxclick\":case\"dblclick\":case\"dragend\":case\"dragstart\":case\"drop\":case\"focusin\":case\"focusout\":case\"input\":case\"invalid\":case\"keydown\":case\"keypress\":case\"keyup\":case\"mousedown\":case\"mouseup\":case\"paste\":case\"pause\":case\"play\":case\"pointercancel\":case\"pointerdown\":case\"pointerup\":case\"ratechange\":case\"reset\":case\"resize\":case\"seeked\":case\"submit\":case\"touchcancel\":case\"touchend\":case\"touchstart\":case\"volumechange\":case\"change\":case\"selectionchange\":case\"textInput\":case\"compositionstart\":case\"compositionend\":case\"compositionupdate\":case\"beforeblur\":case\"afterblur\":case\"beforeinput\":case\"blur\":case\"fullscreenchange\":case\"focus\":case\"hashchange\":case\"popstate\":case\"select\":case\"selectstart\":return 1;case\"drag\":case\"dragenter\":case\"dragexit\":case\"dragleave\":case\"dragover\":case\"mousemove\":case\"mouseout\":case\"mouseover\":case\"pointermove\":case\"pointerout\":case\"pointerover\":case\"scroll\":case\"toggle\":case\"touchmove\":case\"wheel\":case\"mouseenter\":case\"mouseleave\":case\"pointerenter\":case\"pointerleave\":return 4;case\"message\":switch(Xe()){case Je:return 1;case et:return 4;case tt:case nt:return 16;case rt:return 536870912;default:return 16}default:return 16}}var Zt=null,Xt=null,Jt=null;function en(){if(Jt)return Jt;var e,t,n=Xt,r=n.length,a=\"value\"in Zt?Zt.value:Zt.textContent,i=a.length;for(e=0;e<r&&n[e]===a[e];e++);var o=r-e;for(t=1;t<=o&&n[r-t]===a[i-t];t++);return Jt=a.slice(e,1<t?1-t:void 0)}function tn(e){var t=e.keyCode;return\"charCode\"in e?0===(e=e.charCode)&&13===t&&(e=13):e=t,10===e&&(e=13),32<=e||13===e?e:0}function nn(){return!0}function rn(){return!1}function an(e){function t(t,n,r,a,i){for(var o in this._reactName=t,this._targetInst=r,this.type=n,this.nativeEvent=a,this.target=i,this.currentTarget=null,e)e.hasOwnProperty(o)&&(t=e[o],this[o]=t?t(a):a[o]);return this.isDefaultPrevented=(null!=a.defaultPrevented?a.defaultPrevented:!1===a.returnValue)?nn:rn,this.isPropagationStopped=rn,this}return R(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var e=this.nativeEvent;e&&(e.preventDefault?e.preventDefault():\"unknown\"!=typeof e.returnValue&&(e.returnValue=!1),this.isDefaultPrevented=nn)},stopPropagation:function(){var e=this.nativeEvent;e&&(e.stopPropagation?e.stopPropagation():\"unknown\"!=typeof e.cancelBubble&&(e.cancelBubble=!0),this.isPropagationStopped=nn)},persist:function(){},isPersistent:nn}),t}var on,un,ln,sn={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},cn=an(sn),fn=R({},sn,{view:0,detail:0}),pn=an(fn),dn=R({},fn,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:En,button:0,buttons:0,relatedTarget:function(e){return void 0===e.relatedTarget?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return\"movementX\"in e?e.movementX:(e!==ln&&(ln&&\"mousemove\"===e.type?(on=e.screenX-ln.screenX,un=e.screenY-ln.screenY):un=on=0,ln=e),on)},movementY:function(e){return\"movementY\"in e?e.movementY:un}}),hn=an(dn),vn=an(R({},dn,{dataTransfer:0})),gn=an(R({},fn,{relatedTarget:0})),yn=an(R({},sn,{animationName:0,elapsedTime:0,pseudoElement:0})),mn=R({},sn,{clipboardData:function(e){return\"clipboardData\"in e?e.clipboardData:window.clipboardData}}),bn=an(mn),_n=an(R({},sn,{data:0})),wn={Esc:\"Escape\",Spacebar:\" \",Left:\"ArrowLeft\",Up:\"ArrowUp\",Right:\"ArrowRight\",Down:\"ArrowDown\",Del:\"Delete\",Win:\"OS\",Menu:\"ContextMenu\",Apps:\"ContextMenu\",Scroll:\"ScrollLock\",MozPrintableKey:\"Unidentified\"},xn={8:\"Backspace\",9:\"Tab\",12:\"Clear\",13:\"Enter\",16:\"Shift\",17:\"Control\",18:\"Alt\",19:\"Pause\",20:\"CapsLock\",27:\"Escape\",32:\" \",33:\"PageUp\",34:\"PageDown\",35:\"End\",36:\"Home\",37:\"ArrowLeft\",38:\"ArrowUp\",39:\"ArrowRight\",40:\"ArrowDown\",45:\"Insert\",46:\"Delete\",112:\"F1\",113:\"F2\",114:\"F3\",115:\"F4\",116:\"F5\",117:\"F6\",118:\"F7\",119:\"F8\",120:\"F9\",121:\"F10\",122:\"F11\",123:\"F12\",144:\"NumLock\",145:\"ScrollLock\",224:\"Meta\"},kn={Alt:\"altKey\",Control:\"ctrlKey\",Meta:\"metaKey\",Shift:\"shiftKey\"};function Sn(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):!!(e=kn[e])&&!!t[e]}function En(){return Sn}var Cn=R({},fn,{key:function(e){if(e.key){var t=wn[e.key]||e.key;if(\"Unidentified\"!==t)return t}return\"keypress\"===e.type?13===(e=tn(e))?\"Enter\":String.fromCharCode(e):\"keydown\"===e.type||\"keyup\"===e.type?xn[e.keyCode]||\"Unidentified\":\"\"},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:En,charCode:function(e){return\"keypress\"===e.type?tn(e):0},keyCode:function(e){return\"keydown\"===e.type||\"keyup\"===e.type?e.keyCode:0},which:function(e){return\"keypress\"===e.type?tn(e):\"keydown\"===e.type||\"keyup\"===e.type?e.keyCode:0}}),Tn=an(Cn),Mn=an(R({},dn,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0})),Nn=an(R({},fn,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:En})),Pn=an(R({},sn,{propertyName:0,elapsedTime:0,pseudoElement:0})),zn=R({},dn,{deltaX:function(e){return\"deltaX\"in e?e.deltaX:\"wheelDeltaX\"in e?-e.wheelDeltaX:0},deltaY:function(e){return\"deltaY\"in e?e.deltaY:\"wheelDeltaY\"in e?-e.wheelDeltaY:\"wheelDelta\"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),Ln=an(zn),On=[9,13,27,32],An=c&&\"CompositionEvent\"in window,Fn=null;c&&\"documentMode\"in document&&(Fn=document.documentMode);var Dn=c&&\"TextEvent\"in window&&!Fn,Rn=c&&(!An||Fn&&8<Fn&&11>=Fn),jn=String.fromCharCode(32),Un=!1;function In(e,t){switch(e){case\"keyup\":return-1!==On.indexOf(t.keyCode);case\"keydown\":return 229!==t.keyCode;case\"keypress\":case\"mousedown\":case\"focusout\":return!0;default:return!1}}function $n(e){return\"object\"==typeof(e=e.detail)&&\"data\"in e?e.data:null}var Bn=!1,Wn={color:!0,date:!0,datetime:!0,\"datetime-local\":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function Vn(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return\"input\"===t?!!Wn[e.type]:\"textarea\"===t}function Hn(e,t,n,r){Ce(r),0<(t=qr(t,\"onChange\")).length&&(n=new cn(\"onChange\",\"change\",null,n,r),e.push({event:n,listeners:t}))}var qn=null,Qn=null;function Yn(e){jr(e,0)}function Gn(e){if(Q(_a(e)))return e}function Kn(e,t){if(\"change\"===e)return t}var Zn=!1;if(c){var Xn;if(c){var Jn=\"oninput\"in document;if(!Jn){var er=document.createElement(\"div\");er.setAttribute(\"oninput\",\"return;\"),Jn=\"function\"==typeof er.oninput}Xn=Jn}else Xn=!1;Zn=Xn&&(!document.documentMode||9<document.documentMode)}function tr(){qn&&(qn.detachEvent(\"onpropertychange\",nr),Qn=qn=null)}function nr(e){if(\"value\"===e.propertyName&&Gn(Qn)){var t=[];Hn(t,Qn,e,we(e)),ze(Yn,t)}}function rr(e,t,n){\"focusin\"===e?(tr(),Qn=n,(qn=t).attachEvent(\"onpropertychange\",nr)):\"focusout\"===e&&tr()}function ar(e){if(\"selectionchange\"===e||\"keyup\"===e||\"keydown\"===e)return Gn(Qn)}function ir(e,t){if(\"click\"===e)return Gn(t)}function or(e,t){if(\"input\"===e||\"change\"===e)return Gn(t)}var ur=\"function\"==typeof Object.is?Object.is:function(e,t){return e===t&&(0!==e||1/e==1/t)||e!=e&&t!=t};function lr(e,t){if(ur(e,t))return!0;if(\"object\"!=typeof e||null===e||\"object\"!=typeof t||null===t)return!1;var n=Object.keys(e),r=Object.keys(t);if(n.length!==r.length)return!1;for(r=0;r<n.length;r++){var a=n[r];if(!f.call(t,a)||!ur(e[a],t[a]))return!1}return!0}function sr(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function cr(e,t){var n,r=sr(e);for(e=0;r;){if(3===r.nodeType){if(n=e+r.textContent.length,e<=t&&n>=t)return{node:r,offset:t-e};e=n}e:{for(;r;){if(r.nextSibling){r=r.nextSibling;break e}r=r.parentNode}r=void 0}r=sr(r)}}function fr(e,t){return!(!e||!t)&&(e===t||(!e||3!==e.nodeType)&&(t&&3===t.nodeType?fr(e,t.parentNode):\"contains\"in e?e.contains(t):!!e.compareDocumentPosition&&!!(16&e.compareDocumentPosition(t))))}function pr(){for(var e=window,t=Y();t instanceof e.HTMLIFrameElement;){try{var n=\"string\"==typeof t.contentWindow.location.href}catch(e){n=!1}if(!n)break;t=Y((e=t.contentWindow).document)}return t}function dr(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(\"input\"===t&&(\"text\"===e.type||\"search\"===e.type||\"tel\"===e.type||\"url\"===e.type||\"password\"===e.type)||\"textarea\"===t||\"true\"===e.contentEditable)}function hr(e){var t=pr(),n=e.focusedElem,r=e.selectionRange;if(t!==n&&n&&n.ownerDocument&&fr(n.ownerDocument.documentElement,n)){if(null!==r&&dr(n))if(t=r.start,void 0===(e=r.end)&&(e=t),\"selectionStart\"in n)n.selectionStart=t,n.selectionEnd=Math.min(e,n.value.length);else if((e=(t=n.ownerDocument||document)&&t.defaultView||window).getSelection){e=e.getSelection();var a=n.textContent.length,i=Math.min(r.start,a);r=void 0===r.end?i:Math.min(r.end,a),!e.extend&&i>r&&(a=r,r=i,i=a),a=cr(n,i);var o=cr(n,r);a&&o&&(1!==e.rangeCount||e.anchorNode!==a.node||e.anchorOffset!==a.offset||e.focusNode!==o.node||e.focusOffset!==o.offset)&&((t=t.createRange()).setStart(a.node,a.offset),e.removeAllRanges(),i>r?(e.addRange(t),e.extend(o.node,o.offset)):(t.setEnd(o.node,o.offset),e.addRange(t)))}for(t=[],e=n;e=e.parentNode;)1===e.nodeType&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for(\"function\"==typeof n.focus&&n.focus(),n=0;n<t.length;n++)(e=t[n]).element.scrollLeft=e.left,e.element.scrollTop=e.top}}var vr=c&&\"documentMode\"in document&&11>=document.documentMode,gr=null,yr=null,mr=null,br=!1;function _r(e,t,n){var r=n.window===n?n.document:9===n.nodeType?n:n.ownerDocument;br||null==gr||gr!==Y(r)||(r=\"selectionStart\"in(r=gr)&&dr(r)?{start:r.selectionStart,end:r.selectionEnd}:{anchorNode:(r=(r.ownerDocument&&r.ownerDocument.defaultView||window).getSelection()).anchorNode,anchorOffset:r.anchorOffset,focusNode:r.focusNode,focusOffset:r.focusOffset},mr&&lr(mr,r)||(mr=r,0<(r=qr(yr,\"onSelect\")).length&&(t=new cn(\"onSelect\",\"select\",null,t,n),e.push({event:t,listeners:r}),t.target=gr)))}function wr(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n[\"Webkit\"+e]=\"webkit\"+t,n[\"Moz\"+e]=\"moz\"+t,n}var xr={animationend:wr(\"Animation\",\"AnimationEnd\"),animationiteration:wr(\"Animation\",\"AnimationIteration\"),animationstart:wr(\"Animation\",\"AnimationStart\"),transitionend:wr(\"Transition\",\"TransitionEnd\")},kr={},Sr={};function Er(e){if(kr[e])return kr[e];if(!xr[e])return e;var t,n=xr[e];for(t in n)if(n.hasOwnProperty(t)&&t in Sr)return kr[e]=n[t];return e}c&&(Sr=document.createElement(\"div\").style,\"AnimationEvent\"in window||(delete xr.animationend.animation,delete xr.animationiteration.animation,delete xr.animationstart.animation),\"TransitionEvent\"in window||delete xr.transitionend.transition);var Cr=Er(\"animationend\"),Tr=Er(\"animationiteration\"),Mr=Er(\"animationstart\"),Nr=Er(\"transitionend\"),Pr=new Map,zr=\"abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel\".split(\" \");function Lr(e,t){Pr.set(e,t),l(t,[e])}for(var Or=0;Or<zr.length;Or++){var Ar=zr[Or];Lr(Ar.toLowerCase(),\"on\"+(Ar[0].toUpperCase()+Ar.slice(1)))}Lr(Cr,\"onAnimationEnd\"),Lr(Tr,\"onAnimationIteration\"),Lr(Mr,\"onAnimationStart\"),Lr(\"dblclick\",\"onDoubleClick\"),Lr(\"focusin\",\"onFocus\"),Lr(\"focusout\",\"onBlur\"),Lr(Nr,\"onTransitionEnd\"),s(\"onMouseEnter\",[\"mouseout\",\"mouseover\"]),s(\"onMouseLeave\",[\"mouseout\",\"mouseover\"]),s(\"onPointerEnter\",[\"pointerout\",\"pointerover\"]),s(\"onPointerLeave\",[\"pointerout\",\"pointerover\"]),l(\"onChange\",\"change click focusin focusout input keydown keyup selectionchange\".split(\" \")),l(\"onSelect\",\"focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange\".split(\" \")),l(\"onBeforeInput\",[\"compositionend\",\"keypress\",\"textInput\",\"paste\"]),l(\"onCompositionEnd\",\"compositionend focusout keydown keypress keyup mousedown\".split(\" \")),l(\"onCompositionStart\",\"compositionstart focusout keydown keypress keyup mousedown\".split(\" \")),l(\"onCompositionUpdate\",\"compositionupdate focusout keydown keypress keyup mousedown\".split(\" \"));var Fr=\"abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting\".split(\" \"),Dr=new Set(\"cancel close invalid load scroll toggle\".split(\" \").concat(Fr));function Rr(e,t,n){var r=e.type||\"unknown-event\";e.currentTarget=n,function(e,t,n,r,a,o,u,l,s){if($e.apply(this,arguments),De){if(!De)throw Error(i(198));var c=Re;De=!1,Re=null,je||(je=!0,Ue=c)}}(r,t,void 0,e),e.currentTarget=null}function jr(e,t){t=0!=(4&t);for(var n=0;n<e.length;n++){var r=e[n],a=r.event;r=r.listeners;e:{var i=void 0;if(t)for(var o=r.length-1;0<=o;o--){var u=r[o],l=u.instance,s=u.currentTarget;if(u=u.listener,l!==i&&a.isPropagationStopped())break e;Rr(a,u,s),i=l}else for(o=0;o<r.length;o++){if(l=(u=r[o]).instance,s=u.currentTarget,u=u.listener,l!==i&&a.isPropagationStopped())break e;Rr(a,u,s),i=l}}}if(je)throw e=Ue,je=!1,Ue=null,e}function Ur(e,t){var n=t[va];void 0===n&&(n=t[va]=new Set);var r=e+\"__bubble\";n.has(r)||(Wr(t,e,2,!1),n.add(r))}function Ir(e,t,n){var r=0;t&&(r|=4),Wr(n,e,r,t)}var $r=\"_reactListening\"+Math.random().toString(36).slice(2);function Br(e){if(!e[$r]){e[$r]=!0,o.forEach((function(t){\"selectionchange\"!==t&&(Dr.has(t)||Ir(t,!1,e),Ir(t,!0,e))}));var t=9===e.nodeType?e:e.ownerDocument;null===t||t[$r]||(t[$r]=!0,Ir(\"selectionchange\",!1,t))}}function Wr(e,t,n,r){switch(Kt(t)){case 1:var a=Ht;break;case 4:a=qt;break;default:a=Qt}n=a.bind(null,t,n,e),a=void 0,!Oe||\"touchstart\"!==t&&\"touchmove\"!==t&&\"wheel\"!==t||(a=!0),r?void 0!==a?e.addEventListener(t,n,{capture:!0,passive:a}):e.addEventListener(t,n,!0):void 0!==a?e.addEventListener(t,n,{passive:a}):e.addEventListener(t,n,!1)}function Vr(e,t,n,r,a){var i=r;if(0==(1&t)&&0==(2&t)&&null!==r)e:for(;;){if(null===r)return;var o=r.tag;if(3===o||4===o){var u=r.stateNode.containerInfo;if(u===a||8===u.nodeType&&u.parentNode===a)break;if(4===o)for(o=r.return;null!==o;){var l=o.tag;if((3===l||4===l)&&((l=o.stateNode.containerInfo)===a||8===l.nodeType&&l.parentNode===a))return;o=o.return}for(;null!==u;){if(null===(o=ma(u)))return;if(5===(l=o.tag)||6===l){r=i=o;continue e}u=u.parentNode}}r=r.return}ze((function(){var r=i,a=we(n),o=[];e:{var u=Pr.get(e);if(void 0!==u){var l=cn,s=e;switch(e){case\"keypress\":if(0===tn(n))break e;case\"keydown\":case\"keyup\":l=Tn;break;case\"focusin\":s=\"focus\",l=gn;break;case\"focusout\":s=\"blur\",l=gn;break;case\"beforeblur\":case\"afterblur\":l=gn;break;case\"click\":if(2===n.button)break e;case\"auxclick\":case\"dblclick\":case\"mousedown\":case\"mousemove\":case\"mouseup\":case\"mouseout\":case\"mouseover\":case\"contextmenu\":l=hn;break;case\"drag\":case\"dragend\":case\"dragenter\":case\"dragexit\":case\"dragleave\":case\"dragover\":case\"dragstart\":case\"drop\":l=vn;break;case\"touchcancel\":case\"touchend\":case\"touchmove\":case\"touchstart\":l=Nn;break;case Cr:case Tr:case Mr:l=yn;break;case Nr:l=Pn;break;case\"scroll\":l=pn;break;case\"wheel\":l=Ln;break;case\"copy\":case\"cut\":case\"paste\":l=bn;break;case\"gotpointercapture\":case\"lostpointercapture\":case\"pointercancel\":case\"pointerdown\":case\"pointermove\":case\"pointerout\":case\"pointerover\":case\"pointerup\":l=Mn}var c=0!=(4&t),f=!c&&\"scroll\"===e,p=c?null!==u?u+\"Capture\":null:u;c=[];for(var d,h=r;null!==h;){var v=(d=h).stateNode;if(5===d.tag&&null!==v&&(d=v,null!==p&&null!=(v=Le(h,p))&&c.push(Hr(h,v,d))),f)break;h=h.return}0<c.length&&(u=new l(u,s,null,n,a),o.push({event:u,listeners:c}))}}if(0==(7&t)){if(l=\"mouseout\"===e||\"pointerout\"===e,(!(u=\"mouseover\"===e||\"pointerover\"===e)||n===_e||!(s=n.relatedTarget||n.fromElement)||!ma(s)&&!s[ha])&&(l||u)&&(u=a.window===a?a:(u=a.ownerDocument)?u.defaultView||u.parentWindow:window,l?(l=r,null!==(s=(s=n.relatedTarget||n.toElement)?ma(s):null)&&(s!==(f=Be(s))||5!==s.tag&&6!==s.tag)&&(s=null)):(l=null,s=r),l!==s)){if(c=hn,v=\"onMouseLeave\",p=\"onMouseEnter\",h=\"mouse\",\"pointerout\"!==e&&\"pointerover\"!==e||(c=Mn,v=\"onPointerLeave\",p=\"onPointerEnter\",h=\"pointer\"),f=null==l?u:_a(l),d=null==s?u:_a(s),(u=new c(v,h+\"leave\",l,n,a)).target=f,u.relatedTarget=d,v=null,ma(a)===r&&((c=new c(p,h+\"enter\",s,n,a)).target=d,c.relatedTarget=f,v=c),f=v,l&&s)e:{for(p=s,h=0,d=c=l;d;d=Qr(d))h++;for(d=0,v=p;v;v=Qr(v))d++;for(;0<h-d;)c=Qr(c),h--;for(;0<d-h;)p=Qr(p),d--;for(;h--;){if(c===p||null!==p&&c===p.alternate)break e;c=Qr(c),p=Qr(p)}c=null}else c=null;null!==l&&Yr(o,u,l,c,!1),null!==s&&null!==f&&Yr(o,f,s,c,!0)}if(\"select\"===(l=(u=r?_a(r):window).nodeName&&u.nodeName.toLowerCase())||\"input\"===l&&\"file\"===u.type)var g=Kn;else if(Vn(u))if(Zn)g=or;else{g=ar;var y=rr}else(l=u.nodeName)&&\"input\"===l.toLowerCase()&&(\"checkbox\"===u.type||\"radio\"===u.type)&&(g=ir);switch(g&&(g=g(e,r))?Hn(o,g,n,a):(y&&y(e,u,r),\"focusout\"===e&&(y=u._wrapperState)&&y.controlled&&\"number\"===u.type&&ee(u,\"number\",u.value)),y=r?_a(r):window,e){case\"focusin\":(Vn(y)||\"true\"===y.contentEditable)&&(gr=y,yr=r,mr=null);break;case\"focusout\":mr=yr=gr=null;break;case\"mousedown\":br=!0;break;case\"contextmenu\":case\"mouseup\":case\"dragend\":br=!1,_r(o,n,a);break;case\"selectionchange\":if(vr)break;case\"keydown\":case\"keyup\":_r(o,n,a)}var m;if(An)e:{switch(e){case\"compositionstart\":var b=\"onCompositionStart\";break e;case\"compositionend\":b=\"onCompositionEnd\";break e;case\"compositionupdate\":b=\"onCompositionUpdate\";break e}b=void 0}else Bn?In(e,n)&&(b=\"onCompositionEnd\"):\"keydown\"===e&&229===n.keyCode&&(b=\"onCompositionStart\");b&&(Rn&&\"ko\"!==n.locale&&(Bn||\"onCompositionStart\"!==b?\"onCompositionEnd\"===b&&Bn&&(m=en()):(Xt=\"value\"in(Zt=a)?Zt.value:Zt.textContent,Bn=!0)),0<(y=qr(r,b)).length&&(b=new _n(b,e,null,n,a),o.push({event:b,listeners:y}),(m||null!==(m=$n(n)))&&(b.data=m))),(m=Dn?function(e,t){switch(e){case\"compositionend\":return $n(t);case\"keypress\":return 32!==t.which?null:(Un=!0,jn);case\"textInput\":return(e=t.data)===jn&&Un?null:e;default:return null}}(e,n):function(e,t){if(Bn)return\"compositionend\"===e||!An&&In(e,t)?(e=en(),Jt=Xt=Zt=null,Bn=!1,e):null;switch(e){case\"paste\":default:return null;case\"keypress\":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case\"compositionend\":return Rn&&\"ko\"!==t.locale?null:t.data}}(e,n))&&0<(r=qr(r,\"onBeforeInput\")).length&&(a=new _n(\"onBeforeInput\",\"beforeinput\",null,n,a),o.push({event:a,listeners:r}),a.data=m)}jr(o,t)}))}function Hr(e,t,n){return{instance:e,listener:t,currentTarget:n}}function qr(e,t){for(var n=t+\"Capture\",r=[];null!==e;){var a=e,i=a.stateNode;5===a.tag&&null!==i&&(a=i,null!=(i=Le(e,n))&&r.unshift(Hr(e,i,a)),null!=(i=Le(e,t))&&r.push(Hr(e,i,a))),e=e.return}return r}function Qr(e){if(null===e)return null;do{e=e.return}while(e&&5!==e.tag);return e||null}function Yr(e,t,n,r,a){for(var i=t._reactName,o=[];null!==n&&n!==r;){var u=n,l=u.alternate,s=u.stateNode;if(null!==l&&l===r)break;5===u.tag&&null!==s&&(u=s,a?null!=(l=Le(n,i))&&o.unshift(Hr(n,l,u)):a||null!=(l=Le(n,i))&&o.push(Hr(n,l,u))),n=n.return}0!==o.length&&e.push({event:t,listeners:o})}var Gr=/\\r\\n?/g,Kr=/\\u0000|\\uFFFD/g;function Zr(e){return(\"string\"==typeof e?e:\"\"+e).replace(Gr,\"\\n\").replace(Kr,\"\")}function Xr(e,t,n){if(t=Zr(t),Zr(e)!==t&&n)throw Error(i(425))}function Jr(){}var ea=null,ta=null;function na(e,t){return\"textarea\"===e||\"noscript\"===e||\"string\"==typeof t.children||\"number\"==typeof t.children||\"object\"==typeof t.dangerouslySetInnerHTML&&null!==t.dangerouslySetInnerHTML&&null!=t.dangerouslySetInnerHTML.__html}var ra=\"function\"==typeof setTimeout?setTimeout:void 0,aa=\"function\"==typeof clearTimeout?clearTimeout:void 0,ia=\"function\"==typeof Promise?Promise:void 0,oa=\"function\"==typeof queueMicrotask?queueMicrotask:void 0!==ia?function(e){return ia.resolve(null).then(e).catch(ua)}:ra;function ua(e){setTimeout((function(){throw e}))}function la(e,t){var n=t,r=0;do{var a=n.nextSibling;if(e.removeChild(n),a&&8===a.nodeType)if(\"/$\"===(n=a.data)){if(0===r)return e.removeChild(a),void Bt(t);r--}else\"$\"!==n&&\"$?\"!==n&&\"$!\"!==n||r++;n=a}while(n);Bt(t)}function sa(e){for(;null!=e;e=e.nextSibling){var t=e.nodeType;if(1===t||3===t)break;if(8===t){if(\"$\"===(t=e.data)||\"$!\"===t||\"$?\"===t)break;if(\"/$\"===t)return null}}return e}function ca(e){e=e.previousSibling;for(var t=0;e;){if(8===e.nodeType){var n=e.data;if(\"$\"===n||\"$!\"===n||\"$?\"===n){if(0===t)return e;t--}else\"/$\"===n&&t++}e=e.previousSibling}return null}var fa=Math.random().toString(36).slice(2),pa=\"__reactFiber$\"+fa,da=\"__reactProps$\"+fa,ha=\"__reactContainer$\"+fa,va=\"__reactEvents$\"+fa,ga=\"__reactListeners$\"+fa,ya=\"__reactHandles$\"+fa;function ma(e){var t=e[pa];if(t)return t;for(var n=e.parentNode;n;){if(t=n[ha]||n[pa]){if(n=t.alternate,null!==t.child||null!==n&&null!==n.child)for(e=ca(e);null!==e;){if(n=e[pa])return n;e=ca(e)}return t}n=(e=n).parentNode}return null}function ba(e){return!(e=e[pa]||e[ha])||5!==e.tag&&6!==e.tag&&13!==e.tag&&3!==e.tag?null:e}function _a(e){if(5===e.tag||6===e.tag)return e.stateNode;throw Error(i(33))}function wa(e){return e[da]||null}var xa=[],ka=-1;function Sa(e){return{current:e}}function Ea(e){0>ka||(e.current=xa[ka],xa[ka]=null,ka--)}function Ca(e,t){ka++,xa[ka]=e.current,e.current=t}var Ta={},Ma=Sa(Ta),Na=Sa(!1),Pa=Ta;function za(e,t){var n=e.type.contextTypes;if(!n)return Ta;var r=e.stateNode;if(r&&r.__reactInternalMemoizedUnmaskedChildContext===t)return r.__reactInternalMemoizedMaskedChildContext;var a,i={};for(a in n)i[a]=t[a];return r&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=i),i}function La(e){return null!=e.childContextTypes}function Oa(){Ea(Na),Ea(Ma)}function Aa(e,t,n){if(Ma.current!==Ta)throw Error(i(168));Ca(Ma,t),Ca(Na,n)}function Fa(e,t,n){var r=e.stateNode;if(t=t.childContextTypes,\"function\"!=typeof r.getChildContext)return n;for(var a in r=r.getChildContext())if(!(a in t))throw Error(i(108,W(e)||\"Unknown\",a));return R({},n,r)}function Da(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||Ta,Pa=Ma.current,Ca(Ma,e),Ca(Na,Na.current),!0}function Ra(e,t,n){var r=e.stateNode;if(!r)throw Error(i(169));n?(e=Fa(e,t,Pa),r.__reactInternalMemoizedMergedChildContext=e,Ea(Na),Ea(Ma),Ca(Ma,e)):Ea(Na),Ca(Na,n)}var ja=null,Ua=!1,Ia=!1;function $a(e){null===ja?ja=[e]:ja.push(e)}function Ba(){if(!Ia&&null!==ja){Ia=!0;var e=0,t=bt;try{var n=ja;for(bt=1;e<n.length;e++){var r=n[e];do{r=r(!0)}while(null!==r)}ja=null,Ua=!1}catch(t){throw null!==ja&&(ja=ja.slice(e+1)),Qe(Je,Ba),t}finally{bt=t,Ia=!1}}return null}var Wa=[],Va=0,Ha=null,qa=0,Qa=[],Ya=0,Ga=null,Ka=1,Za=\"\";function Xa(e,t){Wa[Va++]=qa,Wa[Va++]=Ha,Ha=e,qa=t}function Ja(e,t,n){Qa[Ya++]=Ka,Qa[Ya++]=Za,Qa[Ya++]=Ga,Ga=e;var r=Ka;e=Za;var a=32-ot(r)-1;r&=~(1<<a),n+=1;var i=32-ot(t)+a;if(30<i){var o=a-a%5;i=(r&(1<<o)-1).toString(32),r>>=o,a-=o,Ka=1<<32-ot(t)+a|n<<a|r,Za=i+e}else Ka=1<<i|n<<a|r,Za=e}function ei(e){null!==e.return&&(Xa(e,1),Ja(e,1,0))}function ti(e){for(;e===Ha;)Ha=Wa[--Va],Wa[Va]=null,qa=Wa[--Va],Wa[Va]=null;for(;e===Ga;)Ga=Qa[--Ya],Qa[Ya]=null,Za=Qa[--Ya],Qa[Ya]=null,Ka=Qa[--Ya],Qa[Ya]=null}var ni=null,ri=null,ai=!1,ii=null;function oi(e,t){var n=Ls(5,null,null,0);n.elementType=\"DELETED\",n.stateNode=t,n.return=e,null===(t=e.deletions)?(e.deletions=[n],e.flags|=16):t.push(n)}function ui(e,t){switch(e.tag){case 5:var n=e.type;return null!==(t=1!==t.nodeType||n.toLowerCase()!==t.nodeName.toLowerCase()?null:t)&&(e.stateNode=t,ni=e,ri=sa(t.firstChild),!0);case 6:return null!==(t=\"\"===e.pendingProps||3!==t.nodeType?null:t)&&(e.stateNode=t,ni=e,ri=null,!0);case 13:return null!==(t=8!==t.nodeType?null:t)&&(n=null!==Ga?{id:Ka,overflow:Za}:null,e.memoizedState={dehydrated:t,treeContext:n,retryLane:1073741824},(n=Ls(18,null,null,0)).stateNode=t,n.return=e,e.child=n,ni=e,ri=null,!0);default:return!1}}function li(e){return 0!=(1&e.mode)&&0==(128&e.flags)}function si(e){if(ai){var t=ri;if(t){var n=t;if(!ui(e,t)){if(li(e))throw Error(i(418));t=sa(n.nextSibling);var r=ni;t&&ui(e,t)?oi(r,n):(e.flags=-4097&e.flags|2,ai=!1,ni=e)}}else{if(li(e))throw Error(i(418));e.flags=-4097&e.flags|2,ai=!1,ni=e}}}function ci(e){for(e=e.return;null!==e&&5!==e.tag&&3!==e.tag&&13!==e.tag;)e=e.return;ni=e}function fi(e){if(e!==ni)return!1;if(!ai)return ci(e),ai=!0,!1;var t;if((t=3!==e.tag)&&!(t=5!==e.tag)&&(t=\"head\"!==(t=e.type)&&\"body\"!==t&&!na(e.type,e.memoizedProps)),t&&(t=ri)){if(li(e))throw pi(),Error(i(418));for(;t;)oi(e,t),t=sa(t.nextSibling)}if(ci(e),13===e.tag){if(!(e=null!==(e=e.memoizedState)?e.dehydrated:null))throw Error(i(317));e:{for(e=e.nextSibling,t=0;e;){if(8===e.nodeType){var n=e.data;if(\"/$\"===n){if(0===t){ri=sa(e.nextSibling);break e}t--}else\"$\"!==n&&\"$!\"!==n&&\"$?\"!==n||t++}e=e.nextSibling}ri=null}}else ri=ni?sa(e.stateNode.nextSibling):null;return!0}function pi(){for(var e=ri;e;)e=sa(e.nextSibling)}function di(){ri=ni=null,ai=!1}function hi(e){null===ii?ii=[e]:ii.push(e)}var vi=_.ReactCurrentBatchConfig;function gi(e,t){if(e&&e.defaultProps){for(var n in t=R({},t),e=e.defaultProps)void 0===t[n]&&(t[n]=e[n]);return t}return t}var yi=Sa(null),mi=null,bi=null,_i=null;function wi(){_i=bi=mi=null}function xi(e){var t=yi.current;Ea(yi),e._currentValue=t}function ki(e,t,n){for(;null!==e;){var r=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,null!==r&&(r.childLanes|=t)):null!==r&&(r.childLanes&t)!==t&&(r.childLanes|=t),e===n)break;e=e.return}}function Si(e,t){mi=e,_i=bi=null,null!==(e=e.dependencies)&&null!==e.firstContext&&(0!=(e.lanes&t)&&(_u=!0),e.firstContext=null)}function Ei(e){var t=e._currentValue;if(_i!==e)if(e={context:e,memoizedValue:t,next:null},null===bi){if(null===mi)throw Error(i(308));bi=e,mi.dependencies={lanes:0,firstContext:e}}else bi=bi.next=e;return t}var Ci=null;function Ti(e){null===Ci?Ci=[e]:Ci.push(e)}function Mi(e,t,n,r){var a=t.interleaved;return null===a?(n.next=n,Ti(t)):(n.next=a.next,a.next=n),t.interleaved=n,Ni(e,r)}function Ni(e,t){e.lanes|=t;var n=e.alternate;for(null!==n&&(n.lanes|=t),n=e,e=e.return;null!==e;)e.childLanes|=t,null!==(n=e.alternate)&&(n.childLanes|=t),n=e,e=e.return;return 3===n.tag?n.stateNode:null}var Pi=!1;function zi(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Li(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function Oi(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Ai(e,t,n){var r=e.updateQueue;if(null===r)return null;if(r=r.shared,0!=(2&Nl)){var a=r.pending;return null===a?t.next=t:(t.next=a.next,a.next=t),r.pending=t,Ni(e,n)}return null===(a=r.interleaved)?(t.next=t,Ti(r)):(t.next=a.next,a.next=t),r.interleaved=t,Ni(e,n)}function Fi(e,t,n){if(null!==(t=t.updateQueue)&&(t=t.shared,0!=(4194240&n))){var r=t.lanes;n|=r&=e.pendingLanes,t.lanes=n,mt(e,n)}}function Di(e,t){var n=e.updateQueue,r=e.alternate;if(null!==r&&n===(r=r.updateQueue)){var a=null,i=null;if(null!==(n=n.firstBaseUpdate)){do{var o={eventTime:n.eventTime,lane:n.lane,tag:n.tag,payload:n.payload,callback:n.callback,next:null};null===i?a=i=o:i=i.next=o,n=n.next}while(null!==n);null===i?a=i=t:i=i.next=t}else a=i=t;return n={baseState:r.baseState,firstBaseUpdate:a,lastBaseUpdate:i,shared:r.shared,effects:r.effects},void(e.updateQueue=n)}null===(e=n.lastBaseUpdate)?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}function Ri(e,t,n,r){var a=e.updateQueue;Pi=!1;var i=a.firstBaseUpdate,o=a.lastBaseUpdate,u=a.shared.pending;if(null!==u){a.shared.pending=null;var l=u,s=l.next;l.next=null,null===o?i=s:o.next=s,o=l;var c=e.alternate;null!==c&&(u=(c=c.updateQueue).lastBaseUpdate)!==o&&(null===u?c.firstBaseUpdate=s:u.next=s,c.lastBaseUpdate=l)}if(null!==i){var f=a.baseState;for(o=0,c=s=l=null,u=i;;){var p=u.lane,d=u.eventTime;if((r&p)===p){null!==c&&(c=c.next={eventTime:d,lane:0,tag:u.tag,payload:u.payload,callback:u.callback,next:null});e:{var h=e,v=u;switch(p=t,d=n,v.tag){case 1:if(\"function\"==typeof(h=v.payload)){f=h.call(d,f,p);break e}f=h;break e;case 3:h.flags=-65537&h.flags|128;case 0:if(null==(p=\"function\"==typeof(h=v.payload)?h.call(d,f,p):h))break e;f=R({},f,p);break e;case 2:Pi=!0}}null!==u.callback&&0!==u.lane&&(e.flags|=64,null===(p=a.effects)?a.effects=[u]:p.push(u))}else d={eventTime:d,lane:p,tag:u.tag,payload:u.payload,callback:u.callback,next:null},null===c?(s=c=d,l=f):c=c.next=d,o|=p;if(null===(u=u.next)){if(null===(u=a.shared.pending))break;u=(p=u).next,p.next=null,a.lastBaseUpdate=p,a.shared.pending=null}}if(null===c&&(l=f),a.baseState=l,a.firstBaseUpdate=s,a.lastBaseUpdate=c,null!==(t=a.shared.interleaved)){a=t;do{o|=a.lane,a=a.next}while(a!==t)}else null===i&&(a.shared.lanes=0);Rl|=o,e.lanes=o,e.memoizedState=f}}function ji(e,t,n){if(e=t.effects,t.effects=null,null!==e)for(t=0;t<e.length;t++){var r=e[t],a=r.callback;if(null!==a){if(r.callback=null,r=n,\"function\"!=typeof a)throw Error(i(191,a));a.call(r)}}}var Ui=(new r.Component).refs;function Ii(e,t,n,r){n=null==(n=n(r,t=e.memoizedState))?t:R({},t,n),e.memoizedState=n,0===e.lanes&&(e.updateQueue.baseState=n)}var $i={isMounted:function(e){return!!(e=e._reactInternals)&&Be(e)===e},enqueueSetState:function(e,t,n){e=e._reactInternals;var r=ts(),a=ns(e),i=Oi(r,a);i.payload=t,null!=n&&(i.callback=n),null!==(t=Ai(e,i,a))&&(rs(t,e,a,r),Fi(t,e,a))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var r=ts(),a=ns(e),i=Oi(r,a);i.tag=1,i.payload=t,null!=n&&(i.callback=n),null!==(t=Ai(e,i,a))&&(rs(t,e,a,r),Fi(t,e,a))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=ts(),r=ns(e),a=Oi(n,r);a.tag=2,null!=t&&(a.callback=t),null!==(t=Ai(e,a,r))&&(rs(t,e,r,n),Fi(t,e,r))}};function Bi(e,t,n,r,a,i,o){return\"function\"==typeof(e=e.stateNode).shouldComponentUpdate?e.shouldComponentUpdate(r,i,o):!(t.prototype&&t.prototype.isPureReactComponent&&lr(n,r)&&lr(a,i))}function Wi(e,t,n){var r=!1,a=Ta,i=t.contextType;return\"object\"==typeof i&&null!==i?i=Ei(i):(a=La(t)?Pa:Ma.current,i=(r=null!=(r=t.contextTypes))?za(e,a):Ta),t=new t(n,i),e.memoizedState=null!==t.state&&void 0!==t.state?t.state:null,t.updater=$i,e.stateNode=t,t._reactInternals=e,r&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=a,e.__reactInternalMemoizedMaskedChildContext=i),t}function Vi(e,t,n,r){e=t.state,\"function\"==typeof t.componentWillReceiveProps&&t.componentWillReceiveProps(n,r),\"function\"==typeof t.UNSAFE_componentWillReceiveProps&&t.UNSAFE_componentWillReceiveProps(n,r),t.state!==e&&$i.enqueueReplaceState(t,t.state,null)}function Hi(e,t,n,r){var a=e.stateNode;a.props=n,a.state=e.memoizedState,a.refs=Ui,zi(e);var i=t.contextType;\"object\"==typeof i&&null!==i?a.context=Ei(i):(i=La(t)?Pa:Ma.current,a.context=za(e,i)),a.state=e.memoizedState,\"function\"==typeof(i=t.getDerivedStateFromProps)&&(Ii(e,t,i,n),a.state=e.memoizedState),\"function\"==typeof t.getDerivedStateFromProps||\"function\"==typeof a.getSnapshotBeforeUpdate||\"function\"!=typeof a.UNSAFE_componentWillMount&&\"function\"!=typeof a.componentWillMount||(t=a.state,\"function\"==typeof a.componentWillMount&&a.componentWillMount(),\"function\"==typeof a.UNSAFE_componentWillMount&&a.UNSAFE_componentWillMount(),t!==a.state&&$i.enqueueReplaceState(a,a.state,null),Ri(e,n,a,r),a.state=e.memoizedState),\"function\"==typeof a.componentDidMount&&(e.flags|=4194308)}function qi(e,t,n){if(null!==(e=n.ref)&&\"function\"!=typeof e&&\"object\"!=typeof e){if(n._owner){if(n=n._owner){if(1!==n.tag)throw Error(i(309));var r=n.stateNode}if(!r)throw Error(i(147,e));var a=r,o=\"\"+e;return null!==t&&null!==t.ref&&\"function\"==typeof t.ref&&t.ref._stringRef===o?t.ref:(t=function(e){var t=a.refs;t===Ui&&(t=a.refs={}),null===e?delete t[o]:t[o]=e},t._stringRef=o,t)}if(\"string\"!=typeof e)throw Error(i(284));if(!n._owner)throw Error(i(290,e))}return e}function Qi(e,t){throw e=Object.prototype.toString.call(t),Error(i(31,\"[object Object]\"===e?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":e))}function Yi(e){return(0,e._init)(e._payload)}function Gi(e){function t(t,n){if(e){var r=t.deletions;null===r?(t.deletions=[n],t.flags|=16):r.push(n)}}function n(n,r){if(!e)return null;for(;null!==r;)t(n,r),r=r.sibling;return null}function r(e,t){for(e=new Map;null!==t;)null!==t.key?e.set(t.key,t):e.set(t.index,t),t=t.sibling;return e}function a(e,t){return(e=As(e,t)).index=0,e.sibling=null,e}function o(t,n,r){return t.index=r,e?null!==(r=t.alternate)?(r=r.index)<n?(t.flags|=2,n):r:(t.flags|=2,n):(t.flags|=1048576,n)}function u(t){return e&&null===t.alternate&&(t.flags|=2),t}function l(e,t,n,r){return null===t||6!==t.tag?((t=js(n,e.mode,r)).return=e,t):((t=a(t,n)).return=e,t)}function s(e,t,n,r){var i=n.type;return i===k?f(e,t,n.props.children,r,n.key):null!==t&&(t.elementType===i||\"object\"==typeof i&&null!==i&&i.$$typeof===L&&Yi(i)===t.type)?((r=a(t,n.props)).ref=qi(e,t,n),r.return=e,r):((r=Fs(n.type,n.key,n.props,null,e.mode,r)).ref=qi(e,t,n),r.return=e,r)}function c(e,t,n,r){return null===t||4!==t.tag||t.stateNode.containerInfo!==n.containerInfo||t.stateNode.implementation!==n.implementation?((t=Us(n,e.mode,r)).return=e,t):((t=a(t,n.children||[])).return=e,t)}function f(e,t,n,r,i){return null===t||7!==t.tag?((t=Ds(n,e.mode,r,i)).return=e,t):((t=a(t,n)).return=e,t)}function p(e,t,n){if(\"string\"==typeof t&&\"\"!==t||\"number\"==typeof t)return(t=js(\"\"+t,e.mode,n)).return=e,t;if(\"object\"==typeof t&&null!==t){switch(t.$$typeof){case w:return(n=Fs(t.type,t.key,t.props,null,e.mode,n)).ref=qi(e,null,t),n.return=e,n;case x:return(t=Us(t,e.mode,n)).return=e,t;case L:return p(e,(0,t._init)(t._payload),n)}if(te(t)||F(t))return(t=Ds(t,e.mode,n,null)).return=e,t;Qi(e,t)}return null}function d(e,t,n,r){var a=null!==t?t.key:null;if(\"string\"==typeof n&&\"\"!==n||\"number\"==typeof n)return null!==a?null:l(e,t,\"\"+n,r);if(\"object\"==typeof n&&null!==n){switch(n.$$typeof){case w:return n.key===a?s(e,t,n,r):null;case x:return n.key===a?c(e,t,n,r):null;case L:return d(e,t,(a=n._init)(n._payload),r)}if(te(n)||F(n))return null!==a?null:f(e,t,n,r,null);Qi(e,n)}return null}function h(e,t,n,r,a){if(\"string\"==typeof r&&\"\"!==r||\"number\"==typeof r)return l(t,e=e.get(n)||null,\"\"+r,a);if(\"object\"==typeof r&&null!==r){switch(r.$$typeof){case w:return s(t,e=e.get(null===r.key?n:r.key)||null,r,a);case x:return c(t,e=e.get(null===r.key?n:r.key)||null,r,a);case L:return h(e,t,n,(0,r._init)(r._payload),a)}if(te(r)||F(r))return f(t,e=e.get(n)||null,r,a,null);Qi(t,r)}return null}function v(a,i,u,l){for(var s=null,c=null,f=i,v=i=0,g=null;null!==f&&v<u.length;v++){f.index>v?(g=f,f=null):g=f.sibling;var y=d(a,f,u[v],l);if(null===y){null===f&&(f=g);break}e&&f&&null===y.alternate&&t(a,f),i=o(y,i,v),null===c?s=y:c.sibling=y,c=y,f=g}if(v===u.length)return n(a,f),ai&&Xa(a,v),s;if(null===f){for(;v<u.length;v++)null!==(f=p(a,u[v],l))&&(i=o(f,i,v),null===c?s=f:c.sibling=f,c=f);return ai&&Xa(a,v),s}for(f=r(a,f);v<u.length;v++)null!==(g=h(f,a,v,u[v],l))&&(e&&null!==g.alternate&&f.delete(null===g.key?v:g.key),i=o(g,i,v),null===c?s=g:c.sibling=g,c=g);return e&&f.forEach((function(e){return t(a,e)})),ai&&Xa(a,v),s}function g(a,u,l,s){var c=F(l);if(\"function\"!=typeof c)throw Error(i(150));if(null==(l=c.call(l)))throw Error(i(151));for(var f=c=null,v=u,g=u=0,y=null,m=l.next();null!==v&&!m.done;g++,m=l.next()){v.index>g?(y=v,v=null):y=v.sibling;var b=d(a,v,m.value,s);if(null===b){null===v&&(v=y);break}e&&v&&null===b.alternate&&t(a,v),u=o(b,u,g),null===f?c=b:f.sibling=b,f=b,v=y}if(m.done)return n(a,v),ai&&Xa(a,g),c;if(null===v){for(;!m.done;g++,m=l.next())null!==(m=p(a,m.value,s))&&(u=o(m,u,g),null===f?c=m:f.sibling=m,f=m);return ai&&Xa(a,g),c}for(v=r(a,v);!m.done;g++,m=l.next())null!==(m=h(v,a,g,m.value,s))&&(e&&null!==m.alternate&&v.delete(null===m.key?g:m.key),u=o(m,u,g),null===f?c=m:f.sibling=m,f=m);return e&&v.forEach((function(e){return t(a,e)})),ai&&Xa(a,g),c}return function e(r,i,o,l){if(\"object\"==typeof o&&null!==o&&o.type===k&&null===o.key&&(o=o.props.children),\"object\"==typeof o&&null!==o){switch(o.$$typeof){case w:e:{for(var s=o.key,c=i;null!==c;){if(c.key===s){if((s=o.type)===k){if(7===c.tag){n(r,c.sibling),(i=a(c,o.props.children)).return=r,r=i;break e}}else if(c.elementType===s||\"object\"==typeof s&&null!==s&&s.$$typeof===L&&Yi(s)===c.type){n(r,c.sibling),(i=a(c,o.props)).ref=qi(r,c,o),i.return=r,r=i;break e}n(r,c);break}t(r,c),c=c.sibling}o.type===k?((i=Ds(o.props.children,r.mode,l,o.key)).return=r,r=i):((l=Fs(o.type,o.key,o.props,null,r.mode,l)).ref=qi(r,i,o),l.return=r,r=l)}return u(r);case x:e:{for(c=o.key;null!==i;){if(i.key===c){if(4===i.tag&&i.stateNode.containerInfo===o.containerInfo&&i.stateNode.implementation===o.implementation){n(r,i.sibling),(i=a(i,o.children||[])).return=r,r=i;break e}n(r,i);break}t(r,i),i=i.sibling}(i=Us(o,r.mode,l)).return=r,r=i}return u(r);case L:return e(r,i,(c=o._init)(o._payload),l)}if(te(o))return v(r,i,o,l);if(F(o))return g(r,i,o,l);Qi(r,o)}return\"string\"==typeof o&&\"\"!==o||\"number\"==typeof o?(o=\"\"+o,null!==i&&6===i.tag?(n(r,i.sibling),(i=a(i,o)).return=r,r=i):(n(r,i),(i=js(o,r.mode,l)).return=r,r=i),u(r)):n(r,i)}}var Ki=Gi(!0),Zi=Gi(!1),Xi={},Ji=Sa(Xi),eo=Sa(Xi),to=Sa(Xi);function no(e){if(e===Xi)throw Error(i(174));return e}function ro(e,t){switch(Ca(to,t),Ca(eo,e),Ca(Ji,Xi),e=t.nodeType){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:le(null,\"\");break;default:t=le(t=(e=8===e?t.parentNode:t).namespaceURI||null,e=e.tagName)}Ea(Ji),Ca(Ji,t)}function ao(){Ea(Ji),Ea(eo),Ea(to)}function io(e){no(to.current);var t=no(Ji.current),n=le(t,e.type);t!==n&&(Ca(eo,e),Ca(Ji,n))}function oo(e){eo.current===e&&(Ea(Ji),Ea(eo))}var uo=Sa(0);function lo(e){for(var t=e;null!==t;){if(13===t.tag){var n=t.memoizedState;if(null!==n&&(null===(n=n.dehydrated)||\"$?\"===n.data||\"$!\"===n.data))return t}else if(19===t.tag&&void 0!==t.memoizedProps.revealOrder){if(0!=(128&t.flags))return t}else if(null!==t.child){t.child.return=t,t=t.child;continue}if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var so=[];function co(){for(var e=0;e<so.length;e++)so[e]._workInProgressVersionPrimary=null;so.length=0}var fo=_.ReactCurrentDispatcher,po=_.ReactCurrentBatchConfig,ho=0,vo=null,go=null,yo=null,mo=!1,bo=!1,_o=0,wo=0;function xo(){throw Error(i(321))}function ko(e,t){if(null===t)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!ur(e[n],t[n]))return!1;return!0}function So(e,t,n,r,a,o){if(ho=o,vo=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,fo.current=null===e||null===e.memoizedState?uu:lu,e=n(r,a),bo){o=0;do{if(bo=!1,_o=0,25<=o)throw Error(i(301));o+=1,yo=go=null,t.updateQueue=null,fo.current=su,e=n(r,a)}while(bo)}if(fo.current=ou,t=null!==go&&null!==go.next,ho=0,yo=go=vo=null,mo=!1,t)throw Error(i(300));return e}function Eo(){var e=0!==_o;return _o=0,e}function Co(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return null===yo?vo.memoizedState=yo=e:yo=yo.next=e,yo}function To(){if(null===go){var e=vo.alternate;e=null!==e?e.memoizedState:null}else e=go.next;var t=null===yo?vo.memoizedState:yo.next;if(null!==t)yo=t,go=e;else{if(null===e)throw Error(i(310));e={memoizedState:(go=e).memoizedState,baseState:go.baseState,baseQueue:go.baseQueue,queue:go.queue,next:null},null===yo?vo.memoizedState=yo=e:yo=yo.next=e}return yo}function Mo(e,t){return\"function\"==typeof t?t(e):t}function No(e){var t=To(),n=t.queue;if(null===n)throw Error(i(311));n.lastRenderedReducer=e;var r=go,a=r.baseQueue,o=n.pending;if(null!==o){if(null!==a){var u=a.next;a.next=o.next,o.next=u}r.baseQueue=a=o,n.pending=null}if(null!==a){o=a.next,r=r.baseState;var l=u=null,s=null,c=o;do{var f=c.lane;if((ho&f)===f)null!==s&&(s=s.next={lane:0,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null}),r=c.hasEagerState?c.eagerState:e(r,c.action);else{var p={lane:f,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null};null===s?(l=s=p,u=r):s=s.next=p,vo.lanes|=f,Rl|=f}c=c.next}while(null!==c&&c!==o);null===s?u=r:s.next=l,ur(r,t.memoizedState)||(_u=!0),t.memoizedState=r,t.baseState=u,t.baseQueue=s,n.lastRenderedState=r}if(null!==(e=n.interleaved)){a=e;do{o=a.lane,vo.lanes|=o,Rl|=o,a=a.next}while(a!==e)}else null===a&&(n.lanes=0);return[t.memoizedState,n.dispatch]}function Po(e){var t=To(),n=t.queue;if(null===n)throw Error(i(311));n.lastRenderedReducer=e;var r=n.dispatch,a=n.pending,o=t.memoizedState;if(null!==a){n.pending=null;var u=a=a.next;do{o=e(o,u.action),u=u.next}while(u!==a);ur(o,t.memoizedState)||(_u=!0),t.memoizedState=o,null===t.baseQueue&&(t.baseState=o),n.lastRenderedState=o}return[o,r]}function zo(){}function Lo(e,t){var n=vo,r=To(),a=t(),o=!ur(r.memoizedState,a);if(o&&(r.memoizedState=a,_u=!0),r=r.queue,Vo(Fo.bind(null,n,r,e),[e]),r.getSnapshot!==t||o||null!==yo&&1&yo.memoizedState.tag){if(n.flags|=2048,Uo(9,Ao.bind(null,n,r,a,t),void 0,null),null===Pl)throw Error(i(349));0!=(30&ho)||Oo(n,t,a)}return a}function Oo(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},null===(t=vo.updateQueue)?(t={lastEffect:null,stores:null},vo.updateQueue=t,t.stores=[e]):null===(n=t.stores)?t.stores=[e]:n.push(e)}function Ao(e,t,n,r){t.value=n,t.getSnapshot=r,Do(t)&&Ro(e)}function Fo(e,t,n){return n((function(){Do(t)&&Ro(e)}))}function Do(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!ur(e,n)}catch(e){return!0}}function Ro(e){var t=Ni(e,1);null!==t&&rs(t,e,1,-1)}function jo(e){var t=Co();return\"function\"==typeof e&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:Mo,lastRenderedState:e},t.queue=e,e=e.dispatch=nu.bind(null,vo,e),[t.memoizedState,e]}function Uo(e,t,n,r){return e={tag:e,create:t,destroy:n,deps:r,next:null},null===(t=vo.updateQueue)?(t={lastEffect:null,stores:null},vo.updateQueue=t,t.lastEffect=e.next=e):null===(n=t.lastEffect)?t.lastEffect=e.next=e:(r=n.next,n.next=e,e.next=r,t.lastEffect=e),e}function Io(){return To().memoizedState}function $o(e,t,n,r){var a=Co();vo.flags|=e,a.memoizedState=Uo(1|t,n,void 0,void 0===r?null:r)}function Bo(e,t,n,r){var a=To();r=void 0===r?null:r;var i=void 0;if(null!==go){var o=go.memoizedState;if(i=o.destroy,null!==r&&ko(r,o.deps))return void(a.memoizedState=Uo(t,n,i,r))}vo.flags|=e,a.memoizedState=Uo(1|t,n,i,r)}function Wo(e,t){return $o(8390656,8,e,t)}function Vo(e,t){return Bo(2048,8,e,t)}function Ho(e,t){return Bo(4,2,e,t)}function qo(e,t){return Bo(4,4,e,t)}function Qo(e,t){return\"function\"==typeof t?(e=e(),t(e),function(){t(null)}):null!=t?(e=e(),t.current=e,function(){t.current=null}):void 0}function Yo(e,t,n){return n=null!=n?n.concat([e]):null,Bo(4,4,Qo.bind(null,t,e),n)}function Go(){}function Ko(e,t){var n=To();t=void 0===t?null:t;var r=n.memoizedState;return null!==r&&null!==t&&ko(t,r[1])?r[0]:(n.memoizedState=[e,t],e)}function Zo(e,t){var n=To();t=void 0===t?null:t;var r=n.memoizedState;return null!==r&&null!==t&&ko(t,r[1])?r[0]:(e=e(),n.memoizedState=[e,t],e)}function Xo(e,t,n){return 0==(21&ho)?(e.baseState&&(e.baseState=!1,_u=!0),e.memoizedState=n):(ur(n,t)||(n=vt(),vo.lanes|=n,Rl|=n,e.baseState=!0),t)}function Jo(e,t){var n=bt;bt=0!==n&&4>n?n:4,e(!0);var r=po.transition;po.transition={};try{e(!1),t()}finally{bt=n,po.transition=r}}function eu(){return To().memoizedState}function tu(e,t,n){var r=ns(e);n={lane:r,action:n,hasEagerState:!1,eagerState:null,next:null},ru(e)?au(t,n):null!==(n=Mi(e,t,n,r))&&(rs(n,e,r,ts()),iu(n,t,r))}function nu(e,t,n){var r=ns(e),a={lane:r,action:n,hasEagerState:!1,eagerState:null,next:null};if(ru(e))au(t,a);else{var i=e.alternate;if(0===e.lanes&&(null===i||0===i.lanes)&&null!==(i=t.lastRenderedReducer))try{var o=t.lastRenderedState,u=i(o,n);if(a.hasEagerState=!0,a.eagerState=u,ur(u,o)){var l=t.interleaved;return null===l?(a.next=a,Ti(t)):(a.next=l.next,l.next=a),void(t.interleaved=a)}}catch(e){}null!==(n=Mi(e,t,a,r))&&(rs(n,e,r,a=ts()),iu(n,t,r))}}function ru(e){var t=e.alternate;return e===vo||null!==t&&t===vo}function au(e,t){bo=mo=!0;var n=e.pending;null===n?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function iu(e,t,n){if(0!=(4194240&n)){var r=t.lanes;n|=r&=e.pendingLanes,t.lanes=n,mt(e,n)}}var ou={readContext:Ei,useCallback:xo,useContext:xo,useEffect:xo,useImperativeHandle:xo,useInsertionEffect:xo,useLayoutEffect:xo,useMemo:xo,useReducer:xo,useRef:xo,useState:xo,useDebugValue:xo,useDeferredValue:xo,useTransition:xo,useMutableSource:xo,useSyncExternalStore:xo,useId:xo,unstable_isNewReconciler:!1},uu={readContext:Ei,useCallback:function(e,t){return Co().memoizedState=[e,void 0===t?null:t],e},useContext:Ei,useEffect:Wo,useImperativeHandle:function(e,t,n){return n=null!=n?n.concat([e]):null,$o(4194308,4,Qo.bind(null,t,e),n)},useLayoutEffect:function(e,t){return $o(4194308,4,e,t)},useInsertionEffect:function(e,t){return $o(4,2,e,t)},useMemo:function(e,t){var n=Co();return t=void 0===t?null:t,e=e(),n.memoizedState=[e,t],e},useReducer:function(e,t,n){var r=Co();return t=void 0!==n?n(t):t,r.memoizedState=r.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},r.queue=e,e=e.dispatch=tu.bind(null,vo,e),[r.memoizedState,e]},useRef:function(e){return e={current:e},Co().memoizedState=e},useState:jo,useDebugValue:Go,useDeferredValue:function(e){return Co().memoizedState=e},useTransition:function(){var e=jo(!1),t=e[0];return e=Jo.bind(null,e[1]),Co().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,n){var r=vo,a=Co();if(ai){if(void 0===n)throw Error(i(407));n=n()}else{if(n=t(),null===Pl)throw Error(i(349));0!=(30&ho)||Oo(r,t,n)}a.memoizedState=n;var o={value:n,getSnapshot:t};return a.queue=o,Wo(Fo.bind(null,r,o,e),[e]),r.flags|=2048,Uo(9,Ao.bind(null,r,o,n,t),void 0,null),n},useId:function(){var e=Co(),t=Pl.identifierPrefix;if(ai){var n=Za;t=\":\"+t+\"R\"+(n=(Ka&~(1<<32-ot(Ka)-1)).toString(32)+n),0<(n=_o++)&&(t+=\"H\"+n.toString(32)),t+=\":\"}else t=\":\"+t+\"r\"+(n=wo++).toString(32)+\":\";return e.memoizedState=t},unstable_isNewReconciler:!1},lu={readContext:Ei,useCallback:Ko,useContext:Ei,useEffect:Vo,useImperativeHandle:Yo,useInsertionEffect:Ho,useLayoutEffect:qo,useMemo:Zo,useReducer:No,useRef:Io,useState:function(){return No(Mo)},useDebugValue:Go,useDeferredValue:function(e){return Xo(To(),go.memoizedState,e)},useTransition:function(){return[No(Mo)[0],To().memoizedState]},useMutableSource:zo,useSyncExternalStore:Lo,useId:eu,unstable_isNewReconciler:!1},su={readContext:Ei,useCallback:Ko,useContext:Ei,useEffect:Vo,useImperativeHandle:Yo,useInsertionEffect:Ho,useLayoutEffect:qo,useMemo:Zo,useReducer:Po,useRef:Io,useState:function(){return Po(Mo)},useDebugValue:Go,useDeferredValue:function(e){var t=To();return null===go?t.memoizedState=e:Xo(t,go.memoizedState,e)},useTransition:function(){return[Po(Mo)[0],To().memoizedState]},useMutableSource:zo,useSyncExternalStore:Lo,useId:eu,unstable_isNewReconciler:!1};function cu(e,t){try{var n=\"\",r=t;do{n+=$(r),r=r.return}while(r);var a=n}catch(e){a=\"\\nError generating stack: \"+e.message+\"\\n\"+e.stack}return{value:e,source:t,stack:a,digest:null}}function fu(e,t,n){return{value:e,source:null,stack:null!=n?n:null,digest:null!=t?t:null}}function pu(e,t){try{console.error(t.value)}catch(e){setTimeout((function(){throw e}))}}var du=\"function\"==typeof WeakMap?WeakMap:Map;function hu(e,t,n){(n=Oi(-1,n)).tag=3,n.payload={element:null};var r=t.value;return n.callback=function(){Hl||(Hl=!0,ql=r),pu(0,t)},n}function vu(e,t,n){(n=Oi(-1,n)).tag=3;var r=e.type.getDerivedStateFromError;if(\"function\"==typeof r){var a=t.value;n.payload=function(){return r(a)},n.callback=function(){pu(0,t)}}var i=e.stateNode;return null!==i&&\"function\"==typeof i.componentDidCatch&&(n.callback=function(){pu(0,t),\"function\"!=typeof r&&(null===Ql?Ql=new Set([this]):Ql.add(this));var e=t.stack;this.componentDidCatch(t.value,{componentStack:null!==e?e:\"\"})}),n}function gu(e,t,n){var r=e.pingCache;if(null===r){r=e.pingCache=new du;var a=new Set;r.set(t,a)}else void 0===(a=r.get(t))&&(a=new Set,r.set(t,a));a.has(n)||(a.add(n),e=Cs.bind(null,e,t,n),t.then(e,e))}function yu(e){do{var t;if((t=13===e.tag)&&(t=null===(t=e.memoizedState)||null!==t.dehydrated),t)return e;e=e.return}while(null!==e);return null}function mu(e,t,n,r,a){return 0==(1&e.mode)?(e===t?e.flags|=65536:(e.flags|=128,n.flags|=131072,n.flags&=-52805,1===n.tag&&(null===n.alternate?n.tag=17:((t=Oi(-1,1)).tag=2,Ai(n,t,1))),n.lanes|=1),e):(e.flags|=65536,e.lanes=a,e)}var bu=_.ReactCurrentOwner,_u=!1;function wu(e,t,n,r){t.child=null===e?Zi(t,null,n,r):Ki(t,e.child,n,r)}function xu(e,t,n,r,a){n=n.render;var i=t.ref;return Si(t,a),r=So(e,t,n,r,i,a),n=Eo(),null===e||_u?(ai&&n&&ei(t),t.flags|=1,wu(e,t,r,a),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,Hu(e,t,a))}function ku(e,t,n,r,a){if(null===e){var i=n.type;return\"function\"!=typeof i||Os(i)||void 0!==i.defaultProps||null!==n.compare||void 0!==n.defaultProps?((e=Fs(n.type,null,r,t,t.mode,a)).ref=t.ref,e.return=t,t.child=e):(t.tag=15,t.type=i,Su(e,t,i,r,a))}if(i=e.child,0==(e.lanes&a)){var o=i.memoizedProps;if((n=null!==(n=n.compare)?n:lr)(o,r)&&e.ref===t.ref)return Hu(e,t,a)}return t.flags|=1,(e=As(i,r)).ref=t.ref,e.return=t,t.child=e}function Su(e,t,n,r,a){if(null!==e){var i=e.memoizedProps;if(lr(i,r)&&e.ref===t.ref){if(_u=!1,t.pendingProps=r=i,0==(e.lanes&a))return t.lanes=e.lanes,Hu(e,t,a);0!=(131072&e.flags)&&(_u=!0)}}return Tu(e,t,n,r,a)}function Eu(e,t,n){var r=t.pendingProps,a=r.children,i=null!==e?e.memoizedState:null;if(\"hidden\"===r.mode)if(0==(1&t.mode))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},Ca(Al,Ol),Ol|=n;else{if(0==(1073741824&n))return e=null!==i?i.baseLanes|n:n,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,Ca(Al,Ol),Ol|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},r=null!==i?i.baseLanes:n,Ca(Al,Ol),Ol|=r}else null!==i?(r=i.baseLanes|n,t.memoizedState=null):r=n,Ca(Al,Ol),Ol|=r;return wu(e,t,a,n),t.child}function Cu(e,t){var n=t.ref;(null===e&&null!==n||null!==e&&e.ref!==n)&&(t.flags|=512,t.flags|=2097152)}function Tu(e,t,n,r,a){var i=La(n)?Pa:Ma.current;return i=za(t,i),Si(t,a),n=So(e,t,n,r,i,a),r=Eo(),null===e||_u?(ai&&r&&ei(t),t.flags|=1,wu(e,t,n,a),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,Hu(e,t,a))}function Mu(e,t,n,r,a){if(La(n)){var i=!0;Da(t)}else i=!1;if(Si(t,a),null===t.stateNode)Vu(e,t),Wi(t,n,r),Hi(t,n,r,a),r=!0;else if(null===e){var o=t.stateNode,u=t.memoizedProps;o.props=u;var l=o.context,s=n.contextType;s=\"object\"==typeof s&&null!==s?Ei(s):za(t,s=La(n)?Pa:Ma.current);var c=n.getDerivedStateFromProps,f=\"function\"==typeof c||\"function\"==typeof o.getSnapshotBeforeUpdate;f||\"function\"!=typeof o.UNSAFE_componentWillReceiveProps&&\"function\"!=typeof o.componentWillReceiveProps||(u!==r||l!==s)&&Vi(t,o,r,s),Pi=!1;var p=t.memoizedState;o.state=p,Ri(t,r,o,a),l=t.memoizedState,u!==r||p!==l||Na.current||Pi?(\"function\"==typeof c&&(Ii(t,n,c,r),l=t.memoizedState),(u=Pi||Bi(t,n,u,r,p,l,s))?(f||\"function\"!=typeof o.UNSAFE_componentWillMount&&\"function\"!=typeof o.componentWillMount||(\"function\"==typeof o.componentWillMount&&o.componentWillMount(),\"function\"==typeof o.UNSAFE_componentWillMount&&o.UNSAFE_componentWillMount()),\"function\"==typeof o.componentDidMount&&(t.flags|=4194308)):(\"function\"==typeof o.componentDidMount&&(t.flags|=4194308),t.memoizedProps=r,t.memoizedState=l),o.props=r,o.state=l,o.context=s,r=u):(\"function\"==typeof o.componentDidMount&&(t.flags|=4194308),r=!1)}else{o=t.stateNode,Li(e,t),u=t.memoizedProps,s=t.type===t.elementType?u:gi(t.type,u),o.props=s,f=t.pendingProps,p=o.context,l=\"object\"==typeof(l=n.contextType)&&null!==l?Ei(l):za(t,l=La(n)?Pa:Ma.current);var d=n.getDerivedStateFromProps;(c=\"function\"==typeof d||\"function\"==typeof o.getSnapshotBeforeUpdate)||\"function\"!=typeof o.UNSAFE_componentWillReceiveProps&&\"function\"!=typeof o.componentWillReceiveProps||(u!==f||p!==l)&&Vi(t,o,r,l),Pi=!1,p=t.memoizedState,o.state=p,Ri(t,r,o,a);var h=t.memoizedState;u!==f||p!==h||Na.current||Pi?(\"function\"==typeof d&&(Ii(t,n,d,r),h=t.memoizedState),(s=Pi||Bi(t,n,s,r,p,h,l)||!1)?(c||\"function\"!=typeof o.UNSAFE_componentWillUpdate&&\"function\"!=typeof o.componentWillUpdate||(\"function\"==typeof o.componentWillUpdate&&o.componentWillUpdate(r,h,l),\"function\"==typeof o.UNSAFE_componentWillUpdate&&o.UNSAFE_componentWillUpdate(r,h,l)),\"function\"==typeof o.componentDidUpdate&&(t.flags|=4),\"function\"==typeof o.getSnapshotBeforeUpdate&&(t.flags|=1024)):(\"function\"!=typeof o.componentDidUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=4),\"function\"!=typeof o.getSnapshotBeforeUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=1024),t.memoizedProps=r,t.memoizedState=h),o.props=r,o.state=h,o.context=l,r=s):(\"function\"!=typeof o.componentDidUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=4),\"function\"!=typeof o.getSnapshotBeforeUpdate||u===e.memoizedProps&&p===e.memoizedState||(t.flags|=1024),r=!1)}return Nu(e,t,n,r,i,a)}function Nu(e,t,n,r,a,i){Cu(e,t);var o=0!=(128&t.flags);if(!r&&!o)return a&&Ra(t,n,!1),Hu(e,t,i);r=t.stateNode,bu.current=t;var u=o&&\"function\"!=typeof n.getDerivedStateFromError?null:r.render();return t.flags|=1,null!==e&&o?(t.child=Ki(t,e.child,null,i),t.child=Ki(t,null,u,i)):wu(e,t,u,i),t.memoizedState=r.state,a&&Ra(t,n,!0),t.child}function Pu(e){var t=e.stateNode;t.pendingContext?Aa(0,t.pendingContext,t.pendingContext!==t.context):t.context&&Aa(0,t.context,!1),ro(e,t.containerInfo)}function zu(e,t,n,r,a){return di(),hi(a),t.flags|=256,wu(e,t,n,r),t.child}var Lu,Ou,Au,Fu,Du={dehydrated:null,treeContext:null,retryLane:0};function Ru(e){return{baseLanes:e,cachePool:null,transitions:null}}function ju(e,t,n){var r,a=t.pendingProps,o=uo.current,u=!1,l=0!=(128&t.flags);if((r=l)||(r=(null===e||null!==e.memoizedState)&&0!=(2&o)),r?(u=!0,t.flags&=-129):null!==e&&null===e.memoizedState||(o|=1),Ca(uo,1&o),null===e)return si(t),null!==(e=t.memoizedState)&&null!==(e=e.dehydrated)?(0==(1&t.mode)?t.lanes=1:\"$!\"===e.data?t.lanes=8:t.lanes=1073741824,null):(l=a.children,e=a.fallback,u?(a=t.mode,u=t.child,l={mode:\"hidden\",children:l},0==(1&a)&&null!==u?(u.childLanes=0,u.pendingProps=l):u=Rs(l,a,0,null),e=Ds(e,a,n,null),u.return=t,e.return=t,u.sibling=e,t.child=u,t.child.memoizedState=Ru(n),t.memoizedState=Du,e):Uu(t,l));if(null!==(o=e.memoizedState)&&null!==(r=o.dehydrated))return function(e,t,n,r,a,o,u){if(n)return 256&t.flags?(t.flags&=-257,Iu(e,t,u,r=fu(Error(i(422))))):null!==t.memoizedState?(t.child=e.child,t.flags|=128,null):(o=r.fallback,a=t.mode,r=Rs({mode:\"visible\",children:r.children},a,0,null),(o=Ds(o,a,u,null)).flags|=2,r.return=t,o.return=t,r.sibling=o,t.child=r,0!=(1&t.mode)&&Ki(t,e.child,null,u),t.child.memoizedState=Ru(u),t.memoizedState=Du,o);if(0==(1&t.mode))return Iu(e,t,u,null);if(\"$!\"===a.data){if(r=a.nextSibling&&a.nextSibling.dataset)var l=r.dgst;return r=l,Iu(e,t,u,r=fu(o=Error(i(419)),r,void 0))}if(l=0!=(u&e.childLanes),_u||l){if(null!==(r=Pl)){switch(u&-u){case 4:a=2;break;case 16:a=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:a=32;break;case 536870912:a=268435456;break;default:a=0}0!==(a=0!=(a&(r.suspendedLanes|u))?0:a)&&a!==o.retryLane&&(o.retryLane=a,Ni(e,a),rs(r,e,a,-1))}return gs(),Iu(e,t,u,r=fu(Error(i(421))))}return\"$?\"===a.data?(t.flags|=128,t.child=e.child,t=Ms.bind(null,e),a._reactRetry=t,null):(e=o.treeContext,ri=sa(a.nextSibling),ni=t,ai=!0,ii=null,null!==e&&(Qa[Ya++]=Ka,Qa[Ya++]=Za,Qa[Ya++]=Ga,Ka=e.id,Za=e.overflow,Ga=t),(t=Uu(t,r.children)).flags|=4096,t)}(e,t,l,a,r,o,n);if(u){u=a.fallback,l=t.mode,r=(o=e.child).sibling;var s={mode:\"hidden\",children:a.children};return 0==(1&l)&&t.child!==o?((a=t.child).childLanes=0,a.pendingProps=s,t.deletions=null):(a=As(o,s)).subtreeFlags=14680064&o.subtreeFlags,null!==r?u=As(r,u):(u=Ds(u,l,n,null)).flags|=2,u.return=t,a.return=t,a.sibling=u,t.child=a,a=u,u=t.child,l=null===(l=e.child.memoizedState)?Ru(n):{baseLanes:l.baseLanes|n,cachePool:null,transitions:l.transitions},u.memoizedState=l,u.childLanes=e.childLanes&~n,t.memoizedState=Du,a}return e=(u=e.child).sibling,a=As(u,{mode:\"visible\",children:a.children}),0==(1&t.mode)&&(a.lanes=n),a.return=t,a.sibling=null,null!==e&&(null===(n=t.deletions)?(t.deletions=[e],t.flags|=16):n.push(e)),t.child=a,t.memoizedState=null,a}function Uu(e,t){return(t=Rs({mode:\"visible\",children:t},e.mode,0,null)).return=e,e.child=t}function Iu(e,t,n,r){return null!==r&&hi(r),Ki(t,e.child,null,n),(e=Uu(t,t.pendingProps.children)).flags|=2,t.memoizedState=null,e}function $u(e,t,n){e.lanes|=t;var r=e.alternate;null!==r&&(r.lanes|=t),ki(e.return,t,n)}function Bu(e,t,n,r,a){var i=e.memoizedState;null===i?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:r,tail:n,tailMode:a}:(i.isBackwards=t,i.rendering=null,i.renderingStartTime=0,i.last=r,i.tail=n,i.tailMode=a)}function Wu(e,t,n){var r=t.pendingProps,a=r.revealOrder,i=r.tail;if(wu(e,t,r.children,n),0!=(2&(r=uo.current)))r=1&r|2,t.flags|=128;else{if(null!==e&&0!=(128&e.flags))e:for(e=t.child;null!==e;){if(13===e.tag)null!==e.memoizedState&&$u(e,n,t);else if(19===e.tag)$u(e,n,t);else if(null!==e.child){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;null===e.sibling;){if(null===e.return||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}r&=1}if(Ca(uo,r),0==(1&t.mode))t.memoizedState=null;else switch(a){case\"forwards\":for(n=t.child,a=null;null!==n;)null!==(e=n.alternate)&&null===lo(e)&&(a=n),n=n.sibling;null===(n=a)?(a=t.child,t.child=null):(a=n.sibling,n.sibling=null),Bu(t,!1,a,n,i);break;case\"backwards\":for(n=null,a=t.child,t.child=null;null!==a;){if(null!==(e=a.alternate)&&null===lo(e)){t.child=a;break}e=a.sibling,a.sibling=n,n=a,a=e}Bu(t,!0,n,null,i);break;case\"together\":Bu(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function Vu(e,t){0==(1&t.mode)&&null!==e&&(e.alternate=null,t.alternate=null,t.flags|=2)}function Hu(e,t,n){if(null!==e&&(t.dependencies=e.dependencies),Rl|=t.lanes,0==(n&t.childLanes))return null;if(null!==e&&t.child!==e.child)throw Error(i(153));if(null!==t.child){for(n=As(e=t.child,e.pendingProps),t.child=n,n.return=t;null!==e.sibling;)e=e.sibling,(n=n.sibling=As(e,e.pendingProps)).return=t;n.sibling=null}return t.child}function qu(e,t){if(!ai)switch(e.tailMode){case\"hidden\":t=e.tail;for(var n=null;null!==t;)null!==t.alternate&&(n=t),t=t.sibling;null===n?e.tail=null:n.sibling=null;break;case\"collapsed\":n=e.tail;for(var r=null;null!==n;)null!==n.alternate&&(r=n),n=n.sibling;null===r?t||null===e.tail?e.tail=null:e.tail.sibling=null:r.sibling=null}}function Qu(e){var t=null!==e.alternate&&e.alternate.child===e.child,n=0,r=0;if(t)for(var a=e.child;null!==a;)n|=a.lanes|a.childLanes,r|=14680064&a.subtreeFlags,r|=14680064&a.flags,a.return=e,a=a.sibling;else for(a=e.child;null!==a;)n|=a.lanes|a.childLanes,r|=a.subtreeFlags,r|=a.flags,a.return=e,a=a.sibling;return e.subtreeFlags|=r,e.childLanes=n,t}function Yu(e,t,n){var r=t.pendingProps;switch(ti(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Qu(t),null;case 1:case 17:return La(t.type)&&Oa(),Qu(t),null;case 3:return r=t.stateNode,ao(),Ea(Na),Ea(Ma),co(),r.pendingContext&&(r.context=r.pendingContext,r.pendingContext=null),null!==e&&null!==e.child||(fi(t)?t.flags|=4:null===e||e.memoizedState.isDehydrated&&0==(256&t.flags)||(t.flags|=1024,null!==ii&&(us(ii),ii=null))),Ou(e,t),Qu(t),null;case 5:oo(t);var a=no(to.current);if(n=t.type,null!==e&&null!=t.stateNode)Au(e,t,n,r,a),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!r){if(null===t.stateNode)throw Error(i(166));return Qu(t),null}if(e=no(Ji.current),fi(t)){r=t.stateNode,n=t.type;var o=t.memoizedProps;switch(r[pa]=t,r[da]=o,e=0!=(1&t.mode),n){case\"dialog\":Ur(\"cancel\",r),Ur(\"close\",r);break;case\"iframe\":case\"object\":case\"embed\":Ur(\"load\",r);break;case\"video\":case\"audio\":for(a=0;a<Fr.length;a++)Ur(Fr[a],r);break;case\"source\":Ur(\"error\",r);break;case\"img\":case\"image\":case\"link\":Ur(\"error\",r),Ur(\"load\",r);break;case\"details\":Ur(\"toggle\",r);break;case\"input\":K(r,o),Ur(\"invalid\",r);break;case\"select\":r._wrapperState={wasMultiple:!!o.multiple},Ur(\"invalid\",r);break;case\"textarea\":ae(r,o),Ur(\"invalid\",r)}for(var l in me(n,o),a=null,o)if(o.hasOwnProperty(l)){var s=o[l];\"children\"===l?\"string\"==typeof s?r.textContent!==s&&(!0!==o.suppressHydrationWarning&&Xr(r.textContent,s,e),a=[\"children\",s]):\"number\"==typeof s&&r.textContent!==\"\"+s&&(!0!==o.suppressHydrationWarning&&Xr(r.textContent,s,e),a=[\"children\",\"\"+s]):u.hasOwnProperty(l)&&null!=s&&\"onScroll\"===l&&Ur(\"scroll\",r)}switch(n){case\"input\":q(r),J(r,o,!0);break;case\"textarea\":q(r),oe(r);break;case\"select\":case\"option\":break;default:\"function\"==typeof o.onClick&&(r.onclick=Jr)}r=a,t.updateQueue=r,null!==r&&(t.flags|=4)}else{l=9===a.nodeType?a:a.ownerDocument,\"http://www.w3.org/1999/xhtml\"===e&&(e=ue(n)),\"http://www.w3.org/1999/xhtml\"===e?\"script\"===n?((e=l.createElement(\"div\")).innerHTML=\"<script><\\/script>\",e=e.removeChild(e.firstChild)):\"string\"==typeof r.is?e=l.createElement(n,{is:r.is}):(e=l.createElement(n),\"select\"===n&&(l=e,r.multiple?l.multiple=!0:r.size&&(l.size=r.size))):e=l.createElementNS(e,n),e[pa]=t,e[da]=r,Lu(e,t,!1,!1),t.stateNode=e;e:{switch(l=be(n,r),n){case\"dialog\":Ur(\"cancel\",e),Ur(\"close\",e),a=r;break;case\"iframe\":case\"object\":case\"embed\":Ur(\"load\",e),a=r;break;case\"video\":case\"audio\":for(a=0;a<Fr.length;a++)Ur(Fr[a],e);a=r;break;case\"source\":Ur(\"error\",e),a=r;break;case\"img\":case\"image\":case\"link\":Ur(\"error\",e),Ur(\"load\",e),a=r;break;case\"details\":Ur(\"toggle\",e),a=r;break;case\"input\":K(e,r),a=G(e,r),Ur(\"invalid\",e);break;case\"option\":default:a=r;break;case\"select\":e._wrapperState={wasMultiple:!!r.multiple},a=R({},r,{value:void 0}),Ur(\"invalid\",e);break;case\"textarea\":ae(e,r),a=re(e,r),Ur(\"invalid\",e)}for(o in me(n,a),s=a)if(s.hasOwnProperty(o)){var c=s[o];\"style\"===o?ge(e,c):\"dangerouslySetInnerHTML\"===o?null!=(c=c?c.__html:void 0)&&fe(e,c):\"children\"===o?\"string\"==typeof c?(\"textarea\"!==n||\"\"!==c)&&pe(e,c):\"number\"==typeof c&&pe(e,\"\"+c):\"suppressContentEditableWarning\"!==o&&\"suppressHydrationWarning\"!==o&&\"autoFocus\"!==o&&(u.hasOwnProperty(o)?null!=c&&\"onScroll\"===o&&Ur(\"scroll\",e):null!=c&&b(e,o,c,l))}switch(n){case\"input\":q(e),J(e,r,!1);break;case\"textarea\":q(e),oe(e);break;case\"option\":null!=r.value&&e.setAttribute(\"value\",\"\"+V(r.value));break;case\"select\":e.multiple=!!r.multiple,null!=(o=r.value)?ne(e,!!r.multiple,o,!1):null!=r.defaultValue&&ne(e,!!r.multiple,r.defaultValue,!0);break;default:\"function\"==typeof a.onClick&&(e.onclick=Jr)}switch(n){case\"button\":case\"input\":case\"select\":case\"textarea\":r=!!r.autoFocus;break e;case\"img\":r=!0;break e;default:r=!1}}r&&(t.flags|=4)}null!==t.ref&&(t.flags|=512,t.flags|=2097152)}return Qu(t),null;case 6:if(e&&null!=t.stateNode)Fu(e,t,e.memoizedProps,r);else{if(\"string\"!=typeof r&&null===t.stateNode)throw Error(i(166));if(n=no(to.current),no(Ji.current),fi(t)){if(r=t.stateNode,n=t.memoizedProps,r[pa]=t,(o=r.nodeValue!==n)&&null!==(e=ni))switch(e.tag){case 3:Xr(r.nodeValue,n,0!=(1&e.mode));break;case 5:!0!==e.memoizedProps.suppressHydrationWarning&&Xr(r.nodeValue,n,0!=(1&e.mode))}o&&(t.flags|=4)}else(r=(9===n.nodeType?n:n.ownerDocument).createTextNode(r))[pa]=t,t.stateNode=r}return Qu(t),null;case 13:if(Ea(uo),r=t.memoizedState,null===e||null!==e.memoizedState&&null!==e.memoizedState.dehydrated){if(ai&&null!==ri&&0!=(1&t.mode)&&0==(128&t.flags))pi(),di(),t.flags|=98560,o=!1;else if(o=fi(t),null!==r&&null!==r.dehydrated){if(null===e){if(!o)throw Error(i(318));if(!(o=null!==(o=t.memoizedState)?o.dehydrated:null))throw Error(i(317));o[pa]=t}else di(),0==(128&t.flags)&&(t.memoizedState=null),t.flags|=4;Qu(t),o=!1}else null!==ii&&(us(ii),ii=null),o=!0;if(!o)return 65536&t.flags?t:null}return 0!=(128&t.flags)?(t.lanes=n,t):((r=null!==r)!=(null!==e&&null!==e.memoizedState)&&r&&(t.child.flags|=8192,0!=(1&t.mode)&&(null===e||0!=(1&uo.current)?0===Fl&&(Fl=3):gs())),null!==t.updateQueue&&(t.flags|=4),Qu(t),null);case 4:return ao(),Ou(e,t),null===e&&Br(t.stateNode.containerInfo),Qu(t),null;case 10:return xi(t.type._context),Qu(t),null;case 19:if(Ea(uo),null===(o=t.memoizedState))return Qu(t),null;if(r=0!=(128&t.flags),null===(l=o.rendering))if(r)qu(o,!1);else{if(0!==Fl||null!==e&&0!=(128&e.flags))for(e=t.child;null!==e;){if(null!==(l=lo(e))){for(t.flags|=128,qu(o,!1),null!==(r=l.updateQueue)&&(t.updateQueue=r,t.flags|=4),t.subtreeFlags=0,r=n,n=t.child;null!==n;)e=r,(o=n).flags&=14680066,null===(l=o.alternate)?(o.childLanes=0,o.lanes=e,o.child=null,o.subtreeFlags=0,o.memoizedProps=null,o.memoizedState=null,o.updateQueue=null,o.dependencies=null,o.stateNode=null):(o.childLanes=l.childLanes,o.lanes=l.lanes,o.child=l.child,o.subtreeFlags=0,o.deletions=null,o.memoizedProps=l.memoizedProps,o.memoizedState=l.memoizedState,o.updateQueue=l.updateQueue,o.type=l.type,e=l.dependencies,o.dependencies=null===e?null:{lanes:e.lanes,firstContext:e.firstContext}),n=n.sibling;return Ca(uo,1&uo.current|2),t.child}e=e.sibling}null!==o.tail&&Ze()>Wl&&(t.flags|=128,r=!0,qu(o,!1),t.lanes=4194304)}else{if(!r)if(null!==(e=lo(l))){if(t.flags|=128,r=!0,null!==(n=e.updateQueue)&&(t.updateQueue=n,t.flags|=4),qu(o,!0),null===o.tail&&\"hidden\"===o.tailMode&&!l.alternate&&!ai)return Qu(t),null}else 2*Ze()-o.renderingStartTime>Wl&&1073741824!==n&&(t.flags|=128,r=!0,qu(o,!1),t.lanes=4194304);o.isBackwards?(l.sibling=t.child,t.child=l):(null!==(n=o.last)?n.sibling=l:t.child=l,o.last=l)}return null!==o.tail?(t=o.tail,o.rendering=t,o.tail=t.sibling,o.renderingStartTime=Ze(),t.sibling=null,n=uo.current,Ca(uo,r?1&n|2:1&n),t):(Qu(t),null);case 22:case 23:return ps(),r=null!==t.memoizedState,null!==e&&null!==e.memoizedState!==r&&(t.flags|=8192),r&&0!=(1&t.mode)?0!=(1073741824&Ol)&&(Qu(t),6&t.subtreeFlags&&(t.flags|=8192)):Qu(t),null;case 24:case 25:return null}throw Error(i(156,t.tag))}function Gu(e,t){switch(ti(t),t.tag){case 1:return La(t.type)&&Oa(),65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 3:return ao(),Ea(Na),Ea(Ma),co(),0!=(65536&(e=t.flags))&&0==(128&e)?(t.flags=-65537&e|128,t):null;case 5:return oo(t),null;case 13:if(Ea(uo),null!==(e=t.memoizedState)&&null!==e.dehydrated){if(null===t.alternate)throw Error(i(340));di()}return 65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 19:return Ea(uo),null;case 4:return ao(),null;case 10:return xi(t.type._context),null;case 22:case 23:return ps(),null;default:return null}}Lu=function(e,t){for(var n=t.child;null!==n;){if(5===n.tag||6===n.tag)e.appendChild(n.stateNode);else if(4!==n.tag&&null!==n.child){n.child.return=n,n=n.child;continue}if(n===t)break;for(;null===n.sibling;){if(null===n.return||n.return===t)return;n=n.return}n.sibling.return=n.return,n=n.sibling}},Ou=function(){},Au=function(e,t,n,r){var a=e.memoizedProps;if(a!==r){e=t.stateNode,no(Ji.current);var i,o=null;switch(n){case\"input\":a=G(e,a),r=G(e,r),o=[];break;case\"select\":a=R({},a,{value:void 0}),r=R({},r,{value:void 0}),o=[];break;case\"textarea\":a=re(e,a),r=re(e,r),o=[];break;default:\"function\"!=typeof a.onClick&&\"function\"==typeof r.onClick&&(e.onclick=Jr)}for(c in me(n,r),n=null,a)if(!r.hasOwnProperty(c)&&a.hasOwnProperty(c)&&null!=a[c])if(\"style\"===c){var l=a[c];for(i in l)l.hasOwnProperty(i)&&(n||(n={}),n[i]=\"\")}else\"dangerouslySetInnerHTML\"!==c&&\"children\"!==c&&\"suppressContentEditableWarning\"!==c&&\"suppressHydrationWarning\"!==c&&\"autoFocus\"!==c&&(u.hasOwnProperty(c)?o||(o=[]):(o=o||[]).push(c,null));for(c in r){var s=r[c];if(l=null!=a?a[c]:void 0,r.hasOwnProperty(c)&&s!==l&&(null!=s||null!=l))if(\"style\"===c)if(l){for(i in l)!l.hasOwnProperty(i)||s&&s.hasOwnProperty(i)||(n||(n={}),n[i]=\"\");for(i in s)s.hasOwnProperty(i)&&l[i]!==s[i]&&(n||(n={}),n[i]=s[i])}else n||(o||(o=[]),o.push(c,n)),n=s;else\"dangerouslySetInnerHTML\"===c?(s=s?s.__html:void 0,l=l?l.__html:void 0,null!=s&&l!==s&&(o=o||[]).push(c,s)):\"children\"===c?\"string\"!=typeof s&&\"number\"!=typeof s||(o=o||[]).push(c,\"\"+s):\"suppressContentEditableWarning\"!==c&&\"suppressHydrationWarning\"!==c&&(u.hasOwnProperty(c)?(null!=s&&\"onScroll\"===c&&Ur(\"scroll\",e),o||l===s||(o=[])):(o=o||[]).push(c,s))}n&&(o=o||[]).push(\"style\",n);var c=o;(t.updateQueue=c)&&(t.flags|=4)}},Fu=function(e,t,n,r){n!==r&&(t.flags|=4)};var Ku=!1,Zu=!1,Xu=\"function\"==typeof WeakSet?WeakSet:Set,Ju=null;function el(e,t){var n=e.ref;if(null!==n)if(\"function\"==typeof n)try{n(null)}catch(n){Es(e,t,n)}else n.current=null}function tl(e,t,n){try{n()}catch(n){Es(e,t,n)}}var nl=!1;function rl(e,t,n){var r=t.updateQueue;if(null!==(r=null!==r?r.lastEffect:null)){var a=r=r.next;do{if((a.tag&e)===e){var i=a.destroy;a.destroy=void 0,void 0!==i&&tl(t,n,i)}a=a.next}while(a!==r)}}function al(e,t){if(null!==(t=null!==(t=t.updateQueue)?t.lastEffect:null)){var n=t=t.next;do{if((n.tag&e)===e){var r=n.create;n.destroy=r()}n=n.next}while(n!==t)}}function il(e){var t=e.ref;if(null!==t){var n=e.stateNode;e.tag,e=n,\"function\"==typeof t?t(e):t.current=e}}function ol(e){var t=e.alternate;null!==t&&(e.alternate=null,ol(t)),e.child=null,e.deletions=null,e.sibling=null,5===e.tag&&null!==(t=e.stateNode)&&(delete t[pa],delete t[da],delete t[va],delete t[ga],delete t[ya]),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function ul(e){return 5===e.tag||3===e.tag||4===e.tag}function ll(e){e:for(;;){for(;null===e.sibling;){if(null===e.return||ul(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;5!==e.tag&&6!==e.tag&&18!==e.tag;){if(2&e.flags)continue e;if(null===e.child||4===e.tag)continue e;e.child.return=e,e=e.child}if(!(2&e.flags))return e.stateNode}}function sl(e,t,n){var r=e.tag;if(5===r||6===r)e=e.stateNode,t?8===n.nodeType?n.parentNode.insertBefore(e,t):n.insertBefore(e,t):(8===n.nodeType?(t=n.parentNode).insertBefore(e,n):(t=n).appendChild(e),null!=(n=n._reactRootContainer)||null!==t.onclick||(t.onclick=Jr));else if(4!==r&&null!==(e=e.child))for(sl(e,t,n),e=e.sibling;null!==e;)sl(e,t,n),e=e.sibling}function cl(e,t,n){var r=e.tag;if(5===r||6===r)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(4!==r&&null!==(e=e.child))for(cl(e,t,n),e=e.sibling;null!==e;)cl(e,t,n),e=e.sibling}var fl=null,pl=!1;function dl(e,t,n){for(n=n.child;null!==n;)hl(e,t,n),n=n.sibling}function hl(e,t,n){if(it&&\"function\"==typeof it.onCommitFiberUnmount)try{it.onCommitFiberUnmount(at,n)}catch(e){}switch(n.tag){case 5:Zu||el(n,t);case 6:var r=fl,a=pl;fl=null,dl(e,t,n),pl=a,null!==(fl=r)&&(pl?(e=fl,n=n.stateNode,8===e.nodeType?e.parentNode.removeChild(n):e.removeChild(n)):fl.removeChild(n.stateNode));break;case 18:null!==fl&&(pl?(e=fl,n=n.stateNode,8===e.nodeType?la(e.parentNode,n):1===e.nodeType&&la(e,n),Bt(e)):la(fl,n.stateNode));break;case 4:r=fl,a=pl,fl=n.stateNode.containerInfo,pl=!0,dl(e,t,n),fl=r,pl=a;break;case 0:case 11:case 14:case 15:if(!Zu&&null!==(r=n.updateQueue)&&null!==(r=r.lastEffect)){a=r=r.next;do{var i=a,o=i.destroy;i=i.tag,void 0!==o&&(0!=(2&i)||0!=(4&i))&&tl(n,t,o),a=a.next}while(a!==r)}dl(e,t,n);break;case 1:if(!Zu&&(el(n,t),\"function\"==typeof(r=n.stateNode).componentWillUnmount))try{r.props=n.memoizedProps,r.state=n.memoizedState,r.componentWillUnmount()}catch(e){Es(n,t,e)}dl(e,t,n);break;case 21:dl(e,t,n);break;case 22:1&n.mode?(Zu=(r=Zu)||null!==n.memoizedState,dl(e,t,n),Zu=r):dl(e,t,n);break;default:dl(e,t,n)}}function vl(e){var t=e.updateQueue;if(null!==t){e.updateQueue=null;var n=e.stateNode;null===n&&(n=e.stateNode=new Xu),t.forEach((function(t){var r=Ns.bind(null,e,t);n.has(t)||(n.add(t),t.then(r,r))}))}}function gl(e,t){var n=t.deletions;if(null!==n)for(var r=0;r<n.length;r++){var a=n[r];try{var o=e,u=t,l=u;e:for(;null!==l;){switch(l.tag){case 5:fl=l.stateNode,pl=!1;break e;case 3:case 4:fl=l.stateNode.containerInfo,pl=!0;break e}l=l.return}if(null===fl)throw Error(i(160));hl(o,u,a),fl=null,pl=!1;var s=a.alternate;null!==s&&(s.return=null),a.return=null}catch(e){Es(a,t,e)}}if(12854&t.subtreeFlags)for(t=t.child;null!==t;)yl(t,e),t=t.sibling}function yl(e,t){var n=e.alternate,r=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(gl(t,e),ml(e),4&r){try{rl(3,e,e.return),al(3,e)}catch(t){Es(e,e.return,t)}try{rl(5,e,e.return)}catch(t){Es(e,e.return,t)}}break;case 1:gl(t,e),ml(e),512&r&&null!==n&&el(n,n.return);break;case 5:if(gl(t,e),ml(e),512&r&&null!==n&&el(n,n.return),32&e.flags){var a=e.stateNode;try{pe(a,\"\")}catch(t){Es(e,e.return,t)}}if(4&r&&null!=(a=e.stateNode)){var o=e.memoizedProps,u=null!==n?n.memoizedProps:o,l=e.type,s=e.updateQueue;if(e.updateQueue=null,null!==s)try{\"input\"===l&&\"radio\"===o.type&&null!=o.name&&Z(a,o),be(l,u);var c=be(l,o);for(u=0;u<s.length;u+=2){var f=s[u],p=s[u+1];\"style\"===f?ge(a,p):\"dangerouslySetInnerHTML\"===f?fe(a,p):\"children\"===f?pe(a,p):b(a,f,p,c)}switch(l){case\"input\":X(a,o);break;case\"textarea\":ie(a,o);break;case\"select\":var d=a._wrapperState.wasMultiple;a._wrapperState.wasMultiple=!!o.multiple;var h=o.value;null!=h?ne(a,!!o.multiple,h,!1):d!==!!o.multiple&&(null!=o.defaultValue?ne(a,!!o.multiple,o.defaultValue,!0):ne(a,!!o.multiple,o.multiple?[]:\"\",!1))}a[da]=o}catch(t){Es(e,e.return,t)}}break;case 6:if(gl(t,e),ml(e),4&r){if(null===e.stateNode)throw Error(i(162));a=e.stateNode,o=e.memoizedProps;try{a.nodeValue=o}catch(t){Es(e,e.return,t)}}break;case 3:if(gl(t,e),ml(e),4&r&&null!==n&&n.memoizedState.isDehydrated)try{Bt(t.containerInfo)}catch(t){Es(e,e.return,t)}break;case 4:default:gl(t,e),ml(e);break;case 13:gl(t,e),ml(e),8192&(a=e.child).flags&&(o=null!==a.memoizedState,a.stateNode.isHidden=o,!o||null!==a.alternate&&null!==a.alternate.memoizedState||(Bl=Ze())),4&r&&vl(e);break;case 22:if(f=null!==n&&null!==n.memoizedState,1&e.mode?(Zu=(c=Zu)||f,gl(t,e),Zu=c):gl(t,e),ml(e),8192&r){if(c=null!==e.memoizedState,(e.stateNode.isHidden=c)&&!f&&0!=(1&e.mode))for(Ju=e,f=e.child;null!==f;){for(p=Ju=f;null!==Ju;){switch(h=(d=Ju).child,d.tag){case 0:case 11:case 14:case 15:rl(4,d,d.return);break;case 1:el(d,d.return);var v=d.stateNode;if(\"function\"==typeof v.componentWillUnmount){r=d,n=d.return;try{t=r,v.props=t.memoizedProps,v.state=t.memoizedState,v.componentWillUnmount()}catch(e){Es(r,n,e)}}break;case 5:el(d,d.return);break;case 22:if(null!==d.memoizedState){xl(p);continue}}null!==h?(h.return=d,Ju=h):xl(p)}f=f.sibling}e:for(f=null,p=e;;){if(5===p.tag){if(null===f){f=p;try{a=p.stateNode,c?\"function\"==typeof(o=a.style).setProperty?o.setProperty(\"display\",\"none\",\"important\"):o.display=\"none\":(l=p.stateNode,u=null!=(s=p.memoizedProps.style)&&s.hasOwnProperty(\"display\")?s.display:null,l.style.display=ve(\"display\",u))}catch(t){Es(e,e.return,t)}}}else if(6===p.tag){if(null===f)try{p.stateNode.nodeValue=c?\"\":p.memoizedProps}catch(t){Es(e,e.return,t)}}else if((22!==p.tag&&23!==p.tag||null===p.memoizedState||p===e)&&null!==p.child){p.child.return=p,p=p.child;continue}if(p===e)break e;for(;null===p.sibling;){if(null===p.return||p.return===e)break e;f===p&&(f=null),p=p.return}f===p&&(f=null),p.sibling.return=p.return,p=p.sibling}}break;case 19:gl(t,e),ml(e),4&r&&vl(e);case 21:}}function ml(e){var t=e.flags;if(2&t){try{e:{for(var n=e.return;null!==n;){if(ul(n)){var r=n;break e}n=n.return}throw Error(i(160))}switch(r.tag){case 5:var a=r.stateNode;32&r.flags&&(pe(a,\"\"),r.flags&=-33),cl(e,ll(e),a);break;case 3:case 4:var o=r.stateNode.containerInfo;sl(e,ll(e),o);break;default:throw Error(i(161))}}catch(t){Es(e,e.return,t)}e.flags&=-3}4096&t&&(e.flags&=-4097)}function bl(e,t,n){Ju=e,_l(e,t,n)}function _l(e,t,n){for(var r=0!=(1&e.mode);null!==Ju;){var a=Ju,i=a.child;if(22===a.tag&&r){var o=null!==a.memoizedState||Ku;if(!o){var u=a.alternate,l=null!==u&&null!==u.memoizedState||Zu;u=Ku;var s=Zu;if(Ku=o,(Zu=l)&&!s)for(Ju=a;null!==Ju;)l=(o=Ju).child,22===o.tag&&null!==o.memoizedState?kl(a):null!==l?(l.return=o,Ju=l):kl(a);for(;null!==i;)Ju=i,_l(i,t,n),i=i.sibling;Ju=a,Ku=u,Zu=s}wl(e)}else 0!=(8772&a.subtreeFlags)&&null!==i?(i.return=a,Ju=i):wl(e)}}function wl(e){for(;null!==Ju;){var t=Ju;if(0!=(8772&t.flags)){var n=t.alternate;try{if(0!=(8772&t.flags))switch(t.tag){case 0:case 11:case 15:Zu||al(5,t);break;case 1:var r=t.stateNode;if(4&t.flags&&!Zu)if(null===n)r.componentDidMount();else{var a=t.elementType===t.type?n.memoizedProps:gi(t.type,n.memoizedProps);r.componentDidUpdate(a,n.memoizedState,r.__reactInternalSnapshotBeforeUpdate)}var o=t.updateQueue;null!==o&&ji(t,o,r);break;case 3:var u=t.updateQueue;if(null!==u){if(n=null,null!==t.child)switch(t.child.tag){case 5:case 1:n=t.child.stateNode}ji(t,u,n)}break;case 5:var l=t.stateNode;if(null===n&&4&t.flags){n=l;var s=t.memoizedProps;switch(t.type){case\"button\":case\"input\":case\"select\":case\"textarea\":s.autoFocus&&n.focus();break;case\"img\":s.src&&(n.src=s.src)}}break;case 6:case 4:case 12:case 19:case 17:case 21:case 22:case 23:case 25:break;case 13:if(null===t.memoizedState){var c=t.alternate;if(null!==c){var f=c.memoizedState;if(null!==f){var p=f.dehydrated;null!==p&&Bt(p)}}}break;default:throw Error(i(163))}Zu||512&t.flags&&il(t)}catch(e){Es(t,t.return,e)}}if(t===e){Ju=null;break}if(null!==(n=t.sibling)){n.return=t.return,Ju=n;break}Ju=t.return}}function xl(e){for(;null!==Ju;){var t=Ju;if(t===e){Ju=null;break}var n=t.sibling;if(null!==n){n.return=t.return,Ju=n;break}Ju=t.return}}function kl(e){for(;null!==Ju;){var t=Ju;try{switch(t.tag){case 0:case 11:case 15:var n=t.return;try{al(4,t)}catch(e){Es(t,n,e)}break;case 1:var r=t.stateNode;if(\"function\"==typeof r.componentDidMount){var a=t.return;try{r.componentDidMount()}catch(e){Es(t,a,e)}}var i=t.return;try{il(t)}catch(e){Es(t,i,e)}break;case 5:var o=t.return;try{il(t)}catch(e){Es(t,o,e)}}}catch(e){Es(t,t.return,e)}if(t===e){Ju=null;break}var u=t.sibling;if(null!==u){u.return=t.return,Ju=u;break}Ju=t.return}}var Sl,El=Math.ceil,Cl=_.ReactCurrentDispatcher,Tl=_.ReactCurrentOwner,Ml=_.ReactCurrentBatchConfig,Nl=0,Pl=null,zl=null,Ll=0,Ol=0,Al=Sa(0),Fl=0,Dl=null,Rl=0,jl=0,Ul=0,Il=null,$l=null,Bl=0,Wl=1/0,Vl=null,Hl=!1,ql=null,Ql=null,Yl=!1,Gl=null,Kl=0,Zl=0,Xl=null,Jl=-1,es=0;function ts(){return 0!=(6&Nl)?Ze():-1!==Jl?Jl:Jl=Ze()}function ns(e){return 0==(1&e.mode)?1:0!=(2&Nl)&&0!==Ll?Ll&-Ll:null!==vi.transition?(0===es&&(es=vt()),es):0!==(e=bt)?e:e=void 0===(e=window.event)?16:Kt(e.type)}function rs(e,t,n,r){if(50<Zl)throw Zl=0,Xl=null,Error(i(185));yt(e,n,r),0!=(2&Nl)&&e===Pl||(e===Pl&&(0==(2&Nl)&&(jl|=n),4===Fl&&ls(e,Ll)),as(e,r),1===n&&0===Nl&&0==(1&t.mode)&&(Wl=Ze()+500,Ua&&Ba()))}function as(e,t){var n=e.callbackNode;!function(e,t){for(var n=e.suspendedLanes,r=e.pingedLanes,a=e.expirationTimes,i=e.pendingLanes;0<i;){var o=31-ot(i),u=1<<o,l=a[o];-1===l?0!=(u&n)&&0==(u&r)||(a[o]=dt(u,t)):l<=t&&(e.expiredLanes|=u),i&=~u}}(e,t);var r=pt(e,e===Pl?Ll:0);if(0===r)null!==n&&Ye(n),e.callbackNode=null,e.callbackPriority=0;else if(t=r&-r,e.callbackPriority!==t){if(null!=n&&Ye(n),1===t)0===e.tag?function(e){Ua=!0,$a(e)}(ss.bind(null,e)):$a(ss.bind(null,e)),oa((function(){0==(6&Nl)&&Ba()})),n=null;else{switch(_t(r)){case 1:n=Je;break;case 4:n=et;break;case 16:default:n=tt;break;case 536870912:n=rt}n=Ps(n,is.bind(null,e))}e.callbackPriority=t,e.callbackNode=n}}function is(e,t){if(Jl=-1,es=0,0!=(6&Nl))throw Error(i(327));var n=e.callbackNode;if(ks()&&e.callbackNode!==n)return null;var r=pt(e,e===Pl?Ll:0);if(0===r)return null;if(0!=(30&r)||0!=(r&e.expiredLanes)||t)t=ys(e,r);else{t=r;var a=Nl;Nl|=2;var o=vs();for(Pl===e&&Ll===t||(Vl=null,Wl=Ze()+500,ds(e,t));;)try{bs();break}catch(t){hs(e,t)}wi(),Cl.current=o,Nl=a,null!==zl?t=0:(Pl=null,Ll=0,t=Fl)}if(0!==t){if(2===t&&0!==(a=ht(e))&&(r=a,t=os(e,a)),1===t)throw n=Dl,ds(e,0),ls(e,r),as(e,Ze()),n;if(6===t)ls(e,r);else{if(a=e.current.alternate,0==(30&r)&&!function(e){for(var t=e;;){if(16384&t.flags){var n=t.updateQueue;if(null!==n&&null!==(n=n.stores))for(var r=0;r<n.length;r++){var a=n[r],i=a.getSnapshot;a=a.value;try{if(!ur(i(),a))return!1}catch(e){return!1}}}if(n=t.child,16384&t.subtreeFlags&&null!==n)n.return=t,t=n;else{if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}(a)&&(2===(t=ys(e,r))&&0!==(o=ht(e))&&(r=o,t=os(e,o)),1===t))throw n=Dl,ds(e,0),ls(e,r),as(e,Ze()),n;switch(e.finishedWork=a,e.finishedLanes=r,t){case 0:case 1:throw Error(i(345));case 2:case 5:xs(e,$l,Vl);break;case 3:if(ls(e,r),(130023424&r)===r&&10<(t=Bl+500-Ze())){if(0!==pt(e,0))break;if(((a=e.suspendedLanes)&r)!==r){ts(),e.pingedLanes|=e.suspendedLanes&a;break}e.timeoutHandle=ra(xs.bind(null,e,$l,Vl),t);break}xs(e,$l,Vl);break;case 4:if(ls(e,r),(4194240&r)===r)break;for(t=e.eventTimes,a=-1;0<r;){var u=31-ot(r);o=1<<u,(u=t[u])>a&&(a=u),r&=~o}if(r=a,10<(r=(120>(r=Ze()-r)?120:480>r?480:1080>r?1080:1920>r?1920:3e3>r?3e3:4320>r?4320:1960*El(r/1960))-r)){e.timeoutHandle=ra(xs.bind(null,e,$l,Vl),r);break}xs(e,$l,Vl);break;default:throw Error(i(329))}}}return as(e,Ze()),e.callbackNode===n?is.bind(null,e):null}function os(e,t){var n=Il;return e.current.memoizedState.isDehydrated&&(ds(e,t).flags|=256),2!==(e=ys(e,t))&&(t=$l,$l=n,null!==t&&us(t)),e}function us(e){null===$l?$l=e:$l.push.apply($l,e)}function ls(e,t){for(t&=~Ul,t&=~jl,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var n=31-ot(t),r=1<<n;e[n]=-1,t&=~r}}function ss(e){if(0!=(6&Nl))throw Error(i(327));ks();var t=pt(e,0);if(0==(1&t))return as(e,Ze()),null;var n=ys(e,t);if(0!==e.tag&&2===n){var r=ht(e);0!==r&&(t=r,n=os(e,r))}if(1===n)throw n=Dl,ds(e,0),ls(e,t),as(e,Ze()),n;if(6===n)throw Error(i(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,xs(e,$l,Vl),as(e,Ze()),null}function cs(e,t){var n=Nl;Nl|=1;try{return e(t)}finally{0===(Nl=n)&&(Wl=Ze()+500,Ua&&Ba())}}function fs(e){null!==Gl&&0===Gl.tag&&0==(6&Nl)&&ks();var t=Nl;Nl|=1;var n=Ml.transition,r=bt;try{if(Ml.transition=null,bt=1,e)return e()}finally{bt=r,Ml.transition=n,0==(6&(Nl=t))&&Ba()}}function ps(){Ol=Al.current,Ea(Al)}function ds(e,t){e.finishedWork=null,e.finishedLanes=0;var n=e.timeoutHandle;if(-1!==n&&(e.timeoutHandle=-1,aa(n)),null!==zl)for(n=zl.return;null!==n;){var r=n;switch(ti(r),r.tag){case 1:null!=(r=r.type.childContextTypes)&&Oa();break;case 3:ao(),Ea(Na),Ea(Ma),co();break;case 5:oo(r);break;case 4:ao();break;case 13:case 19:Ea(uo);break;case 10:xi(r.type._context);break;case 22:case 23:ps()}n=n.return}if(Pl=e,zl=e=As(e.current,null),Ll=Ol=t,Fl=0,Dl=null,Ul=jl=Rl=0,$l=Il=null,null!==Ci){for(t=0;t<Ci.length;t++)if(null!==(r=(n=Ci[t]).interleaved)){n.interleaved=null;var a=r.next,i=n.pending;if(null!==i){var o=i.next;i.next=a,r.next=o}n.pending=r}Ci=null}return e}function hs(e,t){for(;;){var n=zl;try{if(wi(),fo.current=ou,mo){for(var r=vo.memoizedState;null!==r;){var a=r.queue;null!==a&&(a.pending=null),r=r.next}mo=!1}if(ho=0,yo=go=vo=null,bo=!1,_o=0,Tl.current=null,null===n||null===n.return){Fl=1,Dl=t,zl=null;break}e:{var o=e,u=n.return,l=n,s=t;if(t=Ll,l.flags|=32768,null!==s&&\"object\"==typeof s&&\"function\"==typeof s.then){var c=s,f=l,p=f.tag;if(0==(1&f.mode)&&(0===p||11===p||15===p)){var d=f.alternate;d?(f.updateQueue=d.updateQueue,f.memoizedState=d.memoizedState,f.lanes=d.lanes):(f.updateQueue=null,f.memoizedState=null)}var h=yu(u);if(null!==h){h.flags&=-257,mu(h,u,l,0,t),1&h.mode&&gu(o,c,t),s=c;var v=(t=h).updateQueue;if(null===v){var g=new Set;g.add(s),t.updateQueue=g}else v.add(s);break e}if(0==(1&t)){gu(o,c,t),gs();break e}s=Error(i(426))}else if(ai&&1&l.mode){var y=yu(u);if(null!==y){0==(65536&y.flags)&&(y.flags|=256),mu(y,u,l,0,t),hi(cu(s,l));break e}}o=s=cu(s,l),4!==Fl&&(Fl=2),null===Il?Il=[o]:Il.push(o),o=u;do{switch(o.tag){case 3:o.flags|=65536,t&=-t,o.lanes|=t,Di(o,hu(0,s,t));break e;case 1:l=s;var m=o.type,b=o.stateNode;if(0==(128&o.flags)&&(\"function\"==typeof m.getDerivedStateFromError||null!==b&&\"function\"==typeof b.componentDidCatch&&(null===Ql||!Ql.has(b)))){o.flags|=65536,t&=-t,o.lanes|=t,Di(o,vu(o,l,t));break e}}o=o.return}while(null!==o)}ws(n)}catch(e){t=e,zl===n&&null!==n&&(zl=n=n.return);continue}break}}function vs(){var e=Cl.current;return Cl.current=ou,null===e?ou:e}function gs(){0!==Fl&&3!==Fl&&2!==Fl||(Fl=4),null===Pl||0==(268435455&Rl)&&0==(268435455&jl)||ls(Pl,Ll)}function ys(e,t){var n=Nl;Nl|=2;var r=vs();for(Pl===e&&Ll===t||(Vl=null,ds(e,t));;)try{ms();break}catch(t){hs(e,t)}if(wi(),Nl=n,Cl.current=r,null!==zl)throw Error(i(261));return Pl=null,Ll=0,Fl}function ms(){for(;null!==zl;)_s(zl)}function bs(){for(;null!==zl&&!Ge();)_s(zl)}function _s(e){var t=Sl(e.alternate,e,Ol);e.memoizedProps=e.pendingProps,null===t?ws(e):zl=t,Tl.current=null}function ws(e){var t=e;do{var n=t.alternate;if(e=t.return,0==(32768&t.flags)){if(null!==(n=Yu(n,t,Ol)))return void(zl=n)}else{if(null!==(n=Gu(n,t)))return n.flags&=32767,void(zl=n);if(null===e)return Fl=6,void(zl=null);e.flags|=32768,e.subtreeFlags=0,e.deletions=null}if(null!==(t=t.sibling))return void(zl=t);zl=t=e}while(null!==t);0===Fl&&(Fl=5)}function xs(e,t,n){var r=bt,a=Ml.transition;try{Ml.transition=null,bt=1,function(e,t,n,r){do{ks()}while(null!==Gl);if(0!=(6&Nl))throw Error(i(327));n=e.finishedWork;var a=e.finishedLanes;if(null===n)return null;if(e.finishedWork=null,e.finishedLanes=0,n===e.current)throw Error(i(177));e.callbackNode=null,e.callbackPriority=0;var o=n.lanes|n.childLanes;if(function(e,t){var n=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var r=e.eventTimes;for(e=e.expirationTimes;0<n;){var a=31-ot(n),i=1<<a;t[a]=0,r[a]=-1,e[a]=-1,n&=~i}}(e,o),e===Pl&&(zl=Pl=null,Ll=0),0==(2064&n.subtreeFlags)&&0==(2064&n.flags)||Yl||(Yl=!0,Ps(tt,(function(){return ks(),null}))),o=0!=(15990&n.flags),0!=(15990&n.subtreeFlags)||o){o=Ml.transition,Ml.transition=null;var u=bt;bt=1;var l=Nl;Nl|=4,Tl.current=null,function(e,t){if(ea=Vt,dr(e=pr())){if(\"selectionStart\"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{var r=(n=(n=e.ownerDocument)&&n.defaultView||window).getSelection&&n.getSelection();if(r&&0!==r.rangeCount){n=r.anchorNode;var a=r.anchorOffset,o=r.focusNode;r=r.focusOffset;try{n.nodeType,o.nodeType}catch(e){n=null;break e}var u=0,l=-1,s=-1,c=0,f=0,p=e,d=null;t:for(;;){for(var h;p!==n||0!==a&&3!==p.nodeType||(l=u+a),p!==o||0!==r&&3!==p.nodeType||(s=u+r),3===p.nodeType&&(u+=p.nodeValue.length),null!==(h=p.firstChild);)d=p,p=h;for(;;){if(p===e)break t;if(d===n&&++c===a&&(l=u),d===o&&++f===r&&(s=u),null!==(h=p.nextSibling))break;d=(p=d).parentNode}p=h}n=-1===l||-1===s?null:{start:l,end:s}}else n=null}n=n||{start:0,end:0}}else n=null;for(ta={focusedElem:e,selectionRange:n},Vt=!1,Ju=t;null!==Ju;)if(e=(t=Ju).child,0!=(1028&t.subtreeFlags)&&null!==e)e.return=t,Ju=e;else for(;null!==Ju;){t=Ju;try{var v=t.alternate;if(0!=(1024&t.flags))switch(t.tag){case 0:case 11:case 15:case 5:case 6:case 4:case 17:break;case 1:if(null!==v){var g=v.memoizedProps,y=v.memoizedState,m=t.stateNode,b=m.getSnapshotBeforeUpdate(t.elementType===t.type?g:gi(t.type,g),y);m.__reactInternalSnapshotBeforeUpdate=b}break;case 3:var _=t.stateNode.containerInfo;1===_.nodeType?_.textContent=\"\":9===_.nodeType&&_.documentElement&&_.removeChild(_.documentElement);break;default:throw Error(i(163))}}catch(e){Es(t,t.return,e)}if(null!==(e=t.sibling)){e.return=t.return,Ju=e;break}Ju=t.return}v=nl,nl=!1}(e,n),yl(n,e),hr(ta),Vt=!!ea,ta=ea=null,e.current=n,bl(n,e,a),Ke(),Nl=l,bt=u,Ml.transition=o}else e.current=n;if(Yl&&(Yl=!1,Gl=e,Kl=a),0===(o=e.pendingLanes)&&(Ql=null),function(e){if(it&&\"function\"==typeof it.onCommitFiberRoot)try{it.onCommitFiberRoot(at,e,void 0,128==(128&e.current.flags))}catch(e){}}(n.stateNode),as(e,Ze()),null!==t)for(r=e.onRecoverableError,n=0;n<t.length;n++)r((a=t[n]).value,{componentStack:a.stack,digest:a.digest});if(Hl)throw Hl=!1,e=ql,ql=null,e;0!=(1&Kl)&&0!==e.tag&&ks(),0!=(1&(o=e.pendingLanes))?e===Xl?Zl++:(Zl=0,Xl=e):Zl=0,Ba()}(e,t,n,r)}finally{Ml.transition=a,bt=r}return null}function ks(){if(null!==Gl){var e=_t(Kl),t=Ml.transition,n=bt;try{if(Ml.transition=null,bt=16>e?16:e,null===Gl)var r=!1;else{if(e=Gl,Gl=null,Kl=0,0!=(6&Nl))throw Error(i(331));var a=Nl;for(Nl|=4,Ju=e.current;null!==Ju;){var o=Ju,u=o.child;if(0!=(16&Ju.flags)){var l=o.deletions;if(null!==l){for(var s=0;s<l.length;s++){var c=l[s];for(Ju=c;null!==Ju;){var f=Ju;switch(f.tag){case 0:case 11:case 15:rl(8,f,o)}var p=f.child;if(null!==p)p.return=f,Ju=p;else for(;null!==Ju;){var d=(f=Ju).sibling,h=f.return;if(ol(f),f===c){Ju=null;break}if(null!==d){d.return=h,Ju=d;break}Ju=h}}}var v=o.alternate;if(null!==v){var g=v.child;if(null!==g){v.child=null;do{var y=g.sibling;g.sibling=null,g=y}while(null!==g)}}Ju=o}}if(0!=(2064&o.subtreeFlags)&&null!==u)u.return=o,Ju=u;else e:for(;null!==Ju;){if(0!=(2048&(o=Ju).flags))switch(o.tag){case 0:case 11:case 15:rl(9,o,o.return)}var m=o.sibling;if(null!==m){m.return=o.return,Ju=m;break e}Ju=o.return}}var b=e.current;for(Ju=b;null!==Ju;){var _=(u=Ju).child;if(0!=(2064&u.subtreeFlags)&&null!==_)_.return=u,Ju=_;else e:for(u=b;null!==Ju;){if(0!=(2048&(l=Ju).flags))try{switch(l.tag){case 0:case 11:case 15:al(9,l)}}catch(e){Es(l,l.return,e)}if(l===u){Ju=null;break e}var w=l.sibling;if(null!==w){w.return=l.return,Ju=w;break e}Ju=l.return}}if(Nl=a,Ba(),it&&\"function\"==typeof it.onPostCommitFiberRoot)try{it.onPostCommitFiberRoot(at,e)}catch(e){}r=!0}return r}finally{bt=n,Ml.transition=t}}return!1}function Ss(e,t,n){e=Ai(e,t=hu(0,t=cu(n,t),1),1),t=ts(),null!==e&&(yt(e,1,t),as(e,t))}function Es(e,t,n){if(3===e.tag)Ss(e,e,n);else for(;null!==t;){if(3===t.tag){Ss(t,e,n);break}if(1===t.tag){var r=t.stateNode;if(\"function\"==typeof t.type.getDerivedStateFromError||\"function\"==typeof r.componentDidCatch&&(null===Ql||!Ql.has(r))){t=Ai(t,e=vu(t,e=cu(n,e),1),1),e=ts(),null!==t&&(yt(t,1,e),as(t,e));break}}t=t.return}}function Cs(e,t,n){var r=e.pingCache;null!==r&&r.delete(t),t=ts(),e.pingedLanes|=e.suspendedLanes&n,Pl===e&&(Ll&n)===n&&(4===Fl||3===Fl&&(130023424&Ll)===Ll&&500>Ze()-Bl?ds(e,0):Ul|=n),as(e,t)}function Ts(e,t){0===t&&(0==(1&e.mode)?t=1:(t=ct,0==(130023424&(ct<<=1))&&(ct=4194304)));var n=ts();null!==(e=Ni(e,t))&&(yt(e,t,n),as(e,n))}function Ms(e){var t=e.memoizedState,n=0;null!==t&&(n=t.retryLane),Ts(e,n)}function Ns(e,t){var n=0;switch(e.tag){case 13:var r=e.stateNode,a=e.memoizedState;null!==a&&(n=a.retryLane);break;case 19:r=e.stateNode;break;default:throw Error(i(314))}null!==r&&r.delete(t),Ts(e,n)}function Ps(e,t){return Qe(e,t)}function zs(e,t,n,r){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=r,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Ls(e,t,n,r){return new zs(e,t,n,r)}function Os(e){return!(!(e=e.prototype)||!e.isReactComponent)}function As(e,t){var n=e.alternate;return null===n?((n=Ls(e.tag,t,e.key,e.mode)).elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=14680064&e.flags,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=null===t?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n}function Fs(e,t,n,r,a,o){var u=2;if(r=e,\"function\"==typeof e)Os(e)&&(u=1);else if(\"string\"==typeof e)u=5;else e:switch(e){case k:return Ds(n.children,a,o,t);case S:u=8,a|=8;break;case E:return(e=Ls(12,n,t,2|a)).elementType=E,e.lanes=o,e;case N:return(e=Ls(13,n,t,a)).elementType=N,e.lanes=o,e;case P:return(e=Ls(19,n,t,a)).elementType=P,e.lanes=o,e;case O:return Rs(n,a,o,t);default:if(\"object\"==typeof e&&null!==e)switch(e.$$typeof){case C:u=10;break e;case T:u=9;break e;case M:u=11;break e;case z:u=14;break e;case L:u=16,r=null;break e}throw Error(i(130,null==e?e:typeof e,\"\"))}return(t=Ls(u,n,t,a)).elementType=e,t.type=r,t.lanes=o,t}function Ds(e,t,n,r){return(e=Ls(7,e,r,t)).lanes=n,e}function Rs(e,t,n,r){return(e=Ls(22,e,r,t)).elementType=O,e.lanes=n,e.stateNode={isHidden:!1},e}function js(e,t,n){return(e=Ls(6,e,null,t)).lanes=n,e}function Us(e,t,n){return(t=Ls(4,null!==e.children?e.children:[],e.key,t)).lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function Is(e,t,n,r,a){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=gt(0),this.expirationTimes=gt(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=gt(0),this.identifierPrefix=r,this.onRecoverableError=a,this.mutableSourceEagerHydrationData=null}function $s(e,t,n,r,a,i,o,u,l){return e=new Is(e,t,n,u,l),1===t?(t=1,!0===i&&(t|=8)):t=0,i=Ls(3,null,null,t),e.current=i,i.stateNode=e,i.memoizedState={element:r,isDehydrated:n,cache:null,transitions:null,pendingSuspenseBoundaries:null},zi(i),e}function Bs(e){if(!e)return Ta;e:{if(Be(e=e._reactInternals)!==e||1!==e.tag)throw Error(i(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(La(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(null!==t);throw Error(i(171))}if(1===e.tag){var n=e.type;if(La(n))return Fa(e,n,t)}return t}function Ws(e,t,n,r,a,i,o,u,l){return(e=$s(n,r,!0,e,0,i,0,u,l)).context=Bs(null),n=e.current,(i=Oi(r=ts(),a=ns(n))).callback=null!=t?t:null,Ai(n,i,a),e.current.lanes=a,yt(e,a,r),as(e,r),e}function Vs(e,t,n,r){var a=t.current,i=ts(),o=ns(a);return n=Bs(n),null===t.context?t.context=n:t.pendingContext=n,(t=Oi(i,o)).payload={element:e},null!==(r=void 0===r?null:r)&&(t.callback=r),null!==(e=Ai(a,t,o))&&(rs(e,a,o,i),Fi(e,a,o)),o}function Hs(e){return(e=e.current).child?(e.child.tag,e.child.stateNode):null}function qs(e,t){if(null!==(e=e.memoizedState)&&null!==e.dehydrated){var n=e.retryLane;e.retryLane=0!==n&&n<t?n:t}}function Qs(e,t){qs(e,t),(e=e.alternate)&&qs(e,t)}Sl=function(e,t,n){if(null!==e)if(e.memoizedProps!==t.pendingProps||Na.current)_u=!0;else{if(0==(e.lanes&n)&&0==(128&t.flags))return _u=!1,function(e,t,n){switch(t.tag){case 3:Pu(t),di();break;case 5:io(t);break;case 1:La(t.type)&&Da(t);break;case 4:ro(t,t.stateNode.containerInfo);break;case 10:var r=t.type._context,a=t.memoizedProps.value;Ca(yi,r._currentValue),r._currentValue=a;break;case 13:if(null!==(r=t.memoizedState))return null!==r.dehydrated?(Ca(uo,1&uo.current),t.flags|=128,null):0!=(n&t.child.childLanes)?ju(e,t,n):(Ca(uo,1&uo.current),null!==(e=Hu(e,t,n))?e.sibling:null);Ca(uo,1&uo.current);break;case 19:if(r=0!=(n&t.childLanes),0!=(128&e.flags)){if(r)return Wu(e,t,n);t.flags|=128}if(null!==(a=t.memoizedState)&&(a.rendering=null,a.tail=null,a.lastEffect=null),Ca(uo,uo.current),r)break;return null;case 22:case 23:return t.lanes=0,Eu(e,t,n)}return Hu(e,t,n)}(e,t,n);_u=0!=(131072&e.flags)}else _u=!1,ai&&0!=(1048576&t.flags)&&Ja(t,qa,t.index);switch(t.lanes=0,t.tag){case 2:var r=t.type;Vu(e,t),e=t.pendingProps;var a=za(t,Ma.current);Si(t,n),a=So(null,t,r,e,a,n);var o=Eo();return t.flags|=1,\"object\"==typeof a&&null!==a&&\"function\"==typeof a.render&&void 0===a.$$typeof?(t.tag=1,t.memoizedState=null,t.updateQueue=null,La(r)?(o=!0,Da(t)):o=!1,t.memoizedState=null!==a.state&&void 0!==a.state?a.state:null,zi(t),a.updater=$i,t.stateNode=a,a._reactInternals=t,Hi(t,r,e,n),t=Nu(null,t,r,!0,o,n)):(t.tag=0,ai&&o&&ei(t),wu(null,t,a,n),t=t.child),t;case 16:r=t.elementType;e:{switch(Vu(e,t),e=t.pendingProps,r=(a=r._init)(r._payload),t.type=r,a=t.tag=function(e){if(\"function\"==typeof e)return Os(e)?1:0;if(null!=e){if((e=e.$$typeof)===M)return 11;if(e===z)return 14}return 2}(r),e=gi(r,e),a){case 0:t=Tu(null,t,r,e,n);break e;case 1:t=Mu(null,t,r,e,n);break e;case 11:t=xu(null,t,r,e,n);break e;case 14:t=ku(null,t,r,gi(r.type,e),n);break e}throw Error(i(306,r,\"\"))}return t;case 0:return r=t.type,a=t.pendingProps,Tu(e,t,r,a=t.elementType===r?a:gi(r,a),n);case 1:return r=t.type,a=t.pendingProps,Mu(e,t,r,a=t.elementType===r?a:gi(r,a),n);case 3:e:{if(Pu(t),null===e)throw Error(i(387));r=t.pendingProps,a=(o=t.memoizedState).element,Li(e,t),Ri(t,r,null,n);var u=t.memoizedState;if(r=u.element,o.isDehydrated){if(o={element:r,isDehydrated:!1,cache:u.cache,pendingSuspenseBoundaries:u.pendingSuspenseBoundaries,transitions:u.transitions},t.updateQueue.baseState=o,t.memoizedState=o,256&t.flags){t=zu(e,t,r,n,a=cu(Error(i(423)),t));break e}if(r!==a){t=zu(e,t,r,n,a=cu(Error(i(424)),t));break e}for(ri=sa(t.stateNode.containerInfo.firstChild),ni=t,ai=!0,ii=null,n=Zi(t,null,r,n),t.child=n;n;)n.flags=-3&n.flags|4096,n=n.sibling}else{if(di(),r===a){t=Hu(e,t,n);break e}wu(e,t,r,n)}t=t.child}return t;case 5:return io(t),null===e&&si(t),r=t.type,a=t.pendingProps,o=null!==e?e.memoizedProps:null,u=a.children,na(r,a)?u=null:null!==o&&na(r,o)&&(t.flags|=32),Cu(e,t),wu(e,t,u,n),t.child;case 6:return null===e&&si(t),null;case 13:return ju(e,t,n);case 4:return ro(t,t.stateNode.containerInfo),r=t.pendingProps,null===e?t.child=Ki(t,null,r,n):wu(e,t,r,n),t.child;case 11:return r=t.type,a=t.pendingProps,xu(e,t,r,a=t.elementType===r?a:gi(r,a),n);case 7:return wu(e,t,t.pendingProps,n),t.child;case 8:case 12:return wu(e,t,t.pendingProps.children,n),t.child;case 10:e:{if(r=t.type._context,a=t.pendingProps,o=t.memoizedProps,u=a.value,Ca(yi,r._currentValue),r._currentValue=u,null!==o)if(ur(o.value,u)){if(o.children===a.children&&!Na.current){t=Hu(e,t,n);break e}}else for(null!==(o=t.child)&&(o.return=t);null!==o;){var l=o.dependencies;if(null!==l){u=o.child;for(var s=l.firstContext;null!==s;){if(s.context===r){if(1===o.tag){(s=Oi(-1,n&-n)).tag=2;var c=o.updateQueue;if(null!==c){var f=(c=c.shared).pending;null===f?s.next=s:(s.next=f.next,f.next=s),c.pending=s}}o.lanes|=n,null!==(s=o.alternate)&&(s.lanes|=n),ki(o.return,n,t),l.lanes|=n;break}s=s.next}}else if(10===o.tag)u=o.type===t.type?null:o.child;else if(18===o.tag){if(null===(u=o.return))throw Error(i(341));u.lanes|=n,null!==(l=u.alternate)&&(l.lanes|=n),ki(u,n,t),u=o.sibling}else u=o.child;if(null!==u)u.return=o;else for(u=o;null!==u;){if(u===t){u=null;break}if(null!==(o=u.sibling)){o.return=u.return,u=o;break}u=u.return}o=u}wu(e,t,a.children,n),t=t.child}return t;case 9:return a=t.type,r=t.pendingProps.children,Si(t,n),r=r(a=Ei(a)),t.flags|=1,wu(e,t,r,n),t.child;case 14:return a=gi(r=t.type,t.pendingProps),ku(e,t,r,a=gi(r.type,a),n);case 15:return Su(e,t,t.type,t.pendingProps,n);case 17:return r=t.type,a=t.pendingProps,a=t.elementType===r?a:gi(r,a),Vu(e,t),t.tag=1,La(r)?(e=!0,Da(t)):e=!1,Si(t,n),Wi(t,r,a),Hi(t,r,a,n),Nu(null,t,r,!0,e,n);case 19:return Wu(e,t,n);case 22:return Eu(e,t,n)}throw Error(i(156,t.tag))};var Ys=\"function\"==typeof reportError?reportError:function(e){console.error(e)};function Gs(e){this._internalRoot=e}function Ks(e){this._internalRoot=e}function Zs(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType)}function Xs(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType&&(8!==e.nodeType||\" react-mount-point-unstable \"!==e.nodeValue))}function Js(){}function ec(e,t,n,r,a){var i=n._reactRootContainer;if(i){var o=i;if(\"function\"==typeof a){var u=a;a=function(){var e=Hs(o);u.call(e)}}Vs(t,o,e,a)}else o=function(e,t,n,r,a){if(a){if(\"function\"==typeof r){var i=r;r=function(){var e=Hs(o);i.call(e)}}var o=Ws(t,r,e,0,null,!1,0,\"\",Js);return e._reactRootContainer=o,e[ha]=o.current,Br(8===e.nodeType?e.parentNode:e),fs(),o}for(;a=e.lastChild;)e.removeChild(a);if(\"function\"==typeof r){var u=r;r=function(){var e=Hs(l);u.call(e)}}var l=$s(e,0,!1,null,0,!1,0,\"\",Js);return e._reactRootContainer=l,e[ha]=l.current,Br(8===e.nodeType?e.parentNode:e),fs((function(){Vs(t,l,n,r)})),l}(n,t,e,a,r);return Hs(o)}Ks.prototype.render=Gs.prototype.render=function(e){var t=this._internalRoot;if(null===t)throw Error(i(409));Vs(e,t,null,null)},Ks.prototype.unmount=Gs.prototype.unmount=function(){var e=this._internalRoot;if(null!==e){this._internalRoot=null;var t=e.containerInfo;fs((function(){Vs(null,e,null,null)})),t[ha]=null}},Ks.prototype.unstable_scheduleHydration=function(e){if(e){var t=St();e={blockedOn:null,target:e,priority:t};for(var n=0;n<Ot.length&&0!==t&&t<Ot[n].priority;n++);Ot.splice(n,0,e),0===n&&Rt(e)}},wt=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var n=ft(t.pendingLanes);0!==n&&(mt(t,1|n),as(t,Ze()),0==(6&Nl)&&(Wl=Ze()+500,Ba()))}break;case 13:fs((function(){var t=Ni(e,1);if(null!==t){var n=ts();rs(t,e,1,n)}})),Qs(e,1)}},xt=function(e){if(13===e.tag){var t=Ni(e,134217728);null!==t&&rs(t,e,134217728,ts()),Qs(e,134217728)}},kt=function(e){if(13===e.tag){var t=ns(e),n=Ni(e,t);null!==n&&rs(n,e,t,ts()),Qs(e,t)}},St=function(){return bt},Et=function(e,t){var n=bt;try{return bt=e,t()}finally{bt=n}},xe=function(e,t,n){switch(t){case\"input\":if(X(e,n),t=n.name,\"radio\"===n.type&&null!=t){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll(\"input[name=\"+JSON.stringify(\"\"+t)+'][type=\"radio\"]'),t=0;t<n.length;t++){var r=n[t];if(r!==e&&r.form===e.form){var a=wa(r);if(!a)throw Error(i(90));Q(r),X(r,a)}}}break;case\"textarea\":ie(e,n);break;case\"select\":null!=(t=n.value)&&ne(e,!!n.multiple,t,!1)}},Me=cs,Ne=fs;var tc={usingClientEntryPoint:!1,Events:[ba,_a,wa,Ce,Te,cs]},nc={findFiberByHostInstance:ma,bundleType:0,version:\"18.2.0\",rendererPackageName:\"react-dom\"},rc={bundleType:nc.bundleType,version:nc.version,rendererPackageName:nc.rendererPackageName,rendererConfig:nc.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:_.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return null===(e=He(e))?null:e.stateNode},findFiberByHostInstance:nc.findFiberByHostInstance||function(){return null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:\"18.2.0-next-9e3b772b8-20220608\"};if(\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__){var ac=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!ac.isDisabled&&ac.supportsFiber)try{at=ac.inject(rc),it=ac}catch(ce){}}t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=tc,t.createPortal=function(e,t){var n=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;if(!Zs(t))throw Error(i(200));return function(e,t,n){var r=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:x,key:null==r?null:\"\"+r,children:e,containerInfo:t,implementation:n}}(e,t,null,n)},t.createRoot=function(e,t){if(!Zs(e))throw Error(i(299));var n=!1,r=\"\",a=Ys;return null!=t&&(!0===t.unstable_strictMode&&(n=!0),void 0!==t.identifierPrefix&&(r=t.identifierPrefix),void 0!==t.onRecoverableError&&(a=t.onRecoverableError)),t=$s(e,1,!1,null,0,n,0,r,a),e[ha]=t.current,Br(8===e.nodeType?e.parentNode:e),new Gs(t)},t.findDOMNode=function(e){if(null==e)return null;if(1===e.nodeType)return e;var t=e._reactInternals;if(void 0===t){if(\"function\"==typeof e.render)throw Error(i(188));throw e=Object.keys(e).join(\",\"),Error(i(268,e))}return null===(e=He(t))?null:e.stateNode},t.flushSync=function(e){return fs(e)},t.hydrate=function(e,t,n){if(!Xs(t))throw Error(i(200));return ec(null,e,t,!0,n)},t.hydrateRoot=function(e,t,n){if(!Zs(e))throw Error(i(405));var r=null!=n&&n.hydratedSources||null,a=!1,o=\"\",u=Ys;if(null!=n&&(!0===n.unstable_strictMode&&(a=!0),void 0!==n.identifierPrefix&&(o=n.identifierPrefix),void 0!==n.onRecoverableError&&(u=n.onRecoverableError)),t=Ws(t,null,e,1,null!=n?n:null,a,0,o,u),e[ha]=t.current,Br(e),r)for(e=0;e<r.length;e++)a=(a=(n=r[e])._getVersion)(n._source),null==t.mutableSourceEagerHydrationData?t.mutableSourceEagerHydrationData=[n,a]:t.mutableSourceEagerHydrationData.push(n,a);return new Ks(t)},t.render=function(e,t,n){if(!Xs(t))throw Error(i(200));return ec(null,e,t,!1,n)},t.unmountComponentAtNode=function(e){if(!Xs(e))throw Error(i(40));return!!e._reactRootContainer&&(fs((function(){ec(null,null,e,!1,(function(){e._reactRootContainer=null,e[ha]=null}))})),!0)},t.unstable_batchedUpdates=cs,t.unstable_renderSubtreeIntoContainer=function(e,t,n,r){if(!Xs(n))throw Error(i(200));if(null==e||void 0===e._reactInternals)throw Error(i(38));return ec(e,t,n,!1,r)},t.version=\"18.2.0-next-9e3b772b8-20220608\"},935:(e,t,n)=>{\"use strict\";!function e(){if(\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&\"function\"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE)try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(e)}catch(e){console.error(e)}}(),e.exports=n(448)},408:(e,t)=>{\"use strict\";var n=Symbol.for(\"react.element\"),r=Symbol.for(\"react.portal\"),a=Symbol.for(\"react.fragment\"),i=Symbol.for(\"react.strict_mode\"),o=Symbol.for(\"react.profiler\"),u=Symbol.for(\"react.provider\"),l=Symbol.for(\"react.context\"),s=Symbol.for(\"react.forward_ref\"),c=Symbol.for(\"react.suspense\"),f=Symbol.for(\"react.memo\"),p=Symbol.for(\"react.lazy\"),d=Symbol.iterator,h={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},v=Object.assign,g={};function y(e,t,n){this.props=e,this.context=t,this.refs=g,this.updater=n||h}function m(){}function b(e,t,n){this.props=e,this.context=t,this.refs=g,this.updater=n||h}y.prototype.isReactComponent={},y.prototype.setState=function(e,t){if(\"object\"!=typeof e&&\"function\"!=typeof e&&null!=e)throw Error(\"setState(...): takes an object of state variables to update or a function which returns an object of state variables.\");this.updater.enqueueSetState(this,e,t,\"setState\")},y.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,\"forceUpdate\")},m.prototype=y.prototype;var _=b.prototype=new m;_.constructor=b,v(_,y.prototype),_.isPureReactComponent=!0;var w=Array.isArray,x=Object.prototype.hasOwnProperty,k={current:null},S={key:!0,ref:!0,__self:!0,__source:!0};function E(e,t,r){var a,i={},o=null,u=null;if(null!=t)for(a in void 0!==t.ref&&(u=t.ref),void 0!==t.key&&(o=\"\"+t.key),t)x.call(t,a)&&!S.hasOwnProperty(a)&&(i[a]=t[a]);var l=arguments.length-2;if(1===l)i.children=r;else if(1<l){for(var s=Array(l),c=0;c<l;c++)s[c]=arguments[c+2];i.children=s}if(e&&e.defaultProps)for(a in l=e.defaultProps)void 0===i[a]&&(i[a]=l[a]);return{$$typeof:n,type:e,key:o,ref:u,props:i,_owner:k.current}}function C(e){return\"object\"==typeof e&&null!==e&&e.$$typeof===n}var T=/\\/+/g;function M(e,t){return\"object\"==typeof e&&null!==e&&null!=e.key?function(e){var t={\"=\":\"=0\",\":\":\"=2\"};return\"$\"+e.replace(/[=:]/g,(function(e){return t[e]}))}(\"\"+e.key):t.toString(36)}function N(e,t,a,i,o){var u=typeof e;\"undefined\"!==u&&\"boolean\"!==u||(e=null);var l=!1;if(null===e)l=!0;else switch(u){case\"string\":case\"number\":l=!0;break;case\"object\":switch(e.$$typeof){case n:case r:l=!0}}if(l)return o=o(l=e),e=\"\"===i?\".\"+M(l,0):i,w(o)?(a=\"\",null!=e&&(a=e.replace(T,\"$&/\")+\"/\"),N(o,t,a,\"\",(function(e){return e}))):null!=o&&(C(o)&&(o=function(e,t){return{$$typeof:n,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}(o,a+(!o.key||l&&l.key===o.key?\"\":(\"\"+o.key).replace(T,\"$&/\")+\"/\")+e)),t.push(o)),1;if(l=0,i=\"\"===i?\".\":i+\":\",w(e))for(var s=0;s<e.length;s++){var c=i+M(u=e[s],s);l+=N(u,t,a,c,o)}else if(c=function(e){return null===e||\"object\"!=typeof e?null:\"function\"==typeof(e=d&&e[d]||e[\"@@iterator\"])?e:null}(e),\"function\"==typeof c)for(e=c.call(e),s=0;!(u=e.next()).done;)l+=N(u=u.value,t,a,c=i+M(u,s++),o);else if(\"object\"===u)throw t=String(e),Error(\"Objects are not valid as a React child (found: \"+(\"[object Object]\"===t?\"object with keys {\"+Object.keys(e).join(\", \")+\"}\":t)+\"). If you meant to render a collection of children, use an array instead.\");return l}function P(e,t,n){if(null==e)return e;var r=[],a=0;return N(e,r,\"\",\"\",(function(e){return t.call(n,e,a++)})),r}function z(e){if(-1===e._status){var t=e._result;(t=t()).then((function(t){0!==e._status&&-1!==e._status||(e._status=1,e._result=t)}),(function(t){0!==e._status&&-1!==e._status||(e._status=2,e._result=t)})),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var L={current:null},O={transition:null},A={ReactCurrentDispatcher:L,ReactCurrentBatchConfig:O,ReactCurrentOwner:k};t.Children={map:P,forEach:function(e,t,n){P(e,(function(){t.apply(this,arguments)}),n)},count:function(e){var t=0;return P(e,(function(){t++})),t},toArray:function(e){return P(e,(function(e){return e}))||[]},only:function(e){if(!C(e))throw Error(\"React.Children.only expected to receive a single React element child.\");return e}},t.Component=y,t.Fragment=a,t.Profiler=o,t.PureComponent=b,t.StrictMode=i,t.Suspense=c,t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=A,t.cloneElement=function(e,t,r){if(null==e)throw Error(\"React.cloneElement(...): The argument must be a React element, but you passed \"+e+\".\");var a=v({},e.props),i=e.key,o=e.ref,u=e._owner;if(null!=t){if(void 0!==t.ref&&(o=t.ref,u=k.current),void 0!==t.key&&(i=\"\"+t.key),e.type&&e.type.defaultProps)var l=e.type.defaultProps;for(s in t)x.call(t,s)&&!S.hasOwnProperty(s)&&(a[s]=void 0===t[s]&&void 0!==l?l[s]:t[s])}var s=arguments.length-2;if(1===s)a.children=r;else if(1<s){l=Array(s);for(var c=0;c<s;c++)l[c]=arguments[c+2];a.children=l}return{$$typeof:n,type:e.type,key:i,ref:o,props:a,_owner:u}},t.createContext=function(e){return(e={$$typeof:l,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null}).Provider={$$typeof:u,_context:e},e.Consumer=e},t.createElement=E,t.createFactory=function(e){var t=E.bind(null,e);return t.type=e,t},t.createRef=function(){return{current:null}},t.forwardRef=function(e){return{$$typeof:s,render:e}},t.isValidElement=C,t.lazy=function(e){return{$$typeof:p,_payload:{_status:-1,_result:e},_init:z}},t.memo=function(e,t){return{$$typeof:f,type:e,compare:void 0===t?null:t}},t.startTransition=function(e){var t=O.transition;O.transition={};try{e()}finally{O.transition=t}},t.unstable_act=function(){throw Error(\"act(...) is not supported in production builds of React.\")},t.useCallback=function(e,t){return L.current.useCallback(e,t)},t.useContext=function(e){return L.current.useContext(e)},t.useDebugValue=function(){},t.useDeferredValue=function(e){return L.current.useDeferredValue(e)},t.useEffect=function(e,t){return L.current.useEffect(e,t)},t.useId=function(){return L.current.useId()},t.useImperativeHandle=function(e,t,n){return L.current.useImperativeHandle(e,t,n)},t.useInsertionEffect=function(e,t){return L.current.useInsertionEffect(e,t)},t.useLayoutEffect=function(e,t){return L.current.useLayoutEffect(e,t)},t.useMemo=function(e,t){return L.current.useMemo(e,t)},t.useReducer=function(e,t,n){return L.current.useReducer(e,t,n)},t.useRef=function(e){return L.current.useRef(e)},t.useState=function(e){return L.current.useState(e)},t.useSyncExternalStore=function(e,t,n){return L.current.useSyncExternalStore(e,t,n)},t.useTransition=function(){return L.current.useTransition()},t.version=\"18.2.0\"},294:(e,t,n)=>{\"use strict\";e.exports=n(408)},53:(e,t)=>{\"use strict\";function n(e,t){var n=e.length;e.push(t);e:for(;0<n;){var r=n-1>>>1,a=e[r];if(!(0<i(a,t)))break e;e[r]=t,e[n]=a,n=r}}function r(e){return 0===e.length?null:e[0]}function a(e){if(0===e.length)return null;var t=e[0],n=e.pop();if(n!==t){e[0]=n;e:for(var r=0,a=e.length,o=a>>>1;r<o;){var u=2*(r+1)-1,l=e[u],s=u+1,c=e[s];if(0>i(l,n))s<a&&0>i(c,l)?(e[r]=c,e[s]=n,r=s):(e[r]=l,e[u]=n,r=u);else{if(!(s<a&&0>i(c,n)))break e;e[r]=c,e[s]=n,r=s}}}return t}function i(e,t){var n=e.sortIndex-t.sortIndex;return 0!==n?n:e.id-t.id}if(\"object\"==typeof performance&&\"function\"==typeof performance.now){var o=performance;t.unstable_now=function(){return o.now()}}else{var u=Date,l=u.now();t.unstable_now=function(){return u.now()-l}}var s=[],c=[],f=1,p=null,d=3,h=!1,v=!1,g=!1,y=\"function\"==typeof setTimeout?setTimeout:null,m=\"function\"==typeof clearTimeout?clearTimeout:null,b=\"undefined\"!=typeof setImmediate?setImmediate:null;function _(e){for(var t=r(c);null!==t;){if(null===t.callback)a(c);else{if(!(t.startTime<=e))break;a(c),t.sortIndex=t.expirationTime,n(s,t)}t=r(c)}}function w(e){if(g=!1,_(e),!v)if(null!==r(s))v=!0,O(x);else{var t=r(c);null!==t&&A(w,t.startTime-e)}}function x(e,n){v=!1,g&&(g=!1,m(C),C=-1),h=!0;var i=d;try{for(_(n),p=r(s);null!==p&&(!(p.expirationTime>n)||e&&!N());){var o=p.callback;if(\"function\"==typeof o){p.callback=null,d=p.priorityLevel;var u=o(p.expirationTime<=n);n=t.unstable_now(),\"function\"==typeof u?p.callback=u:p===r(s)&&a(s),_(n)}else a(s);p=r(s)}if(null!==p)var l=!0;else{var f=r(c);null!==f&&A(w,f.startTime-n),l=!1}return l}finally{p=null,d=i,h=!1}}\"undefined\"!=typeof navigator&&void 0!==navigator.scheduling&&void 0!==navigator.scheduling.isInputPending&&navigator.scheduling.isInputPending.bind(navigator.scheduling);var k,S=!1,E=null,C=-1,T=5,M=-1;function N(){return!(t.unstable_now()-M<T)}function P(){if(null!==E){var e=t.unstable_now();M=e;var n=!0;try{n=E(!0,e)}finally{n?k():(S=!1,E=null)}}else S=!1}if(\"function\"==typeof b)k=function(){b(P)};else if(\"undefined\"!=typeof MessageChannel){var z=new MessageChannel,L=z.port2;z.port1.onmessage=P,k=function(){L.postMessage(null)}}else k=function(){y(P,0)};function O(e){E=e,S||(S=!0,k())}function A(e,n){C=y((function(){e(t.unstable_now())}),n)}t.unstable_IdlePriority=5,t.unstable_ImmediatePriority=1,t.unstable_LowPriority=4,t.unstable_NormalPriority=3,t.unstable_Profiling=null,t.unstable_UserBlockingPriority=2,t.unstable_cancelCallback=function(e){e.callback=null},t.unstable_continueExecution=function(){v||h||(v=!0,O(x))},t.unstable_forceFrameRate=function(e){0>e||125<e?console.error(\"forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported\"):T=0<e?Math.floor(1e3/e):5},t.unstable_getCurrentPriorityLevel=function(){return d},t.unstable_getFirstCallbackNode=function(){return r(s)},t.unstable_next=function(e){switch(d){case 1:case 2:case 3:var t=3;break;default:t=d}var n=d;d=t;try{return e()}finally{d=n}},t.unstable_pauseExecution=function(){},t.unstable_requestPaint=function(){},t.unstable_runWithPriority=function(e,t){switch(e){case 1:case 2:case 3:case 4:case 5:break;default:e=3}var n=d;d=e;try{return t()}finally{d=n}},t.unstable_scheduleCallback=function(e,a,i){var o=t.unstable_now();switch(i=\"object\"==typeof i&&null!==i&&\"number\"==typeof(i=i.delay)&&0<i?o+i:o,e){case 1:var u=-1;break;case 2:u=250;break;case 5:u=1073741823;break;case 4:u=1e4;break;default:u=5e3}return e={id:f++,callback:a,priorityLevel:e,startTime:i,expirationTime:u=i+u,sortIndex:-1},i>o?(e.sortIndex=i,n(c,e),null===r(s)&&e===r(c)&&(g?(m(C),C=-1):g=!0,A(w,i-o))):(e.sortIndex=u,n(s,e),v||h||(v=!0,O(x))),e},t.unstable_shouldYield=N,t.unstable_wrapCallback=function(e){var t=d;return function(){var n=d;d=t;try{return e.apply(this,arguments)}finally{d=n}}}},840:(e,t,n)=>{\"use strict\";e.exports=n(53)}},t={};function n(r){var a=t[r];if(void 0!==a)return a.exports;var i=t[r]={id:r,loaded:!1,exports:{}};return e[r].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(e){if(\"object\"==typeof window)return window}}(),n.nmd=e=>(e.paths=[],e.children||(e.children=[]),e),(()=>{\"use strict\";var e=n(294),t=n(935);const r=Math.sqrt(50),a=Math.sqrt(10),i=Math.sqrt(2);function o(e,t,n){const u=(t-e)/Math.max(0,n),l=Math.floor(Math.log10(u)),s=u/Math.pow(10,l),c=s>=r?10:s>=a?5:s>=i?2:1;let f,p,d;return l<0?(d=Math.pow(10,-l)/c,f=Math.round(e*d),p=Math.round(t*d),f/d<e&&++f,p/d>t&&--p,d=-d):(d=Math.pow(10,l)*c,f=Math.round(e/d),p=Math.round(t/d),f*d<e&&++f,p*d>t&&--p),p<f&&.5<=n&&n<2?o(e,t,2*n):[f,p,d]}function u(e,t,n){return o(e=+e,t=+t,n=+n)[2]}function l(e,t,n){n=+n;const r=(t=+t)<(e=+e),a=r?u(t,e,n):u(e,t,n);return(r?-1:1)*(a<0?1/-a:a)}function s(e,t){return null==e||null==t?NaN:e<t?-1:e>t?1:e>=t?0:NaN}function c(e,t){return null==e||null==t?NaN:t<e?-1:t>e?1:t>=e?0:NaN}function f(e){let t,n,r;function a(e,r,a=0,i=e.length){if(a<i){if(0!==t(r,r))return i;do{const t=a+i>>>1;n(e[t],r)<0?a=t+1:i=t}while(a<i)}return a}return 2!==e.length?(t=s,n=(t,n)=>s(e(t),n),r=(t,n)=>e(t)-n):(t=e===s||e===c?e:p,n=e,r=e),{left:a,center:function(e,t,n=0,i=e.length){const o=a(e,t,n,i-1);return o>n&&r(e[o-1],t)>-r(e[o],t)?o-1:o},right:function(e,r,a=0,i=e.length){if(a<i){if(0!==t(r,r))return i;do{const t=a+i>>>1;n(e[t],r)<=0?a=t+1:i=t}while(a<i)}return a}}}function p(){return 0}const d=f(s),h=d.right,v=(d.left,f((function(e){return null===e?NaN:+e})).center,h);function g(e,t,n){e.prototype=t.prototype=n,n.constructor=e}function y(e,t){var n=Object.create(e.prototype);for(var r in t)n[r]=t[r];return n}function m(){}var b=.7,_=1/b,w=\"\\\\s*([+-]?\\\\d+)\\\\s*\",x=\"\\\\s*([+-]?(?:\\\\d*\\\\.)?\\\\d+(?:[eE][+-]?\\\\d+)?)\\\\s*\",k=\"\\\\s*([+-]?(?:\\\\d*\\\\.)?\\\\d+(?:[eE][+-]?\\\\d+)?)%\\\\s*\",S=/^#([0-9a-f]{3,8})$/,E=new RegExp(`^rgb\\\\(${w},${w},${w}\\\\)$`),C=new RegExp(`^rgb\\\\(${k},${k},${k}\\\\)$`),T=new RegExp(`^rgba\\\\(${w},${w},${w},${x}\\\\)$`),M=new RegExp(`^rgba\\\\(${k},${k},${k},${x}\\\\)$`),N=new RegExp(`^hsl\\\\(${x},${k},${k}\\\\)$`),P=new RegExp(`^hsla\\\\(${x},${k},${k},${x}\\\\)$`),z={aliceblue:15792383,antiquewhite:16444375,aqua:65535,aquamarine:8388564,azure:15794175,beige:16119260,bisque:16770244,black:0,blanchedalmond:16772045,blue:255,blueviolet:9055202,brown:10824234,burlywood:14596231,cadetblue:6266528,chartreuse:8388352,chocolate:13789470,coral:16744272,cornflowerblue:6591981,cornsilk:16775388,crimson:14423100,cyan:65535,darkblue:139,darkcyan:35723,darkgoldenrod:12092939,darkgray:11119017,darkgreen:25600,darkgrey:11119017,darkkhaki:12433259,darkmagenta:9109643,darkolivegreen:5597999,darkorange:16747520,darkorchid:10040012,darkred:9109504,darksalmon:15308410,darkseagreen:9419919,darkslateblue:4734347,darkslategray:3100495,darkslategrey:3100495,darkturquoise:52945,darkviolet:9699539,deeppink:16716947,deepskyblue:49151,dimgray:6908265,dimgrey:6908265,dodgerblue:2003199,firebrick:11674146,floralwhite:16775920,forestgreen:2263842,fuchsia:16711935,gainsboro:14474460,ghostwhite:16316671,gold:16766720,goldenrod:14329120,gray:8421504,green:32768,greenyellow:11403055,grey:8421504,honeydew:15794160,hotpink:16738740,indianred:13458524,indigo:4915330,ivory:16777200,khaki:15787660,lavender:15132410,lavenderblush:16773365,lawngreen:8190976,lemonchiffon:16775885,lightblue:11393254,lightcoral:15761536,lightcyan:14745599,lightgoldenrodyellow:16448210,lightgray:13882323,lightgreen:9498256,lightgrey:13882323,lightpink:16758465,lightsalmon:16752762,lightseagreen:2142890,lightskyblue:8900346,lightslategray:7833753,lightslategrey:7833753,lightsteelblue:11584734,lightyellow:16777184,lime:65280,limegreen:3329330,linen:16445670,magenta:16711935,maroon:8388608,mediumaquamarine:6737322,mediumblue:205,mediumorchid:12211667,mediumpurple:9662683,mediumseagreen:3978097,mediumslateblue:8087790,mediumspringgreen:64154,mediumturquoise:4772300,mediumvioletred:13047173,midnightblue:1644912,mintcream:16121850,mistyrose:16770273,moccasin:16770229,navajowhite:16768685,navy:128,oldlace:16643558,olive:8421376,olivedrab:7048739,orange:16753920,orangered:16729344,orchid:14315734,palegoldenrod:15657130,palegreen:10025880,paleturquoise:11529966,palevioletred:14381203,papayawhip:16773077,peachpuff:16767673,peru:13468991,pink:16761035,plum:14524637,powderblue:11591910,purple:8388736,rebeccapurple:6697881,red:16711680,rosybrown:12357519,royalblue:4286945,saddlebrown:9127187,salmon:16416882,sandybrown:16032864,seagreen:3050327,seashell:16774638,sienna:10506797,silver:12632256,skyblue:8900331,slateblue:6970061,slategray:7372944,slategrey:7372944,snow:16775930,springgreen:65407,steelblue:4620980,tan:13808780,teal:32896,thistle:14204888,tomato:16737095,turquoise:4251856,violet:15631086,wheat:16113331,white:16777215,whitesmoke:16119285,yellow:16776960,yellowgreen:10145074};function L(){return this.rgb().formatHex()}function O(){return this.rgb().formatRgb()}function A(e){var t,n;return e=(e+\"\").trim().toLowerCase(),(t=S.exec(e))?(n=t[1].length,t=parseInt(t[1],16),6===n?F(t):3===n?new j(t>>8&15|t>>4&240,t>>4&15|240&t,(15&t)<<4|15&t,1):8===n?D(t>>24&255,t>>16&255,t>>8&255,(255&t)/255):4===n?D(t>>12&15|t>>8&240,t>>8&15|t>>4&240,t>>4&15|240&t,((15&t)<<4|15&t)/255):null):(t=E.exec(e))?new j(t[1],t[2],t[3],1):(t=C.exec(e))?new j(255*t[1]/100,255*t[2]/100,255*t[3]/100,1):(t=T.exec(e))?D(t[1],t[2],t[3],t[4]):(t=M.exec(e))?D(255*t[1]/100,255*t[2]/100,255*t[3]/100,t[4]):(t=N.exec(e))?V(t[1],t[2]/100,t[3]/100,1):(t=P.exec(e))?V(t[1],t[2]/100,t[3]/100,t[4]):z.hasOwnProperty(e)?F(z[e]):\"transparent\"===e?new j(NaN,NaN,NaN,0):null}function F(e){return new j(e>>16&255,e>>8&255,255&e,1)}function D(e,t,n,r){return r<=0&&(e=t=n=NaN),new j(e,t,n,r)}function R(e,t,n,r){return 1===arguments.length?((a=e)instanceof m||(a=A(a)),a?new j((a=a.rgb()).r,a.g,a.b,a.opacity):new j):new j(e,t,n,null==r?1:r);var a}function j(e,t,n,r){this.r=+e,this.g=+t,this.b=+n,this.opacity=+r}function U(){return`#${W(this.r)}${W(this.g)}${W(this.b)}`}function I(){const e=$(this.opacity);return`${1===e?\"rgb(\":\"rgba(\"}${B(this.r)}, ${B(this.g)}, ${B(this.b)}${1===e?\")\":`, ${e})`}`}function $(e){return isNaN(e)?1:Math.max(0,Math.min(1,e))}function B(e){return Math.max(0,Math.min(255,Math.round(e)||0))}function W(e){return((e=B(e))<16?\"0\":\"\")+e.toString(16)}function V(e,t,n,r){return r<=0?e=t=n=NaN:n<=0||n>=1?e=t=NaN:t<=0&&(e=NaN),new Q(e,t,n,r)}function H(e){if(e instanceof Q)return new Q(e.h,e.s,e.l,e.opacity);if(e instanceof m||(e=A(e)),!e)return new Q;if(e instanceof Q)return e;var t=(e=e.rgb()).r/255,n=e.g/255,r=e.b/255,a=Math.min(t,n,r),i=Math.max(t,n,r),o=NaN,u=i-a,l=(i+a)/2;return u?(o=t===i?(n-r)/u+6*(n<r):n===i?(r-t)/u+2:(t-n)/u+4,u/=l<.5?i+a:2-i-a,o*=60):u=l>0&&l<1?0:o,new Q(o,u,l,e.opacity)}function q(e,t,n,r){return 1===arguments.length?H(e):new Q(e,t,n,null==r?1:r)}function Q(e,t,n,r){this.h=+e,this.s=+t,this.l=+n,this.opacity=+r}function Y(e){return(e=(e||0)%360)<0?e+360:e}function G(e){return Math.max(0,Math.min(1,e||0))}function K(e,t,n){return 255*(e<60?t+(n-t)*e/60:e<180?n:e<240?t+(n-t)*(240-e)/60:t)}function Z(e,t,n,r,a){var i=e*e,o=i*e;return((1-3*e+3*i-o)*t+(4-6*i+3*o)*n+(1+3*e+3*i-3*o)*r+o*a)/6}g(m,A,{copy(e){return Object.assign(new this.constructor,this,e)},displayable(){return this.rgb().displayable()},hex:L,formatHex:L,formatHex8:function(){return this.rgb().formatHex8()},formatHsl:function(){return H(this).formatHsl()},formatRgb:O,toString:O}),g(j,R,y(m,{brighter(e){return e=null==e?_:Math.pow(_,e),new j(this.r*e,this.g*e,this.b*e,this.opacity)},darker(e){return e=null==e?b:Math.pow(b,e),new j(this.r*e,this.g*e,this.b*e,this.opacity)},rgb(){return this},clamp(){return new j(B(this.r),B(this.g),B(this.b),$(this.opacity))},displayable(){return-.5<=this.r&&this.r<255.5&&-.5<=this.g&&this.g<255.5&&-.5<=this.b&&this.b<255.5&&0<=this.opacity&&this.opacity<=1},hex:U,formatHex:U,formatHex8:function(){return`#${W(this.r)}${W(this.g)}${W(this.b)}${W(255*(isNaN(this.opacity)?1:this.opacity))}`},formatRgb:I,toString:I})),g(Q,q,y(m,{brighter(e){return e=null==e?_:Math.pow(_,e),new Q(this.h,this.s,this.l*e,this.opacity)},darker(e){return e=null==e?b:Math.pow(b,e),new Q(this.h,this.s,this.l*e,this.opacity)},rgb(){var e=this.h%360+360*(this.h<0),t=isNaN(e)||isNaN(this.s)?0:this.s,n=this.l,r=n+(n<.5?n:1-n)*t,a=2*n-r;return new j(K(e>=240?e-240:e+120,a,r),K(e,a,r),K(e<120?e+240:e-120,a,r),this.opacity)},clamp(){return new Q(Y(this.h),G(this.s),G(this.l),$(this.opacity))},displayable(){return(0<=this.s&&this.s<=1||isNaN(this.s))&&0<=this.l&&this.l<=1&&0<=this.opacity&&this.opacity<=1},formatHsl(){const e=$(this.opacity);return`${1===e?\"hsl(\":\"hsla(\"}${Y(this.h)}, ${100*G(this.s)}%, ${100*G(this.l)}%${1===e?\")\":`, ${e})`}`}}));const X=e=>()=>e;function J(e,t){var n=t-e;return n?function(e,t){return function(n){return e+n*t}}(e,n):X(isNaN(e)?t:e)}const ee=function e(t){var n=function(e){return 1==(e=+e)?J:function(t,n){return n-t?function(e,t,n){return e=Math.pow(e,n),t=Math.pow(t,n)-e,n=1/n,function(r){return Math.pow(e+r*t,n)}}(t,n,e):X(isNaN(t)?n:t)}}(t);function r(e,t){var r=n((e=R(e)).r,(t=R(t)).r),a=n(e.g,t.g),i=n(e.b,t.b),o=J(e.opacity,t.opacity);return function(t){return e.r=r(t),e.g=a(t),e.b=i(t),e.opacity=o(t),e+\"\"}}return r.gamma=e,r}(1);function te(e){return function(t){var n,r,a=t.length,i=new Array(a),o=new Array(a),u=new Array(a);for(n=0;n<a;++n)r=R(t[n]),i[n]=r.r||0,o[n]=r.g||0,u[n]=r.b||0;return i=e(i),o=e(o),u=e(u),r.opacity=1,function(e){return r.r=i(e),r.g=o(e),r.b=u(e),r+\"\"}}}function ne(e,t){var n,r=t?t.length:0,a=e?Math.min(r,e.length):0,i=new Array(a),o=new Array(r);for(n=0;n<a;++n)i[n]=ce(e[n],t[n]);for(;n<r;++n)o[n]=t[n];return function(e){for(n=0;n<a;++n)o[n]=i[n](e);return o}}function re(e,t){var n=new Date;return e=+e,t=+t,function(r){return n.setTime(e*(1-r)+t*r),n}}function ae(e,t){return e=+e,t=+t,function(n){return e*(1-n)+t*n}}function ie(e,t){var n,r={},a={};for(n in null!==e&&\"object\"==typeof e||(e={}),null!==t&&\"object\"==typeof t||(t={}),t)n in e?r[n]=ce(e[n],t[n]):a[n]=t[n];return function(e){for(n in r)a[n]=r[n](e);return a}}te((function(e){var t=e.length-1;return function(n){var r=n<=0?n=0:n>=1?(n=1,t-1):Math.floor(n*t),a=e[r],i=e[r+1],o=r>0?e[r-1]:2*a-i,u=r<t-1?e[r+2]:2*i-a;return Z((n-r/t)*t,o,a,i,u)}})),te((function(e){var t=e.length;return function(n){var r=Math.floor(((n%=1)<0?++n:n)*t),a=e[(r+t-1)%t],i=e[r%t],o=e[(r+1)%t],u=e[(r+2)%t];return Z((n-r/t)*t,a,i,o,u)}}));var oe=/[-+]?(?:\\d+\\.?\\d*|\\.?\\d+)(?:[eE][-+]?\\d+)?/g,ue=new RegExp(oe.source,\"g\");function le(e,t){var n,r,a,i=oe.lastIndex=ue.lastIndex=0,o=-1,u=[],l=[];for(e+=\"\",t+=\"\";(n=oe.exec(e))&&(r=ue.exec(t));)(a=r.index)>i&&(a=t.slice(i,a),u[o]?u[o]+=a:u[++o]=a),(n=n[0])===(r=r[0])?u[o]?u[o]+=r:u[++o]=r:(u[++o]=null,l.push({i:o,x:ae(n,r)})),i=ue.lastIndex;return i<t.length&&(a=t.slice(i),u[o]?u[o]+=a:u[++o]=a),u.length<2?l[0]?function(e){return function(t){return e(t)+\"\"}}(l[0].x):function(e){return function(){return e}}(t):(t=l.length,function(e){for(var n,r=0;r<t;++r)u[(n=l[r]).i]=n.x(e);return u.join(\"\")})}function se(e,t){t||(t=[]);var n,r=e?Math.min(t.length,e.length):0,a=t.slice();return function(i){for(n=0;n<r;++n)a[n]=e[n]*(1-i)+t[n]*i;return a}}function ce(e,t){var n,r,a=typeof t;return null==t||\"boolean\"===a?X(t):(\"number\"===a?ae:\"string\"===a?(n=A(t))?(t=n,ee):le:t instanceof A?ee:t instanceof Date?re:(r=t,!ArrayBuffer.isView(r)||r instanceof DataView?Array.isArray(t)?ne:\"function\"!=typeof t.valueOf&&\"function\"!=typeof t.toString||isNaN(t)?ie:ae:se))(e,t)}function fe(e,t){return e=+e,t=+t,function(n){return Math.round(e*(1-n)+t*n)}}function pe(e){return+e}var de=[0,1];function he(e){return e}function ve(e,t){return(t-=e=+e)?function(n){return(n-e)/t}:(n=isNaN(t)?NaN:.5,function(){return n});var n}function ge(e,t,n){var r=e[0],a=e[1],i=t[0],o=t[1];return a<r?(r=ve(a,r),i=n(o,i)):(r=ve(r,a),i=n(i,o)),function(e){return i(r(e))}}function ye(e,t,n){var r=Math.min(e.length,t.length)-1,a=new Array(r),i=new Array(r),o=-1;for(e[r]<e[0]&&(e=e.slice().reverse(),t=t.slice().reverse());++o<r;)a[o]=ve(e[o],e[o+1]),i[o]=n(t[o],t[o+1]);return function(t){var n=v(e,t,1,r)-1;return i[n](a[n](t))}}function me(e,t){return t.domain(e.domain()).range(e.range()).interpolate(e.interpolate()).clamp(e.clamp()).unknown(e.unknown())}function be(){return function(){var e,t,n,r,a,i,o=de,u=de,l=ce,s=he;function c(){var e,t,n,l=Math.min(o.length,u.length);return s!==he&&(e=o[0],t=o[l-1],e>t&&(n=e,e=t,t=n),s=function(n){return Math.max(e,Math.min(t,n))}),r=l>2?ye:ge,a=i=null,f}function f(t){return null==t||isNaN(t=+t)?n:(a||(a=r(o.map(e),u,l)))(e(s(t)))}return f.invert=function(n){return s(t((i||(i=r(u,o.map(e),ae)))(n)))},f.domain=function(e){return arguments.length?(o=Array.from(e,pe),c()):o.slice()},f.range=function(e){return arguments.length?(u=Array.from(e),c()):u.slice()},f.rangeRound=function(e){return u=Array.from(e),l=fe,c()},f.clamp=function(e){return arguments.length?(s=!!e||he,c()):s!==he},f.interpolate=function(e){return arguments.length?(l=e,c()):l},f.unknown=function(e){return arguments.length?(n=e,f):n},function(n,r){return e=n,t=r,c()}}()(he,he)}function _e(e,t){switch(arguments.length){case 0:break;case 1:this.range(e);break;default:this.range(t).domain(e)}return this}var we,xe=/^(?:(.)?([<>=^]))?([+\\-( ])?([$#])?(0)?(\\d+)?(,)?(\\.\\d+)?(~)?([a-z%])?$/i;function ke(e){if(!(t=xe.exec(e)))throw new Error(\"invalid format: \"+e);var t;return new Se({fill:t[1],align:t[2],sign:t[3],symbol:t[4],zero:t[5],width:t[6],comma:t[7],precision:t[8]&&t[8].slice(1),trim:t[9],type:t[10]})}function Se(e){this.fill=void 0===e.fill?\" \":e.fill+\"\",this.align=void 0===e.align?\">\":e.align+\"\",this.sign=void 0===e.sign?\"-\":e.sign+\"\",this.symbol=void 0===e.symbol?\"\":e.symbol+\"\",this.zero=!!e.zero,this.width=void 0===e.width?void 0:+e.width,this.comma=!!e.comma,this.precision=void 0===e.precision?void 0:+e.precision,this.trim=!!e.trim,this.type=void 0===e.type?\"\":e.type+\"\"}function Ee(e,t){if((n=(e=t?e.toExponential(t-1):e.toExponential()).indexOf(\"e\"))<0)return null;var n,r=e.slice(0,n);return[r.length>1?r[0]+r.slice(2):r,+e.slice(n+1)]}function Ce(e){return(e=Ee(Math.abs(e)))?e[1]:NaN}function Te(e,t){var n=Ee(e,t);if(!n)return e+\"\";var r=n[0],a=n[1];return a<0?\"0.\"+new Array(-a).join(\"0\")+r:r.length>a+1?r.slice(0,a+1)+\".\"+r.slice(a+1):r+new Array(a-r.length+2).join(\"0\")}ke.prototype=Se.prototype,Se.prototype.toString=function(){return this.fill+this.align+this.sign+this.symbol+(this.zero?\"0\":\"\")+(void 0===this.width?\"\":Math.max(1,0|this.width))+(this.comma?\",\":\"\")+(void 0===this.precision?\"\":\".\"+Math.max(0,0|this.precision))+(this.trim?\"~\":\"\")+this.type};const Me={\"%\":(e,t)=>(100*e).toFixed(t),b:e=>Math.round(e).toString(2),c:e=>e+\"\",d:function(e){return Math.abs(e=Math.round(e))>=1e21?e.toLocaleString(\"en\").replace(/,/g,\"\"):e.toString(10)},e:(e,t)=>e.toExponential(t),f:(e,t)=>e.toFixed(t),g:(e,t)=>e.toPrecision(t),o:e=>Math.round(e).toString(8),p:(e,t)=>Te(100*e,t),r:Te,s:function(e,t){var n=Ee(e,t);if(!n)return e+\"\";var r=n[0],a=n[1],i=a-(we=3*Math.max(-8,Math.min(8,Math.floor(a/3))))+1,o=r.length;return i===o?r:i>o?r+new Array(i-o+1).join(\"0\"):i>0?r.slice(0,i)+\".\"+r.slice(i):\"0.\"+new Array(1-i).join(\"0\")+Ee(e,Math.max(0,t+i-1))[0]},X:e=>Math.round(e).toString(16).toUpperCase(),x:e=>Math.round(e).toString(16)};function Ne(e){return e}var Pe,ze,Le,Oe=Array.prototype.map,Ae=[\"y\",\"z\",\"a\",\"f\",\"p\",\"n\",\"µ\",\"m\",\"\",\"k\",\"M\",\"G\",\"T\",\"P\",\"E\",\"Z\",\"Y\"];function Fe(e){var t=e.domain;return e.ticks=function(e){var n=t();return function(e,t,n){if(!((n=+n)>0))return[];if((e=+e)==(t=+t))return[e];const r=t<e,[a,i,u]=r?o(t,e,n):o(e,t,n);if(!(i>=a))return[];const l=i-a+1,s=new Array(l);if(r)if(u<0)for(let e=0;e<l;++e)s[e]=(i-e)/-u;else for(let e=0;e<l;++e)s[e]=(i-e)*u;else if(u<0)for(let e=0;e<l;++e)s[e]=(a+e)/-u;else for(let e=0;e<l;++e)s[e]=(a+e)*u;return s}(n[0],n[n.length-1],null==e?10:e)},e.tickFormat=function(e,n){var r=t();return function(e,t,n,r){var a,i=l(e,t,n);switch((r=ke(null==r?\",f\":r)).type){case\"s\":var o=Math.max(Math.abs(e),Math.abs(t));return null!=r.precision||isNaN(a=function(e,t){return Math.max(0,3*Math.max(-8,Math.min(8,Math.floor(Ce(t)/3)))-Ce(Math.abs(e)))}(i,o))||(r.precision=a),Le(r,o);case\"\":case\"e\":case\"g\":case\"p\":case\"r\":null!=r.precision||isNaN(a=function(e,t){return e=Math.abs(e),t=Math.abs(t)-e,Math.max(0,Ce(t)-Ce(e))+1}(i,Math.max(Math.abs(e),Math.abs(t))))||(r.precision=a-(\"e\"===r.type));break;case\"f\":case\"%\":null!=r.precision||isNaN(a=function(e){return Math.max(0,-Ce(Math.abs(e)))}(i))||(r.precision=a-2*(\"%\"===r.type))}return ze(r)}(r[0],r[r.length-1],null==e?10:e,n)},e.nice=function(n){null==n&&(n=10);var r,a,i=t(),o=0,l=i.length-1,s=i[o],c=i[l],f=10;for(c<s&&(a=s,s=c,c=a,a=o,o=l,l=a);f-- >0;){if((a=u(s,c,n))===r)return i[o]=s,i[l]=c,t(i);if(a>0)s=Math.floor(s/a)*a,c=Math.ceil(c/a)*a;else{if(!(a<0))break;s=Math.ceil(s*a)/a,c=Math.floor(c*a)/a}r=a}return e},e}function De(){var e=be();return e.copy=function(){return me(e,De())},_e.apply(e,arguments),Fe(e)}Pe=function(e){var t,n,r=void 0===e.grouping||void 0===e.thousands?Ne:(t=Oe.call(e.grouping,Number),n=e.thousands+\"\",function(e,r){for(var a=e.length,i=[],o=0,u=t[0],l=0;a>0&&u>0&&(l+u+1>r&&(u=Math.max(1,r-l)),i.push(e.substring(a-=u,a+u)),!((l+=u+1)>r));)u=t[o=(o+1)%t.length];return i.reverse().join(n)}),a=void 0===e.currency?\"\":e.currency[0]+\"\",i=void 0===e.currency?\"\":e.currency[1]+\"\",o=void 0===e.decimal?\".\":e.decimal+\"\",u=void 0===e.numerals?Ne:function(e){return function(t){return t.replace(/[0-9]/g,(function(t){return e[+t]}))}}(Oe.call(e.numerals,String)),l=void 0===e.percent?\"%\":e.percent+\"\",s=void 0===e.minus?\"−\":e.minus+\"\",c=void 0===e.nan?\"NaN\":e.nan+\"\";function f(e){var t=(e=ke(e)).fill,n=e.align,f=e.sign,p=e.symbol,d=e.zero,h=e.width,v=e.comma,g=e.precision,y=e.trim,m=e.type;\"n\"===m?(v=!0,m=\"g\"):Me[m]||(void 0===g&&(g=12),y=!0,m=\"g\"),(d||\"0\"===t&&\"=\"===n)&&(d=!0,t=\"0\",n=\"=\");var b=\"$\"===p?a:\"#\"===p&&/[boxX]/.test(m)?\"0\"+m.toLowerCase():\"\",_=\"$\"===p?i:/[%p]/.test(m)?l:\"\",w=Me[m],x=/[defgprs%]/.test(m);function k(e){var a,i,l,p=b,k=_;if(\"c\"===m)k=w(e)+k,e=\"\";else{var S=(e=+e)<0||1/e<0;if(e=isNaN(e)?c:w(Math.abs(e),g),y&&(e=function(e){e:for(var t,n=e.length,r=1,a=-1;r<n;++r)switch(e[r]){case\".\":a=t=r;break;case\"0\":0===a&&(a=r),t=r;break;default:if(!+e[r])break e;a>0&&(a=0)}return a>0?e.slice(0,a)+e.slice(t+1):e}(e)),S&&0==+e&&\"+\"!==f&&(S=!1),p=(S?\"(\"===f?f:s:\"-\"===f||\"(\"===f?\"\":f)+p,k=(\"s\"===m?Ae[8+we/3]:\"\")+k+(S&&\"(\"===f?\")\":\"\"),x)for(a=-1,i=e.length;++a<i;)if(48>(l=e.charCodeAt(a))||l>57){k=(46===l?o+e.slice(a+1):e.slice(a))+k,e=e.slice(0,a);break}}v&&!d&&(e=r(e,1/0));var E=p.length+e.length+k.length,C=E<h?new Array(h-E+1).join(t):\"\";switch(v&&d&&(e=r(C+e,C.length?h-k.length:1/0),C=\"\"),n){case\"<\":e=p+e+k+C;break;case\"=\":e=p+C+e+k;break;case\"^\":e=C.slice(0,E=C.length>>1)+p+e+k+C.slice(E);break;default:e=C+p+e+k}return u(e)}return g=void 0===g?6:/[gprs]/.test(m)?Math.max(1,Math.min(21,g)):Math.max(0,Math.min(20,g)),k.toString=function(){return e+\"\"},k}return{format:f,formatPrefix:function(e,t){var n=f(((e=ke(e)).type=\"f\",e)),r=3*Math.max(-8,Math.min(8,Math.floor(Ce(t)/3))),a=Math.pow(10,-r),i=Ae[8+r/3];return function(e){return n(a*e)+i}}}}({thousands:\",\",grouping:[3],currency:[\"$\",\"\"]}),ze=Pe.format,Le=Pe.formatPrefix;var Re=n(486);const je={colors:{RdBu:[\"rgb(255, 13, 87)\",\"rgb(30, 136, 229)\"],GnPR:[\"rgb(24, 196, 93)\",\"rgb(124, 82, 255)\"],CyPU:[\"#0099C6\",\"#990099\"],PkYg:[\"#DD4477\",\"#66AA00\"],DrDb:[\"#B82E2E\",\"#316395\"],LpLb:[\"#994499\",\"#22AA99\"],YlDp:[\"#AAAA11\",\"#6633CC\"],OrId:[\"#E67300\",\"#3E0099\"]},gray:\"#777\"};function Ue(e){return Ue=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e},Ue(e)}function Ie(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,(void 0,a=function(e,t){if(\"object\"!==Ue(e)||null===e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var r=n.call(e,\"string\");if(\"object\"!==Ue(r))return r;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return String(e)}(r.key),\"symbol\"===Ue(a)?a:String(a)),r)}var a}function $e(e,t){return $e=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},$e(e,t)}function Be(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}function We(e){return We=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},We(e)}var Ve=function(t){!function(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,\"prototype\",{writable:!1}),t&&$e(e,t)}(u,t);var n,r,a,i,o=(a=u,i=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}(),function(){var e,t=We(a);if(i){var n=We(this).constructor;e=Reflect.construct(t,arguments,n)}else e=t.apply(this,arguments);return function(e,t){if(t&&(\"object\"===Ue(t)||\"function\"==typeof t))return t;if(void 0!==t)throw new TypeError(\"Derived constructors may only return object or undefined\");return Be(e)}(this,e)});function u(){var e;return function(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}(this,u),(e=o.call(this)).width=100,window.lastSimpleListInstance=Be(e),e.effectFormat=ze(\".2\"),e}return n=u,(r=[{key:\"render\",value:function(){var t=this,n=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in je.colors?n=je.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),n=je.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(n=this.props.plot_cmap),console.log(this.props.features,this.props.features),this.scale=De().domain([0,(0,Re.max)((0,Re.map)(this.props.features,(function(e){return Math.abs(e.effect)})))]).range([0,this.width]);var r=(0,Re.reverse)((0,Re.sortBy)(Object.keys(this.props.features),(function(e){return Math.abs(t.props.features[e].effect)}))).map((function(r){var a,i,o=t.props.features[r],u=t.props.featureNames[r],l={width:t.scale(Math.abs(o.effect)),height:\"20px\",background:o.effect<0?n[0]:n[1],display:\"inline-block\"},s={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginRight:\"5px\",textAlign:\"right\"},c={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginLeft:\"5px\"};return o.effect<0?(i=e.createElement(\"span\",{style:c},u),s.width=40+t.width-t.scale(Math.abs(o.effect)),s.textAlign=\"right\",s.color=\"#999\",s.fontSize=\"13px\",a=e.createElement(\"span\",{style:s},t.effectFormat(o.effect))):(s.textAlign=\"right\",a=e.createElement(\"span\",{style:s},u),c.width=40,c.textAlign=\"left\",c.color=\"#999\",c.fontSize=\"13px\",i=e.createElement(\"span\",{style:c},t.effectFormat(o.effect))),e.createElement(\"div\",{key:r,style:{marginTop:\"2px\"}},a,e.createElement(\"div\",{style:l}),i)}));return e.createElement(\"span\",null,r)}}])&&Ie(n.prototype,r),Object.defineProperty(n,\"prototype\",{writable:!1}),u}(e.Component);Ve.defaultProps={plot_cmap:\"RdBu\"};const He=Ve;function qe(){}function Qe(e){return null==e?qe:function(){return this.querySelector(e)}}function Ye(){return[]}function Ge(e){return function(t){return t.matches(e)}}var Ke=Array.prototype.find;function Ze(){return this.firstElementChild}var Xe=Array.prototype.filter;function Je(){return Array.from(this.children)}function et(e){return new Array(e.length)}function tt(e,t){this.ownerDocument=e.ownerDocument,this.namespaceURI=e.namespaceURI,this._next=null,this._parent=e,this.__data__=t}function nt(e,t,n,r,a,i){for(var o,u=0,l=t.length,s=i.length;u<s;++u)(o=t[u])?(o.__data__=i[u],r[u]=o):n[u]=new tt(e,i[u]);for(;u<l;++u)(o=t[u])&&(a[u]=o)}function rt(e,t,n,r,a,i,o){var u,l,s,c=new Map,f=t.length,p=i.length,d=new Array(f);for(u=0;u<f;++u)(l=t[u])&&(d[u]=s=o.call(l,l.__data__,u,t)+\"\",c.has(s)?a[u]=l:c.set(s,l));for(u=0;u<p;++u)s=o.call(e,i[u],u,i)+\"\",(l=c.get(s))?(r[u]=l,l.__data__=i[u],c.delete(s)):n[u]=new tt(e,i[u]);for(u=0;u<f;++u)(l=t[u])&&c.get(d[u])===l&&(a[u]=l)}function at(e){return e.__data__}function it(e){return\"object\"==typeof e&&\"length\"in e?e:Array.from(e)}function ot(e,t){return e<t?-1:e>t?1:e>=t?0:NaN}tt.prototype={constructor:tt,appendChild:function(e){return this._parent.insertBefore(e,this._next)},insertBefore:function(e,t){return this._parent.insertBefore(e,t)},querySelector:function(e){return this._parent.querySelector(e)},querySelectorAll:function(e){return this._parent.querySelectorAll(e)}};var ut=\"http://www.w3.org/1999/xhtml\";const lt={svg:\"http://www.w3.org/2000/svg\",xhtml:ut,xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\",xmlns:\"http://www.w3.org/2000/xmlns/\"};function st(e){var t=e+=\"\",n=t.indexOf(\":\");return n>=0&&\"xmlns\"!==(t=e.slice(0,n))&&(e=e.slice(n+1)),lt.hasOwnProperty(t)?{space:lt[t],local:e}:e}function ct(e){return function(){this.removeAttribute(e)}}function ft(e){return function(){this.removeAttributeNS(e.space,e.local)}}function pt(e,t){return function(){this.setAttribute(e,t)}}function dt(e,t){return function(){this.setAttributeNS(e.space,e.local,t)}}function ht(e,t){return function(){var n=t.apply(this,arguments);null==n?this.removeAttribute(e):this.setAttribute(e,n)}}function vt(e,t){return function(){var n=t.apply(this,arguments);null==n?this.removeAttributeNS(e.space,e.local):this.setAttributeNS(e.space,e.local,n)}}function gt(e){return e.ownerDocument&&e.ownerDocument.defaultView||e.document&&e||e.defaultView}function yt(e){return function(){this.style.removeProperty(e)}}function mt(e,t,n){return function(){this.style.setProperty(e,t,n)}}function bt(e,t,n){return function(){var r=t.apply(this,arguments);null==r?this.style.removeProperty(e):this.style.setProperty(e,r,n)}}function _t(e){return function(){delete this[e]}}function wt(e,t){return function(){this[e]=t}}function xt(e,t){return function(){var n=t.apply(this,arguments);null==n?delete this[e]:this[e]=n}}function kt(e){return e.trim().split(/^|\\s+/)}function St(e){return e.classList||new Et(e)}function Et(e){this._node=e,this._names=kt(e.getAttribute(\"class\")||\"\")}function Ct(e,t){for(var n=St(e),r=-1,a=t.length;++r<a;)n.add(t[r])}function Tt(e,t){for(var n=St(e),r=-1,a=t.length;++r<a;)n.remove(t[r])}function Mt(e){return function(){Ct(this,e)}}function Nt(e){return function(){Tt(this,e)}}function Pt(e,t){return function(){(t.apply(this,arguments)?Ct:Tt)(this,e)}}function zt(){this.textContent=\"\"}function Lt(e){return function(){this.textContent=e}}function Ot(e){return function(){var t=e.apply(this,arguments);this.textContent=null==t?\"\":t}}function At(){this.innerHTML=\"\"}function Ft(e){return function(){this.innerHTML=e}}function Dt(e){return function(){var t=e.apply(this,arguments);this.innerHTML=null==t?\"\":t}}function Rt(){this.nextSibling&&this.parentNode.appendChild(this)}function jt(){this.previousSibling&&this.parentNode.insertBefore(this,this.parentNode.firstChild)}function Ut(e){return function(){var t=this.ownerDocument,n=this.namespaceURI;return n===ut&&t.documentElement.namespaceURI===ut?t.createElement(e):t.createElementNS(n,e)}}function It(e){return function(){return this.ownerDocument.createElementNS(e.space,e.local)}}function $t(e){var t=st(e);return(t.local?It:Ut)(t)}function Bt(){return null}function Wt(){var e=this.parentNode;e&&e.removeChild(this)}function Vt(){var e=this.cloneNode(!1),t=this.parentNode;return t?t.insertBefore(e,this.nextSibling):e}function Ht(){var e=this.cloneNode(!0),t=this.parentNode;return t?t.insertBefore(e,this.nextSibling):e}function qt(e){return function(){var t=this.__on;if(t){for(var n,r=0,a=-1,i=t.length;r<i;++r)n=t[r],e.type&&n.type!==e.type||n.name!==e.name?t[++a]=n:this.removeEventListener(n.type,n.listener,n.options);++a?t.length=a:delete this.__on}}}function Qt(e,t,n){return function(){var r,a=this.__on,i=function(e){return function(t){e.call(this,t,this.__data__)}}(t);if(a)for(var o=0,u=a.length;o<u;++o)if((r=a[o]).type===e.type&&r.name===e.name)return this.removeEventListener(r.type,r.listener,r.options),this.addEventListener(r.type,r.listener=i,r.options=n),void(r.value=t);this.addEventListener(e.type,i,n),r={type:e.type,name:e.name,value:t,listener:i,options:n},a?a.push(r):this.__on=[r]}}function Yt(e,t,n){var r=gt(e),a=r.CustomEvent;\"function\"==typeof a?a=new a(t,n):(a=r.document.createEvent(\"Event\"),n?(a.initEvent(t,n.bubbles,n.cancelable),a.detail=n.detail):a.initEvent(t,!1,!1)),e.dispatchEvent(a)}function Gt(e,t){return function(){return Yt(this,e,t)}}function Kt(e,t){return function(){return Yt(this,e,t.apply(this,arguments))}}Et.prototype={add:function(e){this._names.indexOf(e)<0&&(this._names.push(e),this._node.setAttribute(\"class\",this._names.join(\" \")))},remove:function(e){var t=this._names.indexOf(e);t>=0&&(this._names.splice(t,1),this._node.setAttribute(\"class\",this._names.join(\" \")))},contains:function(e){return this._names.indexOf(e)>=0}};var Zt=[null];function Xt(e,t){this._groups=e,this._parents=t}function Jt(e){return\"string\"==typeof e?new Xt([[document.querySelector(e)]],[document.documentElement]):new Xt([[e]],Zt)}function en(e){return e}Xt.prototype=function(){return new Xt([[document.documentElement]],Zt)}.prototype={constructor:Xt,select:function(e){\"function\"!=typeof e&&(e=Qe(e));for(var t=this._groups,n=t.length,r=new Array(n),a=0;a<n;++a)for(var i,o,u=t[a],l=u.length,s=r[a]=new Array(l),c=0;c<l;++c)(i=u[c])&&(o=e.call(i,i.__data__,c,u))&&(\"__data__\"in i&&(o.__data__=i.__data__),s[c]=o);return new Xt(r,this._parents)},selectAll:function(e){e=\"function\"==typeof e?function(e){return function(){return null==(t=e.apply(this,arguments))?[]:Array.isArray(t)?t:Array.from(t);var t}}(e):function(e){return null==e?Ye:function(){return this.querySelectorAll(e)}}(e);for(var t=this._groups,n=t.length,r=[],a=[],i=0;i<n;++i)for(var o,u=t[i],l=u.length,s=0;s<l;++s)(o=u[s])&&(r.push(e.call(o,o.__data__,s,u)),a.push(o));return new Xt(r,a)},selectChild:function(e){return this.select(null==e?Ze:function(e){return function(){return Ke.call(this.children,e)}}(\"function\"==typeof e?e:Ge(e)))},selectChildren:function(e){return this.selectAll(null==e?Je:function(e){return function(){return Xe.call(this.children,e)}}(\"function\"==typeof e?e:Ge(e)))},filter:function(e){\"function\"!=typeof e&&(e=function(e){return function(){return this.matches(e)}}(e));for(var t=this._groups,n=t.length,r=new Array(n),a=0;a<n;++a)for(var i,o=t[a],u=o.length,l=r[a]=[],s=0;s<u;++s)(i=o[s])&&e.call(i,i.__data__,s,o)&&l.push(i);return new Xt(r,this._parents)},data:function(e,t){if(!arguments.length)return Array.from(this,at);var n,r=t?rt:nt,a=this._parents,i=this._groups;\"function\"!=typeof e&&(n=e,e=function(){return n});for(var o=i.length,u=new Array(o),l=new Array(o),s=new Array(o),c=0;c<o;++c){var f=a[c],p=i[c],d=p.length,h=it(e.call(f,f&&f.__data__,c,a)),v=h.length,g=l[c]=new Array(v),y=u[c]=new Array(v);r(f,p,g,y,s[c]=new Array(d),h,t);for(var m,b,_=0,w=0;_<v;++_)if(m=g[_]){for(_>=w&&(w=_+1);!(b=y[w])&&++w<v;);m._next=b||null}}return(u=new Xt(u,a))._enter=l,u._exit=s,u},enter:function(){return new Xt(this._enter||this._groups.map(et),this._parents)},exit:function(){return new Xt(this._exit||this._groups.map(et),this._parents)},join:function(e,t,n){var r=this.enter(),a=this,i=this.exit();return\"function\"==typeof e?(r=e(r))&&(r=r.selection()):r=r.append(e+\"\"),null!=t&&(a=t(a))&&(a=a.selection()),null==n?i.remove():n(i),r&&a?r.merge(a).order():a},merge:function(e){for(var t=e.selection?e.selection():e,n=this._groups,r=t._groups,a=n.length,i=r.length,o=Math.min(a,i),u=new Array(a),l=0;l<o;++l)for(var s,c=n[l],f=r[l],p=c.length,d=u[l]=new Array(p),h=0;h<p;++h)(s=c[h]||f[h])&&(d[h]=s);for(;l<a;++l)u[l]=n[l];return new Xt(u,this._parents)},selection:function(){return this},order:function(){for(var e=this._groups,t=-1,n=e.length;++t<n;)for(var r,a=e[t],i=a.length-1,o=a[i];--i>=0;)(r=a[i])&&(o&&4^r.compareDocumentPosition(o)&&o.parentNode.insertBefore(r,o),o=r);return this},sort:function(e){function t(t,n){return t&&n?e(t.__data__,n.__data__):!t-!n}e||(e=ot);for(var n=this._groups,r=n.length,a=new Array(r),i=0;i<r;++i){for(var o,u=n[i],l=u.length,s=a[i]=new Array(l),c=0;c<l;++c)(o=u[c])&&(s[c]=o);s.sort(t)}return new Xt(a,this._parents).order()},call:function(){var e=arguments[0];return arguments[0]=this,e.apply(null,arguments),this},nodes:function(){return Array.from(this)},node:function(){for(var e=this._groups,t=0,n=e.length;t<n;++t)for(var r=e[t],a=0,i=r.length;a<i;++a){var o=r[a];if(o)return o}return null},size:function(){let e=0;for(const t of this)++e;return e},empty:function(){return!this.node()},each:function(e){for(var t=this._groups,n=0,r=t.length;n<r;++n)for(var a,i=t[n],o=0,u=i.length;o<u;++o)(a=i[o])&&e.call(a,a.__data__,o,i);return this},attr:function(e,t){var n=st(e);if(arguments.length<2){var r=this.node();return n.local?r.getAttributeNS(n.space,n.local):r.getAttribute(n)}return this.each((null==t?n.local?ft:ct:\"function\"==typeof t?n.local?vt:ht:n.local?dt:pt)(n,t))},style:function(e,t,n){return arguments.length>1?this.each((null==t?yt:\"function\"==typeof t?bt:mt)(e,t,null==n?\"\":n)):function(e,t){return e.style.getPropertyValue(t)||gt(e).getComputedStyle(e,null).getPropertyValue(t)}(this.node(),e)},property:function(e,t){return arguments.length>1?this.each((null==t?_t:\"function\"==typeof t?xt:wt)(e,t)):this.node()[e]},classed:function(e,t){var n=kt(e+\"\");if(arguments.length<2){for(var r=St(this.node()),a=-1,i=n.length;++a<i;)if(!r.contains(n[a]))return!1;return!0}return this.each((\"function\"==typeof t?Pt:t?Mt:Nt)(n,t))},text:function(e){return arguments.length?this.each(null==e?zt:(\"function\"==typeof e?Ot:Lt)(e)):this.node().textContent},html:function(e){return arguments.length?this.each(null==e?At:(\"function\"==typeof e?Dt:Ft)(e)):this.node().innerHTML},raise:function(){return this.each(Rt)},lower:function(){return this.each(jt)},append:function(e){var t=\"function\"==typeof e?e:$t(e);return this.select((function(){return this.appendChild(t.apply(this,arguments))}))},insert:function(e,t){var n=\"function\"==typeof e?e:$t(e),r=null==t?Bt:\"function\"==typeof t?t:Qe(t);return this.select((function(){return this.insertBefore(n.apply(this,arguments),r.apply(this,arguments)||null)}))},remove:function(){return this.each(Wt)},clone:function(e){return this.select(e?Ht:Vt)},datum:function(e){return arguments.length?this.property(\"__data__\",e):this.node().__data__},on:function(e,t,n){var r,a,i=function(e){return e.trim().split(/^|\\s+/).map((function(e){var t=\"\",n=e.indexOf(\".\");return n>=0&&(t=e.slice(n+1),e=e.slice(0,n)),{type:e,name:t}}))}(e+\"\"),o=i.length;if(!(arguments.length<2)){for(u=t?Qt:qt,r=0;r<o;++r)this.each(u(i[r],t,n));return this}var u=this.node().__on;if(u)for(var l,s=0,c=u.length;s<c;++s)for(r=0,l=u[s];r<o;++r)if((a=i[r]).type===l.type&&a.name===l.name)return l.value},dispatch:function(e,t){return this.each((\"function\"==typeof t?Kt:Gt)(e,t))},[Symbol.iterator]:function*(){for(var e=this._groups,t=0,n=e.length;t<n;++t)for(var r,a=e[t],i=0,o=a.length;i<o;++i)(r=a[i])&&(yield r)}};var tn=1,nn=2,rn=3,an=4,on=1e-6;function un(e){return\"translate(\"+e+\",0)\"}function ln(e){return\"translate(0,\"+e+\")\"}function sn(e){return t=>+e(t)}function cn(e,t){return t=Math.max(0,e.bandwidth()-2*t)/2,e.round()&&(t=Math.round(t)),n=>+e(n)+t}function fn(){return!this.__axis}function pn(e,t){var n=[],r=null,a=null,i=6,o=6,u=3,l=\"undefined\"!=typeof window&&window.devicePixelRatio>1?0:.5,s=e===tn||e===an?-1:1,c=e===an||e===nn?\"x\":\"y\",f=e===tn||e===rn?un:ln;function p(p){var d=null==r?t.ticks?t.ticks.apply(t,n):t.domain():r,h=null==a?t.tickFormat?t.tickFormat.apply(t,n):en:a,v=Math.max(i,0)+u,g=t.range(),y=+g[0]+l,m=+g[g.length-1]+l,b=(t.bandwidth?cn:sn)(t.copy(),l),_=p.selection?p.selection():p,w=_.selectAll(\".domain\").data([null]),x=_.selectAll(\".tick\").data(d,t).order(),k=x.exit(),S=x.enter().append(\"g\").attr(\"class\",\"tick\"),E=x.select(\"line\"),C=x.select(\"text\");w=w.merge(w.enter().insert(\"path\",\".tick\").attr(\"class\",\"domain\").attr(\"stroke\",\"currentColor\")),x=x.merge(S),E=E.merge(S.append(\"line\").attr(\"stroke\",\"currentColor\").attr(c+\"2\",s*i)),C=C.merge(S.append(\"text\").attr(\"fill\",\"currentColor\").attr(c,s*v).attr(\"dy\",e===tn?\"0em\":e===rn?\"0.71em\":\"0.32em\")),p!==_&&(w=w.transition(p),x=x.transition(p),E=E.transition(p),C=C.transition(p),k=k.transition(p).attr(\"opacity\",on).attr(\"transform\",(function(e){return isFinite(e=b(e))?f(e+l):this.getAttribute(\"transform\")})),S.attr(\"opacity\",on).attr(\"transform\",(function(e){var t=this.parentNode.__axis;return f((t&&isFinite(t=t(e))?t:b(e))+l)}))),k.remove(),w.attr(\"d\",e===an||e===nn?o?\"M\"+s*o+\",\"+y+\"H\"+l+\"V\"+m+\"H\"+s*o:\"M\"+l+\",\"+y+\"V\"+m:o?\"M\"+y+\",\"+s*o+\"V\"+l+\"H\"+m+\"V\"+s*o:\"M\"+y+\",\"+l+\"H\"+m),x.attr(\"opacity\",1).attr(\"transform\",(function(e){return f(b(e)+l)})),E.attr(c+\"2\",s*i),C.attr(c,s*v).text(h),_.filter(fn).attr(\"fill\",\"none\").attr(\"font-size\",10).attr(\"font-family\",\"sans-serif\").attr(\"text-anchor\",e===nn?\"start\":e===an?\"end\":\"middle\"),_.each((function(){this.__axis=b}))}return p.scale=function(e){return arguments.length?(t=e,p):t},p.ticks=function(){return n=Array.from(arguments),p},p.tickArguments=function(e){return arguments.length?(n=null==e?[]:Array.from(e),p):n.slice()},p.tickValues=function(e){return arguments.length?(r=null==e?null:Array.from(e),p):r&&r.slice()},p.tickFormat=function(e){return arguments.length?(a=e,p):a},p.tickSize=function(e){return arguments.length?(i=o=+e,p):i},p.tickSizeInner=function(e){return arguments.length?(i=+e,p):i},p.tickSizeOuter=function(e){return arguments.length?(o=+e,p):o},p.tickPadding=function(e){return arguments.length?(u=+e,p):u},p.offset=function(e){return arguments.length?(l=+e,p):l},p}function dn(e){return pn(rn,e)}function hn(e){return function(){return e}}function vn(e){this._context=e}function gn(e){return new vn(e)}Array.prototype.slice,vn.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._point=0},lineEnd:function(){(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(e,t){switch(e=+e,t=+t,this._point){case 0:this._point=1,this._line?this._context.lineTo(e,t):this._context.moveTo(e,t);break;case 1:this._point=2;default:this._context.lineTo(e,t)}}};const yn=Math.PI,mn=2*yn,bn=1e-6,_n=mn-bn;function wn(e){this._+=e[0];for(let t=1,n=e.length;t<n;++t)this._+=arguments[t]+e[t]}class xn{constructor(e){this._x0=this._y0=this._x1=this._y1=null,this._=\"\",this._append=null==e?wn:function(e){let t=Math.floor(e);if(!(t>=0))throw new Error(`invalid digits: ${e}`);if(t>15)return wn;const n=10**t;return function(e){this._+=e[0];for(let t=1,r=e.length;t<r;++t)this._+=Math.round(arguments[t]*n)/n+e[t]}}(e)}moveTo(e,t){this._append`M${this._x0=this._x1=+e},${this._y0=this._y1=+t}`}closePath(){null!==this._x1&&(this._x1=this._x0,this._y1=this._y0,this._append`Z`)}lineTo(e,t){this._append`L${this._x1=+e},${this._y1=+t}`}quadraticCurveTo(e,t,n,r){this._append`Q${+e},${+t},${this._x1=+n},${this._y1=+r}`}bezierCurveTo(e,t,n,r,a,i){this._append`C${+e},${+t},${+n},${+r},${this._x1=+a},${this._y1=+i}`}arcTo(e,t,n,r,a){if(e=+e,t=+t,n=+n,r=+r,(a=+a)<0)throw new Error(`negative radius: ${a}`);let i=this._x1,o=this._y1,u=n-e,l=r-t,s=i-e,c=o-t,f=s*s+c*c;if(null===this._x1)this._append`M${this._x1=e},${this._y1=t}`;else if(f>bn)if(Math.abs(c*u-l*s)>bn&&a){let p=n-i,d=r-o,h=u*u+l*l,v=p*p+d*d,g=Math.sqrt(h),y=Math.sqrt(f),m=a*Math.tan((yn-Math.acos((h+f-v)/(2*g*y)))/2),b=m/y,_=m/g;Math.abs(b-1)>bn&&this._append`L${e+b*s},${t+b*c}`,this._append`A${a},${a},0,0,${+(c*p>s*d)},${this._x1=e+_*u},${this._y1=t+_*l}`}else this._append`L${this._x1=e},${this._y1=t}`}arc(e,t,n,r,a,i){if(e=+e,t=+t,i=!!i,(n=+n)<0)throw new Error(`negative radius: ${n}`);let o=n*Math.cos(r),u=n*Math.sin(r),l=e+o,s=t+u,c=1^i,f=i?r-a:a-r;null===this._x1?this._append`M${l},${s}`:(Math.abs(this._x1-l)>bn||Math.abs(this._y1-s)>bn)&&this._append`L${l},${s}`,n&&(f<0&&(f=f%mn+mn),f>_n?this._append`A${n},${n},0,1,${c},${e-o},${t-u}A${n},${n},0,1,${c},${this._x1=l},${this._y1=s}`:f>bn&&this._append`A${n},${n},0,${+(f>=yn)},${c},${this._x1=e+n*Math.cos(a)},${this._y1=t+n*Math.sin(a)}`)}rect(e,t,n,r){this._append`M${this._x0=this._x1=+e},${this._y0=this._y1=+t}h${n=+n}v${+r}h${-n}Z`}toString(){return this._}}function kn(e){return e[0]}function Sn(e){return e[1]}function En(e,t){var n=hn(!0),r=null,a=gn,i=null,o=function(e){let t=3;return e.digits=function(n){if(!arguments.length)return t;if(null==n)t=null;else{const e=Math.floor(n);if(!(e>=0))throw new RangeError(`invalid digits: ${n}`);t=e}return e},()=>new xn(t)}(u);function u(u){var l,s,c,f=(u=function(e){return\"object\"==typeof e&&\"length\"in e?e:Array.from(e)}(u)).length,p=!1;for(null==r&&(i=a(c=o())),l=0;l<=f;++l)!(l<f&&n(s=u[l],l,u))===p&&((p=!p)?i.lineStart():i.lineEnd()),p&&i.point(+e(s,l,u),+t(s,l,u));if(c)return i=null,c+\"\"||null}return e=\"function\"==typeof e?e:void 0===e?kn:hn(e),t=\"function\"==typeof t?t:void 0===t?Sn:hn(t),u.x=function(t){return arguments.length?(e=\"function\"==typeof t?t:hn(+t),u):e},u.y=function(e){return arguments.length?(t=\"function\"==typeof e?e:hn(+e),u):t},u.defined=function(e){return arguments.length?(n=\"function\"==typeof e?e:hn(!!e),u):n},u.curve=function(e){return arguments.length?(a=e,null!=r&&(i=a(r)),u):a},u.context=function(e){return arguments.length?(null==e?r=i=null:i=a(r=e),u):r},u}function Cn(e){return Cn=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e},Cn(e)}function Tn(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,(void 0,a=function(e,t){if(\"object\"!==Cn(e)||null===e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var r=n.call(e,\"string\");if(\"object\"!==Cn(r))return r;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return String(e)}(r.key),\"symbol\"===Cn(a)?a:String(a)),r)}var a}function Mn(e,t){return Mn=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},Mn(e,t)}function Nn(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}function Pn(e){return Pn=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},Pn(e)}var zn=function(t){!function(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,\"prototype\",{writable:!1}),t&&Mn(e,t)}(u,t);var n,r,a,i,o=(a=u,i=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}(),function(){var e,t=Pn(a);if(i){var n=Pn(this).constructor;e=Reflect.construct(t,arguments,n)}else e=t.apply(this,arguments);return function(e,t){if(t&&(\"object\"===Cn(t)||\"function\"==typeof t))return t;if(void 0!==t)throw new TypeError(\"Derived constructors may only return object or undefined\");return Nn(e)}(this,e)});function u(){var e;return function(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}(this,u),e=o.call(this),window.lastAdditiveForceVisualizer=Nn(e),e.effectFormat=ze(\".2\"),e.redraw=(0,Re.debounce)((function(){return e.draw()}),200),e}return n=u,(r=[{key:\"componentDidMount\",value:function(){var e=this;this.mainGroup=this.svg.append(\"g\"),this.axisElement=this.mainGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-axis\"),this.onTopGroup=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.joinPointLine=this.svg.append(\"line\"),this.joinPointLabelOutline=this.svg.append(\"text\"),this.joinPointLabel=this.svg.append(\"text\"),this.joinPointTitleLeft=this.svg.append(\"text\"),this.joinPointTitleLeftArrow=this.svg.append(\"text\"),this.joinPointTitle=this.svg.append(\"text\"),this.joinPointTitleRightArrow=this.svg.append(\"text\"),this.joinPointTitleRight=this.svg.append(\"text\"),this.hoverLabelBacking=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").text(\"\").on(\"mouseover\",(function(){e.hoverLabel.attr(\"opacity\",1),e.hoverLabelBacking.attr(\"opacity\",1)})).on(\"mouseout\",(function(){e.hoverLabel.attr(\"opacity\",0),e.hoverLabelBacking.attr(\"opacity\",0)})),this.hoverLabel=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"fill\",\"#0f0\").text(\"\").on(\"mouseover\",(function(){e.hoverLabel.attr(\"opacity\",1),e.hoverLabelBacking.attr(\"opacity\",1)})).on(\"mouseout\",(function(){e.hoverLabel.attr(\"opacity\",0),e.hoverLabelBacking.attr(\"opacity\",0)}));var t=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in je.colors?t=je.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),t=je.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(t=this.props.plot_cmap),this.colors=t.map((function(e){return q(e)})),this.brighterColors=[1.45,1.6].map((function(t,n){return e.colors[n].brighter(t)})),this.colors.map((function(t,n){var r=e.svg.append(\"linearGradient\").attr(\"id\",\"linear-grad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");r.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",t).attr(\"stop-opacity\",.6),r.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",t).attr(\"stop-opacity\",0);var a=e.svg.append(\"linearGradient\").attr(\"id\",\"linear-backgrad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");a.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",t).attr(\"stop-opacity\",.5),a.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",t).attr(\"stop-opacity\",0)})),this.tickFormat=ze(\",.4\"),this.scaleCentered=De(),this.axis=dn().scale(this.scaleCentered).tickSizeInner(4).tickSizeOuter(0).tickFormat((function(t){return e.tickFormat(e.invLinkFunction(t))})).tickPadding(-18),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"draw\",value:function(){var e=this;(0,Re.each)(this.props.featureNames,(function(t,n){e.props.features[n]&&(e.props.features[n].name=t)})),\"identity\"===this.props.link?this.invLinkFunction=function(t){return e.props.baseValue+t}:\"logit\"===this.props.link?this.invLinkFunction=function(t){return 1/(1+Math.exp(-(e.props.baseValue+t)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link);var t=this.svg.node().parentNode.offsetWidth;if(0==t)return setTimeout((function(){return e.draw(e.props)}),500);this.svg.style(\"height\",\"150px\"),this.svg.style(\"width\",t+\"px\");var n=(0,Re.sortBy)(this.props.features,(function(e){return-1/(e.effect+1e-10)})),r=(0,Re.sum)((0,Re.map)(n,(function(e){return Math.abs(e.effect)}))),a=(0,Re.sum)((0,Re.map)((0,Re.filter)(n,(function(e){return e.effect>0})),(function(e){return e.effect})))||0,i=(0,Re.sum)((0,Re.map)((0,Re.filter)(n,(function(e){return e.effect<0})),(function(e){return-e.effect})))||0;this.domainSize=3*Math.max(a,i);var o=De().domain([0,this.domainSize]).range([0,t]),u=t/2-o(i);this.scaleCentered.domain([-this.domainSize/2,this.domainSize/2]).range([0,t]).clamp(!0),this.axisElement.attr(\"transform\",\"translate(0,50)\").call(this.axis);var l,s,c,f=0;for(l=0;l<n.length;++l)n[l].x=f,n[l].effect<0&&void 0===s&&(s=f,c=l),f+=Math.abs(n[l].effect);void 0===s&&(s=f,c=l);var p=En().x((function(e){return e[0]})).y((function(e){return e[1]})),d=function(t){return void 0!==t.value&&null!==t.value&&\"\"!==t.value?t.name+\" = \"+(isNaN(t.value)?t.value:e.tickFormat(t.value)):t.name};n=this.props.hideBars?[]:n;var h=this.mainGroup.selectAll(\".force-bar-blocks\").data(n);h.enter().append(\"path\").attr(\"class\",\"force-bar-blocks\").merge(h).attr(\"d\",(function(e,t){var n=o(e.x)+u,r=o(Math.abs(e.effect)),a=e.effect<0?-4:4,i=a;return t===c&&(a=0),t===c-1&&(i=0),p([[n,56],[n+r,56],[n+r+i,64.5],[n+r,73],[n,73],[n+a,64.5]])})).attr(\"fill\",(function(t){return t.effect>0?e.colors[0]:e.colors[1]})).on(\"mouseover\",(function(t){if(o(Math.abs(t.effect))<o(r)/50||o(Math.abs(t.effect))<10){var n=o(t.x)+u,a=o(Math.abs(t.effect));e.hoverLabel.attr(\"opacity\",1).attr(\"x\",n+a/2).attr(\"y\",50.5).attr(\"fill\",t.effect>0?e.colors[0]:e.colors[1]).text(d(t)),e.hoverLabelBacking.attr(\"opacity\",1).attr(\"x\",n+a/2).attr(\"y\",50.5).text(d(t))}})).on(\"mouseout\",(function(){e.hoverLabel.attr(\"opacity\",0),e.hoverLabelBacking.attr(\"opacity\",0)})),h.exit().remove();var v=(0,Re.filter)(n,(function(e){return o(Math.abs(e.effect))>o(r)/50&&o(Math.abs(e.effect))>10})),g=this.onTopGroup.selectAll(\".force-bar-labels\").data(v);if(g.exit().remove(),g=g.enter().append(\"text\").attr(\"class\",\"force-bar-labels\").attr(\"font-size\",\"12px\").attr(\"y\",98).merge(g).text((function(t){return void 0!==t.value&&null!==t.value&&\"\"!==t.value?t.name+\" = \"+(isNaN(t.value)?t.value:e.tickFormat(t.value)):t.name})).attr(\"fill\",(function(t){return t.effect>0?e.colors[0]:e.colors[1]})).attr(\"stroke\",(function(e){return e.textWidth=Math.max(this.getComputedTextLength(),o(Math.abs(e.effect))-10),e.innerTextWidth=this.getComputedTextLength(),\"none\"})),this.filteredData=v,n.length>0){f=s+o.invert(5);for(var y=c;y<n.length;++y)n[y].textx=f,f+=o.invert(n[y].textWidth+10);f=s-o.invert(5);for(var m=c-1;m>=0;--m)n[m].textx=f,f-=o.invert(n[m].textWidth+10)}g.attr(\"x\",(function(e){return o(e.textx)+u+(e.effect>0?-e.textWidth/2:e.textWidth/2)})).attr(\"text-anchor\",\"middle\"),v=(0,Re.filter)(v,(function(n){return o(n.textx)+u>e.props.labelMargin&&o(n.textx)+u<t-e.props.labelMargin})),this.filteredData2=v;var b=v.slice(),_=(0,Re.findIndex)(n,v[0])-1;_>=0&&b.unshift(n[_]);var w=this.mainGroup.selectAll(\".force-bar-labelBacking\").data(v);w.enter().append(\"path\").attr(\"class\",\"force-bar-labelBacking\").attr(\"stroke\",\"none\").attr(\"opacity\",.2).merge(w).attr(\"d\",(function(e){return p([[o(e.x)+o(Math.abs(e.effect))+u,73],[(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+5,83],[(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+5,104],[(e.effect>0?o(e.textx)-e.textWidth:o(e.textx))+u-5,104],[(e.effect>0?o(e.textx)-e.textWidth:o(e.textx))+u-5,83],[o(e.x)+u,73]])})).attr(\"fill\",(function(e){return\"url(#linear-backgrad-\".concat(e.effect>0?0:1,\")\")})),w.exit().remove();var x=this.mainGroup.selectAll(\".force-bar-labelDividers\").data(v.slice(0,-1));x.enter().append(\"rect\").attr(\"class\",\"force-bar-labelDividers\").attr(\"height\",\"21px\").attr(\"width\",\"1px\").attr(\"y\",83).merge(x).attr(\"x\",(function(e){return(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+4.5})).attr(\"fill\",(function(e){return\"url(#linear-grad-\".concat(e.effect>0?0:1,\")\")})),x.exit().remove();var k=this.mainGroup.selectAll(\".force-bar-labelLinks\").data(v.slice(0,-1));k.enter().append(\"line\").attr(\"class\",\"force-bar-labelLinks\").attr(\"y1\",73).attr(\"y2\",83).attr(\"stroke-opacity\",.5).attr(\"stroke-width\",1).merge(k).attr(\"x1\",(function(e){return o(e.x)+o(Math.abs(e.effect))+u})).attr(\"x2\",(function(e){return(e.effect>0?o(e.textx):o(e.textx)+e.textWidth)+u+5})).attr(\"stroke\",(function(t){return t.effect>0?e.colors[0]:e.colors[1]})),k.exit().remove();var S=this.mainGroup.selectAll(\".force-bar-blockDividers\").data(n.slice(0,-1));S.enter().append(\"path\").attr(\"class\",\"force-bar-blockDividers\").attr(\"stroke-width\",2).attr(\"fill\",\"none\").merge(S).attr(\"d\",(function(e){var t=o(e.x)+o(Math.abs(e.effect))+u;return p([[t,56],[t+(e.effect<0?-4:4),64.5],[t,73]])})).attr(\"stroke\",(function(t,n){return c===n+1||Math.abs(t.effect)<1e-8?\"#rgba(0,0,0,0)\":t.effect>0?e.brighterColors[0]:e.brighterColors[1]})),S.exit().remove(),this.joinPointLine.attr(\"x1\",o(s)+u).attr(\"x2\",o(s)+u).attr(\"y1\",50).attr(\"y2\",56).attr(\"stroke\",\"#F2F2F2\").attr(\"stroke-width\",1).attr(\"opacity\",1),this.joinPointLabelOutline.attr(\"x\",o(s)+u).attr(\"y\",45).attr(\"color\",\"#fff\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",6).text(ze(\",.2f\")(this.invLinkFunction(s-i))).attr(\"opacity\",1),console.log(\"joinPoint\",s,u,50,i),this.joinPointLabel.attr(\"x\",o(s)+u).attr(\"y\",45).attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").text(ze(\",.2f\")(this.invLinkFunction(s-i))).attr(\"opacity\",1),this.joinPointTitle.attr(\"x\",o(s)+u).attr(\"y\",28).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(this.props.outNames[0]).attr(\"opacity\",.5),this.props.hideBars||(this.joinPointTitleLeft.attr(\"x\",o(s)+u-16).attr(\"y\",12).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"higher\").attr(\"opacity\",1),this.joinPointTitleRight.attr(\"x\",o(s)+u+16).attr(\"y\",12).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"lower\").attr(\"opacity\",1),this.joinPointTitleLeftArrow.attr(\"x\",o(s)+u+7).attr(\"y\",8).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"→\").attr(\"opacity\",1),this.joinPointTitleRightArrow.attr(\"x\",o(s)+u-7).attr(\"y\",14).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"←\").attr(\"opacity\",1)),this.props.hideBaseValueLabel||this.baseValueTitle.attr(\"x\",this.scaleCentered(0)).attr(\"y\",28).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(\"base value\").attr(\"opacity\",.5)}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return e.createElement(\"svg\",{ref:function(e){return t.svg=Jt(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}},e.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-axis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-axis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\"}}))}}])&&Tn(n.prototype,r),Object.defineProperty(n,\"prototype\",{writable:!1}),u}(e.Component);zn.defaultProps={plot_cmap:\"RdBu\"};const Ln=zn,On=1e3,An=6e4,Fn=36e5,Dn=864e5,Rn=6048e5,jn=31536e6,Un=new Date,In=new Date;function $n(e,t,n,r){function a(t){return e(t=0===arguments.length?new Date:new Date(+t)),t}return a.floor=t=>(e(t=new Date(+t)),t),a.ceil=n=>(e(n=new Date(n-1)),t(n,1),e(n),n),a.round=e=>{const t=a(e),n=a.ceil(e);return e-t<n-e?t:n},a.offset=(e,n)=>(t(e=new Date(+e),null==n?1:Math.floor(n)),e),a.range=(n,r,i)=>{const o=[];if(n=a.ceil(n),i=null==i?1:Math.floor(i),!(n<r&&i>0))return o;let u;do{o.push(u=new Date(+n)),t(n,i),e(n)}while(u<n&&n<r);return o},a.filter=n=>$n((t=>{if(t>=t)for(;e(t),!n(t);)t.setTime(t-1)}),((e,r)=>{if(e>=e)if(r<0)for(;++r<=0;)for(;t(e,-1),!n(e););else for(;--r>=0;)for(;t(e,1),!n(e););})),n&&(a.count=(t,r)=>(Un.setTime(+t),In.setTime(+r),e(Un),e(In),Math.floor(n(Un,In))),a.every=e=>(e=Math.floor(e),isFinite(e)&&e>0?e>1?a.filter(r?t=>r(t)%e==0:t=>a.count(0,t)%e==0):a:null)),a}const Bn=$n((()=>{}),((e,t)=>{e.setTime(+e+t)}),((e,t)=>t-e));Bn.every=e=>(e=Math.floor(e),isFinite(e)&&e>0?e>1?$n((t=>{t.setTime(Math.floor(t/e)*e)}),((t,n)=>{t.setTime(+t+n*e)}),((t,n)=>(n-t)/e)):Bn:null),Bn.range;const Wn=$n((e=>{e.setTime(e-e.getMilliseconds())}),((e,t)=>{e.setTime(+e+t*On)}),((e,t)=>(t-e)/On),(e=>e.getUTCSeconds())),Vn=(Wn.range,$n((e=>{e.setTime(e-e.getMilliseconds()-e.getSeconds()*On)}),((e,t)=>{e.setTime(+e+t*An)}),((e,t)=>(t-e)/An),(e=>e.getMinutes()))),Hn=(Vn.range,$n((e=>{e.setUTCSeconds(0,0)}),((e,t)=>{e.setTime(+e+t*An)}),((e,t)=>(t-e)/An),(e=>e.getUTCMinutes()))),qn=(Hn.range,$n((e=>{e.setTime(e-e.getMilliseconds()-e.getSeconds()*On-e.getMinutes()*An)}),((e,t)=>{e.setTime(+e+t*Fn)}),((e,t)=>(t-e)/Fn),(e=>e.getHours()))),Qn=(qn.range,$n((e=>{e.setUTCMinutes(0,0,0)}),((e,t)=>{e.setTime(+e+t*Fn)}),((e,t)=>(t-e)/Fn),(e=>e.getUTCHours()))),Yn=(Qn.range,$n((e=>e.setHours(0,0,0,0)),((e,t)=>e.setDate(e.getDate()+t)),((e,t)=>(t-e-(t.getTimezoneOffset()-e.getTimezoneOffset())*An)/Dn),(e=>e.getDate()-1))),Gn=(Yn.range,$n((e=>{e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCDate(e.getUTCDate()+t)}),((e,t)=>(t-e)/Dn),(e=>e.getUTCDate()-1))),Kn=(Gn.range,$n((e=>{e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCDate(e.getUTCDate()+t)}),((e,t)=>(t-e)/Dn),(e=>Math.floor(e/Dn))));function Zn(e){return $n((t=>{t.setDate(t.getDate()-(t.getDay()+7-e)%7),t.setHours(0,0,0,0)}),((e,t)=>{e.setDate(e.getDate()+7*t)}),((e,t)=>(t-e-(t.getTimezoneOffset()-e.getTimezoneOffset())*An)/Rn))}Kn.range;const Xn=Zn(0),Jn=Zn(1),er=Zn(2),tr=Zn(3),nr=Zn(4),rr=Zn(5),ar=Zn(6);function ir(e){return $n((t=>{t.setUTCDate(t.getUTCDate()-(t.getUTCDay()+7-e)%7),t.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCDate(e.getUTCDate()+7*t)}),((e,t)=>(t-e)/Rn))}Xn.range,Jn.range,er.range,tr.range,nr.range,rr.range,ar.range;const or=ir(0),ur=ir(1),lr=ir(2),sr=ir(3),cr=ir(4),fr=ir(5),pr=ir(6),dr=(or.range,ur.range,lr.range,sr.range,cr.range,fr.range,pr.range,$n((e=>{e.setDate(1),e.setHours(0,0,0,0)}),((e,t)=>{e.setMonth(e.getMonth()+t)}),((e,t)=>t.getMonth()-e.getMonth()+12*(t.getFullYear()-e.getFullYear())),(e=>e.getMonth()))),hr=(dr.range,$n((e=>{e.setUTCDate(1),e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCMonth(e.getUTCMonth()+t)}),((e,t)=>t.getUTCMonth()-e.getUTCMonth()+12*(t.getUTCFullYear()-e.getUTCFullYear())),(e=>e.getUTCMonth()))),vr=(hr.range,$n((e=>{e.setMonth(0,1),e.setHours(0,0,0,0)}),((e,t)=>{e.setFullYear(e.getFullYear()+t)}),((e,t)=>t.getFullYear()-e.getFullYear()),(e=>e.getFullYear())));vr.every=e=>isFinite(e=Math.floor(e))&&e>0?$n((t=>{t.setFullYear(Math.floor(t.getFullYear()/e)*e),t.setMonth(0,1),t.setHours(0,0,0,0)}),((t,n)=>{t.setFullYear(t.getFullYear()+n*e)})):null,vr.range;const gr=$n((e=>{e.setUTCMonth(0,1),e.setUTCHours(0,0,0,0)}),((e,t)=>{e.setUTCFullYear(e.getUTCFullYear()+t)}),((e,t)=>t.getUTCFullYear()-e.getUTCFullYear()),(e=>e.getUTCFullYear()));function yr(e,t,n,r,a,i){const o=[[Wn,1,On],[Wn,5,5e3],[Wn,15,15e3],[Wn,30,3e4],[i,1,An],[i,5,3e5],[i,15,9e5],[i,30,18e5],[a,1,Fn],[a,3,108e5],[a,6,216e5],[a,12,432e5],[r,1,Dn],[r,2,1728e5],[n,1,Rn],[t,1,2592e6],[t,3,7776e6],[e,1,jn]];function u(t,n,r){const a=Math.abs(n-t)/r,i=f((([,,e])=>e)).right(o,a);if(i===o.length)return e.every(l(t/jn,n/jn,r));if(0===i)return Bn.every(Math.max(l(t,n,r),1));const[u,s]=o[a/o[i-1][2]<o[i][2]/a?i-1:i];return u.every(s)}return[function(e,t,n){const r=t<e;r&&([e,t]=[t,e]);const a=n&&\"function\"==typeof n.range?n:u(e,t,n),i=a?a.range(e,+t+1):[];return r?i.reverse():i},u]}gr.every=e=>isFinite(e=Math.floor(e))&&e>0?$n((t=>{t.setUTCFullYear(Math.floor(t.getUTCFullYear()/e)*e),t.setUTCMonth(0,1),t.setUTCHours(0,0,0,0)}),((t,n)=>{t.setUTCFullYear(t.getUTCFullYear()+n*e)})):null,gr.range;const[mr,br]=yr(gr,hr,or,Kn,Qn,Hn),[_r,wr]=yr(vr,dr,Xn,Yn,qn,Vn);function xr(e){if(0<=e.y&&e.y<100){var t=new Date(-1,e.m,e.d,e.H,e.M,e.S,e.L);return t.setFullYear(e.y),t}return new Date(e.y,e.m,e.d,e.H,e.M,e.S,e.L)}function kr(e){if(0<=e.y&&e.y<100){var t=new Date(Date.UTC(-1,e.m,e.d,e.H,e.M,e.S,e.L));return t.setUTCFullYear(e.y),t}return new Date(Date.UTC(e.y,e.m,e.d,e.H,e.M,e.S,e.L))}function Sr(e,t,n){return{y:e,m:t,d:n,H:0,M:0,S:0,L:0}}var Er,Cr,Tr,Mr={\"-\":\"\",_:\" \",0:\"0\"},Nr=/^\\s*\\d+/,Pr=/^%/,zr=/[\\\\^$*+?|[\\]().{}]/g;function Lr(e,t,n){var r=e<0?\"-\":\"\",a=(r?-e:e)+\"\",i=a.length;return r+(i<n?new Array(n-i+1).join(t)+a:a)}function Or(e){return e.replace(zr,\"\\\\$&\")}function Ar(e){return new RegExp(\"^(?:\"+e.map(Or).join(\"|\")+\")\",\"i\")}function Fr(e){return new Map(e.map(((e,t)=>[e.toLowerCase(),t])))}function Dr(e,t,n){var r=Nr.exec(t.slice(n,n+1));return r?(e.w=+r[0],n+r[0].length):-1}function Rr(e,t,n){var r=Nr.exec(t.slice(n,n+1));return r?(e.u=+r[0],n+r[0].length):-1}function jr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.U=+r[0],n+r[0].length):-1}function Ur(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.V=+r[0],n+r[0].length):-1}function Ir(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.W=+r[0],n+r[0].length):-1}function $r(e,t,n){var r=Nr.exec(t.slice(n,n+4));return r?(e.y=+r[0],n+r[0].length):-1}function Br(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.y=+r[0]+(+r[0]>68?1900:2e3),n+r[0].length):-1}function Wr(e,t,n){var r=/^(Z)|([+-]\\d\\d)(?::?(\\d\\d))?/.exec(t.slice(n,n+6));return r?(e.Z=r[1]?0:-(r[2]+(r[3]||\"00\")),n+r[0].length):-1}function Vr(e,t,n){var r=Nr.exec(t.slice(n,n+1));return r?(e.q=3*r[0]-3,n+r[0].length):-1}function Hr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.m=r[0]-1,n+r[0].length):-1}function qr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.d=+r[0],n+r[0].length):-1}function Qr(e,t,n){var r=Nr.exec(t.slice(n,n+3));return r?(e.m=0,e.d=+r[0],n+r[0].length):-1}function Yr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.H=+r[0],n+r[0].length):-1}function Gr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.M=+r[0],n+r[0].length):-1}function Kr(e,t,n){var r=Nr.exec(t.slice(n,n+2));return r?(e.S=+r[0],n+r[0].length):-1}function Zr(e,t,n){var r=Nr.exec(t.slice(n,n+3));return r?(e.L=+r[0],n+r[0].length):-1}function Xr(e,t,n){var r=Nr.exec(t.slice(n,n+6));return r?(e.L=Math.floor(r[0]/1e3),n+r[0].length):-1}function Jr(e,t,n){var r=Pr.exec(t.slice(n,n+1));return r?n+r[0].length:-1}function ea(e,t,n){var r=Nr.exec(t.slice(n));return r?(e.Q=+r[0],n+r[0].length):-1}function ta(e,t,n){var r=Nr.exec(t.slice(n));return r?(e.s=+r[0],n+r[0].length):-1}function na(e,t){return Lr(e.getDate(),t,2)}function ra(e,t){return Lr(e.getHours(),t,2)}function aa(e,t){return Lr(e.getHours()%12||12,t,2)}function ia(e,t){return Lr(1+Yn.count(vr(e),e),t,3)}function oa(e,t){return Lr(e.getMilliseconds(),t,3)}function ua(e,t){return oa(e,t)+\"000\"}function la(e,t){return Lr(e.getMonth()+1,t,2)}function sa(e,t){return Lr(e.getMinutes(),t,2)}function ca(e,t){return Lr(e.getSeconds(),t,2)}function fa(e){var t=e.getDay();return 0===t?7:t}function pa(e,t){return Lr(Xn.count(vr(e)-1,e),t,2)}function da(e){var t=e.getDay();return t>=4||0===t?nr(e):nr.ceil(e)}function ha(e,t){return e=da(e),Lr(nr.count(vr(e),e)+(4===vr(e).getDay()),t,2)}function va(e){return e.getDay()}function ga(e,t){return Lr(Jn.count(vr(e)-1,e),t,2)}function ya(e,t){return Lr(e.getFullYear()%100,t,2)}function ma(e,t){return Lr((e=da(e)).getFullYear()%100,t,2)}function ba(e,t){return Lr(e.getFullYear()%1e4,t,4)}function _a(e,t){var n=e.getDay();return Lr((e=n>=4||0===n?nr(e):nr.ceil(e)).getFullYear()%1e4,t,4)}function wa(e){var t=e.getTimezoneOffset();return(t>0?\"-\":(t*=-1,\"+\"))+Lr(t/60|0,\"0\",2)+Lr(t%60,\"0\",2)}function xa(e,t){return Lr(e.getUTCDate(),t,2)}function ka(e,t){return Lr(e.getUTCHours(),t,2)}function Sa(e,t){return Lr(e.getUTCHours()%12||12,t,2)}function Ea(e,t){return Lr(1+Gn.count(gr(e),e),t,3)}function Ca(e,t){return Lr(e.getUTCMilliseconds(),t,3)}function Ta(e,t){return Ca(e,t)+\"000\"}function Ma(e,t){return Lr(e.getUTCMonth()+1,t,2)}function Na(e,t){return Lr(e.getUTCMinutes(),t,2)}function Pa(e,t){return Lr(e.getUTCSeconds(),t,2)}function za(e){var t=e.getUTCDay();return 0===t?7:t}function La(e,t){return Lr(or.count(gr(e)-1,e),t,2)}function Oa(e){var t=e.getUTCDay();return t>=4||0===t?cr(e):cr.ceil(e)}function Aa(e,t){return e=Oa(e),Lr(cr.count(gr(e),e)+(4===gr(e).getUTCDay()),t,2)}function Fa(e){return e.getUTCDay()}function Da(e,t){return Lr(ur.count(gr(e)-1,e),t,2)}function Ra(e,t){return Lr(e.getUTCFullYear()%100,t,2)}function ja(e,t){return Lr((e=Oa(e)).getUTCFullYear()%100,t,2)}function Ua(e,t){return Lr(e.getUTCFullYear()%1e4,t,4)}function Ia(e,t){var n=e.getUTCDay();return Lr((e=n>=4||0===n?cr(e):cr.ceil(e)).getUTCFullYear()%1e4,t,4)}function $a(){return\"+0000\"}function Ba(){return\"%\"}function Wa(e){return+e}function Va(e){return Math.floor(+e/1e3)}function Ha(e){return new Date(e)}function qa(e){return e instanceof Date?+e:+new Date(+e)}function Qa(e,t,n,r,a,i,o,u,l,s){var c=be(),f=c.invert,p=c.domain,d=s(\".%L\"),h=s(\":%S\"),v=s(\"%I:%M\"),g=s(\"%I %p\"),y=s(\"%a %d\"),m=s(\"%b %d\"),b=s(\"%B\"),_=s(\"%Y\");function w(e){return(l(e)<e?d:u(e)<e?h:o(e)<e?v:i(e)<e?g:r(e)<e?a(e)<e?y:m:n(e)<e?b:_)(e)}return c.invert=function(e){return new Date(f(e))},c.domain=function(e){return arguments.length?p(Array.from(e,qa)):p().map(Ha)},c.ticks=function(t){var n=p();return e(n[0],n[n.length-1],null==t?10:t)},c.tickFormat=function(e,t){return null==t?w:s(t)},c.nice=function(e){var n=p();return e&&\"function\"==typeof e.range||(e=t(n[0],n[n.length-1],null==e?10:e)),e?p(function(e,t){var n,r=0,a=(e=e.slice()).length-1,i=e[r],o=e[a];return o<i&&(n=r,r=a,a=n,n=i,i=o,o=n),e[r]=t.floor(i),e[a]=t.ceil(o),e}(n,e)):c},c.copy=function(){return me(c,Qa(e,t,n,r,a,i,o,u,l,s))},c}function Ya(){return _e.apply(Qa(_r,wr,vr,dr,Xn,Yn,qn,Vn,Wn,Cr).domain([new Date(2e3,0,1),new Date(2e3,0,2)]),arguments)}function Ga(e,t){var n=\"undefined\"!=typeof Symbol&&e[Symbol.iterator]||e[\"@@iterator\"];if(!n){if(Array.isArray(e)||(n=function(e,t){if(e){if(\"string\"==typeof e)return Ka(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);return\"Object\"===n&&e.constructor&&(n=e.constructor.name),\"Map\"===n||\"Set\"===n?Array.from(e):\"Arguments\"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?Ka(e,t):void 0}}(e))||t&&e&&\"number\"==typeof e.length){n&&(e=n);var r=0,a=function(){};return{s:a,n:function(){return r>=e.length?{done:!0}:{done:!1,value:e[r++]}},e:function(e){throw e},f:a}}throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\")}var i,o=!0,u=!1;return{s:function(){n=n.call(e)},n:function(){var e=n.next();return o=e.done,e},e:function(e){u=!0,i=e},f:function(){try{o||null==n.return||n.return()}finally{if(u)throw i}}}}function Ka(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,r=new Array(t);n<t;n++)r[n]=e[n];return r}function Za(e){return Za=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&\"function\"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?\"symbol\":typeof e},Za(e)}function Xa(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(e,(void 0,a=function(e,t){if(\"object\"!==Za(e)||null===e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var r=n.call(e,\"string\");if(\"object\"!==Za(r))return r;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return String(e)}(r.key),\"symbol\"===Za(a)?a:String(a)),r)}var a}function Ja(e,t){return Ja=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},Ja(e,t)}function ei(e){if(void 0===e)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return e}function ti(e){return ti=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},ti(e)}Er=function(e){var t=e.dateTime,n=e.date,r=e.time,a=e.periods,i=e.days,o=e.shortDays,u=e.months,l=e.shortMonths,s=Ar(a),c=Fr(a),f=Ar(i),p=Fr(i),d=Ar(o),h=Fr(o),v=Ar(u),g=Fr(u),y=Ar(l),m=Fr(l),b={a:function(e){return o[e.getDay()]},A:function(e){return i[e.getDay()]},b:function(e){return l[e.getMonth()]},B:function(e){return u[e.getMonth()]},c:null,d:na,e:na,f:ua,g:ma,G:_a,H:ra,I:aa,j:ia,L:oa,m:la,M:sa,p:function(e){return a[+(e.getHours()>=12)]},q:function(e){return 1+~~(e.getMonth()/3)},Q:Wa,s:Va,S:ca,u:fa,U:pa,V:ha,w:va,W:ga,x:null,X:null,y:ya,Y:ba,Z:wa,\"%\":Ba},_={a:function(e){return o[e.getUTCDay()]},A:function(e){return i[e.getUTCDay()]},b:function(e){return l[e.getUTCMonth()]},B:function(e){return u[e.getUTCMonth()]},c:null,d:xa,e:xa,f:Ta,g:ja,G:Ia,H:ka,I:Sa,j:Ea,L:Ca,m:Ma,M:Na,p:function(e){return a[+(e.getUTCHours()>=12)]},q:function(e){return 1+~~(e.getUTCMonth()/3)},Q:Wa,s:Va,S:Pa,u:za,U:La,V:Aa,w:Fa,W:Da,x:null,X:null,y:Ra,Y:Ua,Z:$a,\"%\":Ba},w={a:function(e,t,n){var r=d.exec(t.slice(n));return r?(e.w=h.get(r[0].toLowerCase()),n+r[0].length):-1},A:function(e,t,n){var r=f.exec(t.slice(n));return r?(e.w=p.get(r[0].toLowerCase()),n+r[0].length):-1},b:function(e,t,n){var r=y.exec(t.slice(n));return r?(e.m=m.get(r[0].toLowerCase()),n+r[0].length):-1},B:function(e,t,n){var r=v.exec(t.slice(n));return r?(e.m=g.get(r[0].toLowerCase()),n+r[0].length):-1},c:function(e,n,r){return S(e,t,n,r)},d:qr,e:qr,f:Xr,g:Br,G:$r,H:Yr,I:Yr,j:Qr,L:Zr,m:Hr,M:Gr,p:function(e,t,n){var r=s.exec(t.slice(n));return r?(e.p=c.get(r[0].toLowerCase()),n+r[0].length):-1},q:Vr,Q:ea,s:ta,S:Kr,u:Rr,U:jr,V:Ur,w:Dr,W:Ir,x:function(e,t,r){return S(e,n,t,r)},X:function(e,t,n){return S(e,r,t,n)},y:Br,Y:$r,Z:Wr,\"%\":Jr};function x(e,t){return function(n){var r,a,i,o=[],u=-1,l=0,s=e.length;for(n instanceof Date||(n=new Date(+n));++u<s;)37===e.charCodeAt(u)&&(o.push(e.slice(l,u)),null!=(a=Mr[r=e.charAt(++u)])?r=e.charAt(++u):a=\"e\"===r?\" \":\"0\",(i=t[r])&&(r=i(n,a)),o.push(r),l=u+1);return o.push(e.slice(l,u)),o.join(\"\")}}function k(e,t){return function(n){var r,a,i=Sr(1900,void 0,1);if(S(i,e,n+=\"\",0)!=n.length)return null;if(\"Q\"in i)return new Date(i.Q);if(\"s\"in i)return new Date(1e3*i.s+(\"L\"in i?i.L:0));if(t&&!(\"Z\"in i)&&(i.Z=0),\"p\"in i&&(i.H=i.H%12+12*i.p),void 0===i.m&&(i.m=\"q\"in i?i.q:0),\"V\"in i){if(i.V<1||i.V>53)return null;\"w\"in i||(i.w=1),\"Z\"in i?(a=(r=kr(Sr(i.y,0,1))).getUTCDay(),r=a>4||0===a?ur.ceil(r):ur(r),r=Gn.offset(r,7*(i.V-1)),i.y=r.getUTCFullYear(),i.m=r.getUTCMonth(),i.d=r.getUTCDate()+(i.w+6)%7):(a=(r=xr(Sr(i.y,0,1))).getDay(),r=a>4||0===a?Jn.ceil(r):Jn(r),r=Yn.offset(r,7*(i.V-1)),i.y=r.getFullYear(),i.m=r.getMonth(),i.d=r.getDate()+(i.w+6)%7)}else(\"W\"in i||\"U\"in i)&&(\"w\"in i||(i.w=\"u\"in i?i.u%7:\"W\"in i?1:0),a=\"Z\"in i?kr(Sr(i.y,0,1)).getUTCDay():xr(Sr(i.y,0,1)).getDay(),i.m=0,i.d=\"W\"in i?(i.w+6)%7+7*i.W-(a+5)%7:i.w+7*i.U-(a+6)%7);return\"Z\"in i?(i.H+=i.Z/100|0,i.M+=i.Z%100,kr(i)):xr(i)}}function S(e,t,n,r){for(var a,i,o=0,u=t.length,l=n.length;o<u;){if(r>=l)return-1;if(37===(a=t.charCodeAt(o++))){if(a=t.charAt(o++),!(i=w[a in Mr?t.charAt(o++):a])||(r=i(e,n,r))<0)return-1}else if(a!=n.charCodeAt(r++))return-1}return r}return b.x=x(n,b),b.X=x(r,b),b.c=x(t,b),_.x=x(n,_),_.X=x(r,_),_.c=x(t,_),{format:function(e){var t=x(e+=\"\",b);return t.toString=function(){return e},t},parse:function(e){var t=k(e+=\"\",!1);return t.toString=function(){return e},t},utcFormat:function(e){var t=x(e+=\"\",_);return t.toString=function(){return e},t},utcParse:function(e){var t=k(e+=\"\",!0);return t.toString=function(){return e},t}}}({dateTime:\"%x, %X\",date:\"%-m/%-d/%Y\",time:\"%-I:%M:%S %p\",periods:[\"AM\",\"PM\"],days:[\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"],shortDays:[\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"],months:[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],shortMonths:[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]}),Cr=Er.format,Tr=Er.parse,Er.utcFormat,Er.utcParse;var ni=function(t){!function(e,t){if(\"function\"!=typeof t&&null!==t)throw new TypeError(\"Super expression must either be null or a function\");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,\"prototype\",{writable:!1}),t&&Ja(e,t)}(u,t);var n,r,a,i,o=(a=u,i=function(){if(\"undefined\"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if(\"function\"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}(),function(){var e,t=ti(a);if(i){var n=ti(this).constructor;e=Reflect.construct(t,arguments,n)}else e=t.apply(this,arguments);return function(e,t){if(t&&(\"object\"===Za(t)||\"function\"==typeof t))return t;if(void 0!==t)throw new TypeError(\"Derived constructors may only return object or undefined\");return ei(e)}(this,e)});function u(){var e;return function(e,t){if(!(e instanceof t))throw new TypeError(\"Cannot call a class as a function\")}(this,u),e=o.call(this),window.lastAdditiveForceArrayVisualizer=ei(e),e.topOffset=28,e.leftOffset=80,e.height=350,e.effectFormat=ze(\".2\"),e.redraw=(0,Re.debounce)((function(){return e.draw()}),200),e}return n=u,(r=[{key:\"componentDidMount\",value:function(){var e=this;this.mainGroup=this.svg.append(\"g\"),this.onTopGroup=this.svg.append(\"g\"),this.xaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-xaxis\"),this.yaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-yaxis\"),this.hoverGroup1=this.svg.append(\"g\"),this.hoverGroup2=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.hoverLine=this.svg.append(\"line\"),this.hoverxOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hoverx=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.hoverxTitle=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"opacity\",.6).attr(\"font-size\",\"12px\"),this.hoveryOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hovery=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.xlabel=this.wrapper.select(\".additive-force-array-xlabel\"),this.ylabel=this.wrapper.select(\".additive-force-array-ylabel\");var t=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in je.colors?t=je.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),t=je.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(t=this.props.plot_cmap),this.colors=t.map((function(e){return q(e)})),this.brighterColors=[1.45,1.6].map((function(t,n){return e.colors[n].brighter(t)}));var n=ze(\",.4\");null!=this.props.ordering_keys&&null!=this.props.ordering_keys_time_format?(this.parseTime=Tr(this.props.ordering_keys_time_format),this.formatTime=Cr(this.props.ordering_keys_time_format),this.xtickFormat=function(e){return\"object\"==Za(e)?this.formatTime(e):n(e)}):(this.parseTime=null,this.formatTime=null,this.xtickFormat=n),this.xscale=De(),this.xaxis=dn().scale(this.xscale).tickSizeInner(4).tickSizeOuter(0).tickFormat((function(t){return e.xtickFormat(t)})).tickPadding(-18),this.ytickFormat=n,this.yscale=De(),this.yaxis=pn(an,undefined).scale(this.yscale).tickSizeInner(4).tickSizeOuter(0).tickFormat((function(t){return e.ytickFormat(e.invLinkFunction(t))})).tickPadding(2),this.xlabel.node().onchange=function(){return e.internalDraw()},this.ylabel.node().onchange=function(){return e.internalDraw()},this.svg.on(\"mousemove\",(function(t){return e.mouseMoved(t)})),this.svg.on(\"click\",(function(){return alert(\"This original index of the sample you clicked is \"+e.nearestExpIndex)})),this.svg.on(\"mouseout\",(function(t){return e.mouseOut(t)})),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"mouseOut\",value:function(){this.hoverLine.attr(\"display\",\"none\"),this.hoverx.attr(\"display\",\"none\"),this.hoverxOutline.attr(\"display\",\"none\"),this.hoverxTitle.attr(\"display\",\"none\"),this.hovery.attr(\"display\",\"none\"),this.hoveryOutline.attr(\"display\",\"none\"),this.hoverGroup1.attr(\"display\",\"none\"),this.hoverGroup2.attr(\"display\",\"none\")}},{key:\"mouseMoved\",value:function(e){var t,n,r=this;this.hoverLine.attr(\"display\",\"\"),this.hoverx.attr(\"display\",\"\"),this.hoverxOutline.attr(\"display\",\"\"),this.hoverxTitle.attr(\"display\",\"\"),this.hovery.attr(\"display\",\"\"),this.hoveryOutline.attr(\"display\",\"\"),this.hoverGroup1.attr(\"display\",\"\"),this.hoverGroup2.attr(\"display\",\"\");var a=function(e,t){if(e=function(e){let t;for(;t=e.sourceEvent;)e=t;return e}(e),void 0===t&&(t=e.currentTarget),t){var n=t.ownerSVGElement||t;if(n.createSVGPoint){var r=n.createSVGPoint();return r.x=e.clientX,r.y=e.clientY,[(r=r.matrixTransform(t.getScreenCTM().inverse())).x,r.y]}if(t.getBoundingClientRect){var a=t.getBoundingClientRect();return[e.clientX-a.left-t.clientLeft,e.clientY-a.top-t.clientTop]}}return[e.pageX,e.pageY]}(e,this.svg.node())[0];if(this.props.explanations){for(t=0;t<this.currExplanations.length;++t)(!n||Math.abs(n.xmapScaled-a)>Math.abs(this.currExplanations[t].xmapScaled-a))&&(n=this.currExplanations[t]);this.nearestExpIndex=n.origInd,this.hoverLine.attr(\"x1\",n.xmapScaled).attr(\"x2\",n.xmapScaled).attr(\"y1\",0+this.topOffset).attr(\"y2\",this.height),this.hoverx.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxOutline.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxTitle.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-18).text(n.count>1?n.count+\" averaged samples\":\"\"),this.hovery.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint))),this.hoveryOutline.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint)));for(var i,o,u=[],l=this.currPosOrderedFeatures.length-1;l>=0;--l){var s=this.currPosOrderedFeatures[l],c=n.features[s];o=5+(c.posyTop+c.posyBottom)/2,(!i||o-i>=15)&&c.posyTop-c.posyBottom>=6&&(u.push(c),i=o)}var f=[];i=void 0;var p,d=Ga(this.currNegOrderedFeatures);try{for(d.s();!(p=d.n()).done;){var h=p.value,v=n.features[h];o=5+(v.negyTop+v.negyBottom)/2,(!i||i-o>=15)&&v.negyTop-v.negyBottom>=6&&(f.push(v),i=o)}}catch(e){d.e(e)}finally{d.f()}var g=function(e){var t=\"\";return null!==e.value&&void 0!==e.value&&(t=\" = \"+(isNaN(e.value)?e.value:r.ytickFormat(e.value))),n.count>1?\"mean(\"+r.props.featureNames[e.ind]+\")\"+t:r.props.featureNames[e.ind]+t},y=this.hoverGroup1.selectAll(\".pos-values\").data(u);y.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(y).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.posyTop+e.posyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(g),y.exit().remove();var m=this.hoverGroup2.selectAll(\".pos-values\").data(u);m.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(m).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.posyTop+e.posyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[0]).text(g),m.exit().remove();var b=this.hoverGroup1.selectAll(\".neg-values\").data(f);b.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(b).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.negyTop+e.negyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(g),b.exit().remove();var _=this.hoverGroup2.selectAll(\".neg-values\").data(f);_.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(_).attr(\"x\",n.xmapScaled+5).attr(\"y\",(function(e){return 4+(e.negyTop+e.negyBottom)/2})).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[1]).text(g),_.exit().remove()}}},{key:\"draw\",value:function(){var e=this;if(this.props.explanations&&0!==this.props.explanations.length){(0,Re.each)(this.props.explanations,(function(e,t){return e.origInd=t}));var t,n={},r={},a={},i=Ga(this.props.explanations);try{for(i.s();!(t=i.n()).done;){var o=t.value;for(var u in o.features)void 0===n[u]&&(n[u]=0,r[u]=0,a[u]=0),o.features[u].effect>0?n[u]+=o.features[u].effect:r[u]-=o.features[u].effect,null!==o.features[u].value&&void 0!==o.features[u].value&&(a[u]+=1)}}catch(e){i.e(e)}finally{i.f()}this.usedFeatures=(0,Re.sortBy)((0,Re.keys)(n),(function(e){return-(n[e]+r[e])})),console.log(\"found \",this.usedFeatures.length,\" used features\"),this.posOrderedFeatures=(0,Re.sortBy)(this.usedFeatures,(function(e){return n[e]})),this.negOrderedFeatures=(0,Re.sortBy)(this.usedFeatures,(function(e){return-r[e]})),this.singleValueFeatures=(0,Re.filter)(this.usedFeatures,(function(e){return a[e]>0}));var l=[\"sample order by similarity\",\"sample order by output value\",\"original sample ordering\"].concat(this.singleValueFeatures.map((function(t){return e.props.featureNames[t]})));null!=this.props.ordering_keys&&l.unshift(\"sample order by key\");var s=this.xlabel.selectAll(\"option\").data(l);s.enter().append(\"option\").merge(s).attr(\"value\",(function(e){return e})).text((function(e){return e})),s.exit().remove();var c=this.props.outNames[0]?this.props.outNames[0]:\"model output value\";(l=(0,Re.map)(this.usedFeatures,(function(t){return[e.props.featureNames[t],e.props.featureNames[t]+\" effects\"]}))).unshift([\"model output value\",c]);var f=this.ylabel.selectAll(\"option\").data(l);f.enter().append(\"option\").merge(f).attr(\"value\",(function(e){return e[0]})).text((function(e){return e[1]})),f.exit().remove(),this.ylabel.style(\"top\",(this.height-10-this.topOffset)/2+this.topOffset+\"px\").style(\"left\",10-this.ylabel.node().offsetWidth/2+\"px\"),this.internalDraw()}}},{key:\"internalDraw\",value:function(){var e,t,n=this,r=Ga(this.props.explanations);try{for(r.s();!(e=r.n()).done;){var a,i=e.value,o=Ga(this.usedFeatures);try{for(o.s();!(a=o.n()).done;){var u=a.value;i.features.hasOwnProperty(u)||(i.features[u]={effect:0,value:0}),i.features[u].ind=u}}catch(e){o.e(e)}finally{o.f()}}}catch(e){r.e(e)}finally{r.f()}var l=this.xlabel.node().value,s=\"sample order by key\"===l&&null!=this.props.ordering_keys_time_format;if(this.xscale=s?Ya():De(),this.xaxis.scale(this.xscale),\"sample order by similarity\"===l)t=(0,Re.sortBy)(this.props.explanations,(function(e){return e.simIndex})),(0,Re.each)(t,(function(e,t){return e.xmap=t}));else if(\"sample order by output value\"===l)t=(0,Re.sortBy)(this.props.explanations,(function(e){return-e.outValue})),(0,Re.each)(t,(function(e,t){return e.xmap=t}));else if(\"original sample ordering\"===l)t=(0,Re.sortBy)(this.props.explanations,(function(e){return e.origInd})),(0,Re.each)(t,(function(e,t){return e.xmap=t}));else if(\"sample order by key\"===l)t=this.props.explanations,s?(0,Re.each)(t,(function(e,t){return e.xmap=n.parseTime(n.props.ordering_keys[t])})):(0,Re.each)(t,(function(e,t){return e.xmap=n.props.ordering_keys[t]})),t=(0,Re.sortBy)(t,(function(e){return e.xmap}));else{var c=(0,Re.findKey)(this.props.featureNames,(function(e){return e===l}));(0,Re.each)(this.props.explanations,(function(e,t){return e.xmap=e.features[c].value}));var f=(0,Re.sortBy)(this.props.explanations,(function(e){return e.xmap})),p=(0,Re.map)(f,(function(e){return e.xmap}));if(\"string\"==typeof p[0])return void alert(\"Ordering by category names is not yet supported.\");var d,h,v=(0,Re.min)(p),g=((0,Re.max)(p)-v)/100;t=[];for(var y=0;y<f.length;++y){var m=f[y];if(d&&!h&&m.xmap-d.xmap<=g||h&&m.xmap-h.xmap<=g){h||((h=(0,Re.cloneDeep)(d)).count=1);var b,_=Ga(this.usedFeatures);try{for(_.s();!(b=_.n()).done;){var w=b.value;h.features[w].effect+=m.features[w].effect,h.features[w].value+=m.features[w].value}}catch(e){_.e(e)}finally{_.f()}h.count+=1}else if(d)if(h){var x,k=Ga(this.usedFeatures);try{for(k.s();!(x=k.n()).done;){var S=x.value;h.features[S].effect/=h.count,h.features[S].value/=h.count}}catch(e){k.e(e)}finally{k.f()}t.push(h),h=void 0}else t.push(d);d=m}d.xmap-t[t.length-1].xmap>g&&t.push(d)}this.currUsedFeatures=this.usedFeatures,this.currPosOrderedFeatures=this.posOrderedFeatures,this.currNegOrderedFeatures=this.negOrderedFeatures;var E=this.ylabel.node().value;if(\"model output value\"!==E){var C=t;t=(0,Re.cloneDeep)(t);for(var T=(0,Re.findKey)(this.props.featureNames,(function(e){return e===E})),M=0;M<t.length;++M){var N=t[M].features[T];t[M].features={},t[M].features[T]=N,C[M].remapped_version=t[M]}this.currUsedFeatures=[T],this.currPosOrderedFeatures=[T],this.currNegOrderedFeatures=[T]}this.currExplanations=t,\"identity\"===this.props.link?this.invLinkFunction=function(e){return n.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(n.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link),this.predValues=(0,Re.map)(t,(function(e){return(0,Re.sum)((0,Re.map)(e.features,(function(e){return e.effect})))}));var P=this.wrapper.node().offsetWidth;if(0==P)return setTimeout((function(){return n.draw(t)}),500);this.svg.style(\"height\",this.height+\"px\"),this.svg.style(\"width\",P+\"px\");var z=(0,Re.map)(t,(function(e){return e.xmap}));this.xscale.domain([(0,Re.min)(z),(0,Re.max)(z)]).range([this.leftOffset,P]).clamp(!0),this.xaxisElement.attr(\"transform\",\"translate(0,\"+this.topOffset+\")\").call(this.xaxis);for(var L=0;L<this.currExplanations.length;++L)this.currExplanations[L].xmapScaled=this.xscale(this.currExplanations[L].xmap);for(var O=t.length,A=0,F=0;F<O;++F){var D=t[F].features,R=(0,Re.sum)((0,Re.map)((0,Re.filter)(D,(function(e){return e.effect>0})),(function(e){return e.effect})))||0,j=(0,Re.sum)((0,Re.map)((0,Re.filter)(D,(function(e){return e.effect<0})),(function(e){return-e.effect})))||0;A=Math.max(A,2.2*Math.max(R,j))}this.yscale.domain([-A/2,A/2]).range([this.height-10,this.topOffset]),this.yaxisElement.attr(\"transform\",\"translate(\"+this.leftOffset+\",0)\").call(this.yaxis);for(var U=0;U<O;++U){var I,$=t[U].features,B=-((0,Re.sum)((0,Re.map)((0,Re.filter)($,(function(e){return e.effect<0})),(function(e){return-e.effect})))||0),W=void 0,V=Ga(this.currPosOrderedFeatures);try{for(V.s();!(I=V.n()).done;)$[W=I.value].posyTop=this.yscale(B),$[W].effect>0&&(B+=$[W].effect),$[W].posyBottom=this.yscale(B),$[W].ind=W}catch(e){V.e(e)}finally{V.f()}var H,q=B,Q=Ga(this.currNegOrderedFeatures);try{for(Q.s();!(H=Q.n()).done;)$[W=H.value].negyTop=this.yscale(B),$[W].effect<0&&(B-=$[W].effect),$[W].negyBottom=this.yscale(B)}catch(e){Q.e(e)}finally{Q.f()}t[U].joinPoint=q,t[U].joinPointy=this.yscale(q)}var Y=En().x((function(e){return e[0]})).y((function(e){return e[1]})),G=this.mainGroup.selectAll(\".force-bar-array-area-pos\").data(this.currUsedFeatures);G.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-pos\").merge(G).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].posyTop]})),r=(0,Re.map)((0,Re.rangeRight)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].posyBottom]}));return Y(n.concat(r))})).attr(\"fill\",this.colors[0]),G.exit().remove();var K=this.mainGroup.selectAll(\".force-bar-array-area-neg\").data(this.currUsedFeatures);K.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-neg\").merge(K).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].negyTop]})),r=(0,Re.map)((0,Re.rangeRight)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].negyBottom]}));return Y(n.concat(r))})).attr(\"fill\",this.colors[1]),K.exit().remove();var Z=this.mainGroup.selectAll(\".force-bar-array-divider-pos\").data(this.currUsedFeatures);Z.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-pos\").merge(Z).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].posyBottom]}));return Y(n)})).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",(function(){return n.colors[0].brighter(1.2)})),Z.exit().remove();var X=this.mainGroup.selectAll(\".force-bar-array-divider-neg\").data(this.currUsedFeatures);X.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-neg\").merge(X).attr(\"d\",(function(e){var n=(0,Re.map)((0,Re.range)(O),(function(n){return[t[n].xmapScaled,t[n].features[e].negyTop]}));return Y(n)})).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",(function(){return n.colors[1].brighter(1.5)})),X.exit().remove();for(var J=function(e,t,n,r,a){var i,o,u,l;\"pos\"===a?(i=e[n].features[t].posyBottom,o=e[n].features[t].posyTop):(i=e[n].features[t].negyBottom,o=e[n].features[t].negyTop);for(var s=n+1;s<=r;++s)\"pos\"===a?(u=e[s].features[t].posyBottom,l=e[s].features[t].posyTop):(u=e[s].features[t].negyBottom,l=e[s].features[t].negyTop),u>i&&(i=u),l<o&&(o=l);return{top:i,bottom:o}},ee=[],te=0,ne=[\"pos\",\"neg\"];te<ne.length;te++){var re,ae=ne[te],ie=Ga(this.currUsedFeatures);try{for(ie.s();!(re=ie.n()).done;)for(var oe=re.value,ue=0,le=0,se=0,ce={top:0,bottom:0},fe=void 0;le<O-1;){for(;se<100&&le<O-1;)++le,se=t[le].xmapScaled-t[ue].xmapScaled;for(ce=J(t,oe,ue,le,ae);ce.bottom-ce.top<20&&ue<le;)++ue,ce=J(t,oe,ue,le,ae);if(se=t[le].xmapScaled-t[ue].xmapScaled,ce.bottom-ce.top>=20&&se>=100){for(;le<O-1;){if(++le,!((fe=J(t,oe,ue,le,ae)).bottom-fe.top>20)){--le;break}ce=fe}se=t[le].xmapScaled-t[ue].xmapScaled,ee.push([(t[le].xmapScaled+t[ue].xmapScaled)/2,(ce.top+ce.bottom)/2,this.props.featureNames[oe]]);var pe=t[le].xmapScaled;for(ue=le;pe+100>t[ue].xmapScaled&&ue<O-1;)++ue;le=ue}}}catch(e){ie.e(e)}finally{ie.f()}}var de=this.onTopGroup.selectAll(\".force-bar-array-flabels\").data(ee);de.enter().append(\"text\").attr(\"class\",\"force-bar-array-flabels\").merge(de).attr(\"x\",(function(e){return e[0]})).attr(\"y\",(function(e){return e[1]+4})).text((function(e){return e[2]})),de.exit().remove()}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return e.createElement(\"div\",{ref:function(e){return t.wrapper=Jt(e)},style:{textAlign:\"center\"}},e.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-array-wrapper {\\n            text-align: center;\\n          }\\n          .force-bar-array-xaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-xaxis .domain {\\n            opacity: 0;\\n          }\\n          .force-bar-array-xaxis paths {\\n            display: none;\\n          }\\n          .force-bar-array-yaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-yaxis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\\n          .force-bar-array-flabels {\\n            font-size: 12px;\\n            fill: #fff;\\n            text-anchor: middle;\\n          }\\n          .additive-force-array-xlabel {\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            margin-left: 80px;\\n            max-width: 300px;\\n          }\\n          .additive-force-array-xlabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-ylabel {\\n            position: relative;\\n            top: 0px;\\n            left: 0px;\\n            transform: rotate(-90deg);\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            max-width: 150px;\\n          }\\n          .additive-force-array-ylabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-hoverLine {\\n            stroke-width: 1px;\\n            stroke: #fff;\\n            opacity: 1;\\n          }\"}}),e.createElement(\"select\",{className:\"additive-force-array-xlabel\"}),e.createElement(\"div\",{style:{height:\"0px\",textAlign:\"left\"}},e.createElement(\"select\",{className:\"additive-force-array-ylabel\"})),e.createElement(\"svg\",{ref:function(e){return t.svg=Jt(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}}))}}])&&Xa(n.prototype,r),Object.defineProperty(n,\"prototype\",{writable:!1}),u}(e.Component);ni.defaultProps={plot_cmap:\"RdBu\",ordering_keys:null,ordering_keys_time_format:null};const ri=ni;window.SHAP={SimpleListVisualizer:He,AdditiveForceVisualizer:Ln,AdditiveForceArrayVisualizer:ri,React:e,ReactDom:t}})()})();\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d9b93",
   "metadata": {},
   "source": [
    "En primer lugar calculamos los Shap Valus y el Explainer. \n",
    "Los SHAP values nos permitirán entender cómo cada variable contribuye a la salida del modelo. \n",
    "El explainer encapsula el modelo entrenado y los datos para calcular los SHAP values de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb18e867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n"
     ]
    }
   ],
   "source": [
    "# Calcular SHAP values y el explainer\n",
    "explainer = shap.TreeExplainer(best_lgbm_model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b07d3f",
   "metadata": {},
   "source": [
    "#### Bloque 1: Visualizar el gráfico de explicación de SHAP para la primera predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cbf35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='iJYTLNS4ZBX6Z5E8OH8ZJ'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 3.070905504727836, \"outValue\": 2.6216288205147533, \"link\": \"identity\", \"featureNames\": [\"device_os_1\", \"phone_mobile_valid\", \"device_os_3\", \"zip_count_4w\", \"foreign_request\", \"has_other_cards\", \"proposed_credit_limit\", \"income\", \"keep_alive_session\", \"credit_risk_score\", \"name_email_similarity\", \"device_os_2\", \"bank_branch_count_8w\", \"phone_home_valid\", \"device_distinct_emails_8w\", \"employment_status\", \"email_is_free\", \"source_1\", \"housing_status\", \"customer_age\", \"income.1\", \"name_email_similarity.1\", \"days_since_request\", \"intended_balcon_amount\", \"date_of_birth_distinct_emails_4w\", \"housing_status.1\", \"current_address_months_count\", \"customer_age.1\", \"velocity_6h\", \"velocity_24h\", \"velocity_4w\", \"bank_branch_count_8w.1\", \"credit_risk_score.1\", \"bank_months_count\", \"proposed_credit_limit.1\", \"session_length_in_minutes\", \"zip_count_4w.1\", \"device_os_4\", \"device_os_5\", \"Quarter\"], \"features\": {\"0\": {\"effect\": -0.6615375509276002, \"value\": 1.0}, \"1\": {\"effect\": 0.025368290444493697, \"value\": 1.0}, \"2\": {\"effect\": -0.07000898625268923, \"value\": 0.0}, \"3\": {\"effect\": 0.029386359853242096, \"value\": -0.4075021073002325}, \"4\": {\"effect\": 0.0151450787768381, \"value\": 0.0}, \"5\": {\"effect\": -0.22644178852907948, \"value\": 0.0}, \"6\": {\"effect\": 0.018448743774828302, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.4301464376913712, \"value\": 0.9}, \"8\": {\"effect\": 0.37923387858393326, \"value\": 1.0}, \"9\": {\"effect\": 0.0764913014104218, \"value\": 0.4593798568033352}, \"10\": {\"effect\": 0.11593108406500414, \"value\": 0.6856554268961795}, \"11\": {\"effect\": -0.04042459402667802, \"value\": 0.0}, \"12\": {\"effect\": 0.07047007524013078, \"value\": 2.6165632666334875}, \"13\": {\"effect\": -0.4270942326728598, \"value\": 0.0}, \"14\": {\"effect\": 0.03473432041759707, \"value\": 1.0}, \"15\": {\"effect\": -0.12067790766084965, \"value\": 1.0}, \"16\": {\"effect\": -0.18296471696544364, \"value\": 1.0}, \"17\": {\"effect\": 0.0015875410713940376, \"value\": 1.0}, \"18\": {\"effect\": 0.06876333326501381, \"value\": 3.0}, \"19\": {\"effect\": 0.032569403880986746, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.0547145050800425, \"value\": 0.9}, \"21\": {\"effect\": 0.04254127113604579, \"value\": 0.6856554268961795}, \"22\": {\"effect\": -0.21747592382787387, \"value\": 0.0016699051740797}, \"23\": {\"effect\": -0.23652435269910896, \"value\": -1.2430695783155217}, \"24\": {\"effect\": 0.11504818176757405, \"value\": 16.0}, \"25\": {\"effect\": 0.1809582168017767, \"value\": 3.0}, \"26\": {\"effect\": 1.0015110266816352, \"value\": -0.9002484837181745}, \"27\": {\"effect\": 0.038572936107956306, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.052493774751496546, \"value\": -0.1354705137441912}, \"29\": {\"effect\": -0.17452811264489418, \"value\": 0.9399965621820896}, \"30\": {\"effect\": -0.03098767212368277, \"value\": 1.2427886833583188}, \"31\": {\"effect\": -0.061378550331769095, \"value\": 2.6165632666334875}, \"32\": {\"effect\": 0.01429776098820523, \"value\": 0.4593798568033352}, \"33\": {\"effect\": 0.04718997047834408, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.026742924207438023, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.22522202697734117, \"value\": 1.1419672816197566}, \"36\": {\"effect\": 0.0056020653054994745, \"value\": -0.4075021073002325}, \"37\": {\"effect\": 0.013759292345493031, \"value\": 0.0}, \"38\": {\"effect\": 0.0036510422528234147, \"value\": 0.0}, \"39\": {\"effect\": 0.008382144553215844, \"value\": 1.0}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n",
       "    document.getElementById('iJYTLNS4ZBX6Z5E8OH8ZJ')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<shap.plots._force.AdditiveForceVisualizer at 0x2df91a511c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], X_test.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e9751",
   "metadata": {},
   "source": [
    "El gráfico anterior nos proporciona una descomposición visual de cómo cada característica específica contribuye a la predicción del modelo para la primera instancia del dataframe. Observamos la dirección y magnitud de la contribución de cada característica para entender mejor cómo el modelo está tomando decisiones para esa observación en particular. \n",
    "\n",
    "En rojo podemos destacar que:\n",
    "- Housing_status: Tiene un impacto positivo en la predicción. Un valor de 3 en esta característica aumenta la predicción del modelo.\n",
    "- keep_alive_session: Su valor de 1 contribuye positivamente a la predicción.\n",
    "- Current_address_months_count: Su valor de -0.9002 tiene un impacto negativo en la predicción. A medida que este valor aumenta, la predicción tiende a disminuir.\n",
    "\n",
    "En el centro  de nuestro gráfico, el valor en negrita, 2.46, representa la predicción base del modelo antes de considerar las características específicas. La suma de las contribuciones de todas las características más este valor debería dar la predicción final del modelo para esta instancia.\n",
    "\n",
    "Por otro lado, a partir de los datos reflejados en azul concluimos que:\n",
    "- device_os_1: Un valor de 1 contribuye positivamente a la predicción.\n",
    "- income: Su valor de 0.9 tiene un impacto positivo en la predicción.\n",
    "- phone_home_valid: Un valor de 0 contribuye negativamente a la predicción.\n",
    "- intended_balcom_amount: Su valor de -1.243 tiene un impacto negativo en la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a722faa",
   "metadata": {},
   "source": [
    "#### Bloque 2: Visualizar SHAP force plot para una muestra de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe020c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='i4MMFPTMF44OUZMIOHU0R'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceArrayVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 3.070905504727836, \"link\": \"identity\", \"featureNames\": [\"device_os_1\", \"phone_mobile_valid\", \"device_os_3\", \"zip_count_4w\", \"foreign_request\", \"has_other_cards\", \"proposed_credit_limit\", \"income\", \"keep_alive_session\", \"credit_risk_score\", \"name_email_similarity\", \"device_os_2\", \"bank_branch_count_8w\", \"phone_home_valid\", \"device_distinct_emails_8w\", \"employment_status\", \"email_is_free\", \"source_1\", \"housing_status\", \"customer_age\", \"income.1\", \"name_email_similarity.1\", \"days_since_request\", \"intended_balcon_amount\", \"date_of_birth_distinct_emails_4w\", \"housing_status.1\", \"current_address_months_count\", \"customer_age.1\", \"velocity_6h\", \"velocity_24h\", \"velocity_4w\", \"bank_branch_count_8w.1\", \"credit_risk_score.1\", \"bank_months_count\", \"proposed_credit_limit.1\", \"session_length_in_minutes\", \"zip_count_4w.1\", \"device_os_4\", \"device_os_5\", \"Quarter\"], \"explanations\": [{\"outValue\": 2.6216288205147533, \"simIndex\": 21.0, \"features\": {\"0\": {\"effect\": -0.6615375509276002, \"value\": 1.0}, \"1\": {\"effect\": 0.025368290444493697, \"value\": 1.0}, \"2\": {\"effect\": -0.07000898625268923, \"value\": 0.0}, \"3\": {\"effect\": 0.029386359853242096, \"value\": -0.4075021073002325}, \"4\": {\"effect\": 0.0151450787768381, \"value\": 0.0}, \"5\": {\"effect\": -0.22644178852907948, \"value\": 0.0}, \"6\": {\"effect\": 0.018448743774828302, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.4301464376913712, \"value\": 0.9}, \"8\": {\"effect\": 0.37923387858393326, \"value\": 1.0}, \"9\": {\"effect\": 0.0764913014104218, \"value\": 0.4593798568033352}, \"10\": {\"effect\": 0.11593108406500414, \"value\": 0.6856554268961795}, \"11\": {\"effect\": -0.04042459402667802, \"value\": 0.0}, \"12\": {\"effect\": 0.07047007524013078, \"value\": 2.6165632666334875}, \"13\": {\"effect\": -0.4270942326728598, \"value\": 0.0}, \"14\": {\"effect\": 0.03473432041759707, \"value\": 1.0}, \"15\": {\"effect\": -0.12067790766084965, \"value\": 1.0}, \"16\": {\"effect\": -0.18296471696544364, \"value\": 1.0}, \"17\": {\"effect\": 0.0015875410713940376, \"value\": 1.0}, \"18\": {\"effect\": 0.06876333326501381, \"value\": 3.0}, \"19\": {\"effect\": 0.032569403880986746, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.0547145050800425, \"value\": 0.9}, \"21\": {\"effect\": 0.04254127113604579, \"value\": 0.6856554268961795}, \"22\": {\"effect\": -0.21747592382787387, \"value\": 0.0016699051740797}, \"23\": {\"effect\": -0.23652435269910896, \"value\": -1.2430695783155217}, \"24\": {\"effect\": 0.11504818176757405, \"value\": 16.0}, \"25\": {\"effect\": 0.1809582168017767, \"value\": 3.0}, \"26\": {\"effect\": 1.0015110266816352, \"value\": -0.9002484837181745}, \"27\": {\"effect\": 0.038572936107956306, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.052493774751496546, \"value\": -0.1354705137441912}, \"29\": {\"effect\": -0.17452811264489418, \"value\": 0.9399965621820896}, \"30\": {\"effect\": -0.03098767212368277, \"value\": 1.2427886833583188}, \"31\": {\"effect\": -0.061378550331769095, \"value\": 2.6165632666334875}, \"32\": {\"effect\": 0.01429776098820523, \"value\": 0.4593798568033352}, \"33\": {\"effect\": 0.04718997047834408, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.026742924207438023, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.22522202697734117, \"value\": 1.1419672816197566}, \"36\": {\"effect\": 0.0056020653054994745, \"value\": -0.4075021073002325}, \"37\": {\"effect\": 0.013759292345493031, \"value\": 0.0}, \"38\": {\"effect\": 0.0036510422528234147, \"value\": 0.0}, \"39\": {\"effect\": 0.008382144553215844, \"value\": 1.0}}}, {\"outValue\": 5.943180122189693, \"simIndex\": 36.0, \"features\": {\"0\": {\"effect\": -0.6878720216611515, \"value\": 1.0}, \"1\": {\"effect\": 0.02857444068634074, \"value\": 1.0}, \"2\": {\"effect\": -0.12880084380318285, \"value\": 0.0}, \"3\": {\"effect\": 0.012441831647972853, \"value\": 1.110340909809809}, \"4\": {\"effect\": 0.008583255805153456, \"value\": 0.0}, \"5\": {\"effect\": 0.7669670032230745, \"value\": 1.0}, \"6\": {\"effect\": 0.04719799837524873, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.09559482038144218, \"value\": 0.8}, \"8\": {\"effect\": -0.22127342995408988, \"value\": 0.0}, \"9\": {\"effect\": 0.1296126837053451, \"value\": -0.4734321676686074}, \"10\": {\"effect\": 0.2645967655144558, \"value\": 0.5864158853783172}, \"11\": {\"effect\": -0.02534251606844495, \"value\": 0.0}, \"12\": {\"effect\": 0.27227332820317895, \"value\": 3.034295023085665}, \"13\": {\"effect\": 0.5623018242530772, \"value\": 1.0}, \"14\": {\"effect\": 0.03877598872247146, \"value\": 1.0}, \"15\": {\"effect\": 0.05872621165789595, \"value\": 2.0}, \"16\": {\"effect\": 0.35635458068521125, \"value\": 0.0}, \"17\": {\"effect\": 0.0016409836416803741, \"value\": 1.0}, \"18\": {\"effect\": 0.31550232656904703, \"value\": 5.0}, \"19\": {\"effect\": 0.0968951552409159, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.042643526927184865, \"value\": 0.8}, \"21\": {\"effect\": 0.027172858099086507, \"value\": 0.5864158853783172}, \"22\": {\"effect\": 0.1609699627870788, \"value\": 0.0203682750751534}, \"23\": {\"effect\": 0.47516478858165256, \"value\": 32.65823955805774}, \"24\": {\"effect\": -0.01813203976719094, \"value\": 9.0}, \"25\": {\"effect\": 0.10690252718188098, \"value\": 5.0}, \"26\": {\"effect\": -0.49899468601406743, \"value\": -0.1763202628756286}, \"27\": {\"effect\": 0.008609538372742889, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.06354351047954312, \"value\": -0.4741080800747136}, \"29\": {\"effect\": 0.12459041325752758, \"value\": -1.2107590942183302}, \"30\": {\"effect\": 0.20319508409863007, \"value\": -0.6056502353071074}, \"31\": {\"effect\": 0.11997699851131761, \"value\": 3.034295023085665}, \"32\": {\"effect\": 0.10567636697212437, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.18614051772277942, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.009438808023518418, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10506425731471723, \"value\": 0.9733763053573278}, \"36\": {\"effect\": -0.02293911859086728, \"value\": 1.110340909809809}, \"37\": {\"effect\": 0.018668732570021003, \"value\": 0.0}, \"38\": {\"effect\": 0.0015727891889162856, \"value\": 0.0}, \"39\": {\"effect\": 0.146864604166307, \"value\": 2.0}}}, {\"outValue\": 2.3983650531770024, \"simIndex\": 22.0, \"features\": {\"0\": {\"effect\": -0.7665815887612124, \"value\": 1.0}, \"1\": {\"effect\": -0.20677859664609047, \"value\": 0.0}, \"2\": {\"effect\": -0.08279922769780258, \"value\": 0.0}, \"3\": {\"effect\": -0.05909152307794504, \"value\": -0.0633515935911406}, \"4\": {\"effect\": 0.006385578562284432, \"value\": 0.0}, \"5\": {\"effect\": -0.22345388942048083, \"value\": 0.0}, \"6\": {\"effect\": 0.050581216754279755, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.5444045111895335, \"value\": 0.9}, \"8\": {\"effect\": 0.3354956961080702, \"value\": 1.0}, \"9\": {\"effect\": 0.15343818308825083, \"value\": -1.0187684281291278}, \"10\": {\"effect\": 0.13170993540509054, \"value\": 0.6939282538872338}, \"11\": {\"effect\": -0.07705529104645666, \"value\": 0.0}, \"12\": {\"effect\": -0.2708774287992774, \"value\": -0.4011135364871937}, \"13\": {\"effect\": -0.3718742198860907, \"value\": 0.0}, \"14\": {\"effect\": 0.03314648540640795, \"value\": 1.0}, \"15\": {\"effect\": -0.17940916255571457, \"value\": 1.0}, \"16\": {\"effect\": -0.23649292554657292, \"value\": 1.0}, \"17\": {\"effect\": 0.0013955891470439454, \"value\": 1.0}, \"18\": {\"effect\": 0.08485545806160677, \"value\": 3.0}, \"19\": {\"effect\": 0.17309526110213852, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.05030888186974219, \"value\": 0.9}, \"21\": {\"effect\": 0.03338753467964999, \"value\": 0.6939282538872338}, \"22\": {\"effect\": -0.06853324342969977, \"value\": 0.0160169916138557}, \"23\": {\"effect\": -0.10325233766415616, \"value\": -0.7146321080917919}, \"24\": {\"effect\": 0.04318724367405101, \"value\": 12.0}, \"25\": {\"effect\": 0.15942875052979866, \"value\": 3.0}, \"26\": {\"effect\": 0.9816863163785451, \"value\": -0.9002484837181745}, \"27\": {\"effect\": 0.07026769185315745, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.008019607459754191, \"value\": -0.6238535729053909}, \"29\": {\"effect\": 0.12484705074690074, \"value\": -1.018649548123965}, \"30\": {\"effect\": 0.018741667009569897, \"value\": 0.0033769572989511}, \"31\": {\"effect\": -0.05614538635010684, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.057101104105294724, \"value\": -1.0187684281291278}, \"33\": {\"effect\": -0.14848342789962551, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.020429616209312718, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.059290521536819435, \"value\": -0.7568770886196635}, \"36\": {\"effect\": -0.0030944273040005724, \"value\": -0.0633515935911406}, \"37\": {\"effect\": 0.01999428043652539, \"value\": 0.0}, \"38\": {\"effect\": 0.001324304153581377, \"value\": 0.0}, \"39\": {\"effect\": 0.22432574010504902, \"value\": 2.0}}}, {\"outValue\": 4.145484504839985, \"simIndex\": 2.0, \"features\": {\"0\": {\"effect\": 0.3820429269739797, \"value\": 0.0}, \"1\": {\"effect\": -0.02175624539622577, \"value\": 0.0}, \"2\": {\"effect\": 0.21395407847373865, \"value\": 1.0}, \"3\": {\"effect\": -0.10151456998201827, \"value\": 0.0778893686825329}, \"4\": {\"effect\": 0.009529559927870005, \"value\": 0.0}, \"5\": {\"effect\": -0.22951675956063314, \"value\": 0.0}, \"6\": {\"effect\": 0.03597467318953394, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.05279365007505767, \"value\": 0.8}, \"8\": {\"effect\": 0.2804787911119678, \"value\": 1.0}, \"9\": {\"effect\": 0.0348657439294654, \"value\": -0.5882398014497696}, \"10\": {\"effect\": -0.42254798531803806, \"value\": 0.0495588250970678}, \"11\": {\"effect\": -0.02437525618741484, \"value\": 0.0}, \"12\": {\"effect\": 0.6282508923343872, \"value\": 1.0130825140019502}, \"13\": {\"effect\": 0.6098729289651106, \"value\": 1.0}, \"14\": {\"effect\": 0.029296384403748394, \"value\": 1.0}, \"15\": {\"effect\": -0.11343832269667692, \"value\": 1.0}, \"16\": {\"effect\": 0.26999372227294177, \"value\": 0.0}, \"17\": {\"effect\": 0.0006801315810963772, \"value\": 1.0}, \"18\": {\"effect\": -0.6153801042475957, \"value\": 1.0}, \"19\": {\"effect\": -0.22568927104539455, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.02651931811751071, \"value\": 0.8}, \"21\": {\"effect\": -0.14648684270049692, \"value\": 0.0495588250970678}, \"22\": {\"effect\": 0.14092867943848988, \"value\": 0.0250427132599829}, \"23\": {\"effect\": 0.525281587322417, \"value\": 37.515167939581296}, \"24\": {\"effect\": 0.024280105597086356, \"value\": 6.0}, \"25\": {\"effect\": -0.44861257249184716, \"value\": 1.0}, \"26\": {\"effect\": -0.2093974910923839, \"value\": -0.4591047241422481}, \"27\": {\"effect\": -0.008994734339564492, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.04660362976863417, \"value\": 0.9762451094717016}, \"29\": {\"effect\": -0.13971753659362102, \"value\": 0.5782812646074298}, \"30\": {\"effect\": 0.16371805740706913, \"value\": 0.2413228424050724}, \"31\": {\"effect\": 0.07114815870834526, \"value\": 1.0130825140019502}, \"32\": {\"effect\": 0.016132342956007482, \"value\": -0.5882398014497696}, \"33\": {\"effect\": 0.13881184014077988, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.009117888918373725, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.04153256208093657, \"value\": -0.7203189735514977}, \"36\": {\"effect\": -0.003395081262549115, \"value\": 0.0778893686825329}, \"37\": {\"effect\": 0.03428213133728123, \"value\": 0.0}, \"38\": {\"effect\": 0.003644173426691722, \"value\": 0.0}, \"39\": {\"effect\": 0.23735887511509823, \"value\": 2.0}}}, {\"outValue\": 6.64085812487311, \"simIndex\": 84.0, \"features\": {\"0\": {\"effect\": 0.23557822580328744, \"value\": 0.0}, \"1\": {\"effect\": 0.0044098039200086165, \"value\": 1.0}, \"2\": {\"effect\": 0.26290483463325265, \"value\": 1.0}, \"3\": {\"effect\": 0.13108638455628974, \"value\": -0.5348179042793186}, \"4\": {\"effect\": 0.0070168647493354325, \"value\": 0.0}, \"5\": {\"effect\": -0.16873287567337544, \"value\": 0.0}, \"6\": {\"effect\": -0.015049669136965278, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.12542535067734073, \"value\": 0.5}, \"8\": {\"effect\": -0.3545628969172915, \"value\": 0.0}, \"9\": {\"effect\": 0.21097649554214262, \"value\": -0.1577111747704115}, \"10\": {\"effect\": 0.17502460710670417, \"value\": 0.8337016071237345}, \"11\": {\"effect\": -0.012687979670271595, \"value\": 0.0}, \"12\": {\"effect\": 0.5663809496977185, \"value\": 1.1022856494943425}, \"13\": {\"effect\": 0.5947652803420332, \"value\": 1.0}, \"14\": {\"effect\": 0.03431956250497471, \"value\": 1.0}, \"15\": {\"effect\": 0.17647469053170195, \"value\": 2.0}, \"16\": {\"effect\": -0.27971748183065925, \"value\": 1.0}, \"17\": {\"effect\": 0.0004045960808986138, \"value\": 1.0}, \"18\": {\"effect\": 0.39612259549907247, \"value\": 5.0}, \"19\": {\"effect\": 0.18000727936761596, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.02275562708105952, \"value\": 0.5}, \"21\": {\"effect\": 0.04803356084374975, \"value\": 0.8337016071237345}, \"22\": {\"effect\": 0.0890272558496697, \"value\": 0.0236147601720055}, \"23\": {\"effect\": 0.8125638357440382, \"value\": 51.64520390800454}, \"24\": {\"effect\": 0.19935692983371908, \"value\": 19.0}, \"25\": {\"effect\": 0.13093275836820314, \"value\": 5.0}, \"26\": {\"effect\": -0.18548379784314611, \"value\": 0.7512127700788831}, \"27\": {\"effect\": 0.042905762856315637, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.12964587113489345, \"value\": -0.9997823221419488}, \"29\": {\"effect\": 0.02737950701964694, \"value\": -0.3609033256730699}, \"30\": {\"effect\": 0.23215819934307064, \"value\": 0.3498048243624359}, \"31\": {\"effect\": 0.0168038967977574, \"value\": 1.1022856494943425}, \"32\": {\"effect\": 0.055152537489344865, \"value\": -0.1577111747704115}, \"33\": {\"effect\": -0.002468427584815405, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0033718078107318255, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.2413532758796992, \"value\": 3.8462631806596153}, \"36\": {\"effect\": -0.01441589653605083, \"value\": -0.5348179042793186}, \"37\": {\"effect\": 0.035521293889752524, \"value\": 0.0}, \"38\": {\"effect\": 0.003043563039648262, \"value\": 0.0}, \"39\": {\"effect\": 0.15416673537335715, \"value\": 2.0}}}, {\"outValue\": 5.452336550760684, \"simIndex\": 24.0, \"features\": {\"0\": {\"effect\": -0.6669260222275878, \"value\": 1.0}, \"1\": {\"effect\": 0.01902844783461915, \"value\": 1.0}, \"2\": {\"effect\": -0.0797369575171517, \"value\": 0.0}, \"3\": {\"effect\": -0.09491445946028233, \"value\": 1.212790340191417}, \"4\": {\"effect\": 0.012197932679463803, \"value\": 0.0}, \"5\": {\"effect\": -0.26701748852280544, \"value\": 0.0}, \"6\": {\"effect\": 0.07079653713746925, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.10515828491538724, \"value\": 0.6000000000000001}, \"8\": {\"effect\": 0.2811820294146974, \"value\": 1.0}, \"9\": {\"effect\": 0.009170497885801258, \"value\": -0.7461002978988677}, \"10\": {\"effect\": 0.3855405960420013, \"value\": 0.8944699595268933}, \"11\": {\"effect\": -0.034279327055023824, \"value\": 0.0}, \"12\": {\"effect\": 0.392000388495829, \"value\": 1.1675562364399952}, \"13\": {\"effect\": -0.3836335828844138, \"value\": 0.0}, \"14\": {\"effect\": 0.030937440430226386, \"value\": 1.0}, \"15\": {\"effect\": -0.11606589395710125, \"value\": 1.0}, \"16\": {\"effect\": 0.3449452359448501, \"value\": 0.0}, \"17\": {\"effect\": 0.002854750377690734, \"value\": 1.0}, \"18\": {\"effect\": 0.1657691572265705, \"value\": 2.0}, \"19\": {\"effect\": 0.019483859958761295, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.006444638695165091, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.03428070930251125, \"value\": 0.8944699595268933}, \"22\": {\"effect\": 0.07425255991905216, \"value\": 0.0215584555359531}, \"23\": {\"effect\": -0.0006276927555007236, \"value\": -0.8974181827757686}, \"24\": {\"effect\": 0.07576728809099299, \"value\": 11.0}, \"25\": {\"effect\": 0.21219088303633574, \"value\": 2.0}, \"26\": {\"effect\": 1.0318719307284163, \"value\": -0.9002484837181745}, \"27\": {\"effect\": 0.01982793229950381, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.22789259512090027, \"value\": 3.198778042768652}, \"29\": {\"effect\": 0.1781179385898172, \"value\": -0.9531411725843202}, \"30\": {\"effect\": 0.044574612088978484, \"value\": 0.8254933384439148}, \"31\": {\"effect\": 0.11891896945401591, \"value\": 1.1675562364399952}, \"32\": {\"effect\": 0.012948367317875804, \"value\": -0.7461002978988677}, \"33\": {\"effect\": 0.048658633333506854, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0014187692103310614, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.08925258156929802, \"value\": -0.1312981025230191}, \"36\": {\"effect\": -0.023285758963106192, \"value\": 1.212790340191417}, \"37\": {\"effect\": 0.024537110855263243, \"value\": 0.0}, \"38\": {\"effect\": 0.0039671782138457875, \"value\": 0.0}, \"39\": {\"effect\": 0.003930373206643787, \"value\": 1.0}}}, {\"outValue\": 3.8854274448588253, \"simIndex\": 81.0, \"features\": {\"0\": {\"effect\": 0.2729947957172044, \"value\": 0.0}, \"1\": {\"effect\": -0.1990541442438798, \"value\": 0.0}, \"2\": {\"effect\": 0.2976550539944597, \"value\": 1.0}, \"3\": {\"effect\": 0.121742909321844, \"value\": -0.0374905723297637}, \"4\": {\"effect\": 0.013209551060011494, \"value\": 0.0}, \"5\": {\"effect\": -0.16063192632623152, \"value\": 0.0}, \"6\": {\"effect\": 0.043218942247092135, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.25272709816441913, \"value\": 0.1}, \"8\": {\"effect\": -0.24400667066382267, \"value\": 0.0}, \"9\": {\"effect\": 0.14122206504840196, \"value\": -0.9900665196838372}, \"10\": {\"effect\": -0.5802310315695735, \"value\": 0.0466435703155568}, \"11\": {\"effect\": -0.014243997017370998, \"value\": 0.0}, \"12\": {\"effect\": -0.030117163002305474, \"value\": -0.3728296154774109}, \"13\": {\"effect\": 0.4050085181616486, \"value\": 1.0}, \"14\": {\"effect\": -0.9262708175089646, \"value\": 2.0}, \"15\": {\"effect\": 0.9160565867773061, \"value\": 6.0}, \"16\": {\"effect\": 0.3043835165591342, \"value\": 0.0}, \"17\": {\"effect\": 0.0006407099953658526, \"value\": 1.0}, \"18\": {\"effect\": 0.1071093914887685, \"value\": 2.0}, \"19\": {\"effect\": 0.17594686772679963, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.09075826730191554, \"value\": 0.1}, \"21\": {\"effect\": -0.10848798313921536, \"value\": 0.0466435703155568}, \"22\": {\"effect\": -0.0764792469346012, \"value\": 0.0064613662379056}, \"23\": {\"effect\": 0.03200001798846915, \"value\": -1.0220130928386315}, \"24\": {\"effect\": 0.07547871816104189, \"value\": 5.0}, \"25\": {\"effect\": 0.1413664683930523, \"value\": 2.0}, \"26\": {\"effect\": -0.44625211787413016, \"value\": 0.4910510657135932}, \"27\": {\"effect\": 0.031532140517681335, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.10678795446317417, \"value\": -0.8714890438564032}, \"29\": {\"effect\": -0.0358755616943915, \"value\": -0.1047944390672158}, \"30\": {\"effect\": 0.10855513195446366, \"value\": -0.0639249168726184}, \"31\": {\"effect\": 0.01781629617888332, \"value\": -0.3728296154774109}, \"32\": {\"effect\": 0.02630665863461264, \"value\": -0.9900665196838372}, \"33\": {\"effect\": -0.19677511228525574, \"value\": 1.16867629926286}, \"34\": {\"effect\": 0.0075280579933883415, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.18207795286743766, \"value\": -0.1702690453675851}, \"36\": {\"effect\": -0.02201390102739146, \"value\": -0.0374905723297637}, \"37\": {\"effect\": 0.033256046214916346, \"value\": 0.0}, \"38\": {\"effect\": 0.004351198674049666, \"value\": 0.0}, \"39\": {\"effect\": 0.30938660354745673, \"value\": 2.0}}}, {\"outValue\": 5.293052648105007, \"simIndex\": 39.0, \"features\": {\"0\": {\"effect\": 0.3064113999514481, \"value\": 0.0}, \"1\": {\"effect\": 0.007706440226911006, \"value\": 1.0}, \"2\": {\"effect\": 0.14664259579460798, \"value\": 1.0}, \"3\": {\"effect\": -0.1329629500254198, \"value\": 0.0221887075041828}, \"4\": {\"effect\": 0.010178473415867856, \"value\": 0.0}, \"5\": {\"effect\": 1.0305756278788594, \"value\": 1.0}, \"6\": {\"effect\": 0.0201174229125292, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.059918093462789486, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.339156587543416, \"value\": 1.0}, \"9\": {\"effect\": -0.07036125116885461, \"value\": -0.4447302592233169}, \"10\": {\"effect\": -0.4026369203892092, \"value\": 0.0977001258376673}, \"11\": {\"effect\": -0.03720853723539651, \"value\": 0.0}, \"12\": {\"effect\": 0.21262962090563464, \"value\": -0.3902351053295849}, \"13\": {\"effect\": -0.3272534022373264, \"value\": 0.0}, \"14\": {\"effect\": 0.039310942866661314, \"value\": 1.0}, \"15\": {\"effect\": -0.06642987268285311, \"value\": 1.0}, \"16\": {\"effect\": -0.28056420523570835, \"value\": 1.0}, \"17\": {\"effect\": 0.0009012510594239022, \"value\": 1.0}, \"18\": {\"effect\": 0.0475663387583775, \"value\": 3.0}, \"19\": {\"effect\": 0.01272222227551769, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.019494394929358835, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.06480728588643045, \"value\": 0.0977001258376673}, \"22\": {\"effect\": -0.014802951480933461, \"value\": 0.0047335908760908}, \"23\": {\"effect\": 0.4387706829838137, \"value\": 31.617091705598607}, \"24\": {\"effect\": 0.1374956057304153, \"value\": 14.0}, \"25\": {\"effect\": 0.13743889945169735, \"value\": 3.0}, \"26\": {\"effect\": 0.46293730302408004, \"value\": -0.6740209147048789}, \"27\": {\"effect\": 0.0007024668350845192, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.11066392266770973, \"value\": 0.4201378625824888}, \"29\": {\"effect\": -0.005859698038819386, \"value\": 0.4099242472828535}, \"30\": {\"effect\": -0.2520625264593237, \"value\": 1.655008450708043}, \"31\": {\"effect\": 0.015513188869884701, \"value\": -0.3902351053295849}, \"32\": {\"effect\": 0.023394276623269403, \"value\": -0.4447302592233169}, \"33\": {\"effect\": 0.1658948970065656, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.010232651140415988, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.09432885634347034, \"value\": -0.0392684501024257}, \"36\": {\"effect\": 0.0088906169198127, \"value\": 0.0221887075041828}, \"37\": {\"effect\": 0.02480619610512039, \"value\": 0.0}, \"38\": {\"effect\": 0.002480701789046873, \"value\": 0.0}, \"39\": {\"effect\": 0.029203856604373666, \"value\": 1.0}}}, {\"outValue\": 2.3955733194901994, \"simIndex\": 34.0, \"features\": {\"0\": {\"effect\": -0.9232925419072878, \"value\": 1.0}, \"1\": {\"effect\": 0.020951251361288177, \"value\": 1.0}, \"2\": {\"effect\": -0.1000590881610822, \"value\": 0.0}, \"3\": {\"effect\": -0.01176065567123249, \"value\": -0.4264005459143156}, \"4\": {\"effect\": 0.015483167328106269, \"value\": 0.0}, \"5\": {\"effect\": 0.8762689647495077, \"value\": 1.0}, \"6\": {\"effect\": 0.0989213527340365, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.029760917840159017, \"value\": 0.8}, \"8\": {\"effect\": -0.23969453436272484, \"value\": 0.0}, \"9\": {\"effect\": -0.3675730045716419, \"value\": 1.980581004403734}, \"10\": {\"effect\": -0.5505187595481827, \"value\": 0.0753160294910908}, \"11\": {\"effect\": -0.026624320557955564, \"value\": 0.0}, \"12\": {\"effect\": 0.5146677378596075, \"value\": 0.8107436944704265}, \"13\": {\"effect\": -0.28710110584862736, \"value\": 0.0}, \"14\": {\"effect\": 0.03273863207680292, \"value\": 1.0}, \"15\": {\"effect\": -0.10546258897730734, \"value\": 1.0}, \"16\": {\"effect\": -0.3188574483463526, \"value\": 1.0}, \"17\": {\"effect\": 0.0007604932517593038, \"value\": 1.0}, \"18\": {\"effect\": 0.27150074348776587, \"value\": 5.0}, \"19\": {\"effect\": -0.254794748401807, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.04301238548222469, \"value\": 0.8}, \"21\": {\"effect\": -0.16295852566803193, \"value\": 0.0753160294910908}, \"22\": {\"effect\": 0.2965010611492403, \"value\": 0.0327785659676142}, \"23\": {\"effect\": 0.5642600206649064, \"value\": 50.041832936682816}, \"24\": {\"effect\": 0.14038970134351975, \"value\": 21.0}, \"25\": {\"effect\": 0.17514824843666335, \"value\": 5.0}, \"26\": {\"effect\": -0.47293180494329545, \"value\": -0.4477933456915833}, \"27\": {\"effect\": 0.03308274412901371, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.008774776282120913, \"value\": -1.4660513343453423}, \"29\": {\"effect\": -0.24440184603099901, \"value\": 0.6994235142830543}, \"30\": {\"effect\": 0.08829626077893735, \"value\": -0.663736109927928}, \"31\": {\"effect\": 0.17231000221289355, \"value\": 0.8107436944704265}, \"32\": {\"effect\": -0.19576967719057697, \"value\": 1.980581004403734}, \"33\": {\"effect\": 0.23184343270440347, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.01732780146286748, \"value\": 0.9930046138595}, \"35\": {\"effect\": 0.034029965761178886, \"value\": -0.2406363475387151}, \"36\": {\"effect\": -0.011688843176762925, \"value\": -0.4264005459143156}, \"37\": {\"effect\": 0.019099156484256846, \"value\": 0.0}, \"38\": {\"effect\": 0.003980094215777597, \"value\": 0.0}, \"39\": {\"effect\": 0.07214455553820281, \"value\": 2.0}}}, {\"outValue\": 5.222283592228172, \"simIndex\": 47.0, \"features\": {\"0\": {\"effect\": 0.29384014471866626, \"value\": 0.0}, \"1\": {\"effect\": 0.01688265433966751, \"value\": 1.0}, \"2\": {\"effect\": -0.07412550515161163, \"value\": 0.0}, \"3\": {\"effect\": 0.07520480700195703, \"value\": -0.6860054131919833}, \"4\": {\"effect\": 0.010123964594061423, \"value\": 0.0}, \"5\": {\"effect\": 0.7585393656239655, \"value\": 1.0}, \"6\": {\"effect\": 0.1486189725192095, \"value\": 0.9930046138595}, \"7\": {\"effect\": 0.0679559232683702, \"value\": 0.6000000000000001}, \"8\": {\"effect\": 0.2990195042052138, \"value\": 1.0}, \"9\": {\"effect\": 0.1719236778640034, \"value\": -0.0572544952118945}, \"10\": {\"effect\": 0.20259642049389698, \"value\": 0.6562182655974945}, \"11\": {\"effect\": 0.06057223544135094, \"value\": 1.0}, \"12\": {\"effect\": -0.22639898210665974, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.3644059547150018, \"value\": 0.0}, \"14\": {\"effect\": 0.04225944946396836, \"value\": 1.0}, \"15\": {\"effect\": -0.11022274845233686, \"value\": 1.0}, \"16\": {\"effect\": -0.3022389814253671, \"value\": 1.0}, \"17\": {\"effect\": 0.00011858979865693579, \"value\": 1.0}, \"18\": {\"effect\": 0.33056041293894717, \"value\": 5.0}, \"19\": {\"effect\": 0.024013834907822842, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.010193274844240622, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.05436605449423515, \"value\": 0.6562182655974945}, \"22\": {\"effect\": 0.048726542437439076, \"value\": 0.0255387773784521}, \"23\": {\"effect\": 0.311628610979318, \"value\": 17.875403274061945}, \"24\": {\"effect\": 0.1370061473751195, \"value\": 12.0}, \"25\": {\"effect\": 0.12787939245092841, \"value\": 5.0}, \"26\": {\"effect\": -0.7146631961357647, \"value\": 0.2761348751509624}, \"27\": {\"effect\": -0.0027998829347016707, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.012752316167179291, \"value\": -0.966972289947756}, \"29\": {\"effect\": -0.014396526095938689, \"value\": -0.3271617660539367}, \"30\": {\"effect\": 0.14909178486654523, \"value\": -0.5193945352402696}, \"31\": {\"effect\": -0.059927589060740985, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.02052858253358312, \"value\": -0.0572544952118945}, \"33\": {\"effect\": 0.19636432633346432, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.005594908560997484, \"value\": 0.9930046138595}, \"35\": {\"effect\": 0.3429370958210143, \"value\": 0.5186412913484967}, \"36\": {\"effect\": 0.015788398449036557, \"value\": -0.6860054131919833}, \"37\": {\"effect\": 0.034007203090672164, \"value\": 0.0}, \"38\": {\"effect\": 0.0019192163399513883, \"value\": 0.0}, \"39\": {\"effect\": 0.07504827398933546, \"value\": 2.0}}}, {\"outValue\": 4.181685891574104, \"simIndex\": 17.0, \"features\": {\"0\": {\"effect\": 0.3187110333641634, \"value\": 0.0}, \"1\": {\"effect\": -0.202546879930925, \"value\": 0.0}, \"2\": {\"effect\": -0.07305429870705635, \"value\": 0.0}, \"3\": {\"effect\": 0.10509689976828364, \"value\": 2.1895412201403426}, \"4\": {\"effect\": 0.013859143500415812, \"value\": 0.0}, \"5\": {\"effect\": -0.09369110180856037, \"value\": 0.0}, \"6\": {\"effect\": 0.08035694238591332, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.3412279813197677, \"value\": 0.1}, \"8\": {\"effect\": -0.2964770265443173, \"value\": 0.0}, \"9\": {\"effect\": -0.049329887199255205, \"value\": -0.6312926641177055}, \"10\": {\"effect\": -0.37071369249819686, \"value\": 0.09662365265163}, \"11\": {\"effect\": 0.0950488329621027, \"value\": 1.0}, \"12\": {\"effect\": 0.11065131511022767, \"value\": -0.3858837328665414}, \"13\": {\"effect\": 0.6602683617736365, \"value\": 1.0}, \"14\": {\"effect\": 0.046554055283098035, \"value\": 1.0}, \"15\": {\"effect\": -0.15615183346560385, \"value\": 1.0}, \"16\": {\"effect\": 0.4886277009702347, \"value\": 0.0}, \"17\": {\"effect\": 0.0012470131775556214, \"value\": 1.0}, \"18\": {\"effect\": -0.45008094778786, \"value\": 1.0}, \"19\": {\"effect\": 0.04848065847705176, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.07535000531622944, \"value\": 0.1}, \"21\": {\"effect\": -0.11268628366272149, \"value\": 0.09662365265163}, \"22\": {\"effect\": 0.42540723041726375, \"value\": 0.032733260813103}, \"23\": {\"effect\": -0.2035812643742326, \"value\": -1.548627685484825}, \"24\": {\"effect\": -0.10710585936255887, \"value\": 8.0}, \"25\": {\"effect\": -0.47026503291448, \"value\": 1.0}, \"26\": {\"effect\": 1.3179146007974571, \"value\": -0.979428132872828}, \"27\": {\"effect\": 0.028102387282993663, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.114810652256839, \"value\": 1.1928588302132612}, \"29\": {\"effect\": -0.19611745038300965, \"value\": 1.632914435864}, \"30\": {\"effect\": -0.16450205938445792, \"value\": -0.1375671741547335}, \"31\": {\"effect\": 0.02320734742148439, \"value\": -0.3858837328665414}, \"32\": {\"effect\": -0.03132352056030932, \"value\": -0.6312926641177055}, \"33\": {\"effect\": 0.06375799645045536, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.013107847231072578, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.12072668013795357, \"value\": -0.3858969490021638}, \"36\": {\"effect\": 0.14959866875758138, \"value\": 2.1895412201403426}, \"37\": {\"effect\": 0.04604186443614792, \"value\": 0.0}, \"38\": {\"effect\": 0.003856696718171115, \"value\": 0.0}, \"39\": {\"effect\": -0.13252972509670222, \"value\": 1.0}}}, {\"outValue\": 6.269645313505621, \"simIndex\": 13.0, \"features\": {\"0\": {\"effect\": 0.2575499423295589, \"value\": 0.0}, \"1\": {\"effect\": 0.03250796901791579, \"value\": 1.0}, \"2\": {\"effect\": 0.2832977879558777, \"value\": 1.0}, \"3\": {\"effect\": -0.10223425356652235, \"value\": 1.4594646968383964}, \"4\": {\"effect\": 0.01134344848001676, \"value\": 0.0}, \"5\": {\"effect\": -0.23601689783930932, \"value\": 0.0}, \"6\": {\"effect\": 0.059580734644183134, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.12721862945444418, \"value\": 0.8}, \"8\": {\"effect\": -0.3254905171109275, \"value\": 0.0}, \"9\": {\"effect\": 0.04779652511909227, \"value\": -0.8752588859026751}, \"10\": {\"effect\": 0.005237181129087447, \"value\": 0.4241876554038889}, \"11\": {\"effect\": -0.013107747585854054, \"value\": 0.0}, \"12\": {\"effect\": 0.014679114532746175, \"value\": -0.3358429495415409}, \"13\": {\"effect\": 0.4491812468029703, \"value\": 1.0}, \"14\": {\"effect\": 0.03808329794212867, \"value\": 1.0}, \"15\": {\"effect\": 0.6010878227209384, \"value\": 4.0}, \"16\": {\"effect\": 0.3731179428909415, \"value\": 0.0}, \"17\": {\"effect\": 0.0014396504399595046, \"value\": 1.0}, \"18\": {\"effect\": 0.19072328499166416, \"value\": 2.0}, \"19\": {\"effect\": 0.10488613611409243, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.022214936718287608, \"value\": 0.8}, \"21\": {\"effect\": 0.04061569065113685, \"value\": 0.4241876554038889}, \"22\": {\"effect\": -0.1160311437356788, \"value\": 14.24818593223887}, \"23\": {\"effect\": -0.09933159961912966, \"value\": -1.003362630172552}, \"24\": {\"effect\": 0.07053076154646765, \"value\": 7.0}, \"25\": {\"effect\": 0.12624407106055638, \"value\": 2.0}, \"26\": {\"effect\": 1.087022772276412, \"value\": -0.8776257268168449}, \"27\": {\"effect\": 0.008160547379225207, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.012058327161385742, \"value\": 0.6133349864800512}, \"29\": {\"effect\": -0.0690503911706524, \"value\": 0.2550155008997839}, \"30\": {\"effect\": 0.2269715673930339, \"value\": 0.333162279347529}, \"31\": {\"effect\": 0.04392029865491838, \"value\": -0.3358429495415409}, \"32\": {\"effect\": 0.0018023317371821282, \"value\": -0.8752588859026751}, \"33\": {\"effect\": -0.1884745618629238, \"value\": 1.4987945976101402}, \"34\": {\"effect\": 0.023101212888321145, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.09601876357344548, \"value\": -0.0347996479249416}, \"36\": {\"effect\": -0.003006455435350184, \"value\": 1.4594646968383964}, \"37\": {\"effect\": 0.0342938239147853, \"value\": 0.0}, \"38\": {\"effect\": 0.0027785980394952736, \"value\": 0.0}, \"39\": {\"effect\": 0.25688609148932606, \"value\": 2.0}}}, {\"outValue\": 3.709869947985396, \"simIndex\": 1.0, \"features\": {\"0\": {\"effect\": -0.6427963366017462, \"value\": 1.0}, \"1\": {\"effect\": 0.05220819709764282, \"value\": 1.0}, \"2\": {\"effect\": -0.08874887211745885, \"value\": 0.0}, \"3\": {\"effect\": 0.29993348685328464, \"value\": -0.4065074526363335}, \"4\": {\"effect\": 0.017955543784982788, \"value\": 0.0}, \"5\": {\"effect\": -0.16233543184319918, \"value\": 0.0}, \"6\": {\"effect\": -0.02162955241392743, \"value\": 2.01852014148613}, \"7\": {\"effect\": 0.07635340568120137, \"value\": 0.6000000000000001}, \"8\": {\"effect\": 0.3455923327274742, \"value\": 1.0}, \"9\": {\"effect\": -0.15172101068398558, \"value\": 1.6218071488376022}, \"10\": {\"effect\": -0.21672438689155477, \"value\": 0.226885714655147}, \"11\": {\"effect\": -0.01994755884068374, \"value\": 0.0}, \"12\": {\"effect\": 0.2838060686403161, \"value\": -0.3597754980882803}, \"13\": {\"effect\": 0.5914883275776213, \"value\": 1.0}, \"14\": {\"effect\": 0.0356747235309114, \"value\": 1.0}, \"15\": {\"effect\": -0.10734468379931132, \"value\": 1.0}, \"16\": {\"effect\": 0.39818421596107967, \"value\": 0.0}, \"17\": {\"effect\": 0.0010993443480185319, \"value\": 1.0}, \"18\": {\"effect\": -0.4775389899199682, \"value\": 1.0}, \"19\": {\"effect\": -0.13925405139557054, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.0065364050749786564, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.015143925065099935, \"value\": 0.226885714655147}, \"22\": {\"effect\": 0.04128189846026593, \"value\": 0.0181711151442754}, \"23\": {\"effect\": 1.366439046714669, \"value\": 106.59364547578468}, \"24\": {\"effect\": 0.07824727657748036, \"value\": 7.0}, \"25\": {\"effect\": -0.6692137315735371, \"value\": 1.0}, \"26\": {\"effect\": -0.0451668528284246, \"value\": 3.251027407675799}, \"27\": {\"effect\": -0.006468310860545659, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.16329617206671543, \"value\": 0.4805915247567988}, \"29\": {\"effect\": 0.04629782092946106, \"value\": -1.0229133503833792}, \"30\": {\"effect\": -0.43330121308249053, \"value\": -0.8313214238423839}, \"31\": {\"effect\": 0.06422924495993687, \"value\": -0.3597754980882803}, \"32\": {\"effect\": -0.06155446599033449, \"value\": 1.6218071488376022}, \"33\": {\"effect\": 0.1401585807823334, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.015432940996152769, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.08911178999093165, \"value\": -0.5382733385047538}, \"36\": {\"effect\": 0.024462835732759928, \"value\": -0.4065074526363335}, \"37\": {\"effect\": 0.021260707633011546, \"value\": 0.0}, \"38\": {\"effect\": 0.001503109492468048, \"value\": 0.0}, \"39\": {\"effect\": 0.07754352769719428, \"value\": 2.0}}}, {\"outValue\": 2.9865187599197043, \"simIndex\": 55.0, \"features\": {\"0\": {\"effect\": 0.22423939410721455, \"value\": 0.0}, \"1\": {\"effect\": 0.022735389400025514, \"value\": 1.0}, \"2\": {\"effect\": -0.06829813567692268, \"value\": 0.0}, \"3\": {\"effect\": 0.14226416026050928, \"value\": -0.9903697403451108}, \"4\": {\"effect\": 0.011054810693296474, \"value\": 0.0}, \"5\": {\"effect\": 0.9375409649394283, \"value\": 1.0}, \"6\": {\"effect\": -0.14509920111486588, \"value\": 2.01852014148613}, \"7\": {\"effect\": 0.3810042755012634, \"value\": 0.1}, \"8\": {\"effect\": -0.3934654838186132, \"value\": 0.0}, \"9\": {\"effect\": -0.1290028579766739, \"value\": 1.8514224163999269}, \"10\": {\"effect\": 0.282913737198796, \"value\": 0.5357375374369842}, \"11\": {\"effect\": 0.03138752834261592, \"value\": 1.0}, \"12\": {\"effect\": 0.12337388837106036, \"value\": -0.3880594190980632}, \"13\": {\"effect\": -0.3794260239344087, \"value\": 0.0}, \"14\": {\"effect\": 0.04248632777119191, \"value\": 1.0}, \"15\": {\"effect\": -0.05016913196411813, \"value\": 1.0}, \"16\": {\"effect\": 0.302937997898072, \"value\": 0.0}, \"17\": {\"effect\": 0.0018148930834751523, \"value\": 1.0}, \"18\": {\"effect\": -0.4854797819815153, \"value\": 1.0}, \"19\": {\"effect\": 0.17573314135986798, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.03954571021545551, \"value\": 0.1}, \"21\": {\"effect\": 0.0414758722367792, \"value\": 0.5357375374369842}, \"22\": {\"effect\": 0.2518257070501059, \"value\": 0.0288517107391928}, \"23\": {\"effect\": -0.13632602734843396, \"value\": -0.850976542009417}, \"24\": {\"effect\": -0.08989102003408758, \"value\": 3.0}, \"25\": {\"effect\": -0.47973003183410007, \"value\": 1.0}, \"26\": {\"effect\": -0.17949522374085813, \"value\": 1.011374474444173}, \"27\": {\"effect\": 0.018411923557344008, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.18730983685673985, \"value\": -1.513448160154229}, \"29\": {\"effect\": -0.08236521104528048, \"value\": -1.6093036180458482}, \"30\": {\"effect\": -0.28807659528112817, \"value\": -1.961134205438511}, \"31\": {\"effect\": 0.00488339688652787, \"value\": -0.3880594190980632}, \"32\": {\"effect\": -0.0436863674109758, \"value\": 1.8514224163999269}, \"33\": {\"effect\": -0.02628759897870869, \"value\": 1.4987945976101402}, \"34\": {\"effect\": -0.03454042888133931, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.026389648221952368, \"value\": -0.6336701527957489}, \"36\": {\"effect\": 0.017424517539432343, \"value\": -0.9903697403451108}, \"37\": {\"effect\": 0.029835480499370768, \"value\": 0.0}, \"38\": {\"effect\": 0.0038579834154537367, \"value\": 0.0}, \"39\": {\"effect\": -0.24162349231726415, \"value\": 3.0}}}, {\"outValue\": 1.7807955666220088, \"simIndex\": 61.0, \"features\": {\"0\": {\"effect\": -0.6984118705738254, \"value\": 1.0}, \"1\": {\"effect\": 0.022015157252229738, \"value\": 1.0}, \"2\": {\"effect\": -0.060334958700976785, \"value\": 0.0}, \"3\": {\"effect\": -0.09906134109994555, \"value\": 0.1256327925496902}, \"4\": {\"effect\": 0.01800297932710958, \"value\": 0.0}, \"5\": {\"effect\": -0.26032314910166077, \"value\": 0.0}, \"6\": {\"effect\": 0.12165492279287267, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.530027698648976, \"value\": 0.9}, \"8\": {\"effect\": -0.3587786822326406, \"value\": 0.0}, \"9\": {\"effect\": 0.020272627318270148, \"value\": 0.2441155434636561}, \"10\": {\"effect\": 0.6043846056746138, \"value\": 0.9185349779850132}, \"11\": {\"effect\": -0.03987114810241208, \"value\": 0.0}, \"12\": {\"effect\": 0.10680421782327448, \"value\": -0.3684782430143673}, \"13\": {\"effect\": -0.4338982447994279, \"value\": 0.0}, \"14\": {\"effect\": 0.028617203783187706, \"value\": 1.0}, \"15\": {\"effect\": -0.13575582333206135, \"value\": 1.0}, \"16\": {\"effect\": 0.25336752422732567, \"value\": 0.0}, \"17\": {\"effect\": 0.0016190426411379596, \"value\": 1.0}, \"18\": {\"effect\": 0.06978296611777231, \"value\": 2.0}, \"19\": {\"effect\": -0.02034907714982272, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.02084861122449444, \"value\": 0.9}, \"21\": {\"effect\": 0.11047451051212884, \"value\": 0.9185349779850132}, \"22\": {\"effect\": 0.008685481187266817, \"value\": 0.0071965453278727}, \"23\": {\"effect\": -0.2147597014840192, \"value\": -0.7479774985091603}, \"24\": {\"effect\": 0.10464815997735163, \"value\": 13.0}, \"25\": {\"effect\": 0.1626013811967229, \"value\": 2.0}, \"26\": {\"effect\": -0.6205994935282263, \"value\": 0.4231827950096046}, \"27\": {\"effect\": 0.029079490788172485, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.07857688464501544, \"value\": 1.1917189228102172}, \"29\": {\"effect\": -0.211813438396069, \"value\": 0.698942492453125}, \"30\": {\"effect\": 0.27544480446414316, \"value\": -0.3704593170774373}, \"31\": {\"effect\": -0.0007100263152947146, \"value\": -0.3684782430143673}, \"32\": {\"effect\": 0.03756017333351151, \"value\": 0.2441155434636561}, \"33\": {\"effect\": 0.272508090376137, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.016961586222370977, \"value\": 0.9930046138595}, \"35\": {\"effect\": 0.11196435756424647, \"value\": 0.0273455769498943}, \"36\": {\"effect\": -0.015898518271455733, \"value\": 0.1256327925496902}, \"37\": {\"effect\": 0.018679233006752602, \"value\": 0.0}, \"38\": {\"effect\": 0.0021691044427649834, \"value\": 0.0}, \"39\": {\"effect\": 0.1126111094711334, \"value\": 2.0}}}, {\"outValue\": 1.7822962967698563, \"simIndex\": 56.0, \"features\": {\"0\": {\"effect\": 0.2263847816193297, \"value\": 0.0}, \"1\": {\"effect\": 0.018635944554219377, \"value\": 1.0}, \"2\": {\"effect\": -0.06544971928356867, \"value\": 0.0}, \"3\": {\"effect\": 0.04282640084063898, \"value\": -0.1200469094333898}, \"4\": {\"effect\": 0.006710561599111079, \"value\": 0.0}, \"5\": {\"effect\": 1.0587959728622471, \"value\": 1.0}, \"6\": {\"effect\": 0.09912625500790566, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.3704776011557404, \"value\": 0.9}, \"8\": {\"effect\": -0.5646124748175431, \"value\": 0.0}, \"9\": {\"effect\": -0.046681910236497495, \"value\": 0.2728174519089467}, \"10\": {\"effect\": 0.05585037321485121, \"value\": 0.838423928799047}, \"11\": {\"effect\": -0.02000184452148168, \"value\": 0.0}, \"12\": {\"effect\": 0.1153738995157814, \"value\": -0.3815323604034979}, \"13\": {\"effect\": -0.42587538680424786, \"value\": 0.0}, \"14\": {\"effect\": 0.036099703116491334, \"value\": 1.0}, \"15\": {\"effect\": -0.10055312776280453, \"value\": 1.0}, \"16\": {\"effect\": -0.24552804982545304, \"value\": 1.0}, \"17\": {\"effect\": 0.0015766020225784756, \"value\": 1.0}, \"18\": {\"effect\": -0.6352867711567582, \"value\": 1.0}, \"19\": {\"effect\": 0.03143521032457509, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.007898935774578036, \"value\": 0.9}, \"21\": {\"effect\": 0.01004456775824074, \"value\": 0.838423928799047}, \"22\": {\"effect\": 0.03723085753958674, \"value\": 0.0005579096528686}, \"23\": {\"effect\": 0.313982390378652, \"value\": 100.25945723635468}, \"24\": {\"effect\": 0.09942084724558714, \"value\": 14.0}, \"25\": {\"effect\": -0.41326077725787785, \"value\": 1.0}, \"26\": {\"effect\": 0.16770991430184534, \"value\": -0.5495957517475664}, \"27\": {\"effect\": 0.01272613235656077, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.042644583532964166, \"value\": -0.2205902376761144}, \"29\": {\"effect\": 0.07222518010271954, \"value\": -1.3061715803875589}, \"30\": {\"effect\": -0.6888328110506328, \"value\": -1.9360158600248092}, \"31\": {\"effect\": 0.034233337291895295, \"value\": -0.3815323604034979}, \"32\": {\"effect\": 0.027165432532158255, \"value\": 0.2728174519089467}, \"33\": {\"effect\": 0.4249790051300489, \"value\": 0.8385580009155795}, \"34\": {\"effect\": -0.01987918534293718, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.16123754339325186, \"value\": -0.5328448824698934}, \"36\": {\"effect\": -0.04030078238137772, \"value\": -0.1200469094333898}, \"37\": {\"effect\": -0.3439315911312171, \"value\": 1.0}, \"38\": {\"effect\": 0.0012519402841973803, \"value\": 0.0}, \"39\": {\"effect\": -0.0752305891941979, \"value\": 3.0}}}, {\"outValue\": 2.7034940330104105, \"simIndex\": 35.0, \"features\": {\"0\": {\"effect\": -0.5861053720328169, \"value\": 1.0}, \"1\": {\"effect\": 0.03920180088698744, \"value\": 1.0}, \"2\": {\"effect\": -0.10924928297464132, \"value\": 0.0}, \"3\": {\"effect\": 0.00355399456408304, \"value\": -0.1449132760308676}, \"4\": {\"effect\": 0.01887731813018394, \"value\": 0.0}, \"5\": {\"effect\": 0.7668366042126068, \"value\": 1.0}, \"6\": {\"effect\": 0.012633787535125444, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.021857253537319894, \"value\": 0.7000000000000001}, \"8\": {\"effect\": -0.4126216055990314, \"value\": 0.0}, \"9\": {\"effect\": -0.006344383780897178, \"value\": 0.2871684061315919}, \"10\": {\"effect\": -0.13171280488457912, \"value\": 0.2823262122138937}, \"11\": {\"effect\": -0.03145736726531643, \"value\": 0.0}, \"12\": {\"effect\": 0.13482615513784835, \"value\": -0.3728296154774109}, \"13\": {\"effect\": 0.5863081678390497, \"value\": 1.0}, \"14\": {\"effect\": 0.04514544107739987, \"value\": 1.0}, \"15\": {\"effect\": -0.12049466621027916, \"value\": 1.0}, \"16\": {\"effect\": -0.3010121833366073, \"value\": 1.0}, \"17\": {\"effect\": 0.0006807071564165108, \"value\": 1.0}, \"18\": {\"effect\": 0.04842797545361388, \"value\": 3.0}, \"19\": {\"effect\": 0.06188229617441601, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.014561813062529391, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.005401982138292722, \"value\": 0.2823262122138937}, \"22\": {\"effect\": 0.12728068543004442, \"value\": 0.0226005031915871}, \"23\": {\"effect\": -0.2175394108260924, \"value\": -1.0887017613062415}, \"24\": {\"effect\": -0.3089356022949722, \"value\": 3.0}, \"25\": {\"effect\": 0.13213134186317407, \"value\": 3.0}, \"26\": {\"effect\": -0.17085172751308728, \"value\": 3.1039794878171567}, \"27\": {\"effect\": 0.014427005095159012, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.09185566847334789, \"value\": 0.3885662486103252}, \"29\": {\"effect\": 0.03127498947553428, \"value\": -0.3762537590346955}, \"30\": {\"effect\": 0.0685702683969245, \"value\": 0.5215624979795103}, \"31\": {\"effect\": 0.043938943290299515, \"value\": -0.3728296154774109}, \"32\": {\"effect\": 0.00406272621919062, \"value\": 0.2871684061315919}, \"33\": {\"effect\": 0.07016822325977191, \"value\": 0.3433805533946588}, \"34\": {\"effect\": -0.0001395992433289694, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.09435048482938573, \"value\": -0.3975161741653795}, \"36\": {\"effect\": 0.015658001422609532, \"value\": -0.1449132760308676}, \"37\": {\"effect\": 0.025895567025767546, \"value\": 0.0}, \"38\": {\"effect\": 0.0008098455195406086, \"value\": 0.0}, \"39\": {\"effect\": -0.039226615955287175, \"value\": 1.0}}}, {\"outValue\": 1.8131111975641767, \"simIndex\": 20.0, \"features\": {\"0\": {\"effect\": -0.7289427465040751, \"value\": 1.0}, \"1\": {\"effect\": 0.019776463513099064, \"value\": 1.0}, \"2\": {\"effect\": -0.07930255901100361, \"value\": 0.0}, \"3\": {\"effect\": 0.06653701421132723, \"value\": -0.5119408470096392}, \"4\": {\"effect\": 0.005200539599603031, \"value\": 0.0}, \"5\": {\"effect\": -0.2348449619270466, \"value\": 0.0}, \"6\": {\"effect\": 0.06804320523390446, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.5338587499664159, \"value\": 0.9}, \"8\": {\"effect\": 0.3785350231881299, \"value\": 1.0}, \"9\": {\"effect\": 0.04104871589180852, \"value\": 0.2441155434636561}, \"10\": {\"effect\": -0.4454612391495442, \"value\": 0.1466809421263942}, \"11\": {\"effect\": -0.0628945384586258, \"value\": 0.0}, \"12\": {\"effect\": 0.09159809407547191, \"value\": -0.3728296154774109}, \"13\": {\"effect\": -0.4462632940428391, \"value\": 0.0}, \"14\": {\"effect\": 0.030979892656670064, \"value\": 1.0}, \"15\": {\"effect\": -0.10762471411799295, \"value\": 1.0}, \"16\": {\"effect\": -0.22469012419191314, \"value\": 1.0}, \"17\": {\"effect\": 0.0009946489790000773, \"value\": 1.0}, \"18\": {\"effect\": 0.07013670009830346, \"value\": 4.0}, \"19\": {\"effect\": -0.014638263420070224, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.06156312774200198, \"value\": 0.9}, \"21\": {\"effect\": -0.1051249562833422, \"value\": 0.1466809421263942}, \"22\": {\"effect\": 0.06165816752101157, \"value\": 0.0209620875462239}, \"23\": {\"effect\": -0.06799559007778194, \"value\": -0.395195132560878}, \"24\": {\"effect\": -0.33077391201662576, \"value\": 3.0}, \"25\": {\"effect\": 0.17680888833889324, \"value\": 4.0}, \"26\": {\"effect\": 0.9543520628447714, \"value\": -0.7871346992115267}, \"27\": {\"effect\": 0.02632649058290458, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.13849877525216708, \"value\": -1.3397860282730976}, \"29\": {\"effect\": -0.15579447961528187, \"value\": 0.1761448549105544}, \"30\": {\"effect\": 0.12152241826353638, \"value\": -0.5994551903605114}, \"31\": {\"effect\": 0.04601348186166126, \"value\": -0.3728296154774109}, \"32\": {\"effect\": 0.025986853549332264, \"value\": 0.2441155434636561}, \"33\": {\"effect\": 0.205996718676759, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.00885090015512683, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.1850913764948468, \"value\": 0.0706742854790419}, \"36\": {\"effect\": 0.02048551605068362, \"value\": -0.5119408470096392}, \"37\": {\"effect\": 0.01621633460103353, \"value\": 0.0}, \"38\": {\"effect\": 0.00264931809576669, \"value\": 0.0}, \"39\": {\"effect\": -0.14433109987057688, \"value\": 3.0}}}, {\"outValue\": 1.4104604997672285, \"simIndex\": 94.0, \"features\": {\"0\": {\"effect\": 0.3307334541939959, \"value\": 0.0}, \"1\": {\"effect\": 0.01766756535803984, \"value\": 1.0}, \"2\": {\"effect\": -0.06503173598601027, \"value\": 0.0}, \"3\": {\"effect\": 0.10556793054587818, \"value\": -0.6183688960468439}, \"4\": {\"effect\": 0.011575751816710821, \"value\": 0.0}, \"5\": {\"effect\": -0.21369119906866768, \"value\": 0.0}, \"6\": {\"effect\": -0.0412338013082468, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.026325662904363976, \"value\": 0.8}, \"8\": {\"effect\": 0.3363291495141789, \"value\": 1.0}, \"9\": {\"effect\": -0.2812517573151655, \"value\": 2.05233577551696}, \"10\": {\"effect\": -0.05136151851889809, \"value\": 0.8250636626767969}, \"11\": {\"effect\": 0.06944218084031008, \"value\": 1.0}, \"12\": {\"effect\": 0.02953228139588853, \"value\": 2.7710369890715323}, \"13\": {\"effect\": -0.5053017866609477, \"value\": 0.0}, \"14\": {\"effect\": 0.02700898179499693, \"value\": 1.0}, \"15\": {\"effect\": -0.14526969059622236, \"value\": 1.0}, \"16\": {\"effect\": 0.3451054696453919, \"value\": 0.0}, \"17\": {\"effect\": 0.000372766416209393, \"value\": 1.0}, \"18\": {\"effect\": -0.5733894226002785, \"value\": 1.0}, \"19\": {\"effect\": -0.19182647454689153, \"value\": 1.3563280592606042}, \"20\": {\"effect\": 0.004374028248170689, \"value\": 0.8}, \"21\": {\"effect\": 0.020041618739614218, \"value\": 0.8250636626767969}, \"22\": {\"effect\": -0.010263451282323473, \"value\": 0.0065793600081051}, \"23\": {\"effect\": -0.1324000845486368, \"value\": -1.1343380859187744}, \"24\": {\"effect\": 0.07053742037547998, \"value\": 6.0}, \"25\": {\"effect\": -0.5031932859532671, \"value\": 1.0}, \"26\": {\"effect\": -0.543103733781907, \"value\": 0.4797396872629285}, \"27\": {\"effect\": -0.00765434096284778, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.10196854691456793, \"value\": -0.003223211624672}, \"29\": {\"effect\": 0.18122404252382737, \"value\": -1.0014615776700966}, \"30\": {\"effect\": 0.10149546059623862, \"value\": -0.6342878062186565}, \"31\": {\"effect\": 0.22559300608495428, \"value\": 2.7710369890715323}, \"32\": {\"effect\": -0.12544091634643237, \"value\": 2.05233577551696}, \"33\": {\"effect\": -0.12259653818317298, \"value\": 1.16867629926286}, \"34\": {\"effect\": -0.05767702504522336, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.09796272703607173, \"value\": -0.6887251920711804}, \"36\": {\"effect\": 0.020868505096726657, \"value\": -0.6183688960468439}, \"37\": {\"effect\": 0.036237954065169414, \"value\": 0.0}, \"38\": {\"effect\": 0.0031508656859594217, \"value\": 0.0}, \"39\": {\"effect\": -0.20022228623948515, \"value\": 3.0}}}, {\"outValue\": 2.03739544255886, \"simIndex\": 63.0, \"features\": {\"0\": {\"effect\": 0.32514245601229347, \"value\": 0.0}, \"1\": {\"effect\": 0.016636540064515957, \"value\": 1.0}, \"2\": {\"effect\": 0.1343408924914042, \"value\": 1.0}, \"3\": {\"effect\": 0.036507644087022326, \"value\": -0.882947036644007}, \"4\": {\"effect\": 0.010207798170013308, \"value\": 0.0}, \"5\": {\"effect\": -0.2080265384598661, \"value\": 0.0}, \"6\": {\"effect\": 0.13609211678693744, \"value\": 0.9930046138595}, \"7\": {\"effect\": -0.6249433893723729, \"value\": 0.9}, \"8\": {\"effect\": -0.2884325720204506, \"value\": 0.0}, \"9\": {\"effect\": -0.13187920811331477, \"value\": 1.1482256594903082}, \"10\": {\"effect\": -0.3372567416241198, \"value\": 0.1902649533763414}, \"11\": {\"effect\": -0.016270414357194066, \"value\": 0.0}, \"12\": {\"effect\": 0.04865586670006578, \"value\": -0.3750053017089326}, \"13\": {\"effect\": -0.43521933086103837, \"value\": 0.0}, \"14\": {\"effect\": 0.03448233689690551, \"value\": 1.0}, \"15\": {\"effect\": -0.09601415050879655, \"value\": 1.0}, \"16\": {\"effect\": 0.2779374897627536, \"value\": 0.0}, \"17\": {\"effect\": 0.0013543906906949897, \"value\": 1.0}, \"18\": {\"effect\": 0.3474978931593683, \"value\": 5.0}, \"19\": {\"effect\": 0.2540939174545744, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.0032897301881518026, \"value\": 0.9}, \"21\": {\"effect\": -0.10284867680105923, \"value\": 0.1902649533763414}, \"22\": {\"effect\": -0.06242638068319693, \"value\": 0.0029140384928089}, \"23\": {\"effect\": -0.20779944924778526, \"value\": -0.7949532263696695}, \"24\": {\"effect\": 0.03817036207116293, \"value\": 5.0}, \"25\": {\"effect\": 0.18601159985853616, \"value\": 5.0}, \"26\": {\"effect\": -0.6635807430707862, \"value\": 0.2874462536016272}, \"27\": {\"effect\": 0.04784233107315863, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.05042536170363882, \"value\": -1.5283029049562116}, \"29\": {\"effect\": -0.0309633246511659, \"value\": 0.179948098862764}, \"30\": {\"effect\": 0.09276132593257079, \"value\": -0.6065805450041664}, \"31\": {\"effect\": 0.01485103334077997, \"value\": -0.3750053017089326}, \"32\": {\"effect\": -0.018136876306707503, \"value\": 1.1482256594903082}, \"33\": {\"effect\": 0.09787111247149953, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.014568601793526863, \"value\": 0.9930046138595}, \"35\": {\"effect\": -0.09032475645353148, \"value\": -0.5905106245828544}, \"36\": {\"effect\": 0.013009388471566036, \"value\": -0.882947036644007}, \"37\": {\"effect\": 0.025950139064821, \"value\": 0.0}, \"38\": {\"effect\": 0.0015957415233183447, \"value\": 0.0}, \"39\": {\"effect\": 0.07789588096943319, \"value\": 2.0}}}, {\"outValue\": 5.441567016462796, \"simIndex\": 11.0, \"features\": {\"0\": {\"effect\": 0.24869864147930976, \"value\": 0.0}, \"1\": {\"effect\": 0.05363696511401001, \"value\": 1.0}, \"2\": {\"effect\": 0.15661250931539722, \"value\": 1.0}, \"3\": {\"effect\": -0.035477377804789725, \"value\": -0.4632027684785827}, \"4\": {\"effect\": 0.013192311099734821, \"value\": 0.0}, \"5\": {\"effect\": 0.8255936266401106, \"value\": 1.0}, \"6\": {\"effect\": 0.020976155446406394, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.4801950755511337, \"value\": 0.9}, \"8\": {\"effect\": 0.30006634329565157, \"value\": 1.0}, \"9\": {\"effect\": 0.18591705106231618, \"value\": -0.2581678543289284}, \"10\": {\"effect\": -0.4994872835415604, \"value\": 0.1439571342498778}, \"11\": {\"effect\": -0.026097980802540246, \"value\": 0.0}, \"12\": {\"effect\": -0.057842287187363374, \"value\": -0.3293158908469756}, \"13\": {\"effect\": 0.471839363964298, \"value\": 1.0}, \"14\": {\"effect\": 0.029839052256658165, \"value\": 1.0}, \"15\": {\"effect\": 0.24756468673655288, \"value\": 2.0}, \"16\": {\"effect\": -0.26834409792773734, \"value\": 1.0}, \"17\": {\"effect\": -0.002152809127534396, \"value\": 1.0}, \"18\": {\"effect\": 0.21879025469394298, \"value\": 2.0}, \"19\": {\"effect\": 0.05022860658245317, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.047431314858216785, \"value\": 0.9}, \"21\": {\"effect\": -0.0994850488150672, \"value\": 0.1439571342498778}, \"22\": {\"effect\": 0.29428087517687074, \"value\": 0.0524692318456086}, \"23\": {\"effect\": -0.19804553564037997, \"value\": -0.6897968565020084}, \"24\": {\"effect\": -0.051660629162312635, \"value\": 5.0}, \"25\": {\"effect\": 0.1772903332118584, \"value\": 2.0}, \"26\": {\"effect\": 0.44966646365994506, \"value\": -0.7532005638595324}, \"27\": {\"effect\": 0.015822577659014892, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.03729363525381452, \"value\": 2.2236398248656304}, \"29\": {\"effect\": 0.11716170959249492, \"value\": 1.6627118099018383}, \"30\": {\"effect\": 0.059996674946525656, \"value\": 0.7383397647086981}, \"31\": {\"effect\": 0.03001437287964466, \"value\": -0.3293158908469756}, \"32\": {\"effect\": 0.02190847303438465, \"value\": -0.2581678543289284}, \"33\": {\"effect\": 0.15239347178024112, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.028239554393786677, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.026176201486270728, \"value\": -0.2521809014779365}, \"36\": {\"effect\": 0.01869772200213539, \"value\": -0.4632027684785827}, \"37\": {\"effect\": 0.032567121616719874, \"value\": 0.0}, \"38\": {\"effect\": 0.0016638225030611443, \"value\": 0.0}, \"39\": {\"effect\": -0.07466035422238565, \"value\": 1.0}}}, {\"outValue\": 3.7534138908119026, \"simIndex\": 65.0, \"features\": {\"0\": {\"effect\": 0.309789456530776, \"value\": 0.0}, \"1\": {\"effect\": 0.0166172549742788, \"value\": 1.0}, \"2\": {\"effect\": 0.24600559733071167, \"value\": 1.0}, \"3\": {\"effect\": 0.14546762903913318, \"value\": -0.6969466144948735}, \"4\": {\"effect\": 0.01127769255784301, \"value\": 0.0}, \"5\": {\"effect\": -0.20021812427319025, \"value\": 0.0}, \"6\": {\"effect\": 0.14053767801080447, \"value\": 0.9724943033069674}, \"7\": {\"effect\": 0.3320286692930114, \"value\": 0.1}, \"8\": {\"effect\": -0.32897318664589503, \"value\": 0.0}, \"9\": {\"effect\": -0.011843505107423383, \"value\": 0.7176970328109501}, \"10\": {\"effect\": 0.2188214148876639, \"value\": 0.5228322324319671}, \"11\": {\"effect\": -0.029221657060160472, \"value\": 0.0}, \"12\": {\"effect\": -0.2490611324982039, \"value\": -0.4011135364871937}, \"13\": {\"effect\": -0.41230743649153806, \"value\": 0.0}, \"14\": {\"effect\": 0.03204359091868629, \"value\": 1.0}, \"15\": {\"effect\": -0.17974715924931914, \"value\": 1.0}, \"16\": {\"effect\": 0.4043642495618473, \"value\": 0.0}, \"17\": {\"effect\": 0.0003414585478523254, \"value\": 1.0}, \"18\": {\"effect\": 0.19196462693546235, \"value\": 3.0}, \"19\": {\"effect\": 0.04307333080261222, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.022761246852365993, \"value\": 0.1}, \"21\": {\"effect\": 0.07622222353928937, \"value\": 0.5228322324319671}, \"22\": {\"effect\": 0.12090212055472102, \"value\": 0.0221784144262212}, \"23\": {\"effect\": 0.02727634141128761, \"value\": -0.3204386728718779}, \"24\": {\"effect\": 0.24505340137345533, \"value\": 23.0}, \"25\": {\"effect\": 0.13420861049771107, \"value\": 3.0}, \"26\": {\"effect\": -0.6986565287368819, \"value\": 0.2761348751509624}, \"27\": {\"effect\": -0.00603740014485601, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.0417346461733809, \"value\": 0.1299793030505146}, \"29\": {\"effect\": 0.07440636979999156, \"value\": -0.9381340664645018}, \"30\": {\"effect\": 0.040308330585003965, \"value\": 0.8083180925364188}, \"31\": {\"effect\": -0.04300334839952292, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.0028009611621517476, \"value\": 0.7176970328109501}, \"33\": {\"effect\": -0.08476580616152864, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.010174952698687808, \"value\": 0.9724943033069674}, \"35\": {\"effect\": -0.13303211743756446, \"value\": -0.2063164831673995}, \"36\": {\"effect\": 0.015912314773881473, \"value\": -0.6969466144948735}, \"37\": {\"effect\": 0.028133704740707626, \"value\": 0.0}, \"38\": {\"effect\": 0.0026058378035379894, \"value\": 0.0}, \"39\": {\"effect\": 0.13014399925759773, \"value\": 1.0}}}, {\"outValue\": 3.6453998872865094, \"simIndex\": 68.0, \"features\": {\"0\": {\"effect\": 0.2744586787755224, \"value\": 0.0}, \"1\": {\"effect\": 0.015932518620164357, \"value\": 1.0}, \"2\": {\"effect\": 0.1827440110647812, \"value\": 1.0}, \"3\": {\"effect\": 0.08161162947991751, \"value\": -0.5119408470096392}, \"4\": {\"effect\": 0.011244940873538141, \"value\": 0.0}, \"5\": {\"effect\": -0.2582797506631228, \"value\": 0.0}, \"6\": {\"effect\": -0.020771586993066214, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2647342532086135, \"value\": 0.3}, \"8\": {\"effect\": -0.489393660330618, \"value\": 0.0}, \"9\": {\"effect\": 0.0667128621054849, \"value\": -0.1290092663251209}, \"10\": {\"effect\": 0.1380530972870091, \"value\": 0.4058771515049263}, \"11\": {\"effect\": -0.03666692232155058, \"value\": 0.0}, \"12\": {\"effect\": -0.05753866559922408, \"value\": -0.3967621640241502}, \"13\": {\"effect\": -0.31364598166155894, \"value\": 0.0}, \"14\": {\"effect\": 0.029601943534915322, \"value\": 1.0}, \"15\": {\"effect\": -0.1765087692088219, \"value\": 1.0}, \"16\": {\"effect\": -0.2797239879096055, \"value\": 1.0}, \"17\": {\"effect\": 0.00016265221504621554, \"value\": 1.0}, \"18\": {\"effect\": 0.19725401589386546, \"value\": 2.0}, \"19\": {\"effect\": 0.0759376504077004, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.013926080022583012, \"value\": 0.3}, \"21\": {\"effect\": 0.04885065457643289, \"value\": 0.4058771515049263}, \"22\": {\"effect\": -0.24483216262131396, \"value\": 0.0001581464728412}, \"23\": {\"effect\": 0.019408084378909913, \"value\": -0.7934247690654197}, \"24\": {\"effect\": 0.0019615877774599444, \"value\": 7.0}, \"25\": {\"effect\": 0.19283456166840088, \"value\": 2.0}, \"26\": {\"effect\": 0.013983205801484567, \"value\": -0.5722185086488959}, \"27\": {\"effect\": 0.0002457611908216864, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.17891999237517495, \"value\": 1.667822111368752}, \"29\": {\"effect\": 0.08320110461460786, \"value\": 2.363381748575836}, \"30\": {\"effect\": 0.10437751549932679, \"value\": 0.8236336341231767}, \"31\": {\"effect\": 0.001905680409382745, \"value\": -0.3967621640241502}, \"32\": {\"effect\": 0.036494424557260124, \"value\": -0.1290092663251209}, \"33\": {\"effect\": 0.015412646596676814, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0030601814088682586, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.3311131161031611, \"value\": 0.7661714283677769}, \"36\": {\"effect\": -0.0014106589502956273, \"value\": -0.5119408470096392}, \"37\": {\"effect\": 0.033273814886012956, \"value\": 0.0}, \"38\": {\"effect\": 0.0038862006971930115, \"value\": 0.0}, \"39\": {\"effect\": 0.03196366278753491, \"value\": 1.0}}}, {\"outValue\": 0.9779364730374818, \"simIndex\": 4.0, \"features\": {\"0\": {\"effect\": -0.7178248229338609, \"value\": 1.0}, \"1\": {\"effect\": -0.1998320638330076, \"value\": 0.0}, \"2\": {\"effect\": -0.04665022948388905, \"value\": 0.0}, \"3\": {\"effect\": -0.07750748681044192, \"value\": -0.0454478096409566}, \"4\": {\"effect\": 0.013053625948241965, \"value\": 0.0}, \"5\": {\"effect\": -0.28930309228224055, \"value\": 0.0}, \"6\": {\"effect\": 0.16117939736659165, \"value\": 0.9930046138595}, \"7\": {\"effect\": 0.24940586945201265, \"value\": 0.1}, \"8\": {\"effect\": 0.33893956181237933, \"value\": 1.0}, \"9\": {\"effect\": -0.28630089842653106, \"value\": 1.449595698165859}, \"10\": {\"effect\": -0.03528467378469571, \"value\": 0.2687254035631397}, \"11\": {\"effect\": 0.023223805928927973, \"value\": 0.0}, \"12\": {\"effect\": -0.1063090334768666, \"value\": -0.3967621640241502}, \"13\": {\"effect\": 0.6554790770747574, \"value\": 1.0}, \"14\": {\"effect\": 0.039849425239565285, \"value\": 1.0}, \"15\": {\"effect\": -0.1501376854702898, \"value\": 1.0}, \"16\": {\"effect\": 0.3702146828588186, \"value\": 0.0}, \"17\": {\"effect\": 0.0014963172014284514, \"value\": 1.0}, \"18\": {\"effect\": -0.3670678002840843, \"value\": 1.0}, \"19\": {\"effect\": -0.14781759955027937, \"value\": 1.3563280592606042}, \"20\": {\"effect\": 0.005609750786263022, \"value\": 0.1}, \"21\": {\"effect\": 0.01871814342610358, \"value\": 0.2687254035631397}, \"22\": {\"effect\": -0.1049546410312021, \"value\": 0.0101073198582863}, \"23\": {\"effect\": -0.4577674872190124, \"value\": -1.6299725790196913}, \"24\": {\"effect\": -0.098342847889005, \"value\": 4.0}, \"25\": {\"effect\": -0.6569788836380723, \"value\": 1.0}, \"26\": {\"effect\": -0.13438008695988646, \"value\": 1.1810451512041449}, \"27\": {\"effect\": -0.027834421038908964, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.01581280258630958, \"value\": -0.6701417196855498}, \"29\": {\"effect\": -0.18606248550213936, \"value\": 1.0450169573587784}, \"30\": {\"effect\": 0.10262567867440706, \"value\": 0.3034857892972058}, \"31\": {\"effect\": -0.028241410047892688, \"value\": -0.3967621640241502}, \"32\": {\"effect\": -0.029291284600513716, \"value\": 1.449595698165859}, \"33\": {\"effect\": 0.06218661071826008, \"value\": -0.6469743416471827}, \"34\": {\"effect\": 0.007525940042419717, \"value\": 0.9930046138595}, \"35\": {\"effect\": -0.13214683515134173, \"value\": -0.4595795508444403}, \"36\": {\"effect\": -0.005841629467258234, \"value\": -0.0454478096409566}, \"37\": {\"effect\": 0.014704954866283258, \"value\": 0.0}, \"38\": {\"effect\": 0.00031671492729106604, \"value\": 0.0}, \"39\": {\"effect\": 0.14419161345362388, \"value\": 2.0}}}, {\"outValue\": 0.31849094042846726, \"simIndex\": 99.0, \"features\": {\"0\": {\"effect\": 0.41093348614894937, \"value\": 0.0}, \"1\": {\"effect\": 0.024753684360009204, \"value\": 1.0}, \"2\": {\"effect\": -0.08311227705987888, \"value\": 0.0}, \"3\": {\"effect\": -0.17393624838036328, \"value\": 0.9780518395112272}, \"4\": {\"effect\": 0.012798775903409573, \"value\": 0.0}, \"5\": {\"effect\": -0.16669594579209784, \"value\": 0.0}, \"6\": {\"effect\": 0.039219284848815456, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.47459265875694095, \"value\": 0.9}, \"8\": {\"effect\": -0.44638023095900436, \"value\": 0.0}, \"9\": {\"effect\": 0.06797074937274823, \"value\": -0.8896098401253204}, \"10\": {\"effect\": 0.36403906848140144, \"value\": 0.5456563501802075}, \"11\": {\"effect\": 0.04546699662593922, \"value\": 1.0}, \"12\": {\"effect\": -0.19099858695968203, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.41678678147376885, \"value\": 0.0}, \"14\": {\"effect\": 0.027629917347479164, \"value\": 1.0}, \"15\": {\"effect\": -0.10450464001521816, \"value\": 1.0}, \"16\": {\"effect\": -0.3626921798724932, \"value\": 1.0}, \"17\": {\"effect\": 0.0011656525680451394, \"value\": 1.0}, \"18\": {\"effect\": -0.6667083433835866, \"value\": 1.0}, \"19\": {\"effect\": 0.002431753208793269, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.026252630509482597, \"value\": 0.9}, \"21\": {\"effect\": 0.06224865278331073, \"value\": 0.5456563501802075}, \"22\": {\"effect\": 0.5693298940747094, \"value\": 0.0404237194438229}, \"23\": {\"effect\": -0.11325619342143667, \"value\": -0.8898183565146907}, \"24\": {\"effect\": 0.18598974931727114, \"value\": 16.0}, \"25\": {\"effect\": -0.39834469739295547, \"value\": 1.0}, \"26\": {\"effect\": -0.1108949666995619, \"value\": 1.373338584865446}, \"27\": {\"effect\": 0.00573326465510339, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.10000539235938967, \"value\": 1.2750214853715454}, \"29\": {\"effect\": -0.11910344895405156, \"value\": 0.9404408087908313}, \"30\": {\"effect\": -0.406523231987681, \"value\": 2.050810574870477}, \"31\": {\"effect\": -0.04420987060457003, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.02647684901292667, \"value\": -0.8896098401253204}, \"33\": {\"effect\": -0.11181868781850184, \"value\": 1.16867629926286}, \"34\": {\"effect\": 0.022694478935820092, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.05642410010124727, \"value\": -0.2309749956756041}, \"36\": {\"effect\": -0.05827149445258096, \"value\": 0.9780518395112272}, \"37\": {\"effect\": 0.04794786834791257, \"value\": 0.0}, \"38\": {\"effect\": 0.002356222893563348, \"value\": 0.0}, \"39\": {\"effect\": -0.040088306231082976, \"value\": 1.0}}}, {\"outValue\": -0.4726037045817546, \"simIndex\": 92.0, \"features\": {\"0\": {\"effect\": 0.24835443155385512, \"value\": 0.0}, \"1\": {\"effect\": 0.014622420957675223, \"value\": 1.0}, \"2\": {\"effect\": -0.06566018115894033, \"value\": 0.0}, \"3\": {\"effect\": -0.07382551686948587, \"value\": 1.102383672498616}, \"4\": {\"effect\": 0.01586495198946452, \"value\": 0.0}, \"5\": {\"effect\": -0.234056295935958, \"value\": 0.0}, \"6\": {\"effect\": -0.9921074875532215, \"value\": 3.04403566911276}, \"7\": {\"effect\": 0.20118079307209907, \"value\": 0.7000000000000001}, \"8\": {\"effect\": -0.3705375909724968, \"value\": 0.0}, \"9\": {\"effect\": -0.3092376415890741, \"value\": 1.9949319586263796}, \"10\": {\"effect\": 0.07303119845458735, \"value\": 0.6667941987074497}, \"11\": {\"effect\": -0.020429036588263623, \"value\": 0.0}, \"12\": {\"effect\": 0.076688473632906, \"value\": -0.3815323604034979}, \"13\": {\"effect\": -0.29579052153616064, \"value\": 0.0}, \"14\": {\"effect\": -0.7311147857611497, \"value\": 2.0}, \"15\": {\"effect\": -0.14616131765563367, \"value\": 1.0}, \"16\": {\"effect\": 0.3883620888968815, \"value\": 0.0}, \"17\": {\"effect\": 0.0018074826997811339, \"value\": 1.0}, \"18\": {\"effect\": -0.5132320698405692, \"value\": 1.0}, \"19\": {\"effect\": 0.04538564237266258, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.006085365098602508, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.08168768773235255, \"value\": 0.6667941987074497}, \"22\": {\"effect\": 0.1177445665975755, \"value\": 0.0207397599315737}, \"23\": {\"effect\": -0.007348683789249468, \"value\": -0.9169465574063528}, \"24\": {\"effect\": 0.1011405555091994, \"value\": 6.0}, \"25\": {\"effect\": -0.6213451070213576, \"value\": 1.0}, \"26\": {\"effect\": -0.31114331108873966, \"value\": 0.2082666044469737}, \"27\": {\"effect\": 0.01646788074291696, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.2325190086718088, \"value\": 1.8491641908618344}, \"29\": {\"effect\": 0.02604100091524503, \"value\": 0.1068743080232039}, \"30\": {\"effect\": 0.055983786390752154, \"value\": 0.8062524521133926}, \"31\": {\"effect\": 0.019256149328850385, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.16599990119883076, \"value\": 1.9949319586263796}, \"33\": {\"effect\": -0.09171070909856162, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.10481130159508785, \"value\": 3.04403566911276}, \"35\": {\"effect\": -0.060462392283336844, \"value\": -0.2953950887937493}, \"36\": {\"effect\": 0.02244946131171497, \"value\": 1.102383672498616}, \"37\": {\"effect\": 0.03376048310165348, \"value\": 0.0}, \"38\": {\"effect\": -0.22903960894026176, \"value\": 1.0}, \"39\": {\"effect\": 0.022070822136203972, \"value\": 1.0}}}, {\"outValue\": 3.3133324068028043, \"simIndex\": 44.0, \"features\": {\"0\": {\"effect\": 0.19839297346538107, \"value\": 0.0}, \"1\": {\"effect\": 0.02395877817820485, \"value\": 1.0}, \"2\": {\"effect\": 0.23058619894230356, \"value\": 1.0}, \"3\": {\"effect\": -0.010055416810587275, \"value\": -0.438336401881105}, \"4\": {\"effect\": 0.014592830003768011, \"value\": 0.0}, \"5\": {\"effect\": 0.8787818950701938, \"value\": 1.0}, \"6\": {\"effect\": 0.005767282051442912, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.25081454580464707, \"value\": 0.1}, \"8\": {\"effect\": -0.2834993442872503, \"value\": 0.0}, \"9\": {\"effect\": 0.14077854613101817, \"value\": -0.1290092663251209}, \"10\": {\"effect\": -0.20932954432255058, \"value\": 0.8118733016389821}, \"11\": {\"effect\": -0.015446778018823382, \"value\": 0.0}, \"12\": {\"effect\": 0.13363141172061857, \"value\": -0.3663025567828455}, \"13\": {\"effect\": -0.44335677771235604, \"value\": 0.0}, \"14\": {\"effect\": 0.037059966960923146, \"value\": 1.0}, \"15\": {\"effect\": -0.15036906447473117, \"value\": 1.0}, \"16\": {\"effect\": -0.3481812025708501, \"value\": 1.0}, \"17\": {\"effect\": 0.0016761219365781107, \"value\": 1.0}, \"18\": {\"effect\": 0.15104847684252362, \"value\": 2.0}, \"19\": {\"effect\": -0.01950996252659329, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.039442387334904815, \"value\": 0.1}, \"21\": {\"effect\": 0.0274069454218776, \"value\": 0.8118733016389821}, \"22\": {\"effect\": 0.04420398937980625, \"value\": 0.0085113139429613}, \"23\": {\"effect\": 0.16057212384214573, \"value\": 98.9574134707346}, \"24\": {\"effect\": -0.038432520024529675, \"value\": 8.0}, \"25\": {\"effect\": 0.14175917193220783, \"value\": 2.0}, \"26\": {\"effect\": -0.7036258152541957, \"value\": -0.2102543982276229}, \"27\": {\"effect\": 0.002971534439028479, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.07034042985638923, \"value\": -0.4857764207646231}, \"29\": {\"effect\": -0.11330202335895104, \"value\": -0.0991431450267918}, \"30\": {\"effect\": 0.1503210883509638, \"value\": 0.5434141846860041}, \"31\": {\"effect\": 0.01106514257767805, \"value\": -0.3663025567828455}, \"32\": {\"effect\": 0.036494455388198024, \"value\": -0.1290092663251209}, \"33\": {\"effect\": -0.17977560209362267, \"value\": -0.7295039162340028}, \"34\": {\"effect\": 0.012564810743693556, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.18876481902473177, \"value\": -0.4647487834025468}, \"36\": {\"effect\": 0.01956638186142776, \"value\": -0.438336401881105}, \"37\": {\"effect\": 0.022750470377655062, \"value\": 0.0}, \"38\": {\"effect\": 0.0031931929558659256, \"value\": 0.0}, \"39\": {\"effect\": 0.13633462098529608, \"value\": 2.0}}}, {\"outValue\": 1.427577184992058, \"simIndex\": 59.0, \"features\": {\"0\": {\"effect\": -0.7890549076618497, \"value\": 1.0}, \"1\": {\"effect\": 0.015486196886768056, \"value\": 1.0}, \"2\": {\"effect\": -0.12751707242077304, \"value\": 0.0}, \"3\": {\"effect\": -0.2500074020422562, \"value\": 1.5171546673445446}, \"4\": {\"effect\": 0.01169964648357433, \"value\": 0.0}, \"5\": {\"effect\": -0.232070030898643, \"value\": 0.0}, \"6\": {\"effect\": 0.037823248616375045, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.005048361408919113, \"value\": 0.7000000000000001}, \"8\": {\"effect\": -0.2851734530034566, \"value\": 0.0}, \"9\": {\"effect\": 0.025135535607559628, \"value\": -1.6932632765934557}, \"10\": {\"effect\": 0.19483078577897092, \"value\": 0.5185259653237886}, \"11\": {\"effect\": -0.03432753040101341, \"value\": 0.0}, \"12\": {\"effect\": -0.4001980203759598, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.3615665034918666, \"value\": 0.0}, \"14\": {\"effect\": 0.03353662217579253, \"value\": 1.0}, \"15\": {\"effect\": -0.15142458660642202, \"value\": 1.0}, \"16\": {\"effect\": -0.23911536993722407, \"value\": 1.0}, \"17\": {\"effect\": 0.0006851390967258808, \"value\": 1.0}, \"18\": {\"effect\": 0.30484976916564127, \"value\": 5.0}, \"19\": {\"effect\": 0.17979652972842333, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.0070539783752964855, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.057878931428085, \"value\": 0.5185259653237886}, \"22\": {\"effect\": 0.03655187814967603, \"value\": 0.009142919838652}, \"23\": {\"effect\": 0.14522453986538336, \"value\": 51.40918652308189}, \"24\": {\"effect\": 0.049354291545157504, \"value\": 5.0}, \"25\": {\"effect\": 0.1953955355147297, \"value\": 5.0}, \"26\": {\"effect\": -0.3521672450189565, \"value\": -0.2328771551289525}, \"27\": {\"effect\": 0.051732443408471024, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.0114244415138269, \"value\": -0.6580259107613199}, \"29\": {\"effect\": 0.017701259300246484, \"value\": 1.5259510402799736}, \"30\": {\"effect\": 0.05692271336377247, \"value\": 0.7520707177520078}, \"31\": {\"effect\": -0.061960086882839764, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.16515213667838818, \"value\": -1.6932632765934557}, \"33\": {\"effect\": -0.2997192460923045, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0021297315991407337, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.2614890229817399, \"value\": 0.2016459983773806}, \"36\": {\"effect\": 0.02233906064194372, \"value\": 1.5171546673445446}, \"37\": {\"effect\": 0.023682532727643757, \"value\": 0.0}, \"38\": {\"effect\": 0.0024240535558307514, \"value\": 0.0}, \"39\": {\"effect\": 0.06258158927795174, \"value\": 1.0}}}, {\"outValue\": 3.9014722983342853, \"simIndex\": 77.0, \"features\": {\"0\": {\"effect\": 0.2896597640695645, \"value\": 0.0}, \"1\": {\"effect\": -0.22448280102119317, \"value\": 0.0}, \"2\": {\"effect\": -0.06227061280979155, \"value\": 0.0}, \"3\": {\"effect\": 0.10744809183716225, \"value\": -1.085856588079425}, \"4\": {\"effect\": 0.008586189416529978, \"value\": 0.0}, \"5\": {\"effect\": -0.23468180702498442, \"value\": 0.0}, \"6\": {\"effect\": 0.04565817373910473, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.367732524124064, \"value\": 0.9}, \"8\": {\"effect\": 0.26630800390280096, \"value\": 1.0}, \"9\": {\"effect\": 0.06665523160657731, \"value\": 0.0001493216786865}, \"10\": {\"effect\": -0.15690432233494103, \"value\": 0.2457179970395381}, \"11\": {\"effect\": 0.04736760216432255, \"value\": 1.0}, \"12\": {\"effect\": 0.09915339236506933, \"value\": -0.3945864777926284}, \"13\": {\"effect\": 0.5319871938360007, \"value\": 1.0}, \"14\": {\"effect\": 0.03572938650736309, \"value\": 1.0}, \"15\": {\"effect\": -0.12801106271586016, \"value\": 1.0}, \"16\": {\"effect\": 0.309508369634321, \"value\": 0.0}, \"17\": {\"effect\": 0.0012512997669428668, \"value\": 1.0}, \"18\": {\"effect\": 0.07500706098532318, \"value\": 3.0}, \"19\": {\"effect\": 0.07575259112906622, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.041554306618169695, \"value\": 0.9}, \"21\": {\"effect\": -0.10455557712219855, \"value\": 0.2457179970395381}, \"22\": {\"effect\": 0.1541056121570451, \"value\": 0.0252950701814086}, \"23\": {\"effect\": -0.3570526575378419, \"value\": -1.3617048675647152}, \"24\": {\"effect\": 0.05414992477463684, \"value\": 7.0}, \"25\": {\"effect\": 0.13567331715067876, \"value\": 3.0}, \"26\": {\"effect\": -0.25761211837154074, \"value\": -0.4591047241422481}, \"27\": {\"effect\": 0.005351252798208744, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.07427963177403647, \"value\": -0.1969288228443723}, \"29\": {\"effect\": 0.07697611305026011, \"value\": -0.998325770249054}, \"30\": {\"effect\": -0.331466950712484, \"value\": -1.482682347048874}, \"31\": {\"effect\": 0.020549482561872296, \"value\": -0.3945864777926284}, \"32\": {\"effect\": 0.04709173338936009, \"value\": 0.0001493216786865}, \"33\": {\"effect\": 0.21389827674524575, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.01182317719926454, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.23170372627878588, \"value\": 0.3498625449969868}, \"36\": {\"effect\": 0.020536892260462774, \"value\": -1.085856588079425}, \"37\": {\"effect\": 0.02843112278262435, \"value\": 0.0}, \"38\": {\"effect\": 0.0006081846902858877, \"value\": 0.0}, \"39\": {\"effect\": 0.06164073542660204, \"value\": 2.0}}}, {\"outValue\": 4.6216407489647295, \"simIndex\": 74.0, \"features\": {\"0\": {\"effect\": 0.31228642544051016, \"value\": 0.0}, \"1\": {\"effect\": 0.021936086850332596, \"value\": 1.0}, \"2\": {\"effect\": -0.05262009240145442, \"value\": 0.0}, \"3\": {\"effect\": -0.10486575737429173, \"value\": 1.689229924199091}, \"4\": {\"effect\": 0.008475246259264732, \"value\": 0.0}, \"5\": {\"effect\": -0.23838592645917817, \"value\": 0.0}, \"6\": {\"effect\": 0.026264697243992503, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.3933514579967045, \"value\": 0.1}, \"8\": {\"effect\": 0.2874537558805457, \"value\": 1.0}, \"9\": {\"effect\": 0.07404401279331053, \"value\": -0.6456436183403508}, \"10\": {\"effect\": -0.08886849877556673, \"value\": 0.2367375134743228}, \"11\": {\"effect\": 0.05140268464030582, \"value\": 1.0}, \"12\": {\"effect\": 0.10521153697510989, \"value\": -0.035598249591538}, \"13\": {\"effect\": -0.3451397183988213, \"value\": 0.0}, \"14\": {\"effect\": 0.03891994290094825, \"value\": 1.0}, \"15\": {\"effect\": 0.41157521019832594, \"value\": 2.0}, \"16\": {\"effect\": 0.3487737158528601, \"value\": 0.0}, \"17\": {\"effect\": 0.00035489331559354284, \"value\": 1.0}, \"18\": {\"effect\": 0.15085990876668107, \"value\": 2.0}, \"19\": {\"effect\": 0.07561848589454503, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.03605490769242197, \"value\": 0.1}, \"21\": {\"effect\": -0.07464138636688683, \"value\": 0.2367375134743228}, \"22\": {\"effect\": 0.17947280917808597, \"value\": 0.0238485145273115}, \"23\": {\"effect\": -0.2376035042459961, \"value\": -1.2228462797250872}, \"24\": {\"effect\": 0.00810486086973692, \"value\": 4.0}, \"25\": {\"effect\": 0.17917336099232123, \"value\": 2.0}, \"26\": {\"effect\": -0.27936516268607997, \"value\": -0.4930388594942424}, \"27\": {\"effect\": 0.020730732763664078, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0031261037932021267, \"value\": -0.2071059758824562}, \"29\": {\"effect\": -0.11232648942456028, \"value\": 0.8991030004259764}, \"30\": {\"effect\": 0.09975446359337004, \"value\": 0.0087181634713361}, \"31\": {\"effect\": 0.010135971437566157, \"value\": -0.035598249591538}, \"32\": {\"effect\": -0.019640661692931428, \"value\": -0.6456436183403508}, \"33\": {\"effect\": 0.056738636990500246, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.004058792379012364, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.07001828788255679, \"value\": -0.5760364994583359}, \"36\": {\"effect\": -0.04177705493673955, \"value\": 1.689229924199091}, \"37\": {\"effect\": 0.03454838124755832, \"value\": 0.0}, \"38\": {\"effect\": 0.0021388353290466306, \"value\": 0.0}, \"39\": {\"effect\": 0.28167407519284393, \"value\": 2.0}}}, {\"outValue\": 2.4302899388200676, \"simIndex\": 93.0, \"features\": {\"0\": {\"effect\": 0.2823901189216362, \"value\": 0.0}, \"1\": {\"effect\": 0.009353343058701225, \"value\": 1.0}, \"2\": {\"effect\": 0.17978252374439624, \"value\": 1.0}, \"3\": {\"effect\": 0.055285813064460725, \"value\": -0.5954918387771643}, \"4\": {\"effect\": 0.009432272342035008, \"value\": 0.0}, \"5\": {\"effect\": -0.21792756223285692, \"value\": 0.0}, \"6\": {\"effect\": 0.03907040127393089, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2587844846217424, \"value\": 0.3}, \"8\": {\"effect\": -0.2667530500995764, \"value\": 0.0}, \"9\": {\"effect\": -0.021664933057796827, \"value\": -0.7030474352309318}, \"10\": {\"effect\": -0.333460664637793, \"value\": 0.2198051685074796}, \"11\": {\"effect\": -0.014444271058446999, \"value\": 0.0}, \"12\": {\"effect\": -0.021435812557490837, \"value\": 3.508594621557409}, \"13\": {\"effect\": -0.473590327031045, \"value\": 0.0}, \"14\": {\"effect\": 0.02794631497144301, \"value\": 1.0}, \"15\": {\"effect\": 0.8008265802464268, \"value\": 4.0}, \"16\": {\"effect\": 0.3925084583433926, \"value\": 0.0}, \"17\": {\"effect\": 0.0001254345974832613, \"value\": 1.0}, \"18\": {\"effect\": -0.5071442276891642, \"value\": 1.0}, \"19\": {\"effect\": 0.07120199671044793, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.020770773667508555, \"value\": 0.3}, \"21\": {\"effect\": -0.08892665908746392, \"value\": 0.2198051685074796}, \"22\": {\"effect\": 0.28370522015794575, \"value\": 0.038785277333971}, \"23\": {\"effect\": -0.1743582229532167, \"value\": -1.1389610770169014}, \"24\": {\"effect\": 0.06654571643254817, \"value\": 7.0}, \"25\": {\"effect\": -0.6545900538612023, \"value\": 1.0}, \"26\": {\"effect\": -0.581730314698427, \"value\": 0.1743324690949794}, \"27\": {\"effect\": 0.030215789579392863, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0073931294095102755, \"value\": -0.6722742045783877}, \"29\": {\"effect\": 0.003913938597212459, \"value\": -0.2725369192404879}, \"30\": {\"effect\": 0.1176525129835476, \"value\": -0.6087069762390762}, \"31\": {\"effect\": -0.024107873965695397, \"value\": 3.508594621557409}, \"32\": {\"effect\": 0.01102244926739296, \"value\": -0.7030474352309318}, \"33\": {\"effect\": 0.05349071686518352, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.0023073475230989, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.13034184119633155, \"value\": -0.6930771914744531}, \"36\": {\"effect\": 0.019980924377942504, \"value\": -0.5954918387771643}, \"37\": {\"effect\": 0.029420072462880354, \"value\": 0.0}, \"38\": {\"effect\": 0.0015609966353302403, \"value\": 0.0}, \"39\": {\"effect\": -0.15072450521049444, \"value\": 3.0}}}, {\"outValue\": 6.009520553699566, \"simIndex\": 41.0, \"features\": {\"0\": {\"effect\": 0.38999379301978776, \"value\": 0.0}, \"1\": {\"effect\": 0.01838407402283338, \"value\": 1.0}, \"2\": {\"effect\": 0.13738785758082409, \"value\": 1.0}, \"3\": {\"effect\": -0.03749783912192692, \"value\": -0.2672557996904581}, \"4\": {\"effect\": 0.007183030702096203, \"value\": 0.0}, \"5\": {\"effect\": 0.9551193798869114, \"value\": 1.0}, \"6\": {\"effect\": 0.03362030789707469, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.10095854146993682, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.32833900208107647, \"value\": 1.0}, \"9\": {\"effect\": 0.202558421944528, \"value\": -0.1290092663251209}, \"10\": {\"effect\": -0.2864387367369931, \"value\": 0.207584200764263}, \"11\": {\"effect\": -0.04051590213481738, \"value\": 0.0}, \"12\": {\"effect\": -0.2020933973927921, \"value\": -0.3967621640241502}, \"13\": {\"effect\": -0.27015107342230177, \"value\": 0.0}, \"14\": {\"effect\": 0.03773638159142572, \"value\": 1.0}, \"15\": {\"effect\": -0.11700723392086658, \"value\": 1.0}, \"16\": {\"effect\": 0.3495532461194521, \"value\": 0.0}, \"17\": {\"effect\": 0.000831491886277574, \"value\": 1.0}, \"18\": {\"effect\": 0.08912191154480506, \"value\": 3.0}, \"19\": {\"effect\": 0.023919063879059253, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.019758368666535436, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.10174802140421792, \"value\": 0.207584200764263}, \"22\": {\"effect\": -0.06667601602493922, \"value\": 0.015605598808693}, \"23\": {\"effect\": 0.36876382402953456, \"value\": 10.961761672491374}, \"24\": {\"effect\": 0.010533972446416802, \"value\": 6.0}, \"25\": {\"effect\": 0.13364758703183657, \"value\": 3.0}, \"26\": {\"effect\": 0.26627651061803387, \"value\": -0.5495957517475664}, \"27\": {\"effect\": -0.006761846050186127, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.07831410261932768, \"value\": 0.6341739535559496}, \"29\": {\"effect\": -0.04057679549507225, \"value\": 0.3539359763818452}, \"30\": {\"effect\": 0.4186065760484427, \"value\": -0.4703895986064898}, \"31\": {\"effect\": 0.0014159850427847105, \"value\": -0.3967621640241502}, \"32\": {\"effect\": 0.02566344274819479, \"value\": -0.1290092663251209}, \"33\": {\"effect\": 0.15682795607575264, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.005037189059606283, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.007427909896855853, \"value\": -0.2156481959082472}, \"36\": {\"effect\": 0.008592537151174398, \"value\": -0.2672557996904581}, \"37\": {\"effect\": 0.026457147498362466, \"value\": 0.0}, \"38\": {\"effect\": 0.0024909552868425627, \"value\": 0.0}, \"39\": {\"effect\": 0.1145621051954912, \"value\": 2.0}}}, {\"outValue\": 5.177038489473772, \"simIndex\": 53.0, \"features\": {\"0\": {\"effect\": 0.324216904821057, \"value\": 0.0}, \"1\": {\"effect\": 0.05510012162104141, \"value\": 1.0}, \"2\": {\"effect\": -0.08179625214669249, \"value\": 0.0}, \"3\": {\"effect\": -0.006927376554829687, \"value\": -0.3756731580554611}, \"4\": {\"effect\": 0.01199178689740032, \"value\": 0.0}, \"5\": {\"effect\": 0.645951005260239, \"value\": 1.0}, \"6\": {\"effect\": 0.04663822619036232, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.0828573005336889, \"value\": 0.6000000000000001}, \"8\": {\"effect\": -0.3776481837722011, \"value\": 0.0}, \"9\": {\"effect\": -0.037176235381922405, \"value\": 0.3015193603542372}, \"10\": {\"effect\": 0.29679602002426564, \"value\": 0.9960355006330058}, \"11\": {\"effect\": 0.08100675438255255, \"value\": 1.0}, \"12\": {\"effect\": 0.030983926627955016, \"value\": -0.3140860872263233}, \"13\": {\"effect\": 0.4040285249111097, \"value\": 1.0}, \"14\": {\"effect\": 0.04158258909949839, \"value\": 1.0}, \"15\": {\"effect\": 0.3087394656111782, \"value\": 2.0}, \"16\": {\"effect\": 0.32726245761655015, \"value\": 0.0}, \"17\": {\"effect\": 0.0016301077984435352, \"value\": 1.0}, \"18\": {\"effect\": -0.4790635915159648, \"value\": 1.0}, \"19\": {\"effect\": 0.1044372733011229, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.0026389928226045354, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.1370790905462105, \"value\": 0.9960355006330058}, \"22\": {\"effect\": 0.07144331997800983, \"value\": 0.0063754197168118}, \"23\": {\"effect\": 0.09362382014861337, \"value\": -0.5625651631618891}, \"24\": {\"effect\": 0.6634375093788448, \"value\": 31.0}, \"25\": {\"effect\": -0.39933530097969844, \"value\": 1.0}, \"26\": {\"effect\": -0.5269907816666624, \"value\": 0.5136738226149228}, \"27\": {\"effect\": 0.012358672930776048, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.19574529788655834, \"value\": 1.2685570047491672}, \"29\": {\"effect\": -0.06967126318868773, \"value\": -0.0697467373509096}, \"30\": {\"effect\": 0.05464148984811117, \"value\": -0.020013983730829}, \"31\": {\"effect\": 0.0072499172197999315, \"value\": -0.3140860872263233}, \"32\": {\"effect\": 0.01745529896371894, \"value\": 0.3015193603542372}, \"33\": {\"effect\": 0.07954737505781288, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.006068137151463783, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.13344026074429594, \"value\": -0.2361290772280217}, \"36\": {\"effect\": 0.016146588696905707, \"value\": -0.3756731580554611}, \"37\": {\"effect\": 0.029883411015379308, \"value\": 0.0}, \"38\": {\"effect\": 0.001360060492355376, \"value\": 0.0}, \"39\": {\"effect\": 0.19089085814778606, \"value\": 2.0}}}, {\"outValue\": 3.4874826815371116, \"simIndex\": 76.0, \"features\": {\"0\": {\"effect\": 0.30505526368210456, \"value\": 0.0}, \"1\": {\"effect\": 0.022145163120603772, \"value\": 1.0}, \"2\": {\"effect\": 0.16593077759383387, \"value\": 1.0}, \"3\": {\"effect\": -0.04400129577465222, \"value\": 1.5579355085644082}, \"4\": {\"effect\": 0.0011696930083877502, \"value\": 0.0}, \"5\": {\"effect\": -0.2217480945669292, \"value\": 0.0}, \"6\": {\"effect\": 0.004649924751941438, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.030206753343961907, \"value\": 0.8}, \"8\": {\"effect\": 0.3102994314384552, \"value\": 1.0}, \"9\": {\"effect\": 0.045007462167916575, \"value\": -0.4734321676686074}, \"10\": {\"effect\": -0.07863462519432947, \"value\": 0.2358480576693369}, \"11\": {\"effect\": -0.03726698735087678, \"value\": 0.0}, \"12\": {\"effect\": -0.22156314672916108, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.3200226753501078, \"value\": 0.0}, \"14\": {\"effect\": 0.02899839193337384, \"value\": 1.0}, \"15\": {\"effect\": -0.16925421051313927, \"value\": 1.0}, \"16\": {\"effect\": 0.40073711001957096, \"value\": 0.0}, \"17\": {\"effect\": 0.0009421717808425382, \"value\": 1.0}, \"18\": {\"effect\": 0.10006677779061858, \"value\": 3.0}, \"19\": {\"effect\": 0.07481881033427372, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.0065473998880148715, \"value\": 0.8}, \"21\": {\"effect\": -0.12392267900642827, \"value\": 0.2358480576693369}, \"22\": {\"effect\": -0.1056358826779543, \"value\": 0.0105795406477229}, \"23\": {\"effect\": -0.1449071409897119, \"value\": -1.5599453563318753}, \"24\": {\"effect\": 0.1205999500763725, \"value\": 13.0}, \"25\": {\"effect\": 0.14853065107476937, \"value\": 3.0}, \"26\": {\"effect\": 0.18634260297616723, \"value\": -0.5722185086488959}, \"27\": {\"effect\": -0.006307215238960719, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.12124431439255409, \"value\": 1.0976247146913525}, \"29\": {\"effect\": 0.06478924195447584, \"value\": -0.2746072325378001}, \"30\": {\"effect\": -0.3586308167954585, \"value\": 1.994694663559877}, \"31\": {\"effect\": -0.05234061642111015, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.04127058289801228, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.13997996606734306, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.021635839511360194, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.11120809505714141, \"value\": -0.7232988069805538}, \"36\": {\"effect\": -0.02662461254044869, \"value\": 1.5579355085644082}, \"37\": {\"effect\": 0.029899323240289283, \"value\": 0.0}, \"38\": {\"effect\": 0.002991095558057289, \"value\": 0.0}, \"39\": {\"effect\": 0.09795381085923967, \"value\": 1.0}}}, {\"outValue\": 4.032685470106209, \"simIndex\": 48.0, \"features\": {\"0\": {\"effect\": 0.25496189537727804, \"value\": 0.0}, \"1\": {\"effect\": -0.15882745946041854, \"value\": 0.0}, \"2\": {\"effect\": -0.04667690923364266, \"value\": 0.0}, \"3\": {\"effect\": -0.01160700329289532, \"value\": -0.3925822873417459}, \"4\": {\"effect\": 0.014020220659166248, \"value\": 0.0}, \"5\": {\"effect\": 0.8008006033087288, \"value\": 1.0}, \"6\": {\"effect\": 0.053791090936647024, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.37460834936349235, \"value\": 0.9}, \"8\": {\"effect\": 0.303768937520575, \"value\": 1.0}, \"9\": {\"effect\": 0.1265608619495202, \"value\": -0.3729754881100905}, \"10\": {\"effect\": -0.16535594724453084, \"value\": 0.2814096278091333}, \"11\": {\"effect\": -0.021584868584933012, \"value\": 1.0}, \"12\": {\"effect\": 0.15962655980241258, \"value\": -0.361951184319802}, \"13\": {\"effect\": 0.5018788434934744, \"value\": 1.0}, \"14\": {\"effect\": 0.04268765238935479, \"value\": 1.0}, \"15\": {\"effect\": 0.26384369934551494, \"value\": 2.0}, \"16\": {\"effect\": -0.3047459354982945, \"value\": 1.0}, \"17\": {\"effect\": 0.0018759002320408247, \"value\": 1.0}, \"18\": {\"effect\": 0.04332336834861271, \"value\": 3.0}, \"19\": {\"effect\": 0.04035360904829876, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.052775136144468104, \"value\": 0.9}, \"21\": {\"effect\": -0.0137933493436209, \"value\": 0.2814096278091333}, \"22\": {\"effect\": -0.026240318864923902, \"value\": 0.0184864614604537}, \"23\": {\"effect\": -0.13837043671754287, \"value\": -0.9979067238215336}, \"24\": {\"effect\": 0.055025664422949046, \"value\": 7.0}, \"25\": {\"effect\": 0.12929496452997882, \"value\": 3.0}, \"26\": {\"effect\": -0.6204617118546969, \"value\": 0.095152819940326}, \"27\": {\"effect\": 0.01729834606958057, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.11195150390846267, \"value\": -1.573032859936922}, \"29\": {\"effect\": -0.16092935396838995, \"value\": 0.3982780924728248}, \"30\": {\"effect\": -0.19100937538626075, \"value\": -0.7036709555824625}, \"31\": {\"effect\": 0.02597138485998361, \"value\": -0.361951184319802}, \"32\": {\"effect\": 0.04863968286729785, \"value\": -0.3729754881100905}, \"33\": {\"effect\": 0.2227810930884648, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.004448945220265673, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10073693418781485, \"value\": -0.5341016278719797}, \"36\": {\"effect\": 0.022183547135950592, \"value\": -0.3925822873417459}, \"37\": {\"effect\": 0.026409021949589637, \"value\": 0.0}, \"38\": {\"effect\": 0.00019028269763363056, \"value\": 0.0}, \"39\": {\"effect\": 0.07781537536251723, \"value\": 2.0}}}, {\"outValue\": 5.701498636761572, \"simIndex\": 27.0, \"features\": {\"0\": {\"effect\": 0.28156541261238727, \"value\": 0.0}, \"1\": {\"effect\": -0.1051618776465214, \"value\": 0.0}, \"2\": {\"effect\": 0.2666786384445637, \"value\": 1.0}, \"3\": {\"effect\": -0.24431714901109025, \"value\": 0.6150028871880522}, \"4\": {\"effect\": 0.00723638705534717, \"value\": 0.0}, \"5\": {\"effect\": -0.2551646624522858, \"value\": 0.0}, \"6\": {\"effect\": 0.04686053551000441, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2844791774598549, \"value\": 0.3}, \"8\": {\"effect\": 0.3001549644865585, \"value\": 1.0}, \"9\": {\"effect\": 0.08535363692336062, \"value\": -1.1048741534649995}, \"10\": {\"effect\": 0.06994638779937781, \"value\": 0.7496201246436558}, \"11\": {\"effect\": -0.06149756714476196, \"value\": 0.0}, \"12\": {\"effect\": -0.17177324821434245, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.31796629887730515, \"value\": 0.0}, \"14\": {\"effect\": 0.04289228606127221, \"value\": 1.0}, \"15\": {\"effect\": -0.14919804697424552, \"value\": 1.0}, \"16\": {\"effect\": 0.3717186707886818, \"value\": 0.0}, \"17\": {\"effect\": 0.002789782223711051, \"value\": 1.0}, \"18\": {\"effect\": 0.17830357008527414, \"value\": 2.0}, \"19\": {\"effect\": 0.10741615086878052, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.019390532043378986, \"value\": 0.3}, \"21\": {\"effect\": 0.04781899024291624, \"value\": 0.7496201246436558}, \"22\": {\"effect\": 0.1657936591552654, \"value\": 7.486059015267934}, \"23\": {\"effect\": 0.04186922883296603, \"value\": -0.904860461188404}, \"24\": {\"effect\": 0.03265783029774338, \"value\": 13.0}, \"25\": {\"effect\": 0.1922141719870875, \"value\": 2.0}, \"26\": {\"effect\": 1.0379254647648197, \"value\": -0.8663143483661802}, \"27\": {\"effect\": 0.06407786367070387, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.049074279008518136, \"value\": -0.9236426063415026}, \"29\": {\"effect\": 0.09620438798366766, \"value\": 0.0033490954805646}, \"30\": {\"effect\": 0.06798090519587678, \"value\": 0.7500986386270642}, \"31\": {\"effect\": -0.010005165736417382, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.01810185782086106, \"value\": -1.1048741534649995}, \"33\": {\"effect\": -0.03225914943706166, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.001891646691612612, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.18777757707929016, \"value\": 0.2637175924365599}, \"36\": {\"effect\": -0.09362362603478483, \"value\": 0.6150028871880522}, \"37\": {\"effect\": 0.026947638841246065, \"value\": 0.0}, \"38\": {\"effect\": 0.0029471660204483446, \"value\": 0.0}, \"39\": {\"effect\": -0.02650887639302418, \"value\": 1.0}}}, {\"outValue\": 3.009775708382617, \"simIndex\": 89.0, \"features\": {\"0\": {\"effect\": 0.27044496847390453, \"value\": 0.0}, \"1\": {\"effect\": 0.040083296245839145, \"value\": 1.0}, \"2\": {\"effect\": -0.07527260837401643, \"value\": 0.0}, \"3\": {\"effect\": 0.040446300884576146, \"value\": -0.2901328569601376}, \"4\": {\"effect\": 0.020907599098392553, \"value\": 0.0}, \"5\": {\"effect\": -0.2227211514925479, \"value\": 0.0}, \"6\": {\"effect\": 0.031511389535595145, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.07714235787726133, \"value\": 0.7000000000000001}, \"8\": {\"effect\": -0.3757140411752506, \"value\": 0.0}, \"9\": {\"effect\": 0.019977909641304338, \"value\": -0.4447302592233169}, \"10\": {\"effect\": -0.39510541457385145, \"value\": 0.153754379736744}, \"11\": {\"effect\": 0.04583825658423274, \"value\": 1.0}, \"12\": {\"effect\": 0.074364485764659, \"value\": -0.3641268705513238}, \"13\": {\"effect\": 0.6306858959222768, \"value\": 1.0}, \"14\": {\"effect\": 0.03861515042159129, \"value\": 1.0}, \"15\": {\"effect\": -0.11878240933463743, \"value\": 1.0}, \"16\": {\"effect\": 0.3403322447277324, \"value\": 0.0}, \"17\": {\"effect\": 0.0014828676714600242, \"value\": 1.0}, \"18\": {\"effect\": 0.33994420413020593, \"value\": 5.0}, \"19\": {\"effect\": 0.07866383085610308, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.01944387761850857, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.1782860398641028, \"value\": 0.153754379736744}, \"22\": {\"effect\": 0.006382283204096937, \"value\": 0.0076284236411141}, \"23\": {\"effect\": -0.21212520127589776, \"value\": -1.1552254298079605}, \"24\": {\"effect\": 0.01773775805105084, \"value\": 10.0}, \"25\": {\"effect\": 0.2485430842294154, \"value\": 5.0}, \"26\": {\"effect\": -0.1464011735077165, \"value\": 0.7512127700788831}, \"27\": {\"effect\": 0.019720892176729173, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.05494403309171789, \"value\": 0.3802047432886652}, \"29\": {\"effect\": -0.11122414205958339, \"value\": 0.1563581062758069}, \"30\": {\"effect\": 0.1765749030290184, \"value\": 0.3827972232978841}, \"31\": {\"effect\": 0.0508650904241019, \"value\": -0.3641268705513238}, \"32\": {\"effect\": 0.03632976250111093, \"value\": -0.4447302592233169}, \"33\": {\"effect\": -0.6072961654712035, \"value\": 1.5813241721969604}, \"34\": {\"effect\": 0.0025573875382690577, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.14501230359886547, \"value\": -0.4958037814224769}, \"36\": {\"effect\": 0.008994525466844134, \"value\": -0.2901328569601376}, \"37\": {\"effect\": 0.035844430834621396, \"value\": 0.0}, \"38\": {\"effect\": 0.0010840080579979543, \"value\": 0.0}, \"39\": {\"effect\": -0.05387611825571016, \"value\": 1.0}}}, {\"outValue\": 1.2027570102799108, \"simIndex\": 64.0, \"features\": {\"0\": {\"effect\": 0.3140858261896037, \"value\": 0.0}, \"1\": {\"effect\": 0.01554552275707224, \"value\": 1.0}, \"2\": {\"effect\": -0.06091423448432739, \"value\": 0.0}, \"3\": {\"effect\": 0.08710134831311993, \"value\": -0.3945715966695441}, \"4\": {\"effect\": 0.008629802356394867, \"value\": 0.0}, \"5\": {\"effect\": -0.2706905871651419, \"value\": 0.0}, \"6\": {\"effect\": 0.03501633955934526, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.5414016716276763, \"value\": 0.9}, \"8\": {\"effect\": -0.312671695105693, \"value\": 0.0}, \"9\": {\"effect\": 0.09157968136110492, \"value\": -0.6312926641177055}, \"10\": {\"effect\": -0.3878373888891625, \"value\": 0.0657063291874649}, \"11\": {\"effect\": 0.033350380972638115, \"value\": 1.0}, \"12\": {\"effect\": 0.042117489510011645, \"value\": -0.3837080466350197}, \"13\": {\"effect\": -0.4223703605083139, \"value\": 0.0}, \"14\": {\"effect\": 0.0355498059990964, \"value\": 1.0}, \"15\": {\"effect\": -0.16034214826916912, \"value\": 1.0}, \"16\": {\"effect\": 0.3548380190461825, \"value\": 0.0}, \"17\": {\"effect\": 0.0008939072933007652, \"value\": 1.0}, \"18\": {\"effect\": 0.13394917618229402, \"value\": 2.0}, \"19\": {\"effect\": 0.025878418570626706, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.03304105129569488, \"value\": 0.9}, \"21\": {\"effect\": -0.12651712490643366, \"value\": 0.0657063291874649}, \"22\": {\"effect\": -0.040219164249284914, \"value\": 0.0150663426552952}, \"23\": {\"effect\": -0.1390516518457152, \"value\": -0.8998996930614878}, \"24\": {\"effect\": 0.047942230319234724, \"value\": 15.0}, \"25\": {\"effect\": 0.18430310739587688, \"value\": 2.0}, \"26\": {\"effect\": -0.7350196554438531, \"value\": -0.312056804283606}, \"27\": {\"effect\": 0.005266643448707786, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.039746248072188156, \"value\": -0.8247228699094711}, \"29\": {\"effect\": -0.1145021777562725, \"value\": 1.6416079520855889}, \"30\": {\"effect\": 0.15573845184865823, \"value\": 0.0979961663942158}, \"31\": {\"effect\": 0.01778886761010282, \"value\": -0.3837080466350197}, \"32\": {\"effect\": 0.021984768754202928, \"value\": -0.6312926641177055}, \"33\": {\"effect\": -0.22303699181422604, \"value\": 1.16867629926286}, \"34\": {\"effect\": 0.021211239716110667, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1450679321217467, \"value\": -0.4334828104224658}, \"36\": {\"effect\": 0.01188500889353031, \"value\": -0.3945715966695441}, \"37\": {\"effect\": 0.03920251298895806, \"value\": 0.0}, \"38\": {\"effect\": 0.003066859959587236, \"value\": 0.0}, \"39\": {\"effect\": 0.19735618006121297, \"value\": 2.0}}}, {\"outValue\": 3.107136583713614, \"simIndex\": 75.0, \"features\": {\"0\": {\"effect\": 0.30597218110137225, \"value\": 0.0}, \"1\": {\"effect\": 0.01707487581451461, \"value\": 1.0}, \"2\": {\"effect\": -0.07153283786539728, \"value\": 0.0}, \"3\": {\"effect\": 0.049762001908302864, \"value\": 2.782355399824212}, \"4\": {\"effect\": 0.005876746657476922, \"value\": 0.0}, \"5\": {\"effect\": -0.25276863468772276, \"value\": 0.0}, \"6\": {\"effect\": -0.010144291608924463, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.1211260569571406, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.3044644939897424, \"value\": 1.0}, \"9\": {\"effect\": 0.11480743789406782, \"value\": -0.2438169001062831}, \"10\": {\"effect\": -0.24370442978960694, \"value\": 0.2000865281438929}, \"11\": {\"effect\": -0.0032200987919126472, \"value\": 1.0}, \"12\": {\"effect\": -0.18685679011324566, \"value\": 3.417215799833495}, \"13\": {\"effect\": -0.3480843577449812, \"value\": 0.0}, \"14\": {\"effect\": 0.0351489786357815, \"value\": 1.0}, \"15\": {\"effect\": 0.22575270680420112, \"value\": 2.0}, \"16\": {\"effect\": 0.3734552162481639, \"value\": 0.0}, \"17\": {\"effect\": 0.001595924689634645, \"value\": 1.0}, \"18\": {\"effect\": 0.4329451610840965, \"value\": 5.0}, \"19\": {\"effect\": 0.008282381700610896, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.010586317300141278, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.15406815363734142, \"value\": 0.2000865281438929}, \"22\": {\"effect\": 0.017259736653880232, \"value\": 0.008723130333755}, \"23\": {\"effect\": -0.05103079429912439, \"value\": -0.8403255387099654}, \"24\": {\"effect\": 0.06413602799460773, \"value\": 14.0}, \"25\": {\"effect\": 0.22968121634072253, \"value\": 5.0}, \"26\": {\"effect\": -0.6641394144462968, \"value\": 0.2422007397989681}, \"27\": {\"effect\": -0.006542682344195215, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.027055653728696904, \"value\": -0.4242432627811128}, \"29\": {\"effect\": -0.07661872784919502, \"value\": 0.2150558160978708}, \"30\": {\"effect\": -0.16600483828058366, \"value\": 1.6846213834143553}, \"31\": {\"effect\": -0.06635556099355377, \"value\": 3.417215799833495}, \"32\": {\"effect\": 0.035959122747567594, \"value\": -0.2438169001062831}, \"33\": {\"effect\": 0.03476473969190871, \"value\": -0.5644447670603625}, \"34\": {\"effect\": 0.002051391757079425, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1541990895717223, \"value\": -0.4762974766720713}, \"36\": {\"effect\": -0.051392705085931294, \"value\": 2.782355399824212}, \"37\": {\"effect\": 0.03569394236520123, \"value\": 0.0}, \"38\": {\"effect\": 0.0026403633433595254, \"value\": 0.0}, \"39\": {\"effect\": 0.1079744452875237, \"value\": 1.0}}}, {\"outValue\": 4.4507963049005355, \"simIndex\": 80.0, \"features\": {\"0\": {\"effect\": 0.265346344130972, \"value\": 0.0}, \"1\": {\"effect\": 0.02630628581084167, \"value\": 1.0}, \"2\": {\"effect\": -0.1337361614083485, \"value\": 0.0}, \"3\": {\"effect\": -0.2629614714080008, \"value\": 0.3195904520100166}, \"4\": {\"effect\": 0.020301518427479112, \"value\": 0.0}, \"5\": {\"effect\": -0.26202602262079666, \"value\": 0.0}, \"6\": {\"effect\": 0.0379454493389798, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.32469658048787825, \"value\": 0.2}, \"8\": {\"effect\": 0.2759464792297019, \"value\": 1.0}, \"9\": {\"effect\": 0.44498905235257274, \"value\": -2.0950899948275232}, \"10\": {\"effect\": -0.07981967808469556, \"value\": 0.9003346540356256}, \"11\": {\"effect\": 0.019979223906458524, \"value\": 1.0}, \"12\": {\"effect\": -0.13041169100909558, \"value\": -0.3967621640241502}, \"13\": {\"effect\": 0.5221144220427609, \"value\": 1.0}, \"14\": {\"effect\": 0.04968636622462515, \"value\": 1.0}, \"15\": {\"effect\": -0.13712462833877542, \"value\": 1.0}, \"16\": {\"effect\": 0.26083482570612243, \"value\": 0.0}, \"17\": {\"effect\": 0.0013228595668173702, \"value\": 1.0}, \"18\": {\"effect\": 0.034513908947238936, \"value\": 3.0}, \"19\": {\"effect\": 0.0939892439459008, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.017067899386164414, \"value\": 0.2}, \"21\": {\"effect\": 0.06142279793043402, \"value\": 0.9003346540356256}, \"22\": {\"effect\": -0.24342516441025852, \"value\": 15.970416979977465}, \"23\": {\"effect\": 0.18794842133023262, \"value\": 32.60600133487275}, \"24\": {\"effect\": -0.004624851992852779, \"value\": 7.0}, \"25\": {\"effect\": 0.10859813574828041, \"value\": 3.0}, \"26\": {\"effect\": -0.7434638755357591, \"value\": -0.2441885335796173}, \"27\": {\"effect\": 0.042939285164371066, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.05761111994537815, \"value\": -0.5889210887132186}, \"29\": {\"effect\": 0.1484242759612897, \"value\": 1.7809694988143827}, \"30\": {\"effect\": 0.03257439531449704, \"value\": 0.7711248280880857}, \"31\": {\"effect\": -0.0009111305121191507, \"value\": -0.3967621640241502}, \"32\": {\"effect\": 0.17466808309048304, \"value\": -2.0950899948275232}, \"33\": {\"effect\": 0.07233900252695763, \"value\": 0.3433805533946588}, \"34\": {\"effect\": -0.00015501483929983997, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.036582566617652384, \"value\": -0.225396153699623}, \"36\": {\"effect\": -0.04424576311132331, \"value\": 0.3195904520100166}, \"37\": {\"effect\": 0.03652164965408098, \"value\": 0.0}, \"38\": {\"effect\": 0.0016505182750527145, \"value\": 0.0}, \"39\": {\"effect\": 0.06647554238080093, \"value\": 1.0}}}, {\"outValue\": 4.342412558222022, \"simIndex\": 30.0, \"features\": {\"0\": {\"effect\": 0.28739674997941766, \"value\": 0.0}, \"1\": {\"effect\": 0.02304421938766428, \"value\": 1.0}, \"2\": {\"effect\": 0.17786901501768188, \"value\": 1.0}, \"3\": {\"effect\": -0.22721369912248354, \"value\": 0.767185050764616}, \"4\": {\"effect\": 0.008590516140183892, \"value\": 0.0}, \"5\": {\"effect\": -0.2521586428052903, \"value\": 0.0}, \"6\": {\"effect\": 0.024130640946674872, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.3310924683821493, \"value\": 0.1}, \"8\": {\"effect\": 0.37512124251307516, \"value\": 1.0}, \"9\": {\"effect\": 0.09847952684686091, \"value\": -0.9900665196838372}, \"10\": {\"effect\": 0.09014941148651047, \"value\": 0.7474859016020629}, \"11\": {\"effect\": -0.02793734065951328, \"value\": 0.0}, \"12\": {\"effect\": -0.1423784050394787, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.2928268823607301, \"value\": 0.0}, \"14\": {\"effect\": 0.04018308065380866, \"value\": 1.0}, \"15\": {\"effect\": -0.1614635582764351, \"value\": 1.0}, \"16\": {\"effect\": -0.28364941512231384, \"value\": 1.0}, \"17\": {\"effect\": 0.0013168114372770895, \"value\": 1.0}, \"18\": {\"effect\": 0.1917545383563968, \"value\": 2.0}, \"19\": {\"effect\": 0.006512483518065209, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.010089292209230466, \"value\": 0.1}, \"21\": {\"effect\": 0.07665553806561073, \"value\": 0.7474859016020629}, \"22\": {\"effect\": 0.0819489495215284, \"value\": 0.0224154686109596}, \"23\": {\"effect\": -0.02281025362617228, \"value\": -0.5909010049000778}, \"24\": {\"effect\": 0.09434806088974027, \"value\": 21.0}, \"25\": {\"effect\": 0.1896602980260585, \"value\": 2.0}, \"26\": {\"effect\": 0.08983184909126393, \"value\": -0.5609071301982311}, \"27\": {\"effect\": -0.013767787661559134, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.086619934944577, \"value\": 0.2208159082669271}, \"29\": {\"effect\": 0.024519777022640285, \"value\": -0.3680086799100812}, \"30\": {\"effect\": 0.20965943625133784, \"value\": 0.9635836267353636}, \"31\": {\"effect\": -0.02990973408835395, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.031613270837395596, \"value\": -0.9900665196838372}, \"33\": {\"effect\": -0.04288245350151894, \"value\": -0.9770926399944632}, \"34\": {\"effect\": -0.0018888316423712546, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.18910613286978778, \"value\": 0.3594479959811}, \"36\": {\"effect\": -0.047668213243130975, \"value\": 0.767185050764616}, \"37\": {\"effect\": 0.0385955445398448, \"value\": 0.0}, \"38\": {\"effect\": 0.0011023747563580367, \"value\": 0.0}, \"39\": {\"effect\": 0.03867110695239739, \"value\": 1.0}}}, {\"outValue\": 1.5440433306086851, \"simIndex\": 95.0, \"features\": {\"0\": {\"effect\": 0.4043271223831457, \"value\": 0.0}, \"1\": {\"effect\": 0.012556093171839961, \"value\": 1.0}, \"2\": {\"effect\": 0.1347493876645987, \"value\": 1.0}, \"3\": {\"effect\": -0.20985516294202636, \"value\": 1.4435502222160106}, \"4\": {\"effect\": 0.006119007084180791, \"value\": 0.0}, \"5\": {\"effect\": -0.19439703696812122, \"value\": 0.0}, \"6\": {\"effect\": -0.028790662573461048, \"value\": 2.01852014148613}, \"7\": {\"effect\": 0.10157881767971265, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.2938303415827737, \"value\": 1.0}, \"9\": {\"effect\": -0.060470801981286404, \"value\": 1.0621199341544367}, \"10\": {\"effect\": -0.3149051080446085, \"value\": 0.1849774831565682}, \"11\": {\"effect\": -0.01932345801587089, \"value\": 0.0}, \"12\": {\"effect\": -0.18912006978394674, \"value\": -0.3967621640241502}, \"13\": {\"effect\": -0.40137560152288726, \"value\": 0.0}, \"14\": {\"effect\": 0.03249742411455406, \"value\": 1.0}, \"15\": {\"effect\": -0.1513499857964474, \"value\": 1.0}, \"16\": {\"effect\": 0.3948936911623289, \"value\": 0.0}, \"17\": {\"effect\": 0.0014648073179973952, \"value\": 1.0}, \"18\": {\"effect\": -0.6028537060508252, \"value\": 1.0}, \"19\": {\"effect\": 0.042952113619587, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.0015922239845267006, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.13261795615380362, \"value\": 0.1849774831565682}, \"22\": {\"effect\": -0.002192343283393745, \"value\": 0.0073156162514227}, \"23\": {\"effect\": 0.3706563697236456, \"value\": 37.240431915681626}, \"24\": {\"effect\": 0.002742027688369131, \"value\": 8.0}, \"25\": {\"effect\": -0.5063397377229928, \"value\": 1.0}, \"26\": {\"effect\": -0.7291718650566283, \"value\": -0.1197633706223047}, \"27\": {\"effect\": -0.004496105737551386, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0802294679083704, \"value\": 1.1644849611143349}, \"29\": {\"effect\": 0.02986784262587907, \"value\": -0.1706537305201994}, \"30\": {\"effect\": 0.10583013187795182, \"value\": 0.0778038021963255}, \"31\": {\"effect\": -0.009795833664802585, \"value\": -0.3967621640241502}, \"32\": {\"effect\": -0.00966663957884825, \"value\": 1.0621199341544367}, \"33\": {\"effect\": 0.1637640244070845, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.019228148392966632, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.1128463177143952, \"value\": -0.4620596339246541}, \"36\": {\"effect\": -0.038605001789049576, \"value\": 1.4435502222160106}, \"37\": {\"effect\": 0.028629848636438384, \"value\": 0.0}, \"38\": {\"effect\": 0.003272594659449033, \"value\": 0.0}, \"39\": {\"effect\": 0.1594449671790691, \"value\": 2.0}}}, {\"outValue\": 4.753092608376793, \"simIndex\": 16.0, \"features\": {\"0\": {\"effect\": 0.23579241817539479, \"value\": 0.0}, \"1\": {\"effect\": 0.0259825316632664, \"value\": 1.0}, \"2\": {\"effect\": -0.09189293401796696, \"value\": 0.0}, \"3\": {\"effect\": -0.321934710297888, \"value\": 0.5324465500844261}, \"4\": {\"effect\": 0.011558395732760917, \"value\": 0.0}, \"5\": {\"effect\": -0.25584516427148085, \"value\": 0.0}, \"6\": {\"effect\": 0.013405246301026078, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.11351487125214837, \"value\": 0.6000000000000001}, \"8\": {\"effect\": 0.2791246417027688, \"value\": 1.0}, \"9\": {\"effect\": -0.09109817050006827, \"value\": 0.6746441701430143}, \"10\": {\"effect\": 0.09523538289360899, \"value\": 0.7758329122947942}, \"11\": {\"effect\": -0.04720887909954432, \"value\": 0.0}, \"12\": {\"effect\": 0.34000341076703017, \"value\": 0.1101727279204198}, \"13\": {\"effect\": 0.6946910203136968, \"value\": 1.0}, \"14\": {\"effect\": 0.040197959040220624, \"value\": 1.0}, \"15\": {\"effect\": -0.0797573445820082, \"value\": 1.0}, \"16\": {\"effect\": 0.3616926336435442, \"value\": 0.0}, \"17\": {\"effect\": 0.0038210487939384823, \"value\": 1.0}, \"18\": {\"effect\": 0.08345823289980617, \"value\": 3.0}, \"19\": {\"effect\": 0.01972681353764248, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.04825923979153381, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.12836671769844876, \"value\": 0.7758329122947942}, \"22\": {\"effect\": -0.046291058766293136, \"value\": 0.0059931653573817}, \"23\": {\"effect\": -0.22780734304381056, \"value\": -1.1883961829346164}, \"24\": {\"effect\": -0.0046922698808126995, \"value\": 9.0}, \"25\": {\"effect\": 0.09393021906324922, \"value\": 3.0}, \"26\": {\"effect\": 1.11233727211586, \"value\": -0.8550029699155153}, \"27\": {\"effect\": 0.012646810461792174, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.11451834720415216, \"value\": -1.3814688789712135}, \"29\": {\"effect\": -0.04359118507297451, \"value\": -1.7032334136973943}, \"30\": {\"effect\": 0.19730308916424308, \"value\": -0.545987455207056}, \"31\": {\"effect\": 0.02548917379227942, \"value\": 0.1101727279204198}, \"32\": {\"effect\": -0.014391774523840597, \"value\": 0.6746441701430143}, \"33\": {\"effect\": -0.11797436438828565, \"value\": 0.7560284263287593}, \"34\": {\"effect\": -0.02366094886999905, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.18937163521480377, \"value\": -0.4123844900121388}, \"36\": {\"effect\": -0.059813580631147736, \"value\": 0.5324465500844261}, \"37\": {\"effect\": -0.39013319894419207, \"value\": 1.0}, \"38\": {\"effect\": 0.0047274662606651505, \"value\": 0.0}, \"39\": {\"effect\": -0.13909458210669973, \"value\": 3.0}}}, {\"outValue\": 2.26018467320218, \"simIndex\": 25.0, \"features\": {\"0\": {\"effect\": -0.8692306743982424, \"value\": 1.0}, \"1\": {\"effect\": 0.015061122122455094, \"value\": 1.0}, \"2\": {\"effect\": -0.10799485030476998, \"value\": 0.0}, \"3\": {\"effect\": -0.24200684910544523, \"value\": 0.5085748381508475}, \"4\": {\"effect\": 0.009173637264966032, \"value\": 0.0}, \"5\": {\"effect\": -0.2742746514850549, \"value\": 0.0}, \"6\": {\"effect\": -0.1092709276672431, \"value\": 2.01852014148613}, \"7\": {\"effect\": 0.13937996316597853, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.33971550585290927, \"value\": 1.0}, \"9\": {\"effect\": -0.4052171542054229, \"value\": 1.7509657368414098}, \"10\": {\"effect\": 0.007584413779758755, \"value\": 0.8091895944048574}, \"11\": {\"effect\": -0.05490875219271568, \"value\": 0.0}, \"12\": {\"effect\": -0.2725353915289664, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.3715534974776506, \"value\": 0.0}, \"14\": {\"effect\": 0.039357511510386044, \"value\": 1.0}, \"15\": {\"effect\": -0.08449895176713373, \"value\": 1.0}, \"16\": {\"effect\": 0.3402139426647012, \"value\": 0.0}, \"17\": {\"effect\": 0.0033031643208286513, \"value\": 1.0}, \"18\": {\"effect\": 0.027043227606947016, \"value\": 3.0}, \"19\": {\"effect\": 0.018116378784397646, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.03306635416962202, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.10092949112556125, \"value\": 0.8091895944048574}, \"22\": {\"effect\": 0.0017964811924668, \"value\": 0.0098560308140484}, \"23\": {\"effect\": 0.3813071417397041, \"value\": 16.647705640888883}, \"24\": {\"effect\": 0.024104462702776826, \"value\": 14.0}, \"25\": {\"effect\": 0.20930479099980873, \"value\": 3.0}, \"26\": {\"effect\": 1.0490690551864383, \"value\": -0.8889371052675097}, \"27\": {\"effect\": 0.00942965135504691, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.3032318431947159, \"value\": -1.2263366888104512}, \"29\": {\"effect\": 0.0880262017284099, \"value\": -0.5451231089986989}, \"30\": {\"effect\": -0.2314203573137338, \"value\": 1.6260333041095136}, \"31\": {\"effect\": -0.03093571455777888, \"value\": -0.3989378502556719}, \"32\": {\"effect\": -0.16480489077901087, \"value\": 1.7509657368414098}, \"33\": {\"effect\": -0.24311678213608662, \"value\": 1.4162650230233202}, \"34\": {\"effect\": 0.003723876754233091, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.054704479306611785, \"value\": 1.112042033548979}, \"36\": {\"effect\": -0.015674808894999216, \"value\": 0.5085748381508475}, \"37\": {\"effect\": 0.03304094332284325, \"value\": 0.0}, \"38\": {\"effect\": 0.004593592311706204, \"value\": 0.0}, \"39\": {\"effect\": 0.037909876514756496, \"value\": 1.0}}}, {\"outValue\": 0.9549726262841052, \"simIndex\": 96.0, \"features\": {\"0\": {\"effect\": -0.5877492105343142, \"value\": 1.0}, \"1\": {\"effect\": 0.019848503515869483, \"value\": 1.0}, \"2\": {\"effect\": -0.10123547669672064, \"value\": 0.0}, \"3\": {\"effect\": -0.31963717179852696, \"value\": 0.4190559183999275}, \"4\": {\"effect\": 0.016369997986548545, \"value\": 0.0}, \"5\": {\"effect\": -0.2731935118001228, \"value\": 0.0}, \"6\": {\"effect\": 0.06672275933818296, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.351647634850545, \"value\": 0.2}, \"8\": {\"effect\": -0.3294343309926447, \"value\": 0.0}, \"9\": {\"effect\": 0.17550340364263803, \"value\": -1.7793690019293271}, \"10\": {\"effect\": 0.36532396478033025, \"value\": 0.8983855429393464}, \"11\": {\"effect\": -0.009666207541691289, \"value\": 0.0}, \"12\": {\"effect\": 0.10369290058336353, \"value\": -0.3663025567828455}, \"13\": {\"effect\": -0.3473058873293265, \"value\": 0.0}, \"14\": {\"effect\": 0.037963904311176945, \"value\": 1.0}, \"15\": {\"effect\": 0.057823484550080066, \"value\": 3.0}, \"16\": {\"effect\": 0.2547437900621971, \"value\": 0.0}, \"17\": {\"effect\": 0.0006630062554718915, \"value\": 1.0}, \"18\": {\"effect\": -0.4711523290202954, \"value\": 1.0}, \"19\": {\"effect\": -0.2803144449820057, \"value\": 1.3563280592606042}, \"20\": {\"effect\": 0.005391263297945412, \"value\": 0.2}, \"21\": {\"effect\": 0.0272527045896897, \"value\": 0.8983855429393464}, \"22\": {\"effect\": -0.025264605527693766, \"value\": 0.0175660327593277}, \"23\": {\"effect\": 0.12807169121818257, \"value\": -0.222553037035036}, \"24\": {\"effect\": -0.010659379129175788, \"value\": 5.0}, \"25\": {\"effect\": -0.568427241554176, \"value\": 1.0}, \"26\": {\"effect\": -0.36842851695097845, \"value\": 2.052021291905332}, \"27\": {\"effect\": -0.07893356062035763, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.1547216991499025, \"value\": 1.3964007932086813}, \"29\": {\"effect\": -0.10772617643859474, \"value\": 0.5225976370886384}, \"30\": {\"effect\": 0.23161330132621108, \"value\": 0.1665270681986227}, \"31\": {\"effect\": 0.01372527628864875, \"value\": -0.3663025567828455}, \"32\": {\"effect\": 0.04398067095324134, \"value\": -1.7793690019293271}, \"33\": {\"effect\": -0.44994325648493333, \"value\": 1.5813241721969604}, \"34\": {\"effect\": 0.008290284407066643, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10360753635829126, \"value\": -0.426484719368509}, \"36\": {\"effect\": -0.024754652423292004, \"value\": 0.4190559183999275}, \"37\": {\"effect\": 0.027035262245949484, \"value\": 0.0}, \"38\": {\"effect\": 0.0018851779101855292, \"value\": 0.0}, \"39\": {\"effect\": 0.24922993647598296, \"value\": 2.0}}}, {\"outValue\": 5.236519020251971, \"simIndex\": 15.0, \"features\": {\"0\": {\"effect\": 0.26861197583447594, \"value\": 0.0}, \"1\": {\"effect\": 0.020403186407481223, \"value\": 1.0}, \"2\": {\"effect\": -0.06980509966721354, \"value\": 0.0}, \"3\": {\"effect\": -0.1447756550000858, \"value\": 0.966115983544438}, \"4\": {\"effect\": 0.014110102932249383, \"value\": 0.0}, \"5\": {\"effect\": -0.24117002926928063, \"value\": 0.0}, \"6\": {\"effect\": 0.11906071191201469, \"value\": 0.9930046138595}, \"7\": {\"effect\": 0.10339730503640482, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.29254020289374455, \"value\": 1.0}, \"9\": {\"effect\": -0.035474519295990284, \"value\": 0.818153712369467}, \"10\": {\"effect\": -0.43647797661353527, \"value\": 0.1004355908199503}, \"11\": {\"effect\": 0.07025367771749533, \"value\": 1.0}, \"12\": {\"effect\": -0.025628720756510442, \"value\": -0.3793566741719761}, \"13\": {\"effect\": 0.434806124059489, \"value\": 1.0}, \"14\": {\"effect\": 0.04310643194901392, \"value\": 1.0}, \"15\": {\"effect\": -0.13769466447437262, \"value\": 1.0}, \"16\": {\"effect\": 0.26987034183999026, \"value\": 0.0}, \"17\": {\"effect\": 0.0016172429345098147, \"value\": 1.0}, \"18\": {\"effect\": 0.12507301685234537, \"value\": 3.0}, \"19\": {\"effect\": 0.015350144382972978, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.015494727414674942, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.14956241085323072, \"value\": 0.1004355908199503}, \"22\": {\"effect\": -0.00563619505966663, \"value\": 0.0036131955023819}, \"23\": {\"effect\": 0.4134358553688893, \"value\": 17.09337799604331}, \"24\": {\"effect\": 0.02381055121093801, \"value\": 11.0}, \"25\": {\"effect\": 0.13681385882660863, \"value\": 3.0}, \"26\": {\"effect\": 0.9390814647059506, \"value\": -0.922871240619504}, \"27\": {\"effect\": 0.009284611916135964, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.0034428803713706163, \"value\": 0.2975378264378087}, \"29\": {\"effect\": -0.11834499640150979, \"value\": 1.3761103899159726}, \"30\": {\"effect\": 0.17760593299163152, \"value\": -0.5256213593132205}, \"31\": {\"effect\": 0.020146885596073378, \"value\": -0.3793566741719761}, \"32\": {\"effect\": 0.0039105315272847194, \"value\": 0.818153712369467}, \"33\": {\"effect\": -0.11178676606279056, \"value\": 1.4162650230233202}, \"34\": {\"effect\": -0.005107687693928614, \"value\": 0.9930046138595}, \"35\": {\"effect\": -0.033467474884147135, \"value\": -0.6518048492033595}, \"36\": {\"effect\": -0.04401011434228542, \"value\": 0.966115983544438}, \"37\": {\"effect\": 0.036140733251142525, \"value\": 0.0}, \"38\": {\"effect\": 0.004695422825443952, \"value\": 0.0}, \"39\": {\"effect\": 0.20036712071244198, \"value\": 2.0}}}, {\"outValue\": -0.5185143345732603, \"simIndex\": 98.0, \"features\": {\"0\": {\"effect\": 0.3334646722229921, \"value\": 0.0}, \"1\": {\"effect\": 0.01626317697329997, \"value\": 1.0}, \"2\": {\"effect\": -0.05043668362938082, \"value\": 0.0}, \"3\": {\"effect\": 0.0836436750620257, \"value\": -0.9058240939136866}, \"4\": {\"effect\": 0.010737189278654816, \"value\": 0.0}, \"5\": {\"effect\": -0.2941438475802575, \"value\": 0.0}, \"6\": {\"effect\": -0.043944145881358254, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.46929032838474616, \"value\": 0.9}, \"8\": {\"effect\": 0.3619652288254675, \"value\": 1.0}, \"9\": {\"effect\": -0.032011442789061276, \"value\": 0.7751008497015311}, \"10\": {\"effect\": -0.6906283044547168, \"value\": 0.0580318121139235}, \"11\": {\"effect\": -0.018128252204051613, \"value\": 1.0}, \"12\": {\"effect\": 0.037519611687592366, \"value\": -0.3815323604034979}, \"13\": {\"effect\": -0.35094154342121087, \"value\": 0.0}, \"14\": {\"effect\": 0.031025555270519724, \"value\": 1.0}, \"15\": {\"effect\": -0.1282389280742818, \"value\": 1.0}, \"16\": {\"effect\": -0.23661299071651454, \"value\": 1.0}, \"17\": {\"effect\": 0.0013635790819422993, \"value\": 1.0}, \"18\": {\"effect\": -0.5684173753371881, \"value\": 1.0}, \"19\": {\"effect\": 0.06362264903441363, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.033847415423844944, \"value\": 0.9}, \"21\": {\"effect\": -0.20402841462697743, \"value\": 0.0580318121139235}, \"22\": {\"effect\": 0.1834436383006542, \"value\": 0.0256887108419516}, \"23\": {\"effect\": -0.30167796493700555, \"value\": -0.6841366987478685}, \"24\": {\"effect\": 0.053924908729739054, \"value\": 9.0}, \"25\": {\"effect\": -0.628848976038031, \"value\": 1.0}, \"26\": {\"effect\": -0.19484248774677715, \"value\": -0.4817274810435776}, \"27\": {\"effect\": 0.019130408982430822, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.09744977642824874, \"value\": -1.6456119373601756}, \"29\": {\"effect\": 0.06591529800080852, \"value\": -1.188332786192459}, \"30\": {\"effect\": -0.22922956797591992, \"value\": -1.9297427683647976}, \"31\": {\"effect\": 0.00163899403273345, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.10749995145405276, \"value\": 0.7751008497015311}, \"33\": {\"effect\": -0.16680337511994975, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.006018787441721842, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.06519849835277312, \"value\": 0.5545011574157146}, \"36\": {\"effect\": 0.005290163958879701, \"value\": -0.9058240939136866}, \"37\": {\"effect\": 0.02641051242624481, \"value\": 0.0}, \"38\": {\"effect\": 0.0016543534384255445, \"value\": 0.0}, \"39\": {\"effect\": -0.29349094615189464, \"value\": 3.0}}}, {\"outValue\": 6.136865630422421, \"simIndex\": 28.0, \"features\": {\"0\": {\"effect\": 0.2874978531067489, \"value\": 0.0}, \"1\": {\"effect\": 0.009688649117400677, \"value\": 1.0}, \"2\": {\"effect\": 0.17404428175552641, \"value\": 1.0}, \"3\": {\"effect\": -0.4163335669860278, \"value\": 0.7283935188725507}, \"4\": {\"effect\": 0.020959919377791018, \"value\": 0.0}, \"5\": {\"effect\": -0.2309494206934708, \"value\": 0.0}, \"6\": {\"effect\": 0.04944486451612524, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.009252217767290453, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.2684972044228817, \"value\": 1.0}, \"9\": {\"effect\": 0.08003879565855364, \"value\": 0.0862550470145581}, \"10\": {\"effect\": 0.3599017620323275, \"value\": 0.9978064083231728}, \"11\": {\"effect\": -0.02960480511032484, \"value\": 0.0}, \"12\": {\"effect\": 0.08821636667176669, \"value\": -0.3837080466350197}, \"13\": {\"effect\": -0.26697806633820464, \"value\": 0.0}, \"14\": {\"effect\": 0.031138571219177298, \"value\": 1.0}, \"15\": {\"effect\": 0.2998577388754609, \"value\": 2.0}, \"16\": {\"effect\": 0.33728733157735685, \"value\": 0.0}, \"17\": {\"effect\": 0.0037708634156078313, \"value\": 1.0}, \"18\": {\"effect\": 0.13915986848471668, \"value\": 2.0}, \"19\": {\"effect\": 0.02681956225877831, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.001692585587347961, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.1554953618064939, \"value\": 0.9978064083231728}, \"22\": {\"effect\": -0.042691623937520344, \"value\": 0.0026222115350568}, \"23\": {\"effect\": 0.3818702215425987, \"value\": 41.04136460147297}, \"24\": {\"effect\": 0.0011895656140668172, \"value\": 7.0}, \"25\": {\"effect\": 0.13858689967417992, \"value\": 2.0}, \"26\": {\"effect\": 1.3308643114871916, \"value\": -0.8550029699155153}, \"27\": {\"effect\": -0.008280498217822849, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.13697072966654858, \"value\": -1.2998521078775005}, \"29\": {\"effect\": 0.03898136795745769, \"value\": 0.0735837846735578}, \"30\": {\"effect\": 0.1257706572380871, \"value\": 0.3392739080961101}, \"31\": {\"effect\": 0.011814912364352935, \"value\": -0.3837080466350197}, \"32\": {\"effect\": 0.04637580150323325, \"value\": 0.0862550470145581}, \"33\": {\"effect\": 0.03813645932693461, \"value\": 0.0132622550473782}, \"34\": {\"effect\": 0.009468163762035893, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.24260125111500191, \"value\": -0.3660742007757301}, \"36\": {\"effect\": -0.030689293508129167, \"value\": 0.7283935188725507}, \"37\": {\"effect\": 0.03355745931557046, \"value\": 0.0}, \"38\": {\"effect\": 0.003763235813465325, \"value\": 0.0}, \"39\": {\"effect\": -0.03208347198289106, \"value\": 1.0}}}, {\"outValue\": 3.5977580224901837, \"simIndex\": 3.0, \"features\": {\"0\": {\"effect\": 0.37005469889440484, \"value\": 0.0}, \"1\": {\"effect\": -0.13387551562479594, \"value\": 0.0}, \"2\": {\"effect\": -0.12879673183449353, \"value\": 0.0}, \"3\": {\"effect\": -0.06331378522025191, \"value\": 0.0470550741016605}, \"4\": {\"effect\": 0.009273535544092453, \"value\": 0.0}, \"5\": {\"effect\": -0.21719762272466608, \"value\": 0.0}, \"6\": {\"effect\": 0.0384437878648675, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.44827450486429316, \"value\": 0.1}, \"8\": {\"effect\": 0.2990691576901088, \"value\": 1.0}, \"9\": {\"effect\": -0.03722085099231414, \"value\": -0.9183117485706108}, \"10\": {\"effect\": 0.02454173599458235, \"value\": 0.4253356789021363}, \"11\": {\"effect\": -0.027087357502510463, \"value\": 1.0}, \"12\": {\"effect\": 0.20476573402128886, \"value\": 4.146070687393284}, \"13\": {\"effect\": 0.5648602351965349, \"value\": 1.0}, \"14\": {\"effect\": 0.04479258518022352, \"value\": 1.0}, \"15\": {\"effect\": -0.11183539342148059, \"value\": 1.0}, \"16\": {\"effect\": 0.3978331745161269, \"value\": 0.0}, \"17\": {\"effect\": 0.001002748653699477, \"value\": 1.0}, \"18\": {\"effect\": -0.6536930997861523, \"value\": 1.0}, \"19\": {\"effect\": 0.08733106025637422, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.028154138215748133, \"value\": 0.1}, \"21\": {\"effect\": 0.044905188037062664, \"value\": 0.4253356789021363}, \"22\": {\"effect\": -0.20949721137604188, \"value\": 0.6132841709628309}, \"23\": {\"effect\": 0.39191999962617696, \"value\": 24.75391057560111}, \"24\": {\"effect\": 0.0702355532304891, \"value\": 5.0}, \"25\": {\"effect\": -0.43310517011158783, \"value\": 1.0}, \"26\": {\"effect\": -0.26391159103491946, \"value\": 1.7805482090893778}, \"27\": {\"effect\": 0.01883886185172171, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.011907906057781758, \"value\": -0.5168199751686737}, \"29\": {\"effect\": -0.03832430897369928, \"value\": -0.2686789856404498}, \"30\": {\"effect\": -0.14664998273608829, \"value\": -0.7088153913000559}, \"31\": {\"effect\": -0.010390640472599822, \"value\": 4.146070687393284}, \"32\": {\"effect\": 0.09931517234033724, \"value\": -0.9183117485706108}, \"33\": {\"effect\": -0.1549649614174962, \"value\": 0.6734988517419392}, \"34\": {\"effect\": 0.0013193570781294232, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.20156577821827526, \"value\": 0.4432750460218564}, \"36\": {\"effect\": -0.02408345741655484, \"value\": 0.0470550741016605}, \"37\": {\"effect\": 0.03392361084928491, \"value\": 0.0}, \"38\": {\"effect\": 0.00011140505672619284, \"value\": 0.0}, \"39\": {\"effect\": -0.2116397308303302, \"value\": 3.0}}}, {\"outValue\": 2.6670747769923033, \"simIndex\": 67.0, \"features\": {\"0\": {\"effect\": 0.30079260448231393, \"value\": 0.0}, \"1\": {\"effect\": 0.026099219964737748, \"value\": 1.0}, \"2\": {\"effect\": -0.10654582792423585, \"value\": 0.0}, \"3\": {\"effect\": -0.22221997451584016, \"value\": 0.3573873292381828}, \"4\": {\"effect\": 0.013665195971857664, \"value\": 0.0}, \"5\": {\"effect\": -0.2458371669366033, \"value\": 0.0}, \"6\": {\"effect\": 0.04145537198921141, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.4257456533119399, \"value\": 0.1}, \"8\": {\"effect\": 0.23835958818542194, \"value\": 1.0}, \"9\": {\"effect\": 0.5817128589441151, \"value\": -2.066388086382233}, \"10\": {\"effect\": -0.41367550135934916, \"value\": 0.086475841080249}, \"11\": {\"effect\": 0.04932991147763721, \"value\": 1.0}, \"12\": {\"effect\": -0.19075415720614192, \"value\": -0.4011135364871937}, \"13\": {\"effect\": -0.3810422051084961, \"value\": 0.0}, \"14\": {\"effect\": 0.03773841285505812, \"value\": 1.0}, \"15\": {\"effect\": -0.18685427318664144, \"value\": 1.0}, \"16\": {\"effect\": -0.21588152344487543, \"value\": 1.0}, \"17\": {\"effect\": 0.0008808001130523513, \"value\": 1.0}, \"18\": {\"effect\": 0.07972712182920563, \"value\": 3.0}, \"19\": {\"effect\": 0.2281814862133627, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.013472073445478568, \"value\": 0.1}, \"21\": {\"effect\": -0.1420808183195006, \"value\": 0.086475841080249}, \"22\": {\"effect\": -0.15107207498456596, \"value\": 0.004611918760104}, \"23\": {\"effect\": -0.02109620776060488, \"value\": -0.6361151194328155}, \"24\": {\"effect\": 0.11139708413166621, \"value\": 13.0}, \"25\": {\"effect\": 0.1596896845144588, \"value\": 3.0}, \"26\": {\"effect\": -0.793889422117468, \"value\": -0.2554999120302821}, \"27\": {\"effect\": 0.0630203397635786, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.12593117050715738, \"value\": 0.0595226669955877}, \"29\": {\"effect\": 0.07509532223550505, \"value\": 1.882509580019311}, \"30\": {\"effect\": 0.0548838471617988, \"value\": 0.8579907722245983}, \"31\": {\"effect\": -0.0473027754511085, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.12715034003549366, \"value\": -2.066388086382233}, \"33\": {\"effect\": -0.030894366404339745, \"value\": -0.9770926399944632}, \"34\": {\"effect\": -0.0007175787558168782, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.12323642321607801, \"value\": -0.6416296879206786}, \"36\": {\"effect\": -0.0339552428277104, \"value\": 0.3573873292381828}, \"37\": {\"effect\": 0.034198274909830594, \"value\": 0.0}, \"38\": {\"effect\": 0.005564993255460541, \"value\": 0.0}, \"39\": {\"effect\": 0.10913345648550155, \"value\": 1.0}}}, {\"outValue\": 0.7015035576302848, \"simIndex\": 5.0, \"features\": {\"0\": {\"effect\": -0.7140314993151632, \"value\": 1.0}, \"1\": {\"effect\": 0.044508564733789245, \"value\": 1.0}, \"2\": {\"effect\": -0.061549346307660326, \"value\": 0.0}, \"3\": {\"effect\": 0.059942788251817446, \"value\": -0.7228076357562504}, \"4\": {\"effect\": 0.018156527733044846, \"value\": 0.0}, \"5\": {\"effect\": -0.2601974524344674, \"value\": 0.0}, \"6\": {\"effect\": 0.0310266893054367, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.34918542120030316, \"value\": 0.9}, \"8\": {\"effect\": 0.2862331360370783, \"value\": 1.0}, \"9\": {\"effect\": 0.19709118869316208, \"value\": -0.3586245338874453}, \"10\": {\"effect\": -0.10662434324794921, \"value\": 0.2858771665427634}, \"11\": {\"effect\": -0.025700512132925974, \"value\": 0.0}, \"12\": {\"effect\": -0.33706897654976314, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.6258448148956129, \"value\": 1.0}, \"14\": {\"effect\": 0.03747328596905586, \"value\": 1.0}, \"15\": {\"effect\": -0.12586466589508302, \"value\": 1.0}, \"16\": {\"effect\": 0.39171684453636396, \"value\": 0.0}, \"17\": {\"effect\": 0.00010479212448261345, \"value\": 1.0}, \"18\": {\"effect\": -0.47193980128111473, \"value\": 1.0}, \"19\": {\"effect\": 0.015772686966740692, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.021398206057138387, \"value\": 0.9}, \"21\": {\"effect\": 0.012702472226487675, \"value\": 0.2858771665427634}, \"22\": {\"effect\": -0.1918072497286473, \"value\": 0.0015814639754678}, \"23\": {\"effect\": -0.3037429907283665, \"value\": -1.369304660207218}, \"24\": {\"effect\": 0.10281134887699812, \"value\": 10.0}, \"25\": {\"effect\": -0.6623484770176061, \"value\": 1.0}, \"26\": {\"effect\": -0.5261719753053877, \"value\": 0.3553145243056159}, \"27\": {\"effect\": 0.004519406164767165, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.10143809815062038, \"value\": 0.0642044196844573}, \"29\": {\"effect\": 0.025807192829680234, \"value\": -0.2874986471982434}, \"30\": {\"effect\": -0.2330090730825077, \"value\": -0.7846240594637387}, \"31\": {\"effect\": -0.0528204248074448, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.055969115049124066, \"value\": -0.3586245338874453}, \"33\": {\"effect\": -0.07651643491334746, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.007219400756398741, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.007556547253429075, \"value\": -0.1070363011432582}, \"36\": {\"effect\": 0.026912022754965986, \"value\": -0.7228076357562504}, \"37\": {\"effect\": 0.020060191895203812, \"value\": 0.0}, \"38\": {\"effect\": 0.0014131645485284, \"value\": 0.0}, \"39\": {\"effect\": 0.0762946231545361, \"value\": 2.0}}}, {\"outValue\": 4.77172179131307, \"simIndex\": 38.0, \"features\": {\"0\": {\"effect\": 0.2987841206948421, \"value\": 0.0}, \"1\": {\"effect\": 0.028144880259271757, \"value\": 1.0}, \"2\": {\"effect\": -0.09505550270679648, \"value\": 0.0}, \"3\": {\"effect\": -0.2533525698899799, \"value\": 0.7532598854700284}, \"4\": {\"effect\": 0.01618558266072273, \"value\": 0.0}, \"5\": {\"effect\": 1.156475673704112, \"value\": 1.0}, \"6\": {\"effect\": -0.10058200091739174, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.44525041605000926, \"value\": 0.9}, \"8\": {\"effect\": 0.4423993883157475, \"value\": 1.0}, \"9\": {\"effect\": 0.05071288005227975, \"value\": 0.7033460785883049}, \"10\": {\"effect\": -0.5813028680745662, \"value\": 0.0682841515287472}, \"11\": {\"effect\": 0.05516121063063889, \"value\": 1.0}, \"12\": {\"effect\": 0.12920134941704972, \"value\": -0.3880594190980632}, \"13\": {\"effect\": -0.3099912167587701, \"value\": 0.0}, \"14\": {\"effect\": 0.036130422243437016, \"value\": 1.0}, \"15\": {\"effect\": -0.1473423688360181, \"value\": 1.0}, \"16\": {\"effect\": 0.2999253706391129, \"value\": 0.0}, \"17\": {\"effect\": 0.0004775945637988067, \"value\": 1.0}, \"18\": {\"effect\": 0.0634240756348248, \"value\": 3.0}, \"19\": {\"effect\": 0.04692193780622955, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.009852071207680625, \"value\": 0.9}, \"21\": {\"effect\": -0.13721956761727036, \"value\": 0.0682841515287472}, \"22\": {\"effect\": -0.003298040246525782, \"value\": 0.0029238684599572}, \"23\": {\"effect\": -0.2878001227869244, \"value\": -1.4365463598359742}, \"24\": {\"effect\": 0.6284813802125027, \"value\": 20.0}, \"25\": {\"effect\": 0.1520665585596513, \"value\": 3.0}, \"26\": {\"effect\": 0.43600809573575505, \"value\": -0.6061526440008902}, \"27\": {\"effect\": 0.0008805564586786901, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.03653894638932969, \"value\": 0.1820769797603826}, \"29\": {\"effect\": 0.2305827986316009, \"value\": 1.5935666949123877}, \"30\": {\"effect\": 0.09498298596759427, \"value\": 1.5758910609737786}, \"31\": {\"effect\": 0.020312074835501796, \"value\": -0.3880594190980632}, \"32\": {\"effect\": 0.0209224534424718, \"value\": 0.7033460785883049}, \"33\": {\"effect\": -0.2479316615346957, \"value\": 1.5813241721969604}, \"34\": {\"effect\": -0.07296176955034743, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.04215307797930379, \"value\": -0.8907587198250733}, \"36\": {\"effect\": -0.04078655373529698, \"value\": 0.7532598854700284}, \"37\": {\"effect\": 0.02343556779627971, \"value\": 0.0}, \"38\": {\"effect\": 0.003710286045819641, \"value\": 0.0}, \"39\": {\"effect\": 0.11952374782094931, \"value\": 1.0}}}, {\"outValue\": 2.5206195724442346, \"simIndex\": 66.0, \"features\": {\"0\": {\"effect\": 0.24976867630597244, \"value\": 0.0}, \"1\": {\"effect\": 0.026810714128572926, \"value\": 1.0}, \"2\": {\"effect\": -0.07300213400433332, \"value\": 0.0}, \"3\": {\"effect\": 0.026331406512698413, \"value\": -0.4373417472172058}, \"4\": {\"effect\": 0.010308946113041324, \"value\": 0.0}, \"5\": {\"effect\": -0.21811567514855604, \"value\": 0.0}, \"6\": {\"effect\": 0.008994385341555498, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.038595971986621826, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.2917919712144339, \"value\": 1.0}, \"9\": {\"effect\": 0.15551144861409796, \"value\": -0.1146583121024756}, \"10\": {\"effect\": -0.16012316469083748, \"value\": 0.2547231408100571}, \"11\": {\"effect\": -0.03741033115324282, \"value\": 0.0}, \"12\": {\"effect\": -0.21141975022025966, \"value\": -0.3989378502556719}, \"13\": {\"effect\": -0.39884758965845435, \"value\": 0.0}, \"14\": {\"effect\": 0.037613974552519615, \"value\": 1.0}, \"15\": {\"effect\": -0.14764009679877693, \"value\": 1.0}, \"16\": {\"effect\": 0.3522378684872872, \"value\": 0.0}, \"17\": {\"effect\": 0.0019169293853943793, \"value\": 1.0}, \"18\": {\"effect\": 0.06958046459205063, \"value\": 2.0}, \"19\": {\"effect\": 0.3586479183405878, \"value\": -1.969856016832232}, \"20\": {\"effect\": -0.00234321636035155, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.01812787828617299, \"value\": 0.2547231408100571}, \"22\": {\"effect\": -0.13347046300906112, \"value\": 0.0031779749194716}, \"23\": {\"effect\": -0.22028977474161748, \"value\": -1.034772067635902}, \"24\": {\"effect\": 0.005738599891470849, \"value\": 5.0}, \"25\": {\"effect\": 0.1839248726523844, \"value\": 2.0}, \"26\": {\"effect\": -0.6006392092945434, \"value\": 0.400560038108275}, \"27\": {\"effect\": -0.004980421560414872, \"value\": -1.969856016832232}, \"28\": {\"effect\": 0.001476364374514194, \"value\": -0.9552196274062306}, \"29\": {\"effect\": 0.16329679793577387, \"value\": -0.8677863892053393}, \"30\": {\"effect\": 0.06984694593726523, \"value\": -0.6401243059290145}, \"31\": {\"effect\": -0.013899068375037741, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.06693624881531945, \"value\": -0.1146583121024756}, \"33\": {\"effect\": -0.09047939569368865, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.00025533201638904007, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.06830690940804547, \"value\": -0.3477761303190556}, \"36\": {\"effect\": 0.017021411341200592, \"value\": -0.4373417472172058}, \"37\": {\"effect\": -0.35495810846901465, \"value\": 1.0}, \"38\": {\"effect\": 0.0018682883374328365, \"value\": 0.0}, \"39\": {\"effect\": 0.0652917177122226, \"value\": 2.0}}}, {\"outValue\": 2.255430850084736, \"simIndex\": 60.0, \"features\": {\"0\": {\"effect\": -0.7629524553319186, \"value\": 1.0}, \"1\": {\"effect\": 0.01655142361390082, \"value\": 1.0}, \"2\": {\"effect\": -0.10962720828899046, \"value\": 0.0}, \"3\": {\"effect\": 0.06982506239165007, \"value\": -1.220134967705805}, \"4\": {\"effect\": 0.01323676880058899, \"value\": 0.0}, \"5\": {\"effect\": -0.221407760881378, \"value\": 0.0}, \"6\": {\"effect\": 0.05920413322585839, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.07191505138280507, \"value\": 0.8}, \"8\": {\"effect\": -0.30863687005088003, \"value\": 0.0}, \"9\": {\"effect\": 0.03404590227627546, \"value\": 0.1293079096824939}, \"10\": {\"effect\": 0.3001851703241966, \"value\": 0.4682919094684842}, \"11\": {\"effect\": -0.03261612321439012, \"value\": 0.0}, \"12\": {\"effect\": 0.33255087233824393, \"value\": 3.019065219465013}, \"13\": {\"effect\": -0.4451784143821863, \"value\": 0.0}, \"14\": {\"effect\": 0.030138615595680443, \"value\": 1.0}, \"15\": {\"effect\": -0.08381238061040328, \"value\": 1.0}, \"16\": {\"effect\": 0.27827271509514445, \"value\": 0.0}, \"17\": {\"effect\": 0.0015230458919459906, \"value\": 1.0}, \"18\": {\"effect\": 0.09556943519965981, \"value\": 2.0}, \"19\": {\"effect\": 0.009977818596982596, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.017054839895538163, \"value\": 0.8}, \"21\": {\"effect\": 0.08199619502026073, \"value\": 0.4682919094684842}, \"22\": {\"effect\": 0.27959920310485376, \"value\": 0.0221891999049787}, \"23\": {\"effect\": -0.2898789995611729, \"value\": -1.3908733741674504}, \"24\": {\"effect\": 0.061896950716950304, \"value\": 6.0}, \"25\": {\"effect\": 0.1619196567254563, \"value\": 2.0}, \"26\": {\"effect\": -0.702499896642608, \"value\": -0.4025478318889242}, \"27\": {\"effect\": 0.036221593072609276, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.0791894766657413, \"value\": 1.130705286989996}, \"29\": {\"effect\": -0.13718534785339964, \"value\": 0.4650961230471678}, \"30\": {\"effect\": 0.07329667763294057, \"value\": -0.1441408041756536}, \"31\": {\"effect\": 0.06276823589813849, \"value\": 3.019065219465013}, \"32\": {\"effect\": 0.05177679541442195, \"value\": 0.1293079096824939}, \"33\": {\"effect\": -0.09156526256349451, \"value\": -0.7295039162340028}, \"34\": {\"effect\": 0.015568768487957838, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.11913577276516868, \"value\": 0.0294570923193311}, \"36\": {\"effect\": 0.0503327956961885, \"value\": -1.220134967705805}, \"37\": {\"effect\": 0.021951632579180532, \"value\": 0.0}, \"38\": {\"effect\": 0.003419337872317782, \"value\": 0.0}, \"39\": {\"effect\": 0.2770808543452339, \"value\": 2.0}}}, {\"outValue\": 2.866423219479845, \"simIndex\": 51.0, \"features\": {\"0\": {\"effect\": 0.2663688298512208, \"value\": 0.0}, \"1\": {\"effect\": 0.026997196839906753, \"value\": 1.0}, \"2\": {\"effect\": -0.08944628597044853, \"value\": 0.0}, \"3\": {\"effect\": -0.10984910378661326, \"value\": 0.0003063048984023}, \"4\": {\"effect\": 0.0055535442218542196, \"value\": 0.0}, \"5\": {\"effect\": 1.0198893218569745, \"value\": 1.0}, \"6\": {\"effect\": 0.01989186386643804, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.6164934978153672, \"value\": 0.9}, \"8\": {\"effect\": -0.4136721887356088, \"value\": 0.0}, \"9\": {\"effect\": 0.18913512456447368, \"value\": -0.2151149916609925}, \"10\": {\"effect\": 0.09842260358747158, \"value\": 0.5202790851955159}, \"11\": {\"effect\": 0.016458743875781064, \"value\": 1.0}, \"12\": {\"effect\": 0.07022953723047949, \"value\": -0.3815323604034979}, \"13\": {\"effect\": -0.4146758828880263, \"value\": 0.0}, \"14\": {\"effect\": 0.03672242909965427, \"value\": 1.0}, \"15\": {\"effect\": -0.09518313500771133, \"value\": 1.0}, \"16\": {\"effect\": 0.30860751076338533, \"value\": 0.0}, \"17\": {\"effect\": 0.0017991230357121768, \"value\": 1.0}, \"18\": {\"effect\": 0.06893665309126208, \"value\": 3.0}, \"19\": {\"effect\": 0.14529530989391717, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.07169411301835435, \"value\": 0.9}, \"21\": {\"effect\": 0.034352444147120666, \"value\": 0.5202790851955159}, \"22\": {\"effect\": -0.14384485545001924, \"value\": 0.0037675516528476}, \"23\": {\"effect\": -0.3171314629544242, \"value\": -1.3473288028918673}, \"24\": {\"effect\": 0.1431840623849566, \"value\": 12.0}, \"25\": {\"effect\": 0.08161276534648498, \"value\": 3.0}, \"26\": {\"effect\": -0.6147030161822878, \"value\": -0.3007454258329412}, \"27\": {\"effect\": 0.01640973402943292, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.001848747411219614, \"value\": 0.9029643667102012}, \"29\": {\"effect\": -0.30663329688937796, \"value\": 0.7993148927671195}, \"30\": {\"effect\": 0.08775744620903506, \"value\": 0.6846077998782062}, \"31\": {\"effect\": 0.012350527450060798, \"value\": -0.3815323604034979}, \"32\": {\"effect\": 0.03372523197050858, \"value\": -0.2151149916609925}, \"33\": {\"effect\": 0.3188951674691659, \"value\": -0.6469743416471827}, \"34\": {\"effect\": 0.004869815099238413, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.18348890058104614, \"value\": -0.4253031873757872}, \"36\": {\"effect\": 0.0029368766339329115, \"value\": 0.0003063048984023}, \"37\": {\"effect\": 0.025466634637973714, \"value\": 0.0}, \"38\": {\"effect\": 0.0029246983718950385, \"value\": 0.0}, \"39\": {\"effect\": -0.01169671494497067, \"value\": 1.0}}}, {\"outValue\": 2.6893028359517905, \"simIndex\": 70.0, \"features\": {\"0\": {\"effect\": 0.2697974847085654, \"value\": 0.0}, \"1\": {\"effect\": 0.014922403453438924, \"value\": 1.0}, \"2\": {\"effect\": 0.22015955780478388, \"value\": 1.0}, \"3\": {\"effect\": 0.06862367065489494, \"value\": -0.6183688960468439}, \"4\": {\"effect\": 0.012863171101854549, \"value\": 0.0}, \"5\": {\"effect\": -0.22446571663355463, \"value\": 0.0}, \"6\": {\"effect\": 0.05961141154081041, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.2750215697662055, \"value\": 0.2}, \"8\": {\"effect\": -0.3286815554926689, \"value\": 0.0}, \"9\": {\"effect\": -0.04403430006286936, \"value\": 1.1195237510450178}, \"10\": {\"effect\": -0.2095377816544608, \"value\": 0.2878631675268583}, \"11\": {\"effect\": -0.029609914434201325, \"value\": 0.0}, \"12\": {\"effect\": 0.23215423433195995, \"value\": 2.618738952865009}, \"13\": {\"effect\": -0.4712454021199877, \"value\": 0.0}, \"14\": {\"effect\": 0.042958553148588846, \"value\": 1.0}, \"15\": {\"effect\": -0.17873371122951376, \"value\": 1.0}, \"16\": {\"effect\": -0.3107573405900732, \"value\": 1.0}, \"17\": {\"effect\": 0.0008266856096192764, \"value\": 1.0}, \"18\": {\"effect\": 0.09094054057021343, \"value\": 4.0}, \"19\": {\"effect\": 0.34302416157538296, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.039327361838514874, \"value\": 0.2}, \"21\": {\"effect\": 0.009714778045212476, \"value\": 0.2878631675268583}, \"22\": {\"effect\": 0.11639010598515433, \"value\": 0.0070738291820691}, \"23\": {\"effect\": -0.1511444054611426, \"value\": -1.0138865755698867}, \"24\": {\"effect\": -0.0020053602466927984, \"value\": 10.0}, \"25\": {\"effect\": 0.16886270965180397, \"value\": 4.0}, \"26\": {\"effect\": -0.5658202637277182, \"value\": -0.4251705887902537}, \"27\": {\"effect\": 0.01905854752948422, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.020891745902838564, \"value\": -0.481280687218376}, \"29\": {\"effect\": 0.0897920722759268, \"value\": -0.6027763687150239}, \"30\": {\"effect\": -0.263852273054418, \"value\": -0.7543192372890553}, \"31\": {\"effect\": 0.049483442474629276, \"value\": 2.618738952865009}, \"32\": {\"effect\": -0.010584483878723414, \"value\": 1.1195237510450178}, \"33\": {\"effect\": 0.27066076824531254, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.006046768432705568, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.1915169668817732, \"value\": -0.3895225012713656}, \"36\": {\"effect\": 0.009992048531985771, \"value\": -0.6183688960468439}, \"37\": {\"effect\": 0.024350025947312604, \"value\": 0.0}, \"38\": {\"effect\": 0.0027561657104161223, \"value\": 0.0}, \"39\": {\"effect\": 0.14215682185413708, \"value\": 2.0}}}, {\"outValue\": 5.516335702744044, \"simIndex\": 9.0, \"features\": {\"0\": {\"effect\": 0.34007176572668646, \"value\": 0.0}, \"1\": {\"effect\": 0.018824656256468036, \"value\": 1.0}, \"2\": {\"effect\": 0.28933444733297864, \"value\": 1.0}, \"3\": {\"effect\": 0.15377635345347218, \"value\": -1.1415572492577757}, \"4\": {\"effect\": 0.015427633973292705, \"value\": 0.0}, \"5\": {\"effect\": 0.8925678490409386, \"value\": 1.0}, \"6\": {\"effect\": 0.06310536400996572, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.08570373158354742, \"value\": 0.6000000000000001}, \"8\": {\"effect\": -0.3616050085557397, \"value\": 0.0}, \"9\": {\"effect\": -0.005331061476060765, \"value\": 0.2441155434636561}, \"10\": {\"effect\": 0.026105520357572562, \"value\": 0.3970790402300558}, \"11\": {\"effect\": -0.03674904343387903, \"value\": 0.0}, \"12\": {\"effect\": -0.25024505932870167, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.4273110465388918, \"value\": 1.0}, \"14\": {\"effect\": 0.03902231397519088, \"value\": 1.0}, \"15\": {\"effect\": -0.023420140169693574, \"value\": 3.0}, \"16\": {\"effect\": -0.30189981041491676, \"value\": 1.0}, \"17\": {\"effect\": 0.00046579803657627566, \"value\": 1.0}, \"18\": {\"effect\": 0.2159354500276185, \"value\": 2.0}, \"19\": {\"effect\": -0.17933550144521057, \"value\": 1.3563280592606042}, \"20\": {\"effect\": 0.015697211781072962, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.025929309394165437, \"value\": 0.3970790402300558}, \"22\": {\"effect\": 0.11042499355792713, \"value\": 0.0068165976963421}, \"23\": {\"effect\": 0.1599184495391018, \"value\": -0.4360904704802789}, \"24\": {\"effect\": -0.6150800904962247, \"value\": 1.0}, \"25\": {\"effect\": 0.16364867488382775, \"value\": 2.0}, \"26\": {\"effect\": 0.873714235054998, \"value\": -0.922871240619504}, \"27\": {\"effect\": -0.012922081744831072, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.07043308319412393, \"value\": -0.3133717397101241}, \"29\": {\"effect\": 0.05632998307608321, \"value\": -0.4987102257707593}, \"30\": {\"effect\": 0.11557435321651746, \"value\": 0.2367731141577185}, \"31\": {\"effect\": -0.04013052371205528, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.006896454350289856, \"value\": 0.2441155434636561}, \"33\": {\"effect\": -0.049053664957110714, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.01952987495174728, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.0368636845918286, \"value\": 1.0362114155571316}, \"36\": {\"effect\": -0.04560092910980343, \"value\": -1.1415572492577757}, \"37\": {\"effect\": 0.022316766419639623, \"value\": 0.0}, \"38\": {\"effect\": 0.0030118028133542564, \"value\": 0.0}, \"39\": {\"effect\": 0.13265521442313785, \"value\": 2.0}}}, {\"outValue\": -0.007423562552860474, \"simIndex\": 100.0, \"features\": {\"0\": {\"effect\": 0.298045961768589, \"value\": 0.0}, \"1\": {\"effect\": 0.017638946013521298, \"value\": 1.0}, \"2\": {\"effect\": 0.192989086208914, \"value\": 1.0}, \"3\": {\"effect\": 0.1587389779942512, \"value\": -0.9416316618140544}, \"4\": {\"effect\": 0.0031240252863926152, \"value\": 0.0}, \"5\": {\"effect\": -0.2531874310470855, \"value\": 0.0}, \"6\": {\"effect\": -0.0067715504490676965, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2811354361075567, \"value\": 0.4}, \"8\": {\"effect\": -0.2523753107383347, \"value\": 0.0}, \"9\": {\"effect\": -0.02274645945130456, \"value\": 0.2441155434636561}, \"10\": {\"effect\": 0.1333248020276077, \"value\": 0.7338505531627748}, \"11\": {\"effect\": -0.024472193580708335, \"value\": 0.0}, \"12\": {\"effect\": 0.49974924649889085, \"value\": 2.4599138579639206}, \"13\": {\"effect\": -0.47032744632314033, \"value\": 0.0}, \"14\": {\"effect\": 0.044039135931077465, \"value\": 1.0}, \"15\": {\"effect\": 0.16123596462698278, \"value\": 2.0}, \"16\": {\"effect\": -0.3285258453245492, \"value\": 1.0}, \"17\": {\"effect\": 0.0009829122216311126, \"value\": 1.0}, \"18\": {\"effect\": -0.056308885410671396, \"value\": 3.0}, \"19\": {\"effect\": -1.1975566243005877, \"value\": 3.850966116330231}, \"20\": {\"effect\": 0.04913584447277508, \"value\": 0.4}, \"21\": {\"effect\": -0.002220126140821438, \"value\": 0.7338505531627748}, \"22\": {\"effect\": 0.024139001473941775, \"value\": 0.0073237439710313}, \"23\": {\"effect\": -0.4594221403038211, \"value\": -1.2965578965167923}, \"24\": {\"effect\": -0.7135160528280405, \"value\": 2.0}, \"25\": {\"effect\": 0.12156069507846622, \"value\": 3.0}, \"26\": {\"effect\": -0.6560166352819888, \"value\": -0.3686136965369299}, \"27\": {\"effect\": -0.2071634253404053, \"value\": 3.850966116330231}, \"28\": {\"effect\": -0.07292080745804766, \"value\": 0.613683061706632}, \"29\": {\"effect\": -0.04570490976191751, \"value\": -0.1651569129420882}, \"30\": {\"effect\": -0.3115214626636392, \"value\": -0.7571279439777315}, \"31\": {\"effect\": 0.049791467912914666, \"value\": 2.4599138579639206}, \"32\": {\"effect\": 0.024003458087692692, \"value\": 0.2441155434636561}, \"33\": {\"effect\": -0.0649446904464499, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0015000940807017834, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1351763346988752, \"value\": -0.5490612672173829}, \"36\": {\"effect\": 0.0027374612569181582, \"value\": -0.9416316618140544}, \"37\": {\"effect\": 0.021306294468433472, \"value\": 0.0}, \"38\": {\"effect\": 0.003424537544956506, \"value\": 0.0}, \"39\": {\"effect\": 0.11394591520654436, \"value\": 2.0}}}, {\"outValue\": 4.361942439358363, \"simIndex\": 19.0, \"features\": {\"0\": {\"effect\": -0.7683062761483105, \"value\": 1.0}, \"1\": {\"effect\": 0.016205666924121148, \"value\": 1.0}, \"2\": {\"effect\": -0.06087897552941314, \"value\": 0.0}, \"3\": {\"effect\": 0.12814967693868212, \"value\": -1.0430864375317637}, \"4\": {\"effect\": 0.012110649248817893, \"value\": 0.0}, \"5\": {\"effect\": -0.2559284021264011, \"value\": 0.0}, \"6\": {\"effect\": 0.01579251381673134, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.4967483789872869, \"value\": 0.9}, \"8\": {\"effect\": 0.3227881372493208, \"value\": 1.0}, \"9\": {\"effect\": 0.14606075315502284, \"value\": -0.4734321676686074}, \"10\": {\"effect\": 0.05613213269107419, \"value\": 0.6798431096067559}, \"11\": {\"effect\": -0.02864415466855671, \"value\": 0.0}, \"12\": {\"effect\": -0.2258980833257081, \"value\": -0.3989378502556719}, \"13\": {\"effect\": 0.6452892422509399, \"value\": 1.0}, \"14\": {\"effect\": 0.03761054160487095, \"value\": 1.0}, \"15\": {\"effect\": 0.23932125062744933, \"value\": 2.0}, \"16\": {\"effect\": 0.32921619067997, \"value\": 0.0}, \"17\": {\"effect\": 0.0021365486056552064, \"value\": 1.0}, \"18\": {\"effect\": 0.047924980753873234, \"value\": 3.0}, \"19\": {\"effect\": -0.16275936131461963, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.03971418693306505, \"value\": 0.9}, \"21\": {\"effect\": 0.04981042057195958, \"value\": 0.6798431096067559}, \"22\": {\"effect\": 0.0037350293402528567, \"value\": 0.0066508972706722}, \"23\": {\"effect\": -0.0643980676739247, \"value\": -0.8932683955325513}, \"24\": {\"effect\": 0.04729162984951975, \"value\": 11.0}, \"25\": {\"effect\": 0.16989718388751773, \"value\": 3.0}, \"26\": {\"effect\": 0.4169563790927462, \"value\": -0.6627095362542141}, \"27\": {\"effect\": -0.035595916611057224, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.036510167382205236, \"value\": -0.139752802330851}, \"29\": {\"effect\": 0.24454068923068115, \"value\": -0.7718761071530612}, \"30\": {\"effect\": 0.11077253716939967, \"value\": 0.033431609266413}, \"31\": {\"effect\": -0.057326078984866205, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.06153624020228225, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.228306354664509, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.020810413417908454, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1930386310950202, \"value\": -0.5874717225011025}, \"36\": {\"effect\": 0.04868313790691227, \"value\": -1.0430864375317637}, \"37\": {\"effect\": 0.020941448286960256, \"value\": 0.0}, \"38\": {\"effect\": 0.0017413142017006806, \"value\": 0.0}, \"39\": {\"effect\": 0.22000221827767236, \"value\": 2.0}}}, {\"outValue\": 3.019270358487971, \"simIndex\": 69.0, \"features\": {\"0\": {\"effect\": 0.36454889270514396, \"value\": 0.0}, \"1\": {\"effect\": 0.01642213006676537, \"value\": 1.0}, \"2\": {\"effect\": -0.07946269968421606, \"value\": 0.0}, \"3\": {\"effect\": -0.08984486422596717, \"value\": 0.1365739938525804}, \"4\": {\"effect\": 0.007032148489895594, \"value\": 0.0}, \"5\": {\"effect\": -0.2294678480229403, \"value\": 0.0}, \"6\": {\"effect\": 0.05305378436565974, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.0900420541771166, \"value\": 0.8}, \"8\": {\"effect\": -0.37157971952063984, \"value\": 0.0}, \"9\": {\"effect\": 0.15347992775870753, \"value\": -0.4303793050006717}, \"10\": {\"effect\": -0.3238798356259642, \"value\": 0.1193150046967689}, \"11\": {\"effect\": 0.04682416934749068, \"value\": 1.0}, \"12\": {\"effect\": 0.17912193591009298, \"value\": -0.3924107915611067}, \"13\": {\"effect\": -0.2955280402495598, \"value\": 0.0}, \"14\": {\"effect\": 0.036851980503823316, \"value\": 1.0}, \"15\": {\"effect\": -0.13289789585975692, \"value\": 1.0}, \"16\": {\"effect\": -0.23666879363052853, \"value\": 1.0}, \"17\": {\"effect\": 0.0009042426843299305, \"value\": 1.0}, \"18\": {\"effect\": 0.1514118102858205, \"value\": 2.0}, \"19\": {\"effect\": -0.01089045032716519, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.014354919528896195, \"value\": 0.8}, \"21\": {\"effect\": -0.10883948540405873, \"value\": 0.1193150046967689}, \"22\": {\"effect\": -0.04353128461885375, \"value\": 0.0128614106944093}, \"23\": {\"effect\": -0.007888608212570545, \"value\": -0.3724649416606316}, \"24\": {\"effect\": 0.05718117498666189, \"value\": 13.0}, \"25\": {\"effect\": 0.20653338289973916, \"value\": 2.0}, \"26\": {\"effect\": -0.2750086092208339, \"value\": -0.4930388594942424}, \"27\": {\"effect\": 0.006708684244120602, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.030444671716647925, \"value\": -0.8027319306707918}, \"29\": {\"effect\": -0.08642841544768974, \"value\": -0.0157367842147424}, \"30\": {\"effect\": 0.17223683011988486, \"value\": 0.1931277299784901}, \"31\": {\"effect\": 0.008931636860905876, \"value\": -0.3924107915611067}, \"32\": {\"effect\": 0.03176232237484528, \"value\": -0.4303793050006717}, \"33\": {\"effect\": 0.2568471297645355, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.005796001896322302, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.21383412179362388, \"value\": 0.16014414527477}, \"36\": {\"effect\": -0.0028412246063404378, \"value\": 0.1365739938525804}, \"37\": {\"effect\": 0.03457549600846062, \"value\": 0.0}, \"38\": {\"effect\": 0.002495674686883219, \"value\": 0.0}, \"39\": {\"effect\": 0.19132668773193454, \"value\": 2.0}}}, {\"outValue\": -1.601529958551959, \"simIndex\": 97.0, \"features\": {\"0\": {\"effect\": -0.6765604133211383, \"value\": 1.0}, \"1\": {\"effect\": 0.015770900762881634, \"value\": 1.0}, \"2\": {\"effect\": -0.1401207428528416, \"value\": 0.0}, \"3\": {\"effect\": 0.05609411203872667, \"value\": -0.7307648730674432}, \"4\": {\"effect\": 0.014950503457351227, \"value\": 0.0}, \"5\": {\"effect\": -0.260766330207459, \"value\": 0.0}, \"6\": {\"effect\": 0.1281614931793649, \"value\": 0.9724943033069674}, \"7\": {\"effect\": 0.030052598698638452, \"value\": 0.8}, \"8\": {\"effect\": -0.3582166744766001, \"value\": 0.0}, \"9\": {\"effect\": 0.04668559100112794, \"value\": 1.1769275679355988}, \"10\": {\"effect\": -0.5375350859608727, \"value\": 0.0433116266338233}, \"11\": {\"effect\": -0.03636913175623421, \"value\": 0.0}, \"12\": {\"effect\": -0.22260749510097258, \"value\": -0.4011135364871937}, \"13\": {\"effect\": -0.4021800183723805, \"value\": 0.0}, \"14\": {\"effect\": 0.03346498910576781, \"value\": 1.0}, \"15\": {\"effect\": -0.18045761721372108, \"value\": 1.0}, \"16\": {\"effect\": -0.31126509321747203, \"value\": 1.0}, \"17\": {\"effect\": -8.199380840544645e-05, \"value\": 1.0}, \"18\": {\"effect\": -0.32571686290148694, \"value\": 1.0}, \"19\": {\"effect\": 0.07123155279281074, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.009386695692891951, \"value\": 0.8}, \"21\": {\"effect\": -0.14229400636637382, \"value\": 0.0433116266338233}, \"22\": {\"effect\": -0.18740525940633188, \"value\": 0.0001870149936176}, \"23\": {\"effect\": -0.06350719889628258, \"value\": -0.8169371857615849}, \"24\": {\"effect\": 0.1200982413536931, \"value\": 6.0}, \"25\": {\"effect\": -0.68510383927812, \"value\": 1.0}, \"26\": {\"effect\": -0.401790417302821, \"value\": 0.5702307148682467}, \"27\": {\"effect\": 0.024380225273068688, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.023090464516880387, \"value\": -0.7186305506267472}, \"29\": {\"effect\": -0.023332367828841027, \"value\": -1.3136878244991792}, \"30\": {\"effect\": -0.07577366826018639, \"value\": -1.922494551424788}, \"31\": {\"effect\": -0.04968118096846218, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.017381885756776454, \"value\": 1.1769275679355988}, \"33\": {\"effect\": -0.05051306442210983, \"value\": -0.9770926399944632}, \"34\": {\"effect\": -0.020996051416186386, \"value\": 0.9724943033069674}, \"35\": {\"effect\": 0.0869468125731661, \"value\": -0.868722982175827}, \"36\": {\"effect\": 0.02146915967755195, \"value\": -0.7307648730674432}, \"37\": {\"effect\": 0.02378009859160676, \"value\": 0.0}, \"38\": {\"effect\": 0.0032316960090616902, \"value\": 0.0}, \"39\": {\"effect\": -0.19280080752652465, \"value\": 3.0}}}, {\"outValue\": 5.672751450157646, \"simIndex\": 37.0, \"features\": {\"0\": {\"effect\": -0.677879790404484, \"value\": 1.0}, \"1\": {\"effect\": 0.027576179788108734, \"value\": 1.0}, \"2\": {\"effect\": -0.05010066068034204, \"value\": 0.0}, \"3\": {\"effect\": -0.16272343263872582, \"value\": 0.1166809005745982}, \"4\": {\"effect\": 0.011369218780730772, \"value\": 0.0}, \"5\": {\"effect\": 0.9370234688014417, \"value\": 1.0}, \"6\": {\"effect\": 0.04356116387412041, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.1875474974954878, \"value\": 0.5}, \"8\": {\"effect\": 0.22979897972927732, \"value\": 1.0}, \"9\": {\"effect\": -0.019496532759525575, \"value\": 1.0477689799317913}, \"10\": {\"effect\": -0.21860308932740094, \"value\": 0.2435472293672471}, \"11\": {\"effect\": -0.013787303888500869, \"value\": 0.0}, \"12\": {\"effect\": 0.09422933059830241, \"value\": -0.3815323604034979}, \"13\": {\"effect\": 0.685605825179036, \"value\": 1.0}, \"14\": {\"effect\": 0.03792765808039806, \"value\": 1.0}, \"15\": {\"effect\": -0.13094593226192064, \"value\": 1.0}, \"16\": {\"effect\": 0.3492452728527221, \"value\": 0.0}, \"17\": {\"effect\": 0.0006614890451472169, \"value\": 1.0}, \"18\": {\"effect\": 0.03827260026672214, \"value\": 3.0}, \"19\": {\"effect\": 0.1920750921008154, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.06263855827148351, \"value\": 0.5}, \"21\": {\"effect\": -0.01985829292202654, \"value\": 0.2435472293672471}, \"22\": {\"effect\": 0.3607007830380169, \"value\": 0.0503824074250401}, \"23\": {\"effect\": 0.5560604323254823, \"value\": 97.19691623774608}, \"24\": {\"effect\": 0.03520027318975982, \"value\": 12.0}, \"25\": {\"effect\": 0.12877879492391195, \"value\": 3.0}, \"26\": {\"effect\": -0.4748181549042076, \"value\": -0.413859210339589}, \"27\": {\"effect\": 0.020262624210933958, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.29711251755512247, \"value\": -1.6290002964231745}, \"29\": {\"effect\": -0.004771035983210547, \"value\": -0.371471529047616}, \"30\": {\"effect\": 0.11545808493474839, \"value\": -0.507037821783886}, \"31\": {\"effect\": -0.0016736467555604725, \"value\": -0.3815323604034979}, \"32\": {\"effect\": -0.003968018411684507, \"value\": 1.0477689799317913}, \"33\": {\"effect\": -0.18092392571116106, \"value\": 0.7560284263287593}, \"34\": {\"effect\": 0.010429825660256641, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.05503880937398547, \"value\": -0.7203801481721747}, \"36\": {\"effect\": -0.013779448807292165, \"value\": 0.1166809005745982}, \"37\": {\"effect\": 0.014623651016453673, \"value\": 0.0}, \"38\": {\"effect\": 0.0030457652336511203, \"value\": 0.0}, \"39\": {\"effect\": 0.08093131455973675, \"value\": 2.0}}}, {\"outValue\": 3.537027665055812, \"simIndex\": 57.0, \"features\": {\"0\": {\"effect\": 0.2605788871544266, \"value\": 0.0}, \"1\": {\"effect\": 0.033083277242985376, \"value\": 1.0}, \"2\": {\"effect\": -0.046679002224797324, \"value\": 0.0}, \"3\": {\"effect\": -0.07722436084788836, \"value\": 0.2101784389811145}, \"4\": {\"effect\": 0.011714973639867244, \"value\": 0.0}, \"5\": {\"effect\": -0.13449733444632003, \"value\": 0.0}, \"6\": {\"effect\": 0.0029560388083344513, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.4879317201844208, \"value\": 0.9}, \"8\": {\"effect\": 0.23911323317601768, \"value\": 1.0}, \"9\": {\"effect\": 0.07847658649385295, \"value\": 0.2871684061315919}, \"10\": {\"effect\": 0.09438438961704626, \"value\": 0.4996263154817879}, \"11\": {\"effect\": 0.034461452336019646, \"value\": 1.0}, \"12\": {\"effect\": 0.06841448635106288, \"value\": -0.3945864777926284}, \"13\": {\"effect\": -0.5105049430532137, \"value\": 0.0}, \"14\": {\"effect\": 0.030589184071331682, \"value\": 1.0}, \"15\": {\"effect\": -0.12866392309724795, \"value\": 1.0}, \"16\": {\"effect\": -0.201818359426496, \"value\": 1.0}, \"17\": {\"effect\": 0.0013273209550547142, \"value\": 1.0}, \"18\": {\"effect\": 0.6396731350345882, \"value\": 5.0}, \"19\": {\"effect\": -0.006269995392835463, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.0232111983563679, \"value\": 0.9}, \"21\": {\"effect\": 0.09307226310608661, \"value\": 0.4996263154817879}, \"22\": {\"effect\": -0.2639504163600029, \"value\": 0.0046017739268205}, \"23\": {\"effect\": 1.356645024464471, \"value\": 105.28494410346563}, \"24\": {\"effect\": 0.11780403190480022, \"value\": 15.0}, \"25\": {\"effect\": 0.10891251865423594, \"value\": 5.0}, \"26\": {\"effect\": -0.7068985763746832, \"value\": -0.1876316413262934}, \"27\": {\"effect\": 0.0011868161272425124, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.14383725145361484, \"value\": 2.8281067955679404}, \"29\": {\"effect\": -0.16860857872213464, \"value\": 0.9523207498417148}, \"30\": {\"effect\": -0.1598766241854329, \"value\": 1.1077698514664904}, \"31\": {\"effect\": -0.07925257789066029, \"value\": -0.3945864777926284}, \"32\": {\"effect\": 0.05370440395866874, \"value\": 0.2871684061315919}, \"33\": {\"effect\": 0.21513601544886357, \"value\": 1.6638537467837806}, \"34\": {\"effect\": -0.011717949521044602, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.12599029955850657, \"value\": -0.7645422650469426}, \"36\": {\"effect\": -0.0389448364128673, \"value\": 0.2101784389811145}, \"37\": {\"effect\": 0.028446608127500536, \"value\": 0.0}, \"38\": {\"effect\": 0.002653195253317532, \"value\": 0.0}, \"39\": {\"effect\": 0.05768566679372321, \"value\": 1.0}}}, {\"outValue\": 4.63628393534839, \"simIndex\": 82.0, \"features\": {\"0\": {\"effect\": 0.2934206496245379, \"value\": 0.0}, \"1\": {\"effect\": 0.057374576741692065, \"value\": 1.0}, \"2\": {\"effect\": -0.05511939293171797, \"value\": 0.0}, \"3\": {\"effect\": 0.09055503153753454, \"value\": -0.665117665250102}, \"4\": {\"effect\": 0.014464142233041596, \"value\": 0.0}, \"5\": {\"effect\": -0.14404036839031262, \"value\": 0.0}, \"6\": {\"effect\": 0.05978096389072045, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.07108037609455281, \"value\": 0.6000000000000001}, \"8\": {\"effect\": 0.3396831730683238, \"value\": 1.0}, \"9\": {\"effect\": -0.15061197174775723, \"value\": -1.2053308330235164}, \"10\": {\"effect\": 0.2042226672970977, \"value\": 0.5377895408054849}, \"11\": {\"effect\": 0.03361738540645689, \"value\": 1.0}, \"12\": {\"effect\": -0.18055957092982108, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.5308371019274218, \"value\": 1.0}, \"14\": {\"effect\": 0.03275587576319775, \"value\": 1.0}, \"15\": {\"effect\": 0.887195289796498, \"value\": 6.0}, \"16\": {\"effect\": 0.2975927713948112, \"value\": 0.0}, \"17\": {\"effect\": 0.0004956952946059358, \"value\": 1.0}, \"18\": {\"effect\": 0.12888118170650245, \"value\": 2.0}, \"19\": {\"effect\": 0.16493139207115587, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.07434461333981017, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.08510934270381797, \"value\": 0.5377895408054849}, \"22\": {\"effect\": 0.16576958565327798, \"value\": 0.0265708705755777}, \"23\": {\"effect\": -0.16204704913241574, \"value\": -0.9369378598141014}, \"24\": {\"effect\": -0.012349508825292949, \"value\": 11.0}, \"25\": {\"effect\": 0.13391719440290678, \"value\": 2.0}, \"26\": {\"effect\": -0.5591339339722177, \"value\": 0.5815420933189115}, \"27\": {\"effect\": 0.030971037471695943, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.07661324178887002, \"value\": -0.2136809213498082}, \"29\": {\"effect\": -0.24225528266023832, \"value\": -1.6496266684962078}, \"30\": {\"effect\": -0.49552123759557526, \"value\": -1.845624939261468}, \"31\": {\"effect\": -0.05932884974054504, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.014588170197201536, \"value\": -1.2053308330235164}, \"33\": {\"effect\": -0.03539052980670854, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.002521520179113478, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.12305941655755018, \"value\": -0.6788394604596062}, \"36\": {\"effect\": 0.0029189930271324026, \"value\": -0.665117665250102}, \"37\": {\"effect\": 0.035822808733182214, \"value\": 0.0}, \"38\": {\"effect\": 0.0016746380311610134, \"value\": 0.0}, \"39\": {\"effect\": -0.11459714250669079, \"value\": 3.0}}}, {\"outValue\": 3.751016155957842, \"simIndex\": 86.0, \"features\": {\"0\": {\"effect\": 0.2965324129314164, \"value\": 0.0}, \"1\": {\"effect\": -0.1279463211424036, \"value\": 0.0}, \"2\": {\"effect\": -0.12620504991162768, \"value\": 0.0}, \"3\": {\"effect\": 0.11304085599874353, \"value\": -0.5696308175157875}, \"4\": {\"effect\": 0.019091259854513484, \"value\": 0.0}, \"5\": {\"effect\": -0.23492300701147673, \"value\": 0.0}, \"6\": {\"effect\": -0.10190844022992011, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.06036008965794314, \"value\": 0.7000000000000001}, \"8\": {\"effect\": -0.3456835769685233, \"value\": 0.0}, \"9\": {\"effect\": -0.5203308518877627, \"value\": 2.29630199730193}, \"10\": {\"effect\": 0.2685523509505403, \"value\": 0.5981929020957328}, \"11\": {\"effect\": 0.03141975429522766, \"value\": 1.0}, \"12\": {\"effect\": -9.801464908753554e-05, \"value\": 3.599973443281323}, \"13\": {\"effect\": 0.4944326003874017, \"value\": 1.0}, \"14\": {\"effect\": 0.030322762751880703, \"value\": 1.0}, \"15\": {\"effect\": 0.25627825697943063, \"value\": 2.0}, \"16\": {\"effect\": 0.37751572695380464, \"value\": 0.0}, \"17\": {\"effect\": 0.001290106872127103, \"value\": 1.0}, \"18\": {\"effect\": 0.04647123274554723, \"value\": 3.0}, \"19\": {\"effect\": 0.043466929409750284, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.008120269001652004, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.04792623285343959, \"value\": 0.5981929020957328}, \"22\": {\"effect\": -0.00960130055124632, \"value\": 0.0021440040551625}, \"23\": {\"effect\": 0.463261822919856, \"value\": 18.90561103555649}, \"24\": {\"effect\": 0.1425013826385443, \"value\": 4.0}, \"25\": {\"effect\": 0.11013074459273582, \"value\": 3.0}, \"26\": {\"effect\": -0.5649187632609749, \"value\": -0.0066495861156569}, \"27\": {\"effect\": -0.0005625215536658525, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.02780219103639996, \"value\": -0.5013047873604283}, \"29\": {\"effect\": 0.14258779911846176, \"value\": -1.2199670542273366}, \"30\": {\"effect\": 0.125320180715695, \"value\": -0.6240618079971808}, \"31\": {\"effect\": -0.03652705185911835, \"value\": 3.599973443281323}, \"32\": {\"effect\": -0.4866355400985448, \"value\": 2.29630199730193}, \"33\": {\"effect\": -0.08298784082034236, \"value\": -0.4819151924735424}, \"34\": {\"effect\": -0.002148732343176119, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.07105342031771707, \"value\": -0.6595051235525008}, \"36\": {\"effect\": 0.02378364453899883, \"value\": -0.5696308175157875}, \"37\": {\"effect\": 0.03440822313034339, \"value\": 0.0}, \"38\": {\"effect\": 0.0011916284592554194, \"value\": 0.0}, \"39\": {\"effect\": 0.09996632240975409, \"value\": 2.0}}}, {\"outValue\": 3.3035815547003726, \"simIndex\": 78.0, \"features\": {\"0\": {\"effect\": 0.3192050937674506, \"value\": 0.0}, \"1\": {\"effect\": 0.044391213373864716, \"value\": 1.0}, \"2\": {\"effect\": -0.045705125793028045, \"value\": 0.0}, \"3\": {\"effect\": 0.03515656057890007, \"value\": -1.1883060184610337}, \"4\": {\"effect\": 0.016753302767271227, \"value\": 0.0}, \"5\": {\"effect\": -0.21408446222714203, \"value\": 0.0}, \"6\": {\"effect\": -0.04830427604981454, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.04377725956183982, \"value\": 0.8}, \"8\": {\"effect\": 0.23886699173610643, \"value\": 1.0}, \"9\": {\"effect\": -0.054721120446259784, \"value\": 0.344572223022173}, \"10\": {\"effect\": -0.3025708499610934, \"value\": 0.2060838792736372}, \"11\": {\"effect\": 0.042023024642335614, \"value\": 1.0}, \"12\": {\"effect\": 0.06894693611512213, \"value\": -0.3750053017089326}, \"13\": {\"effect\": 0.5500933889134642, \"value\": 1.0}, \"14\": {\"effect\": 0.044417510149131534, \"value\": 1.0}, \"15\": {\"effect\": -0.09541721398083325, \"value\": 1.0}, \"16\": {\"effect\": -0.24249023735931655, \"value\": 1.0}, \"17\": {\"effect\": 0.0007894793287292436, \"value\": 1.0}, \"18\": {\"effect\": 0.4715655783671021, \"value\": 5.0}, \"19\": {\"effect\": 0.0031294971781835393, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.025145001722348462, \"value\": 0.8}, \"21\": {\"effect\": -0.18301736985577247, \"value\": 0.2060838792736372}, \"22\": {\"effect\": -0.09305519741567406, \"value\": 0.0138691399622683}, \"23\": {\"effect\": -0.13277303954467373, \"value\": -1.4846086848638758}, \"24\": {\"effect\": -0.0008975570351409227, \"value\": 5.0}, \"25\": {\"effect\": 0.20958744509498373, \"value\": 5.0}, \"26\": {\"effect\": -0.6673776706262723, \"value\": -0.1763202628756286}, \"27\": {\"effect\": -0.011091390381906803, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.11490284695545129, \"value\": 0.0620134065367428}, \"29\": {\"effect\": -0.004301075576124132, \"value\": -1.261832491404238}, \"30\": {\"effect\": 0.1549230927841526, \"value\": -0.5450759857533607}, \"31\": {\"effect\": 0.046769113663822776, \"value\": -0.3750053017089326}, \"32\": {\"effect\": 0.008774474358201466, \"value\": 0.344572223022173}, \"33\": {\"effect\": -0.04535337035920959, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.0035214485292206356, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.05682486749243876, \"value\": -0.5797121844480827}, \"36\": {\"effect\": 0.0261341388745412, \"value\": -1.1883060184610337}, \"37\": {\"effect\": 0.03342132536102044, \"value\": 0.0}, \"38\": {\"effect\": 0.004248974110492563, \"value\": 0.0}, \"39\": {\"effect\": 0.06196169871187687, \"value\": 2.0}}}, {\"outValue\": 5.147537879248487, \"simIndex\": 40.0, \"features\": {\"0\": {\"effect\": 0.3393972003775152, \"value\": 0.0}, \"1\": {\"effect\": 0.027531215913340294, \"value\": 1.0}, \"2\": {\"effect\": -0.03521444429145531, \"value\": 0.0}, \"3\": {\"effect\": -0.1071786506566831, \"value\": 0.4081147170970374}, \"4\": {\"effect\": 0.009260899590071156, \"value\": 0.0}, \"5\": {\"effect\": 0.9124340456790623, \"value\": 1.0}, \"6\": {\"effect\": 0.01632851601004969, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.3858612420844177, \"value\": 0.9}, \"8\": {\"effect\": 0.32495011824182823, \"value\": 1.0}, \"9\": {\"effect\": 0.1977870788898438, \"value\": -0.0716054494345398}, \"10\": {\"effect\": -0.41696094769171027, \"value\": 0.1106106362302945}, \"11\": {\"effect\": 0.07694397254308614, \"value\": 1.0}, \"12\": {\"effect\": 0.09647453854244531, \"value\": -0.3880594190980632}, \"13\": {\"effect\": -0.28995142882996183, \"value\": 0.0}, \"14\": {\"effect\": 0.038853984451766216, \"value\": 1.0}, \"15\": {\"effect\": 0.29135457181047697, \"value\": 2.0}, \"16\": {\"effect\": -0.15606043364193584, \"value\": 1.0}, \"17\": {\"effect\": 0.001155265838038431, \"value\": 1.0}, \"18\": {\"effect\": 0.352887915641102, \"value\": 5.0}, \"19\": {\"effect\": 0.06677006778706102, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.023768681764190135, \"value\": 0.9}, \"21\": {\"effect\": -0.040773517295746214, \"value\": 0.1106106362302945}, \"22\": {\"effect\": 0.03253988294575592, \"value\": 0.0086511959416975}, \"23\": {\"effect\": 0.4272462194899075, \"value\": 21.35749812227217}, \"24\": {\"effect\": 0.10385004367268298, \"value\": 17.0}, \"25\": {\"effect\": 0.1912113060801837, \"value\": 5.0}, \"26\": {\"effect\": 0.025673039201839103, \"value\": -0.5043502379449072}, \"27\": {\"effect\": -0.0075883208487606555, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.10011754874749947, \"value\": 0.5120867880481232}, \"29\": {\"effect\": 0.1666785129157801, \"value\": -1.0657916044049605}, \"30\": {\"effect\": 0.18054937809986144, \"value\": -0.6478046696744966}, \"31\": {\"effect\": 0.02525716502286919, \"value\": -0.3880594190980632}, \"32\": {\"effect\": 0.021093190298802782, \"value\": -0.0716054494345398}, \"33\": {\"effect\": 0.03397188400350741, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.015836439824134827, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.08327292364520311, \"value\": -0.5468654746906229}, \"36\": {\"effect\": -0.06209322420174483, \"value\": 0.4081147170970374}, \"37\": {\"effect\": 0.0180572252745655, \"value\": 0.0}, \"38\": {\"effect\": 0.0024139900587972366, \"value\": 0.0}, \"39\": {\"effect\": -0.21103392998441498, \"value\": 3.0}}}, {\"outValue\": 6.052100953901623, \"simIndex\": 14.0, \"features\": {\"0\": {\"effect\": 0.2679117553050474, \"value\": 0.0}, \"1\": {\"effect\": 0.022485796582214227, \"value\": 1.0}, \"2\": {\"effect\": 0.210259931918221, \"value\": 1.0}, \"3\": {\"effect\": 0.2376153002800404, \"value\": 3.233928617234408}, \"4\": {\"effect\": 0.015926901953407648, \"value\": 0.0}, \"5\": {\"effect\": -0.23605046973403382, \"value\": 0.0}, \"6\": {\"effect\": 0.035502547048408356, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.13889008512783638, \"value\": 0.8}, \"8\": {\"effect\": 0.2904424367829987, \"value\": 1.0}, \"9\": {\"effect\": 0.053592422518483146, \"value\": -0.4590812134459622}, \"10\": {\"effect\": 0.1304608641469537, \"value\": 0.4811823553005151}, \"11\": {\"effect\": -0.018027822350740397, \"value\": 0.0}, \"12\": {\"effect\": -0.16519263883798962, \"value\": -0.3989378502556719}, \"13\": {\"effect\": 0.42252801536283585, \"value\": 1.0}, \"14\": {\"effect\": 0.038831494504978435, \"value\": 1.0}, \"15\": {\"effect\": 0.22782513844563773, \"value\": 2.0}, \"16\": {\"effect\": 0.40600726556596867, \"value\": 0.0}, \"17\": {\"effect\": 0.0013474044646557418, \"value\": 1.0}, \"18\": {\"effect\": 0.17467592143999688, \"value\": 2.0}, \"19\": {\"effect\": -0.19235557670203496, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.02496368177882145, \"value\": 0.8}, \"21\": {\"effect\": 0.13300319488706777, \"value\": 0.4811823553005151}, \"22\": {\"effect\": 0.1012691846638164, \"value\": 0.0215093655207356}, \"23\": {\"effect\": -0.03835009596690099, \"value\": -0.605074282328782}, \"24\": {\"effect\": -0.2264578239097633, \"value\": 3.0}, \"25\": {\"effect\": 0.12981672545932524, \"value\": 2.0}, \"26\": {\"effect\": 0.6871163924417681, \"value\": -0.7645119423101971}, \"27\": {\"effect\": -0.01609155079967483, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.01152589952051517, \"value\": -0.6285566813482152}, \"29\": {\"effect\": -0.06365428721164268, \"value\": 0.1434285770316744}, \"30\": {\"effect\": 0.15705699269358217, \"value\": 0.3790147994780415}, \"31\": {\"effect\": -0.049875236751299366, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.032798717789140744, \"value\": -0.4590812134459622}, \"33\": {\"effect\": 0.33207444890488563, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.00609569519267271, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.030548588433794453, \"value\": 1.0895357679400168}, \"36\": {\"effect\": -0.03763012888157873, \"value\": 3.233928617234408}, \"37\": {\"effect\": 0.033903610292847865, \"value\": 0.0}, \"38\": {\"effect\": 0.0017877223673491945, \"value\": 0.0}, \"39\": {\"effect\": -0.003675521740510013, \"value\": 1.0}}}, {\"outValue\": 4.9794169166205275, \"simIndex\": 50.0, \"features\": {\"0\": {\"effect\": 0.23066401251683477, \"value\": 0.0}, \"1\": {\"effect\": 0.02959756097812863, \"value\": 1.0}, \"2\": {\"effect\": 0.2126194089548885, \"value\": 1.0}, \"3\": {\"effect\": -0.23135629403140445, \"value\": -0.4731493151175738}, \"4\": {\"effect\": 0.02228765023386655, \"value\": 0.0}, \"5\": {\"effect\": 0.6179724753889617, \"value\": 1.0}, \"6\": {\"effect\": 0.058031949847254544, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.29199315040954005, \"value\": 0.1}, \"8\": {\"effect\": 0.33209933997554125, \"value\": 1.0}, \"9\": {\"effect\": 0.027692339602562156, \"value\": -0.7461002978988677}, \"10\": {\"effect\": -0.005129007077439111, \"value\": 0.9987182381174642}, \"11\": {\"effect\": -0.01474472482695039, \"value\": 0.0}, \"12\": {\"effect\": 0.09389432603752419, \"value\": -0.3684782430143673}, \"13\": {\"effect\": 0.47366363053154004, \"value\": 1.0}, \"14\": {\"effect\": 0.0446836403963529, \"value\": 1.0}, \"15\": {\"effect\": -0.09046044639913116, \"value\": 1.0}, \"16\": {\"effect\": -0.4168743377928922, \"value\": 1.0}, \"17\": {\"effect\": 0.0003227534317993256, \"value\": 1.0}, \"18\": {\"effect\": 0.35429574958906934, \"value\": 5.0}, \"19\": {\"effect\": 0.14787388772661733, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.05503363249803111, \"value\": 0.1}, \"21\": {\"effect\": 0.07217319436313921, \"value\": 0.9987182381174642}, \"22\": {\"effect\": -0.749981185097332, \"value\": 3.35122213790062}, \"23\": {\"effect\": 0.11323727708990565, \"value\": 49.07401604230266}, \"24\": {\"effect\": -0.04373121821304, \"value\": 10.0}, \"25\": {\"effect\": 0.1612172198601612, \"value\": 5.0}, \"26\": {\"effect\": -0.3312695206758621, \"value\": 1.6900571814840597}, \"27\": {\"effect\": 0.018753555056617785, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.14657084531776665, \"value\": 0.2108433545602651}, \"29\": {\"effect\": -0.051371258448147744, \"value\": -0.0850582934858596}, \"30\": {\"effect\": 0.09924141711508885, \"value\": -0.655815634901328}, \"31\": {\"effect\": -0.002185777790373398, \"value\": -0.3684782430143673}, \"32\": {\"effect\": -0.018318685723286817, \"value\": -0.7461002978988677}, \"33\": {\"effect\": 0.23819289486619508, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.0038822173568651957, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.10171529715395859, \"value\": -0.3439182011556325}, \"36\": {\"effect\": 0.014580043782202784, \"value\": -0.4731493151175738}, \"37\": {\"effect\": 0.02644732235960495, \"value\": 0.0}, \"38\": {\"effect\": 0.00040225542384386557, \"value\": 0.0}, \"39\": {\"effect\": 0.07822541441260614, \"value\": 2.0}}}, {\"outValue\": 6.979081409298175, \"simIndex\": 32.0, \"features\": {\"0\": {\"effect\": 0.2950291507622301, \"value\": 0.0}, \"1\": {\"effect\": 0.03469613612215668, \"value\": 1.0}, \"2\": {\"effect\": 0.2758708448689526, \"value\": 1.0}, \"3\": {\"effect\": 0.7880289760661886, \"value\": -1.2867768301870457}, \"4\": {\"effect\": 0.013749753102364818, \"value\": 0.0}, \"5\": {\"effect\": -0.2186437142574577, \"value\": 0.0}, \"6\": {\"effect\": 0.06561843436714758, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.029921348782899457, \"value\": 0.8}, \"8\": {\"effect\": 0.3796382596912855, \"value\": 1.0}, \"9\": {\"effect\": 0.23281171659312613, \"value\": -0.5451869387818339}, \"10\": {\"effect\": 0.1051755436488749, \"value\": 0.4142159600918499}, \"11\": {\"effect\": -0.02743126030351908, \"value\": 0.0}, \"12\": {\"effect\": 0.13766941109458677, \"value\": -0.3663025567828455}, \"13\": {\"effect\": 0.5073123524924187, \"value\": 1.0}, \"14\": {\"effect\": 0.03434887206225817, \"value\": 1.0}, \"15\": {\"effect\": -0.08104664517764504, \"value\": 1.0}, \"16\": {\"effect\": -0.31595221987323113, \"value\": 1.0}, \"17\": {\"effect\": 0.001343851276095746, \"value\": 1.0}, \"18\": {\"effect\": 0.09148181716820472, \"value\": 4.0}, \"19\": {\"effect\": 0.08876795227337399, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.04129923035254656, \"value\": 0.8}, \"21\": {\"effect\": 0.0417966459820912, \"value\": 0.4142159600918499}, \"22\": {\"effect\": 0.012777257635529215, \"value\": 0.0074448698104111}, \"23\": {\"effect\": -0.07930955804953843, \"value\": -0.9092391068806444}, \"24\": {\"effect\": 0.07605430533701305, \"value\": 6.0}, \"25\": {\"effect\": 0.10748637814316157, \"value\": 4.0}, \"26\": {\"effect\": 0.892374060154292, \"value\": -0.8776257268168449}, \"27\": {\"effect\": 0.008762326980464535, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.008102449496885227, \"value\": -1.4174289712920645}, \"29\": {\"effect\": 0.034686666216327704, \"value\": -1.2651411187262174}, \"30\": {\"effect\": -0.2580101595940317, \"value\": -1.9107905951685125}, \"31\": {\"effect\": 0.03557943668955846, \"value\": -0.3663025567828455}, \"32\": {\"effect\": 0.17899793375905818, \"value\": -0.5451869387818339}, \"33\": {\"effect\": 0.2529065789322774, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.02085235283740412, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.175701137538975, \"value\": 0.188739950573121}, \"36\": {\"effect\": 0.18545221703978032, \"value\": -1.2867768301870457}, \"37\": {\"effect\": 0.02648477659913002, \"value\": 0.0}, \"38\": {\"effect\": 0.002523414338431701, \"value\": 0.0}, \"39\": {\"effect\": -0.1360860693146661, \"value\": 3.0}}}, {\"outValue\": 2.4111214856711936, \"simIndex\": 12.0, \"features\": {\"0\": {\"effect\": 0.285467372045972, \"value\": 0.0}, \"1\": {\"effect\": 0.02896581978611578, \"value\": 1.0}, \"2\": {\"effect\": -0.05234358499028671, \"value\": 0.0}, \"3\": {\"effect\": -0.03684262060686921, \"value\": -0.8799630726523097}, \"4\": {\"effect\": 0.014780155516159821, \"value\": 0.0}, \"5\": {\"effect\": 0.9146031131383593, \"value\": 1.0}, \"6\": {\"effect\": 0.01160533827386448, \"value\": -0.0325109137671299}, \"7\": {\"effect\": -0.4992850584865865, \"value\": 0.9}, \"8\": {\"effect\": 0.3358101744009884, \"value\": 1.0}, \"9\": {\"effect\": 0.022221874644176673, \"value\": 0.2154136350183655}, \"10\": {\"effect\": -0.4888804953203863, \"value\": 0.1564632172356464}, \"11\": {\"effect\": 0.05974440819573922, \"value\": 1.0}, \"12\": {\"effect\": -0.1947801221595872, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.38088479226967475, \"value\": 1.0}, \"14\": {\"effect\": 0.04067743948916372, \"value\": 1.0}, \"15\": {\"effect\": -0.13893482803802104, \"value\": 3.0}, \"16\": {\"effect\": 0.27000488852414173, \"value\": 0.0}, \"17\": {\"effect\": 0.0011149859425158386, \"value\": 1.0}, \"18\": {\"effect\": 0.12313919754166087, \"value\": 2.0}, \"19\": {\"effect\": -0.5760170248616522, \"value\": 2.187874078283813}, \"20\": {\"effect\": -0.04548672683505937, \"value\": 0.9}, \"21\": {\"effect\": -0.10872429306307131, \"value\": 0.1564632172356464}, \"22\": {\"effect\": -0.11928263354745185, \"value\": 0.0105618046708123}, \"23\": {\"effect\": -0.373531129466454, \"value\": -1.4355360095965857}, \"24\": {\"effect\": -0.7304694750881147, \"value\": 2.0}, \"25\": {\"effect\": 0.15729236415029796, \"value\": 2.0}, \"26\": {\"effect\": 0.15176504585360323, \"value\": -0.5948412655502254}, \"27\": {\"effect\": -0.25509270051870675, \"value\": 2.187874078283813}, \"28\": {\"effect\": 0.07883367841628262, \"value\": -0.7866647783930796}, \"29\": {\"effect\": -0.06710536763123336, \"value\": 0.4994477862816683}, \"30\": {\"effect\": 0.11040384082430868, \"value\": 0.0801793399739205}, \"31\": {\"effect\": -0.06362590036606044, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.01582209528188749, \"value\": 0.2154136350183655}, \"33\": {\"effect\": -0.036112044823179784, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.02426150414444724, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.04833905914785731, \"value\": -0.6009311120340071}, \"36\": {\"effect\": -0.02921874981515859, \"value\": -0.8799630726523097}, \"37\": {\"effect\": 0.0231706794182524, \"value\": 0.0}, \"38\": {\"effect\": 0.0014936379917946632, \"value\": 0.0}, \"39\": {\"effect\": 0.15222538985968703, \"value\": 2.0}}}, {\"outValue\": 1.8296752486758687, \"simIndex\": 62.0, \"features\": {\"0\": {\"effect\": -0.7544376392078065, \"value\": 1.0}, \"1\": {\"effect\": 0.017176848793396367, \"value\": 1.0}, \"2\": {\"effect\": -0.05405920823296789, \"value\": 0.0}, \"3\": {\"effect\": 0.053203898989778585, \"value\": -0.2045925558648142}, \"4\": {\"effect\": 0.009924258976287285, \"value\": 0.0}, \"5\": {\"effect\": -0.248730875307242, \"value\": 0.0}, \"6\": {\"effect\": 0.04089791902663499, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.46930772036558893, \"value\": 0.9}, \"8\": {\"effect\": 0.22740421625598917, \"value\": 1.0}, \"9\": {\"effect\": 0.16044074910747674, \"value\": -0.2868697627742189}, \"10\": {\"effect\": -0.40218092041778275, \"value\": 0.1403616920368182}, \"11\": {\"effect\": -0.021144946135461026, \"value\": 0.0}, \"12\": {\"effect\": 0.23255580619245356, \"value\": -0.3597754980882803}, \"13\": {\"effect\": -0.4313945416007015, \"value\": 0.0}, \"14\": {\"effect\": 0.03125008362678668, \"value\": 1.0}, \"15\": {\"effect\": -0.09856461396361241, \"value\": 1.0}, \"16\": {\"effect\": 0.28485120234717154, \"value\": 0.0}, \"17\": {\"effect\": 0.0008486883968124198, \"value\": 1.0}, \"18\": {\"effect\": 0.03783285295402598, \"value\": 3.0}, \"19\": {\"effect\": 0.03033708751471952, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.04012063480389508, \"value\": 0.9}, \"21\": {\"effect\": -0.13782463917374865, \"value\": 0.1403616920368182}, \"22\": {\"effect\": 0.2941943476184118, \"value\": 0.035233677867892}, \"23\": {\"effect\": 0.4622365145353676, \"value\": 27.307914162737696}, \"24\": {\"effect\": 0.0093133296148992, \"value\": 6.0}, \"25\": {\"effect\": 0.12782719692241568, \"value\": 3.0}, \"26\": {\"effect\": -0.6997573370973289, \"value\": -0.2441885335796173}, \"27\": {\"effect\": 0.025937908392644017, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.04546658838258003, \"value\": -0.4966656237784947}, \"29\": {\"effect\": -0.09329982339240514, \"value\": 0.8210038965543722}, \"30\": {\"effect\": -0.021217697745322284, \"value\": 0.6722033952479106}, \"31\": {\"effect\": 0.03709790418748833, \"value\": -0.3597754980882803}, \"32\": {\"effect\": 0.05585128433628951, \"value\": -0.2868697627742189}, \"33\": {\"effect\": -0.09316218693953855, \"value\": 0.7560284263287593}, \"34\": {\"effect\": 0.0027617309247745317, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.1522387493461484, \"value\": 1.4026538641361106}, \"36\": {\"effect\": 0.00431306118260485, \"value\": -0.2045925558648142}, \"37\": {\"effect\": 0.016534212586521834, \"value\": 0.0}, \"38\": {\"effect\": 0.0032305598821337593, \"value\": 0.0}, \"39\": {\"effect\": -0.03975447176237851, \"value\": 1.0}}}, {\"outValue\": 0.9460643222245433, \"simIndex\": 23.0, \"features\": {\"0\": {\"effect\": -0.730748256498257, \"value\": 1.0}, \"1\": {\"effect\": 0.0016823825952589232, \"value\": 1.0}, \"2\": {\"effect\": -0.06793285389801552, \"value\": 0.0}, \"3\": {\"effect\": 0.09695774453404955, \"value\": -0.6312994066775323}, \"4\": {\"effect\": 0.015541167866019931, \"value\": 0.0}, \"5\": {\"effect\": -0.26171269457175933, \"value\": 0.0}, \"6\": {\"effect\": -0.05751429092388474, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.721512871127686, \"value\": 0.9}, \"8\": {\"effect\": 0.34362837352535947, \"value\": 1.0}, \"9\": {\"effect\": -0.10505820806367171, \"value\": 1.0190670714865009}, \"10\": {\"effect\": -0.027009333095893682, \"value\": 0.9970402809198936}, \"11\": {\"effect\": -0.05145984054188031, \"value\": 0.0}, \"12\": {\"effect\": -0.2549854952505883, \"value\": -0.4011135364871937}, \"13\": {\"effect\": -0.37662511313776814, \"value\": 0.0}, \"14\": {\"effect\": 0.03390010097055901, \"value\": 1.0}, \"15\": {\"effect\": -0.13886181542608286, \"value\": 1.0}, \"16\": {\"effect\": -0.2687742454408941, \"value\": 1.0}, \"17\": {\"effect\": 0.00028008295347479713, \"value\": 1.0}, \"18\": {\"effect\": 0.052971237987947555, \"value\": 3.0}, \"19\": {\"effect\": 0.05594589714149765, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.03171157293443438, \"value\": 0.9}, \"21\": {\"effect\": 0.05904016802112809, \"value\": 0.9970402809198936}, \"22\": {\"effect\": -0.10628472739933864, \"value\": 0.0161529339663407}, \"23\": {\"effect\": -0.2323278635760066, \"value\": -0.7820004376862214}, \"24\": {\"effect\": 0.058409906222649355, \"value\": 12.0}, \"25\": {\"effect\": 0.18993539713877355, \"value\": 3.0}, \"26\": {\"effect\": 0.44828912125019454, \"value\": -0.6853322931555437}, \"27\": {\"effect\": 0.02209794452207516, \"value\": -0.3067639787858137}, \"28\": {\"effect\": -0.12075912309758624, \"value\": -1.434248427856879}, \"29\": {\"effect\": -0.026670969996290764, \"value\": 0.547713384554009}, \"30\": {\"effect\": 0.16477795783320537, \"value\": -0.5380101793780183}, \"31\": {\"effect\": -0.07219755627278428, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.06541639417730175, \"value\": 1.0190670714865009}, \"33\": {\"effect\": -0.02385874559488273, \"value\": -0.9770926399944632}, \"34\": {\"effect\": -0.02571376456672482, \"value\": 2.01852014148613}, \"35\": {\"effect\": 0.008807859535211232, \"value\": 1.2274223303847962}, \"36\": {\"effect\": 0.0043364195652178875, \"value\": -0.6312994066775323}, \"37\": {\"effect\": 0.021030905143347746, \"value\": 0.0}, \"38\": {\"effect\": 0.0012907528840072323, \"value\": 0.0}, \"39\": {\"effect\": 0.06337113339846187, \"value\": 2.0}}}, {\"outValue\": 4.462837596529612, \"simIndex\": 43.0, \"features\": {\"0\": {\"effect\": 0.2988696247861488, \"value\": 0.0}, \"1\": {\"effect\": 0.021495509834902896, \"value\": 1.0}, \"2\": {\"effect\": -0.12716233422780215, \"value\": 0.0}, \"3\": {\"effect\": -0.07008640071686943, \"value\": 0.1395579578442777}, \"4\": {\"effect\": 0.00896749891978704, \"value\": 0.0}, \"5\": {\"effect\": 0.970067323053321, \"value\": 1.0}, \"6\": {\"effect\": 0.058077587415567615, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.26167148312313027, \"value\": 0.3}, \"8\": {\"effect\": -0.32137457690610943, \"value\": 0.0}, \"9\": {\"effect\": 0.13695197264054268, \"value\": -0.0859564036571851}, \"10\": {\"effect\": -0.46156638362435276, \"value\": 0.0708682914508214}, \"11\": {\"effect\": 0.0334410198212074, \"value\": 1.0}, \"12\": {\"effect\": 0.8531261310579751, \"value\": 0.5409586017617283}, \"13\": {\"effect\": -0.38128978537170644, \"value\": 0.0}, \"14\": {\"effect\": 0.044362947456735996, \"value\": 1.0}, \"15\": {\"effect\": -0.1474377080243689, \"value\": 1.0}, \"16\": {\"effect\": -0.2715961308843448, \"value\": 1.0}, \"17\": {\"effect\": 0.0006383121025866382, \"value\": 1.0}, \"18\": {\"effect\": 0.11562560723788042, \"value\": 2.0}, \"19\": {\"effect\": 0.04843073503901536, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.056385521292055325, \"value\": 0.3}, \"21\": {\"effect\": 0.008437892571990346, \"value\": 0.0708682914508214}, \"22\": {\"effect\": 0.10598361689720678, \"value\": 0.0233797415018459}, \"23\": {\"effect\": -0.11776958409312388, \"value\": -0.6636277991569788}, \"24\": {\"effect\": 0.058133036495226026, \"value\": 9.0}, \"25\": {\"effect\": 0.18669888079176902, \"value\": 2.0}, \"26\": {\"effect\": -0.5766305599401029, \"value\": -0.0179609645663217}, \"27\": {\"effect\": 0.006675092695875665, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.06911380890731499, \"value\": 2.3694793192071253}, \"29\": {\"effect\": -0.1903266527941265, \"value\": 1.130205306510044}, \"30\": {\"effect\": 0.1853033365143861, \"value\": 0.2320548469976098}, \"31\": {\"effect\": 0.15495355945416667, \"value\": 0.5409586017617283}, \"32\": {\"effect\": 0.02898087802624322, \"value\": -0.0859564036571851}, \"33\": {\"effect\": 0.08025950330338426, \"value\": 1.25120587384968}, \"34\": {\"effect\": 0.016423123499282814, \"value\": -0.0325109137671299}, \"35\": {\"effect\": 0.015343605613941184, \"value\": -0.3052557541788284}, \"36\": {\"effect\": -0.001596321269745363, \"value\": 0.1395579578442777}, \"37\": {\"effect\": 0.026711591395920203, \"value\": 0.0}, \"38\": {\"effect\": 0.004121104304713115, \"value\": 0.0}, \"39\": {\"effect\": 0.20351822540215123, \"value\": 2.0}}}, {\"outValue\": 3.2315151057628633, \"simIndex\": 33.0, \"features\": {\"0\": {\"effect\": 0.27716276052321925, \"value\": 0.0}, \"1\": {\"effect\": 0.031100305179959663, \"value\": 1.0}, \"2\": {\"effect\": -0.12975459831206076, \"value\": 0.0}, \"3\": {\"effect\": -0.009720511417130871, \"value\": -0.221501685151099}, \"4\": {\"effect\": 0.007297694298116133, \"value\": 0.0}, \"5\": {\"effect\": -0.1946858855437021, \"value\": 0.0}, \"6\": {\"effect\": 0.03421641477168743, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.21161158086080076, \"value\": 0.2}, \"8\": {\"effect\": -0.4816448300516757, \"value\": 0.0}, \"9\": {\"effect\": -0.10328984743886856, \"value\": 1.0477689799317913}, \"10\": {\"effect\": 0.21953485082373358, \"value\": 0.7247549367845437}, \"11\": {\"effect\": 0.07447994226795729, \"value\": 1.0}, \"12\": {\"effect\": -0.2925937119666924, \"value\": -0.3989378502556719}, \"13\": {\"effect\": 0.4972899677986431, \"value\": 1.0}, \"14\": {\"effect\": -1.2402857996115133, \"value\": 2.0}, \"15\": {\"effect\": -0.1875422386275116, \"value\": 1.0}, \"16\": {\"effect\": -0.28295978928410587, \"value\": 1.0}, \"17\": {\"effect\": 0.001435854435349052, \"value\": 1.0}, \"18\": {\"effect\": 0.3288533793938385, \"value\": 5.0}, \"19\": {\"effect\": 0.1729304790442213, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.0755981924237361, \"value\": 0.2}, \"21\": {\"effect\": 0.0014327339413631958, \"value\": 0.7247549367845437}, \"22\": {\"effect\": -0.7003939984299087, \"value\": 69.91814651603755}, \"23\": {\"effect\": 0.45948217951085013, \"value\": 100.0235465738382}, \"24\": {\"effect\": 0.1345533400395088, \"value\": 13.0}, \"25\": {\"effect\": -0.010624042990536185, \"value\": 5.0}, \"26\": {\"effect\": 0.6071999790399002, \"value\": -0.922871240619504}, \"27\": {\"effect\": 0.025814837114738722, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.15338983675001083, \"value\": -0.0499642908133406}, \"29\": {\"effect\": -0.013641721127688489, \"value\": 0.1172725726794637}, \"30\": {\"effect\": 0.1280430028614492, \"value\": 0.3570155927744334}, \"31\": {\"effect\": -0.12586674550217494, \"value\": -0.3989378502556719}, \"32\": {\"effect\": -0.04583223182848865, \"value\": 1.0477689799317913}, \"33\": {\"effect\": 0.20040465578613875, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.041141891565412814, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.2769813710600722, \"value\": -0.7587545978451201}, \"36\": {\"effect\": -0.011998639831527411, \"value\": -0.221501685151099}, \"37\": {\"effect\": 0.03800529161920472, \"value\": 0.0}, \"38\": {\"effect\": 0.004135699457743143, \"value\": 0.0}, \"39\": {\"effect\": -0.010652047569041985, \"value\": 1.0}}}, {\"outValue\": 3.5696724004772027, \"simIndex\": 71.0, \"features\": {\"0\": {\"effect\": 0.274949314578977, \"value\": 0.0}, \"1\": {\"effect\": 0.019170184717907938, \"value\": 1.0}, \"2\": {\"effect\": 0.2255448334529939, \"value\": 1.0}, \"3\": {\"effect\": -0.08218451234049674, \"value\": 0.0908198793132213}, \"4\": {\"effect\": 0.009767430443734262, \"value\": 0.0}, \"5\": {\"effect\": -0.19494531577207821, \"value\": 0.0}, \"6\": {\"effect\": 0.024261868225622284, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.22322289442249202, \"value\": 0.4}, \"8\": {\"effect\": -0.36054307610619146, \"value\": 0.0}, \"9\": {\"effect\": 0.07352808069935608, \"value\": -0.502134076113898}, \"10\": {\"effect\": 0.04699916410417851, \"value\": 0.4000087856537531}, \"11\": {\"effect\": -0.013786955896377103, \"value\": 0.0}, \"12\": {\"effect\": 0.013793113563193501, \"value\": -0.3706539292458891}, \"13\": {\"effect\": -0.3455511269265684, \"value\": 0.0}, \"14\": {\"effect\": 0.0232945064165874, \"value\": 1.0}, \"15\": {\"effect\": 0.7157223361334744, \"value\": 4.0}, \"16\": {\"effect\": -0.25534820535775765, \"value\": 1.0}, \"17\": {\"effect\": 0.0016581934063803945, \"value\": 1.0}, \"18\": {\"effect\": 0.1703837845960283, \"value\": 2.0}, \"19\": {\"effect\": 0.2639353865190177, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.036110997667220646, \"value\": 0.4}, \"21\": {\"effect\": 0.02359260568440642, \"value\": 0.4000087856537531}, \"22\": {\"effect\": -0.024650810200106052, \"value\": 0.0141369580639306}, \"23\": {\"effect\": -0.02979080950879018, \"value\": -0.6056601420283743}, \"24\": {\"effect\": -0.004806709479352667, \"value\": 9.0}, \"25\": {\"effect\": 0.14340310004423762, \"value\": 2.0}, \"26\": {\"effect\": -0.6900359533233463, \"value\": -0.1310747490729695}, \"27\": {\"effect\": 0.01613673799589368, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.053585671836336786, \"value\": 0.2223196339099332}, \"29\": {\"effect\": -0.08122329376716163, \"value\": 0.9392691923695023}, \"30\": {\"effect\": 0.14661823435810123, \"value\": 0.3038042941265529}, \"31\": {\"effect\": -0.002132321265195222, \"value\": -0.3706539292458891}, \"32\": {\"effect\": 0.04230107339368451, \"value\": -0.502134076113898}, \"33\": {\"effect\": 0.07954861684435376, \"value\": 0.3433805533946588}, \"34\": {\"effect\": 0.003609989775968798, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.011607774979028668, \"value\": 1.6270283483843555}, \"36\": {\"effect\": -0.01031772751098634, \"value\": 0.0908198793132213}, \"37\": {\"effect\": 0.021814337185993238, \"value\": 0.0}, \"38\": {\"effect\": 0.0024189982195752784, \"value\": 0.0}, \"39\": {\"effect\": -0.04967996610291235, \"value\": 1.0}}}, {\"outValue\": 2.0666384402378957, \"simIndex\": 91.0, \"features\": {\"0\": {\"effect\": 0.3596125234530973, \"value\": 0.0}, \"1\": {\"effect\": -0.0780868737314838, \"value\": 0.0}, \"2\": {\"effect\": -0.12965550020292593, \"value\": 0.0}, \"3\": {\"effect\": -0.020526226691620908, \"value\": -0.4940370630594551}, \"4\": {\"effect\": 0.01623130194801916, \"value\": 0.0}, \"5\": {\"effect\": -0.24663178581675033, \"value\": 0.0}, \"6\": {\"effect\": 0.0681383731970194, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.406075299801187, \"value\": 0.9}, \"8\": {\"effect\": -0.3955631669109752, \"value\": 0.0}, \"9\": {\"effect\": 0.07295285881273113, \"value\": -0.5882398014497696}, \"10\": {\"effect\": 0.41146962082615607, \"value\": 0.9919814384154968}, \"11\": {\"effect\": 0.010127055134275777, \"value\": 1.0}, \"12\": {\"effect\": -0.06960288394115123, \"value\": -0.3989378502556719}, \"13\": {\"effect\": 0.6211994543967527, \"value\": 1.0}, \"14\": {\"effect\": 0.03425274576735727, \"value\": 1.0}, \"15\": {\"effect\": -0.14915328157523952, \"value\": 1.0}, \"16\": {\"effect\": -0.33982539502825726, \"value\": 1.0}, \"17\": {\"effect\": -0.0006655352614877174, \"value\": 1.0}, \"18\": {\"effect\": 0.10785828895783915, \"value\": 3.0}, \"19\": {\"effect\": -0.14983789276647008, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.022826784501399106, \"value\": 0.9}, \"21\": {\"effect\": 0.048087485752793424, \"value\": 0.9919814384154968}, \"22\": {\"effect\": -0.7649484368109466, \"value\": 25.54738303404452}, \"23\": {\"effect\": -0.0900530190262846, \"value\": -0.4755397614288425}, \"24\": {\"effect\": 0.05543693500108456, \"value\": 9.0}, \"25\": {\"effect\": 0.13546816278294987, \"value\": 3.0}, \"26\": {\"effect\": -0.858765116226548, \"value\": 0.0838414414896612}, \"27\": {\"effect\": -0.014077485622908774, \"value\": 1.3563280592606042}, \"28\": {\"effect\": 0.05198844059284238, \"value\": -0.4709390566393988}, \"29\": {\"effect\": -0.03116382174769747, \"value\": -0.199687142453285}, \"30\": {\"effect\": 0.40022340499250575, \"value\": -0.4721433118165544}, \"31\": {\"effect\": -0.021187048561896373, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.07808801279007348, \"value\": -0.5882398014497696}, \"33\": {\"effect\": -0.08379524209959599, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.02595535875529748, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.20972835233929601, \"value\": 0.2752363485371405}, \"36\": {\"effect\": 0.008657596786986674, \"value\": -0.4940370630594551}, \"37\": {\"effect\": 0.0504798034569495, \"value\": 0.0}, \"38\": {\"effect\": 0.0006344154616090612, \"value\": 0.0}, \"39\": {\"effect\": 0.10158354062924911, \"value\": 2.0}}}, {\"outValue\": 5.69733562490065, \"simIndex\": 83.0, \"features\": {\"0\": {\"effect\": 0.22155897902040778, \"value\": 0.0}, \"1\": {\"effect\": 0.04171267472112721, \"value\": 1.0}, \"2\": {\"effect\": -0.0923950659831665, \"value\": 0.0}, \"3\": {\"effect\": 0.0008826243236755405, \"value\": -1.235054787664292}, \"4\": {\"effect\": 0.019038204541178726, \"value\": 0.0}, \"5\": {\"effect\": -0.208524394264091, \"value\": 0.0}, \"6\": {\"effect\": 0.0023678412051368176, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2167973814425376, \"value\": 0.2}, \"8\": {\"effect\": -0.4329265198343546, \"value\": 0.0}, \"9\": {\"effect\": 0.0735187438398201, \"value\": -0.9183117485706108}, \"10\": {\"effect\": 0.31280365404773847, \"value\": 0.4934185957400509}, \"11\": {\"effect\": -0.031202944836238772, \"value\": 0.0}, \"12\": {\"effect\": 0.07717353335224154, \"value\": -0.3924107915611067}, \"13\": {\"effect\": 0.42126772696810083, \"value\": 1.0}, \"14\": {\"effect\": 0.04030929533295045, \"value\": 1.0}, \"15\": {\"effect\": 0.5716752929050836, \"value\": 5.0}, \"16\": {\"effect\": 0.322935045417537, \"value\": 0.0}, \"17\": {\"effect\": 0.0014636936657590543, \"value\": 1.0}, \"18\": {\"effect\": 0.21573470582004695, \"value\": 5.0}, \"19\": {\"effect\": 0.14261417954614464, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.1395089554142027, \"value\": 0.2}, \"21\": {\"effect\": 0.09713534616529966, \"value\": 0.4934185957400509}, \"22\": {\"effect\": 0.5935349830920965, \"value\": 0.0385331774791204}, \"23\": {\"effect\": 0.012236685550494081, \"value\": -0.8211700893282886}, \"24\": {\"effect\": -0.08800249068779824, \"value\": 5.0}, \"25\": {\"effect\": 0.11195382818560728, \"value\": 5.0}, \"26\": {\"effect\": 0.18546837650714124, \"value\": -0.6400867793528845}, \"27\": {\"effect\": 0.014324027983251454, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.030458176441066267, \"value\": -0.4613704105692202}, \"29\": {\"effect\": -0.13179482184420271, \"value\": 0.8322693856691558}, \"30\": {\"effect\": -0.02479351311177788, \"value\": -1.8656643984257488}, \"31\": {\"effect\": -0.025892342224227104, \"value\": -0.3924107915611067}, \"32\": {\"effect\": 0.032871773134352855, \"value\": -0.9183117485706108}, \"33\": {\"effect\": 0.15325039453054845, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0027315521598307254, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.12910563064843855, \"value\": -0.4290302096020846}, \"36\": {\"effect\": 0.13722394434451737, \"value\": -1.235054787664292}, \"37\": {\"effect\": -0.3644900855773105, \"value\": 1.0}, \"38\": {\"effect\": 0.002315070208747882, \"value\": 0.0}, \"39\": {\"effect\": -0.03930876068222263, \"value\": 1.0}}}, {\"outValue\": 3.5378672413005012, \"simIndex\": 73.0, \"features\": {\"0\": {\"effect\": 0.2686281385302892, \"value\": 0.0}, \"1\": {\"effect\": 0.027931297632657726, \"value\": 1.0}, \"2\": {\"effect\": -0.04612169318943279, \"value\": 0.0}, \"3\": {\"effect\": -0.22484436981082304, \"value\": 0.3703178398688712}, \"4\": {\"effect\": 0.009422852984970635, \"value\": 0.0}, \"5\": {\"effect\": -0.2172758566581131, \"value\": 0.0}, \"6\": {\"effect\": 0.008594021438126343, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.25934231611614433, \"value\": 0.2}, \"8\": {\"effect\": 0.35937024636189774, \"value\": 1.0}, \"9\": {\"effect\": 0.05483379819026269, \"value\": -0.8896098401253204}, \"10\": {\"effect\": 0.2775756184558321, \"value\": 0.7662394195194531}, \"11\": {\"effect\": 0.05834767791128983, \"value\": 1.0}, \"12\": {\"effect\": 0.08679594478525081, \"value\": -0.3902351053295849}, \"13\": {\"effect\": -0.3819410857236576, \"value\": 0.0}, \"14\": {\"effect\": 0.03115883220896973, \"value\": 1.0}, \"15\": {\"effect\": -0.17233259903490245, \"value\": 1.0}, \"16\": {\"effect\": 0.24712992466002393, \"value\": 0.0}, \"17\": {\"effect\": 0.0017133415567639786, \"value\": 1.0}, \"18\": {\"effect\": 0.5645848256391303, \"value\": 5.0}, \"19\": {\"effect\": 0.13902655765235863, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.035837267716206864, \"value\": 0.2}, \"21\": {\"effect\": 0.0958737058011351, \"value\": 0.7662394195194531}, \"22\": {\"effect\": -0.0929152708793902, \"value\": 0.0159383173283264}, \"23\": {\"effect\": -0.1787203995382716, \"value\": -1.131641786557652}, \"24\": {\"effect\": 0.029825775522060158, \"value\": 11.0}, \"25\": {\"effect\": 0.17409303900616688, \"value\": 5.0}, \"26\": {\"effect\": -0.5181565422011786, \"value\": 0.4344941734602693}, \"27\": {\"effect\": 0.021651680953508334, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.04821116852161431, \"value\": -0.5359883621549663}, \"29\": {\"effect\": 0.20393271823632333, \"value\": -0.860430305587644}, \"30\": {\"effect\": -0.1280291061574623, \"value\": -0.776694796514561}, \"31\": {\"effect\": 0.017519874115550064, \"value\": -0.3902351053295849}, \"32\": {\"effect\": 0.0844406933404487, \"value\": -0.8896098401253204}, \"33\": {\"effect\": -0.4512652831671834, \"value\": 1.5813241721969604}, \"34\": {\"effect\": 0.0023360829101509778, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.027230375466327072, \"value\": -0.784634332826866}, \"36\": {\"effect\": -0.04727459252838808, \"value\": 0.3703178398688712}, \"37\": {\"effect\": 0.027235126302171453, \"value\": 0.0}, \"38\": {\"effect\": 0.001232845726232799, \"value\": 0.0}, \"39\": {\"effect\": -0.23803721228039573, \"value\": 3.0}}}, {\"outValue\": 6.345981158907529, \"simIndex\": 26.0, \"features\": {\"0\": {\"effect\": 0.2979839919091749, \"value\": 0.0}, \"1\": {\"effect\": 0.010790453320146437, \"value\": 1.0}, \"2\": {\"effect\": -0.05945040973483613, \"value\": 0.0}, \"3\": {\"effect\": 0.0730837061715226, \"value\": -0.5179087749930338}, \"4\": {\"effect\": 0.009008589088371821, \"value\": 0.0}, \"5\": {\"effect\": -0.18383227897270302, \"value\": 0.0}, \"6\": {\"effect\": 0.0478766343541787, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.23426662905029252, \"value\": 0.2}, \"8\": {\"effect\": -0.41165130059007954, \"value\": 0.0}, \"9\": {\"effect\": 0.16917258908807775, \"value\": -0.1577111747704115}, \"10\": {\"effect\": -0.2123069278677594, \"value\": 0.1046006086375311}, \"11\": {\"effect\": 0.0774218016052635, \"value\": 1.0}, \"12\": {\"effect\": 0.3667521808774579, \"value\": 1.1153397668834728}, \"13\": {\"effect\": -0.3727814981792384, \"value\": 0.0}, \"14\": {\"effect\": 0.03993717640295269, \"value\": 1.0}, \"15\": {\"effect\": -0.14036179750248745, \"value\": 1.0}, \"16\": {\"effect\": 0.3450289330894231, \"value\": 0.0}, \"17\": {\"effect\": 0.002013886943912967, \"value\": 1.0}, \"18\": {\"effect\": 0.1112531998356567, \"value\": 3.0}, \"19\": {\"effect\": 0.2304773810687966, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.060407823643237414, \"value\": 0.2}, \"21\": {\"effect\": -0.08405702333704629, \"value\": 0.1046006086375311}, \"22\": {\"effect\": -0.06751420613883191, \"value\": 0.0042674325733836}, \"23\": {\"effect\": 0.46395998156559587, \"value\": 51.36713515430231}, \"24\": {\"effect\": -0.055639046828112645, \"value\": 4.0}, \"25\": {\"effect\": 0.15758314746781404, \"value\": 3.0}, \"26\": {\"effect\": 1.101969261147876, \"value\": -0.8663143483661802}, \"27\": {\"effect\": 0.01860557903735671, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.020555530012133144, \"value\": 1.1830620014078956}, \"29\": {\"effect\": 0.24258098275624648, \"value\": -0.4130522388976846}, \"30\": {\"effect\": 0.19164646181424713, \"value\": 0.2962333108970576}, \"31\": {\"effect\": 0.049813149193391325, \"value\": 1.1153397668834728}, \"32\": {\"effect\": 0.02766786138769931, \"value\": -0.1577111747704115}, \"33\": {\"effect\": 0.30154954306330833, \"value\": -0.3993856178867223}, \"34\": {\"effect\": 0.006386126297581977, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.045664074996894954, \"value\": -0.6473329644311107}, \"36\": {\"effect\": 0.027910665773284583, \"value\": -0.5179087749930338}, \"37\": {\"effect\": 0.04122597480337462, \"value\": 0.0}, \"38\": {\"effect\": 0.008166605588228761, \"value\": 0.0}, \"39\": {\"effect\": 0.21434943199534523, \"value\": 2.0}}}, {\"outValue\": 3.655073883688183, \"simIndex\": 46.0, \"features\": {\"0\": {\"effect\": 0.2613531721973744, \"value\": 0.0}, \"1\": {\"effect\": 0.02617747796468646, \"value\": 1.0}, \"2\": {\"effect\": -0.09193826776708365, \"value\": 0.0}, \"3\": {\"effect\": -0.2744177468482359, \"value\": 1.9925995966883192}, \"4\": {\"effect\": 0.013266544161097002, \"value\": 0.0}, \"5\": {\"effect\": 0.9180996830482056, \"value\": 1.0}, \"6\": {\"effect\": -0.08868837000062374, \"value\": 2.01852014148613}, \"7\": {\"effect\": 0.28792907100306325, \"value\": 0.2}, \"8\": {\"effect\": -0.4335659364721902, \"value\": 0.0}, \"9\": {\"effect\": 0.09156244640643917, \"value\": 1.50699951505644}, \"10\": {\"effect\": 0.2212620147679227, \"value\": 0.7052369127470163}, \"11\": {\"effect\": 0.06674494527859283, \"value\": 1.0}, \"12\": {\"effect\": -0.010082856989090007, \"value\": -0.3728296154774109}, \"13\": {\"effect\": -0.31376810286852663, \"value\": 0.0}, \"14\": {\"effect\": 0.04226442809802855, \"value\": 1.0}, \"15\": {\"effect\": -0.17880556044205964, \"value\": 1.0}, \"16\": {\"effect\": -0.2825744136473538, \"value\": 1.0}, \"17\": {\"effect\": 0.001447458836898852, \"value\": 1.0}, \"18\": {\"effect\": 0.09438877889803188, \"value\": 3.0}, \"19\": {\"effect\": 0.030808567181168874, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.13494256762752227, \"value\": 0.2}, \"21\": {\"effect\": -0.007685745155291144, \"value\": 0.7052369127470163}, \"22\": {\"effect\": 0.13096165480527558, \"value\": 0.0205999593675372}, \"23\": {\"effect\": -0.3860496664797584, \"value\": -1.3580328226840268}, \"24\": {\"effect\": 0.019651068453925016, \"value\": 7.0}, \"25\": {\"effect\": 0.11081228125733694, \"value\": 3.0}, \"26\": {\"effect\": -0.38892861611284796, \"value\": -0.4477933456915833}, \"27\": {\"effect\": 0.0072854464128827914, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.3705420644183442, \"value\": 2.108388302074217}, \"29\": {\"effect\": -0.0451815379407074, \"value\": 0.87730427622897}, \"30\": {\"effect\": 0.08655263267092218, \"value\": -0.1775915438878483}, \"31\": {\"effect\": 0.017673162621205225, \"value\": -0.3728296154774109}, \"32\": {\"effect\": -0.0204095522280658, \"value\": 1.50699951505644}, \"33\": {\"effect\": 0.13924520262445844, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.10633678535283002, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.030652516611738186, \"value\": -0.717388302089682}, \"36\": {\"effect\": -0.023087846514466114, \"value\": 1.9925995966883192}, \"37\": {\"effect\": 0.021654907900437517, \"value\": 0.0}, \"38\": {\"effect\": 0.0033256316211622127, \"value\": 0.0}, \"39\": {\"effect\": 0.16839069213623348, \"value\": 2.0}}}, {\"outValue\": 1.6151803463978167, \"simIndex\": 18.0, \"features\": {\"0\": {\"effect\": -0.6736811302099688, \"value\": 1.0}, \"1\": {\"effect\": -0.045295684965563625, \"value\": 0.0}, \"2\": {\"effect\": -0.10440072571765013, \"value\": 0.0}, \"3\": {\"effect\": 0.08029828857653894, \"value\": -0.7496633116815263}, \"4\": {\"effect\": 0.01524149515947702, \"value\": 0.0}, \"5\": {\"effect\": -0.25112065215704477, \"value\": 0.0}, \"6\": {\"effect\": 0.038369655860877996, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.09890181870796536, \"value\": 0.8}, \"8\": {\"effect\": -0.3997032121667902, \"value\": 0.0}, \"9\": {\"effect\": 0.21190071853713927, \"value\": -0.3155716712195094}, \"10\": {\"effect\": 0.2487951602593702, \"value\": 0.8318992447104098}, \"11\": {\"effect\": -0.0003247274507844546, \"value\": 0.0}, \"12\": {\"effect\": 0.12774919144119604, \"value\": -0.3336672633100191}, \"13\": {\"effect\": 0.5873782687723567, \"value\": 1.0}, \"14\": {\"effect\": 0.03571738728197691, \"value\": 1.0}, \"15\": {\"effect\": -0.12137303435797249, \"value\": 1.0}, \"16\": {\"effect\": 0.37115479247346966, \"value\": 0.0}, \"17\": {\"effect\": 0.0011287172368710573, \"value\": 1.0}, \"18\": {\"effect\": -0.5148200331235299, \"value\": 1.0}, \"19\": {\"effect\": -0.25617898752849705, \"value\": 1.3563280592606042}, \"20\": {\"effect\": -0.013854404678725835, \"value\": 0.8}, \"21\": {\"effect\": 0.007260082485577332, \"value\": 0.8318992447104098}, \"22\": {\"effect\": -0.15224282501553513, \"value\": 0.0051960473695625}, \"23\": {\"effect\": -0.1508376110640688, \"value\": -1.1125551095741466}, \"24\": {\"effect\": -0.6435217372760899, \"value\": 1.0}, \"25\": {\"effect\": -0.5026635851408554, \"value\": 1.0}, \"26\": {\"effect\": 0.6884137253863658, \"value\": -0.6740209147048789}, \"27\": {\"effect\": -0.07159214250040759, \"value\": 1.3563280592606042}, \"28\": {\"effect\": -0.08789251104427832, \"value\": 0.4649091653346371}, \"29\": {\"effect\": -0.09449113986161838, \"value\": 0.3566612200769836}, \"30\": {\"effect\": 0.10062770833908775, \"value\": -0.1456030087276265}, \"31\": {\"effect\": 0.03496827909829185, \"value\": -0.3336672633100191}, \"32\": {\"effect\": 0.03690150180177321, \"value\": -0.3155716712195094}, \"33\": {\"effect\": -0.10037649817508376, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.010646571720593159, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.1275849847317913, \"value\": -0.4586300152232994}, \"36\": {\"effect\": 0.06153080267096416, \"value\": -0.7496633116815263}, \"37\": {\"effect\": 0.022562667172831573, \"value\": 0.0}, \"38\": {\"effect\": 0.001266486906910228, \"value\": 0.0}, \"39\": {\"effect\": 0.2732207863625328, \"value\": 2.0}}}, {\"outValue\": 3.010455607149797, \"simIndex\": 90.0, \"features\": {\"0\": {\"effect\": 0.3403228861525518, \"value\": 0.0}, \"1\": {\"effect\": 0.036635326719672574, \"value\": 1.0}, \"2\": {\"effect\": -0.1478105996867629, \"value\": 0.0}, \"3\": {\"effect\": -0.15843090488753203, \"value\": 0.2947240854125388}, \"4\": {\"effect\": 0.010388395222478267, \"value\": 0.0}, \"5\": {\"effect\": -0.2452406592182159, \"value\": 0.0}, \"6\": {\"effect\": 0.062040640457964154, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.022023991423209096, \"value\": 0.8}, \"8\": {\"effect\": -0.47287003862375154, \"value\": 0.0}, \"9\": {\"effect\": 0.05263724502735042, \"value\": -0.6312926641177055}, \"10\": {\"effect\": 0.448619408698315, \"value\": 0.8523239092128007}, \"11\": {\"effect\": 0.0739464441615835, \"value\": 1.0}, \"12\": {\"effect\": -0.15333101330805915, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.5486047798517781, \"value\": 1.0}, \"14\": {\"effect\": 0.04111401038488346, \"value\": 1.0}, \"15\": {\"effect\": -0.15872933836540945, \"value\": 1.0}, \"16\": {\"effect\": -0.3877775666380578, \"value\": 1.0}, \"17\": {\"effect\": 0.0018457786646127042, \"value\": 1.0}, \"18\": {\"effect\": 0.14927427962115736, \"value\": 2.0}, \"19\": {\"effect\": 0.09384255586675914, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.0004308354156684257, \"value\": 0.8}, \"21\": {\"effect\": -0.024468177267409387, \"value\": 0.8523239092128007}, \"22\": {\"effect\": -0.3987722356959325, \"value\": 20.498378252464185}, \"23\": {\"effect\": -0.0734354542089591, \"value\": -0.9279533460845792}, \"24\": {\"effect\": 0.02997134840467247, \"value\": 12.0}, \"25\": {\"effect\": 0.14220927184436669, \"value\": 2.0}, \"26\": {\"effect\": 0.3048287363496291, \"value\": -0.617464022451555}, \"27\": {\"effect\": 0.02694545550513219, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.01296754795265689, \"value\": -0.8190826818501851}, \"29\": {\"effect\": -0.09128296322479339, \"value\": -1.1013434472637695}, \"30\": {\"effect\": 0.16454594015703372, \"value\": -0.5733070177633218}, \"31\": {\"effect\": -0.02876467404472882, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.012481527748013855, \"value\": -0.6312926641177055}, \"33\": {\"effect\": -0.05324623183741433, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.022725841700132424, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.11065501152953922, \"value\": -0.5675613587251344}, \"36\": {\"effect\": -0.04033167079915078, \"value\": 0.2947240854125388}, \"37\": {\"effect\": 0.038192252345622506, \"value\": 0.0}, \"38\": {\"effect\": 0.0013256545740088974, \"value\": 0.0}, \"39\": {\"effect\": -0.08324043373984384, \"value\": 3.0}}}, {\"outValue\": 2.97922675736212, \"simIndex\": 58.0, \"features\": {\"0\": {\"effect\": -0.8837940953138472, \"value\": 1.0}, \"1\": {\"effect\": 0.03298417005416476, \"value\": 1.0}, \"2\": {\"effect\": -0.07296343060074516, \"value\": 0.0}, \"3\": {\"effect\": -0.006276160689318842, \"value\": -0.1289988014084818}, \"4\": {\"effect\": 0.016544245673546804, \"value\": 0.0}, \"5\": {\"effect\": -0.13906690133086405, \"value\": 0.0}, \"6\": {\"effect\": -0.0030942837744247762, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.07635288719730522, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.334977858745663, \"value\": 1.0}, \"9\": {\"effect\": 0.23161310739359556, \"value\": -0.1003073578798304}, \"10\": {\"effect\": 0.3879309238185955, \"value\": 0.9204548732601774}, \"11\": {\"effect\": -0.04530927151524569, \"value\": 0.0}, \"12\": {\"effect\": -0.3056112938377975, \"value\": -0.4011135364871937}, \"13\": {\"effect\": -0.42966645599517417, \"value\": 0.0}, \"14\": {\"effect\": 0.03287494708769266, \"value\": 1.0}, \"15\": {\"effect\": -0.13821865038804992, \"value\": 1.0}, \"16\": {\"effect\": 0.2673906069742887, \"value\": 0.0}, \"17\": {\"effect\": 0.0023051658108009924, \"value\": 1.0}, \"18\": {\"effect\": 0.4010494122418111, \"value\": 5.0}, \"19\": {\"effect\": 0.025235321929983987, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.03380550211012099, \"value\": 0.7000000000000001}, \"21\": {\"effect\": 0.06341636158762501, \"value\": 0.9204548732601774}, \"22\": {\"effect\": -0.09540375875178218, \"value\": 0.0146867125070176}, \"23\": {\"effect\": -0.24895322342004655, \"value\": -1.1507835419731294}, \"24\": {\"effect\": 0.17413292982511167, \"value\": 12.0}, \"25\": {\"effect\": 0.1940696811877857, \"value\": 5.0}, \"26\": {\"effect\": -0.11426441107733684, \"value\": 3.251027407675799}, \"27\": {\"effect\": 0.03213007082729252, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.009137231496254842, \"value\": 0.597135480026874}, \"29\": {\"effect\": -0.060715606981266525, \"value\": -1.4351292463444678}, \"30\": {\"effect\": 0.28694605606299606, \"value\": -0.487589998950607}, \"31\": {\"effect\": -0.11287328559088664, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.06747954276938009, \"value\": -0.1003073578798304}, \"33\": {\"effect\": -0.1551773922518227, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0012398996976388226, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.005905017805948076, \"value\": -0.5998969118938438}, \"36\": {\"effect\": 0.010097784852288454, \"value\": -0.1289988014084818}, \"37\": {\"effect\": 0.03335363598349987, \"value\": 0.0}, \"38\": {\"effect\": 0.0013690669864916032, \"value\": 0.0}, \"39\": {\"effect\": 0.07678908586514868, \"value\": 2.0}}}, {\"outValue\": 1.4125251858972354, \"simIndex\": 7.0, \"features\": {\"0\": {\"effect\": -0.8981065032290579, \"value\": 1.0}, \"1\": {\"effect\": 0.02901521087277403, \"value\": 1.0}, \"2\": {\"effect\": -0.06752039646000244, \"value\": 0.0}, \"3\": {\"effect\": 0.14289616011015926, \"value\": -0.583555982810375}, \"4\": {\"effect\": 0.010779182571623613, \"value\": 0.0}, \"5\": {\"effect\": -0.2321950285427753, \"value\": 0.0}, \"6\": {\"effect\": -0.017783722332484757, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.059190816954578056, \"value\": 0.7000000000000001}, \"8\": {\"effect\": 0.318529558740079, \"value\": 1.0}, \"9\": {\"effect\": 0.14307782046881604, \"value\": -0.0142016325439587}, \"10\": {\"effect\": -0.2815312366107185, \"value\": 0.2019664079944557}, \"11\": {\"effect\": -0.025844045674939024, \"value\": 0.0}, \"12\": {\"effect\": -0.2619155481676979, \"value\": -0.3989378502556719}, \"13\": {\"effect\": 0.5360825477249842, \"value\": 1.0}, \"14\": {\"effect\": 0.030181895497131003, \"value\": 1.0}, \"15\": {\"effect\": -0.13780054185001012, \"value\": 1.0}, \"16\": {\"effect\": -0.2588890781286466, \"value\": 1.0}, \"17\": {\"effect\": 0.00015923195167049362, \"value\": 1.0}, \"18\": {\"effect\": 0.09883971742248664, \"value\": 2.0}, \"19\": {\"effect\": -0.4534236489357767, \"value\": 2.187874078283813}, \"20\": {\"effect\": -0.029427561122648847, \"value\": 0.7000000000000001}, \"21\": {\"effect\": -0.11112339129707358, \"value\": 0.2019664079944557}, \"22\": {\"effect\": -0.055112395293977864, \"value\": 0.0121383355598789}, \"23\": {\"effect\": -0.06426250415277698, \"value\": -0.7504790566717457}, \"24\": {\"effect\": 0.08484065781131382, \"value\": 11.0}, \"25\": {\"effect\": 0.193429864516337, \"value\": 2.0}, \"26\": {\"effect\": -0.6093976494535589, \"value\": 0.4458055519109341}, \"27\": {\"effect\": -0.251090450757388, \"value\": 2.187874078283813}, \"28\": {\"effect\": -0.10188825549390952, \"value\": -1.5458201344803708}, \"29\": {\"effect\": -0.08631440144499065, \"value\": -1.373035455450852}, \"30\": {\"effect\": 0.42842087046719957, \"value\": -0.4577450618366232}, \"31\": {\"effect\": -0.04238856354628694, \"value\": -0.3989378502556719}, \"32\": {\"effect\": 0.04018970823273872, \"value\": -0.0142016325439587}, \"33\": {\"effect\": -0.036347045399842515, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0034943316754173772, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.29156461516419124, \"value\": 0.7697870997683016}, \"36\": {\"effect\": 0.012681836205879265, \"value\": -0.583555982810375}, \"37\": {\"effect\": 0.025993622952092312, \"value\": 0.0}, \"38\": {\"effect\": 0.0019579433414067928, \"value\": 0.0}, \"39\": {\"effect\": -0.08734394361691615, \"value\": 3.0}}}, {\"outValue\": 3.2856968779482134, \"simIndex\": 31.0, \"features\": {\"0\": {\"effect\": 0.24789451060195736, \"value\": 0.0}, \"1\": {\"effect\": 0.02479512609991597, \"value\": 1.0}, \"2\": {\"effect\": -0.0675439698669812, \"value\": 0.0}, \"3\": {\"effect\": 0.06586023348701754, \"value\": -0.7745296782790041}, \"4\": {\"effect\": 0.006732927170649986, \"value\": 0.0}, \"5\": {\"effect\": -0.23948199438748305, \"value\": 0.0}, \"6\": {\"effect\": 0.0018821930260258346, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.4733697018290713, \"value\": 0.9}, \"8\": {\"effect\": 0.3282517690748003, \"value\": 1.0}, \"9\": {\"effect\": 0.18776762129880828, \"value\": -0.3586245338874453}, \"10\": {\"effect\": -0.29715674300041695, \"value\": 0.0575583905238937}, \"11\": {\"effect\": -0.047526745263735196, \"value\": 0.0}, \"12\": {\"effect\": 0.06138460909692821, \"value\": -0.3771809879404544}, \"13\": {\"effect\": -0.2893118613365819, \"value\": 0.0}, \"14\": {\"effect\": 0.03314429417228617, \"value\": 1.0}, \"15\": {\"effect\": 0.31740203449120197, \"value\": 2.0}, \"16\": {\"effect\": -0.23142446761485091, \"value\": 1.0}, \"17\": {\"effect\": 0.0013633417351445012, \"value\": 1.0}, \"18\": {\"effect\": 0.0749121562577826, \"value\": 3.0}, \"19\": {\"effect\": 0.02830420996666843, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.038153249624723745, \"value\": 0.9}, \"21\": {\"effect\": -0.1807490523735024, \"value\": 0.0575583905238937}, \"22\": {\"effect\": -0.06768844561764632, \"value\": 0.011676425130783}, \"23\": {\"effect\": -0.18645484810277774, \"value\": -1.0517937600727676}, \"24\": {\"effect\": 0.06187403113750324, \"value\": 10.0}, \"25\": {\"effect\": 0.18146531666841495, \"value\": 3.0}, \"26\": {\"effect\": 0.6363694920854657, \"value\": -0.7532005638595324}, \"27\": {\"effect\": 0.02108941345175499, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.08144676351489524, \"value\": -0.8182004300901746}, \"29\": {\"effect\": 0.005203986662755925, \"value\": 0.01169646689064}, \"30\": {\"effect\": 0.0824327254840436, \"value\": -0.0632797988384604}, \"31\": {\"effect\": 0.008798864251508581, \"value\": -0.3771809879404544}, \"32\": {\"effect\": 0.0382338308992855, \"value\": -0.3586245338874453}, \"33\": {\"effect\": 0.20358936258947016, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.0011399990348925347, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.040553142139595516, \"value\": 1.050737350366422}, \"36\": {\"effect\": 0.0219885987532262, \"value\": -0.7745296782790041}, \"37\": {\"effect\": -0.48147587821782595, \"value\": 1.0}, \"38\": {\"effect\": 0.0029134130996467398, \"value\": 0.0}, \"39\": {\"effect\": 0.21122789123411853, \"value\": 2.0}}}, {\"outValue\": 2.680012643962189, \"simIndex\": 72.0, \"features\": {\"0\": {\"effect\": 0.25644735271176217, \"value\": 0.0}, \"1\": {\"effect\": 0.022782509257665364, \"value\": 1.0}, \"2\": {\"effect\": -0.061332684901471764, \"value\": 0.0}, \"3\": {\"effect\": -0.46862670038130166, \"value\": 0.6816447496692926}, \"4\": {\"effect\": 0.011254433994368134, \"value\": 0.0}, \"5\": {\"effect\": -0.22311543783475188, \"value\": 0.0}, \"6\": {\"effect\": 0.035152879015009596, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.03610408743051225, \"value\": 0.8}, \"8\": {\"effect\": 0.2551400056025335, \"value\": 1.0}, \"9\": {\"effect\": 0.08094378233544196, \"value\": -0.6456436183403508}, \"10\": {\"effect\": 0.31567356819313336, \"value\": 0.5523226174179785}, \"11\": {\"effect\": 0.03803672613344622, \"value\": 1.0}, \"12\": {\"effect\": 0.050725591176166124, \"value\": -0.3706539292458891}, \"13\": {\"effect\": -0.38387017379401367, \"value\": 0.0}, \"14\": {\"effect\": 0.034545650059707576, \"value\": 1.0}, \"15\": {\"effect\": -0.12877502182560716, \"value\": 1.0}, \"16\": {\"effect\": -0.32597510323619966, \"value\": 1.0}, \"17\": {\"effect\": 0.0012340947912910243, \"value\": 1.0}, \"18\": {\"effect\": 0.11512935816269793, \"value\": 2.0}, \"19\": {\"effect\": 0.044948218973530754, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.02248580125766366, \"value\": 0.8}, \"21\": {\"effect\": 0.06300391168482643, \"value\": 0.5523226174179785}, \"22\": {\"effect\": 0.22507125088749744, \"value\": 0.0276923340184357}, \"23\": {\"effect\": -0.1674116914774316, \"value\": -0.952606816436472}, \"24\": {\"effect\": 0.13651807494033205, \"value\": 5.0}, \"25\": {\"effect\": 0.14199497520819537, \"value\": 2.0}, \"26\": {\"effect\": -0.2118545156182928, \"value\": 1.1018655020494912}, \"27\": {\"effect\": 0.012651166958794974, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.04650995563280631, \"value\": -0.912011911014789}, \"29\": {\"effect\": 0.12904704273551576, \"value\": -1.9643719451595736}, \"30\": {\"effect\": -0.3580684053429817, \"value\": -1.8685154231988124}, \"31\": {\"effect\": 0.02497502537145199, \"value\": -0.3706539292458891}, \"32\": {\"effect\": 0.013866474059542755, \"value\": -0.6456436183403508}, \"33\": {\"effect\": 0.14105483426021295, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.02302113271437047, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.08984580637376667, \"value\": -0.736868733023555}, \"36\": {\"effect\": -0.08554004051532477, \"value\": 0.6816447496692926}, \"37\": {\"effect\": 0.03205103476699671, \"value\": 0.0}, \"38\": {\"effect\": 0.0014289748224857574, \"value\": 0.0}, \"39\": {\"effect\": -0.12606701774143833, \"value\": 3.0}}}, {\"outValue\": 1.432775408069863, \"simIndex\": 88.0, \"features\": {\"0\": {\"effect\": 0.21483838154398788, \"value\": 0.0}, \"1\": {\"effect\": 0.04502723410454431, \"value\": 1.0}, \"2\": {\"effect\": -0.1022973510635142, \"value\": 0.0}, \"3\": {\"effect\": 0.2831138934246495, \"value\": -0.8550967060548319}, \"4\": {\"effect\": 0.018716509475400246, \"value\": 0.0}, \"5\": {\"effect\": -0.19205238326709045, \"value\": 0.0}, \"6\": {\"effect\": 0.03116497295244629, \"value\": -0.0325109137671299}, \"7\": {\"effect\": 0.04672563856691143, \"value\": 0.6000000000000001}, \"8\": {\"effect\": -0.3251790995792635, \"value\": 0.0}, \"9\": {\"effect\": -0.10552621852723171, \"value\": 1.076470888377082}, \"10\": {\"effect\": -0.17370666032408855, \"value\": 0.2807515028667204}, \"11\": {\"effect\": -0.034809583977020365, \"value\": 0.0}, \"12\": {\"effect\": -0.35332244055521245, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.6920405730565401, \"value\": 1.0}, \"14\": {\"effect\": 0.04614622682227916, \"value\": 1.0}, \"15\": {\"effect\": -0.041033384589639385, \"value\": 1.0}, \"16\": {\"effect\": -0.3511380451905055, \"value\": 1.0}, \"17\": {\"effect\": 0.001287582625417154, \"value\": 1.0}, \"18\": {\"effect\": 0.1275801681432498, \"value\": 2.0}, \"19\": {\"effect\": 0.018994036410983694, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.00030367243065926075, \"value\": 0.6000000000000001}, \"21\": {\"effect\": 0.025401879940142032, \"value\": 0.2807515028667204}, \"22\": {\"effect\": 0.05943898514715693, \"value\": 0.0035527499046989}, \"23\": {\"effect\": -0.32169510057036893, \"value\": -1.292209625207026}, \"24\": {\"effect\": 0.0034712272312721532, \"value\": 4.0}, \"25\": {\"effect\": 0.14306989448334617, \"value\": 2.0}, \"26\": {\"effect\": -0.2988952396607314, \"value\": 2.413985402326605}, \"27\": {\"effect\": 0.009526372937043127, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.10071524612942118, \"value\": -0.136440740260222}, \"29\": {\"effect\": 0.011965965636094004, \"value\": -0.5830737003029167}, \"30\": {\"effect\": -0.35849744792581667, \"value\": -1.9041863948255853}, \"31\": {\"effect\": -0.03841929238480238, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.016772914974121467, \"value\": 1.076470888377082}, \"33\": {\"effect\": -0.03050877185844366, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.005044635083337293, \"value\": -0.0325109137671299}, \"35\": {\"effect\": -0.09413254674766695, \"value\": 5.774991204210308}, \"36\": {\"effect\": 0.01705082252713444, \"value\": -0.8550967060548319}, \"37\": {\"effect\": -0.5730715910032257, \"value\": 1.0}, \"38\": {\"effect\": 0.0029704799381803015, \"value\": 0.0}, \"39\": {\"effect\": -0.16521225301766926, \"value\": 3.0}}}, {\"outValue\": 6.337045742592609, \"simIndex\": 42.0, \"features\": {\"0\": {\"effect\": 0.29149412678547, \"value\": 0.0}, \"1\": {\"effect\": 0.02606006915437765, \"value\": 1.0}, \"2\": {\"effect\": 0.14614278209836973, \"value\": 1.0}, \"3\": {\"effect\": -0.0013370795978420063, \"value\": -0.17574757061174}, \"4\": {\"effect\": 0.009245454726698576, \"value\": 0.0}, \"5\": {\"effect\": 0.9931811834521186, \"value\": 1.0}, \"6\": {\"effect\": -0.024683994350503953, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2013743098530904, \"value\": 0.5}, \"8\": {\"effect\": 0.30532826669930846, \"value\": 1.0}, \"9\": {\"effect\": 0.08840342393297651, \"value\": 0.028851230123977}, \"10\": {\"effect\": 0.0655555737353862, \"value\": 0.3748539984757265}, \"11\": {\"effect\": -0.018030285763119113, \"value\": 0.0}, \"12\": {\"effect\": 0.10512083411031373, \"value\": -0.3880594190980632}, \"13\": {\"effect\": -0.2505627306076681, \"value\": 0.0}, \"14\": {\"effect\": 0.030971220823966635, \"value\": 1.0}, \"15\": {\"effect\": 0.3815457676465105, \"value\": 2.0}, \"16\": {\"effect\": 0.36203209545839676, \"value\": 0.0}, \"17\": {\"effect\": 0.001955584814341899, \"value\": 1.0}, \"18\": {\"effect\": 0.10346023265470095, \"value\": 2.0}, \"19\": {\"effect\": 0.0475717651828335, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.043838840778113904, \"value\": 0.5}, \"21\": {\"effect\": 0.02235729690493113, \"value\": 0.3748539984757265}, \"22\": {\"effect\": -0.014422493355133974, \"value\": 0.0169191896061718}, \"23\": {\"effect\": -0.1184293172706185, \"value\": -0.6526972349943726}, \"24\": {\"effect\": -0.05765335801511529, \"value\": 7.0}, \"25\": {\"effect\": 0.136669937183421, \"value\": 2.0}, \"26\": {\"effect\": 0.10224099616332605, \"value\": -0.5722185086488959}, \"27\": {\"effect\": -0.012152565178050308, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.17848107965841636, \"value\": 1.7067494260371807}, \"29\": {\"effect\": -0.1451708861493347, \"value\": 0.8851042740114154}, \"30\": {\"effect\": 0.09221502923420005, \"value\": 0.6507816238631844}, \"31\": {\"effect\": 0.012078176974966135, \"value\": -0.3880594190980632}, \"32\": {\"effect\": 0.011573454660947268, \"value\": 0.028851230123977}, \"33\": {\"effect\": 0.1525906616210348, \"value\": 0.8385580009155795}, \"34\": {\"effect\": 0.006050260172936331, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.050251730929409794, \"value\": -0.675624240333203}, \"36\": {\"effect\": 0.017242517138287197, \"value\": -0.17574757061174}, \"37\": {\"effect\": 0.023541486359975827, \"value\": 0.0}, \"38\": {\"effect\": 0.0024910906016083548, \"value\": 0.0}, \"39\": {\"effect\": -0.001978839499455448, \"value\": 1.0}}}, {\"outValue\": 2.6368120994662183, \"simIndex\": 87.0, \"features\": {\"0\": {\"effect\": 0.3863155460470086, \"value\": 0.0}, \"1\": {\"effect\": 0.032375234597692704, \"value\": 1.0}, \"2\": {\"effect\": 0.17919097366942882, \"value\": 1.0}, \"3\": {\"effect\": 0.03963035162662464, \"value\": -0.8361982674407489}, \"4\": {\"effect\": 0.011708290015054945, \"value\": 0.0}, \"5\": {\"effect\": -0.22883662561641147, \"value\": 0.0}, \"6\": {\"effect\": 0.06744946601524546, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.07103311705606347, \"value\": 0.8}, \"8\": {\"effect\": -0.31837401820158195, \"value\": 0.0}, \"9\": {\"effect\": 0.32833886440026483, \"value\": -1.965931406823716}, \"10\": {\"effect\": -0.157680494906098, \"value\": 0.2726349603313193}, \"11\": {\"effect\": -0.016545205464829616, \"value\": 0.0}, \"12\": {\"effect\": -0.28651416638450455, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.5461721386051915, \"value\": 1.0}, \"14\": {\"effect\": -0.1738456938139689, \"value\": 0.0}, \"15\": {\"effect\": -0.11944532351055087, \"value\": 1.0}, \"16\": {\"effect\": -0.22749946795801118, \"value\": 1.0}, \"17\": {\"effect\": 0.0011180670534378671, \"value\": 1.0}, \"18\": {\"effect\": 0.15073802370940823, \"value\": 2.0}, \"19\": {\"effect\": 0.1501871545828907, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.0217956126674381, \"value\": 0.8}, \"21\": {\"effect\": 0.004473288935255931, \"value\": 0.2726349603313193}, \"22\": {\"effect\": 0.423741017024125, \"value\": 0.0424752529889124}, \"23\": {\"effect\": 0.009118121262526382, \"value\": -0.8683455899673869}, \"24\": {\"effect\": -0.49415637091937614, \"value\": 2.0}, \"25\": {\"effect\": 0.16343985573839995, \"value\": 2.0}, \"26\": {\"effect\": -0.536038566070569, \"value\": -0.4025478318889242}, \"27\": {\"effect\": -0.0067011470231430345, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.13667658801898058, \"value\": -1.1202412658637315}, \"29\": {\"effect\": -0.11053282296847805, \"value\": -1.383518351325267}, \"30\": {\"effect\": -0.19025765414306894, \"value\": -1.1480916340465366}, \"31\": {\"effect\": -0.06885084239820813, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.01998179544082226, \"value\": -1.965931406823716}, \"33\": {\"effect\": 0.021675476821466116, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.02815726785403864, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.13178279672592572, \"value\": 0.231507410387458}, \"36\": {\"effect\": 0.026124671379370887, \"value\": -0.8361982674407489}, \"37\": {\"effect\": 0.045809877012865194, \"value\": 0.0}, \"38\": {\"effect\": 0.0016250763415816068, \"value\": 0.0}, \"39\": {\"effect\": -0.03846304299896195, \"value\": 3.0}}}, {\"outValue\": 6.641718399808629, \"simIndex\": 10.0, \"features\": {\"0\": {\"effect\": 0.2509487571040048, \"value\": 0.0}, \"1\": {\"effect\": -0.26607366251834136, \"value\": 0.0}, \"2\": {\"effect\": 0.13294834863567379, \"value\": 1.0}, \"3\": {\"effect\": 0.1748627194791837, \"value\": -0.746679347689829}, \"4\": {\"effect\": 0.011751860072599199, \"value\": 0.0}, \"5\": {\"effect\": 0.9012819634792093, \"value\": 1.0}, \"6\": {\"effect\": 0.0722420426087921, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.13213194224174965, \"value\": 0.5}, \"8\": {\"effect\": 0.22356726146039424, \"value\": 1.0}, \"9\": {\"effect\": 0.11008628703963923, \"value\": -1.3201384668046785}, \"10\": {\"effect\": -0.4193571000527367, \"value\": 0.1088545509851735}, \"11\": {\"effect\": -0.04183732792177018, \"value\": 0.0}, \"12\": {\"effect\": 0.21613212746066301, \"value\": -0.3924107915611067}, \"13\": {\"effect\": 0.479053592579312, \"value\": 1.0}, \"14\": {\"effect\": 0.041801080574456854, \"value\": 1.0}, \"15\": {\"effect\": -0.088087999577713, \"value\": 1.0}, \"16\": {\"effect\": 0.3627868730985142, \"value\": 0.0}, \"17\": {\"effect\": 0.0016331465631861273, \"value\": 1.0}, \"18\": {\"effect\": 0.05617863195642249, \"value\": 3.0}, \"19\": {\"effect\": 0.077893370401142, \"value\": 0.5247820402373953}, \"20\": {\"effect\": 0.015556154725018777, \"value\": 0.5}, \"21\": {\"effect\": -0.12341284353405894, \"value\": 0.1088545509851735}, \"22\": {\"effect\": 0.42255034564047145, \"value\": 0.0353553689809371}, \"23\": {\"effect\": -0.18292437156900634, \"value\": -1.829432435912942}, \"24\": {\"effect\": -0.41203798683818976, \"value\": 3.0}, \"25\": {\"effect\": 0.12345322056745714, \"value\": 3.0}, \"26\": {\"effect\": 0.8597847085150774, \"value\": -0.7871346992115267}, \"27\": {\"effect\": -0.0008580602275885271, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.09658756111071858, \"value\": 0.6381354078143412}, \"29\": {\"effect\": -0.0517937931969103, \"value\": 0.2920513124968045}, \"30\": {\"effect\": 0.16881626230299274, \"value\": 0.3750470315055309}, \"31\": {\"effect\": 0.011953821248830064, \"value\": -0.3924107915611067}, \"32\": {\"effect\": 0.005780760147728562, \"value\": -1.3201384668046785}, \"33\": {\"effect\": 0.16332911113002382, \"value\": -0.8120334908208229}, \"34\": {\"effect\": 0.016455089386299235, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.27196295015332816, \"value\": 0.4565241875266769}, \"36\": {\"effect\": 0.002013780481466086, \"value\": -0.746679347689829}, \"37\": {\"effect\": 0.022828869331335728, \"value\": 0.0}, \"38\": {\"effect\": 0.0032475502288341657, \"value\": 0.0}, \"39\": {\"effect\": -0.07924902698597946, \"value\": 1.0}}}, {\"outValue\": 5.626587093909259, \"simIndex\": 85.0, \"features\": {\"0\": {\"effect\": 0.2812738833877657, \"value\": 0.0}, \"1\": {\"effect\": 0.03803493114110548, \"value\": 1.0}, \"2\": {\"effect\": -0.10739020882452936, \"value\": 0.0}, \"3\": {\"effect\": 0.043294432342304394, \"value\": -0.0752874495579299}, \"4\": {\"effect\": 0.025741916695647602, \"value\": 0.0}, \"5\": {\"effect\": -0.1364023944754871, \"value\": 0.0}, \"6\": {\"effect\": -0.021979107427298746, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.43554942490751075, \"value\": 0.9}, \"8\": {\"effect\": -0.25783561811970696, \"value\": 0.0}, \"9\": {\"effect\": 0.08633378136150151, \"value\": 0.1006060012372034}, \"10\": {\"effect\": 0.10816563225620472, \"value\": 0.7059286336704218}, \"11\": {\"effect\": 0.013393260973857658, \"value\": 1.0}, \"12\": {\"effect\": 0.3129244312504109, \"value\": 3.506418935325887}, \"13\": {\"effect\": 0.6820316169898228, \"value\": 1.0}, \"14\": {\"effect\": 0.0329885442998752, \"value\": 1.0}, \"15\": {\"effect\": 0.8967221411559079, \"value\": 6.0}, \"16\": {\"effect\": 0.2906765480512655, \"value\": 0.0}, \"17\": {\"effect\": 0.000997001648679915, \"value\": 1.0}, \"18\": {\"effect\": 0.12709430177047118, \"value\": 3.0}, \"19\": {\"effect\": 0.02807333874368963, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.07233216314683807, \"value\": 0.9}, \"21\": {\"effect\": 0.07834572820913308, \"value\": 0.7059286336704218}, \"22\": {\"effect\": 0.0968202429162535, \"value\": 0.0293169624376109}, \"23\": {\"effect\": 0.383920484495994, \"value\": 11.156380872167569}, \"24\": {\"effect\": 0.0543518947563705, \"value\": 5.0}, \"25\": {\"effect\": 0.09383495980380943, \"value\": 3.0}, \"26\": {\"effect\": -0.5685998697033282, \"value\": 0.1177755768416555}, \"27\": {\"effect\": 0.010149327918261637, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.040299702965043066, \"value\": -0.7162901022658115}, \"29\": {\"effect\": 0.3083841406551876, \"value\": -1.2018157562573255}, \"30\": {\"effect\": -0.08645900410629191, \"value\": -0.7156273456130745}, \"31\": {\"effect\": -0.03686780289607665, \"value\": 3.506418935325887}, \"32\": {\"effect\": 0.07560123869277387, \"value\": 0.1006060012372034}, \"33\": {\"effect\": 0.19353651295292945, \"value\": 1.6638537467837806}, \"34\": {\"effect\": 0.002370467845664589, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.07985488837596029, \"value\": -0.1925333403764098}, \"36\": {\"effect\": -0.010517310471524967, \"value\": -0.0752874495579299}, \"37\": {\"effect\": 0.03201476636871737, \"value\": 0.0}, \"38\": {\"effect\": 0.0011289053003227171, \"value\": 0.0}, \"39\": {\"effect\": 0.1115646526170907, \"value\": 2.0}}}, {\"outValue\": 3.104356062719592, \"simIndex\": 79.0, \"features\": {\"0\": {\"effect\": 0.29104788053931707, \"value\": 0.0}, \"1\": {\"effect\": 0.039749828289981075, \"value\": 1.0}, \"2\": {\"effect\": 0.16309706465971366, \"value\": 1.0}, \"3\": {\"effect\": 0.12887423601382159, \"value\": -0.9396423524862564}, \"4\": {\"effect\": 0.014120973382230345, \"value\": 0.0}, \"5\": {\"effect\": -0.2148814023966454, \"value\": 0.0}, \"6\": {\"effect\": 0.03339616846334538, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.14596596969897915, \"value\": 0.4}, \"8\": {\"effect\": 0.307318962494278, \"value\": 1.0}, \"9\": {\"effect\": -0.004747729882272084, \"value\": -0.7891531605668035}, \"10\": {\"effect\": -0.23897740907750786, \"value\": 0.2532843528317163}, \"11\": {\"effect\": -0.021750408019556647, \"value\": 0.0}, \"12\": {\"effect\": -0.23611565720095073, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.5413260103527857, \"value\": 1.0}, \"14\": {\"effect\": 0.04230617099529518, \"value\": 1.0}, \"15\": {\"effect\": -0.15593322197655812, \"value\": 1.0}, \"16\": {\"effect\": -0.2884145866474566, \"value\": 1.0}, \"17\": {\"effect\": 0.0014827771675194606, \"value\": 1.0}, \"18\": {\"effect\": 0.1072171096684492, \"value\": 2.0}, \"19\": {\"effect\": 0.1545074702607821, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.03137725665273572, \"value\": 0.4}, \"21\": {\"effect\": -0.03321149472018645, \"value\": 0.2532843528317163}, \"22\": {\"effect\": -0.06788632876488374, \"value\": 0.0061921003178911}, \"23\": {\"effect\": -0.16730415426301645, \"value\": -1.1395690241202407}, \"24\": {\"effect\": 0.004792156817006781, \"value\": 10.0}, \"25\": {\"effect\": 0.16070266419478194, \"value\": 2.0}, \"26\": {\"effect\": -0.5720852810669914, \"value\": 0.3553145243056159}, \"27\": {\"effect\": 0.06024501515691606, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.15749830095931044, \"value\": -1.1344333991473083}, \"29\": {\"effect\": -0.02251926279139159, \"value\": -1.2655525188165888}, \"30\": {\"effect\": 0.1713813490007812, \"value\": -0.5276744178586049}, \"31\": {\"effect\": -0.08433430463397477, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.0259348309513815, \"value\": -0.7891531605668035}, \"33\": {\"effect\": -0.09884849487238348, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.002472791047459134, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.16199115007040432, \"value\": -0.3859064619628272}, \"36\": {\"effect\": -0.01100208868888348, \"value\": -0.9396423524862564}, \"37\": {\"effect\": 0.04841043553331415, \"value\": 0.0}, \"38\": {\"effect\": 0.001415966994740808, \"value\": 0.0}, \"39\": {\"effect\": 0.09380874568851418, \"value\": 2.0}}}, {\"outValue\": 5.026465749010081, \"simIndex\": 54.0, \"features\": {\"0\": {\"effect\": 0.27392244745871486, \"value\": 0.0}, \"1\": {\"effect\": 0.010418468995888596, \"value\": 1.0}, \"2\": {\"effect\": 0.372088495346776, \"value\": 1.0}, \"3\": {\"effect\": 0.17575652773267172, \"value\": -1.064968840137544}, \"4\": {\"effect\": 0.013919278759250628, \"value\": 0.0}, \"5\": {\"effect\": 0.7208251139372878, \"value\": 1.0}, \"6\": {\"effect\": -0.12172360186370204, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.01352394410644855, \"value\": 0.8}, \"8\": {\"effect\": -0.3263489775930028, \"value\": 0.0}, \"9\": {\"effect\": -0.39496265300978683, \"value\": 1.9949319586263796}, \"10\": {\"effect\": 0.26213867375501765, \"value\": 0.4654272493085154}, \"11\": {\"effect\": -0.01683497920266981, \"value\": 0.0}, \"12\": {\"effect\": 0.7612434295080124, \"value\": 0.5648911503084676}, \"13\": {\"effect\": -0.37830091530281007, \"value\": 0.0}, \"14\": {\"effect\": 0.030561109393312427, \"value\": 1.0}, \"15\": {\"effect\": -0.1419440858841814, \"value\": 1.0}, \"16\": {\"effect\": 0.2823321032300406, \"value\": 0.0}, \"17\": {\"effect\": 0.0004632486722509886, \"value\": 1.0}, \"18\": {\"effect\": -0.5906125576478275, \"value\": 1.0}, \"19\": {\"effect\": 0.03298156028390435, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.02382576469750948, \"value\": 0.8}, \"21\": {\"effect\": 0.022852717588869538, \"value\": 0.4654272493085154}, \"22\": {\"effect\": 0.16516899307826086, \"value\": 0.0288035730020428}, \"23\": {\"effect\": 0.4893832031072707, \"value\": 103.3505499972026}, \"24\": {\"effect\": 0.07991067590554686, \"value\": 5.0}, \"25\": {\"effect\": -0.4622195191491816, \"value\": 1.0}, \"26\": {\"effect\": -0.07669567328031056, \"value\": 1.1923565296548095}, \"27\": {\"effect\": 0.004675260246903631, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.008498011833689315, \"value\": -0.0123642355236906}, \"29\": {\"effect\": 0.11488518190137281, \"value\": -0.7674116465923634}, \"30\": {\"effect\": 0.15885413855178726, \"value\": 0.4947555498955592}, \"31\": {\"effect\": 0.16163350489473896, \"value\": 0.5648911503084676}, \"32\": {\"effect\": -0.14952415693610185, \"value\": 1.9949319586263796}, \"33\": {\"effect\": 0.4099217851753572, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.039922339879294305, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.0005251559262696357, \"value\": -0.5618131067135683}, \"36\": {\"effect\": -0.010559415852732618, \"value\": -1.064968840137544}, \"37\": {\"effect\": 0.021365917701381163, \"value\": 0.0}, \"38\": {\"effect\": 0.003207542355810725, \"value\": 0.0}, \"39\": {\"effect\": 0.1260765951999566, \"value\": 2.0}}}, {\"outValue\": 4.194810930311911, \"simIndex\": 8.0, \"features\": {\"0\": {\"effect\": -0.655306600916583, \"value\": 1.0}, \"1\": {\"effect\": 0.018478589745385673, \"value\": 1.0}, \"2\": {\"effect\": -0.06047355600034267, \"value\": 0.0}, \"3\": {\"effect\": -0.007532568817637374, \"value\": -0.0693195215745352}, \"4\": {\"effect\": 0.009716562126681021, \"value\": 0.0}, \"5\": {\"effect\": 0.9118578532783116, \"value\": 1.0}, \"6\": {\"effect\": 0.017945998965599064, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.33816761986905886, \"value\": 0.9}, \"8\": {\"effect\": 0.2970872140102514, \"value\": 1.0}, \"9\": {\"effect\": -0.04634188374423666, \"value\": 0.7751008497015311}, \"10\": {\"effect\": -0.4204240789473135, \"value\": 0.1075886224745157}, \"11\": {\"effect\": -0.038418087984315855, \"value\": 0.0}, \"12\": {\"effect\": 0.13187706956146805, \"value\": -0.3793566741719761}, \"13\": {\"effect\": 0.6336768569309176, \"value\": 1.0}, \"14\": {\"effect\": 0.036951698696805174, \"value\": 1.0}, \"15\": {\"effect\": -0.15007868161209284, \"value\": 1.0}, \"16\": {\"effect\": -0.3120548548851816, \"value\": 1.0}, \"17\": {\"effect\": 0.0014710919598341112, \"value\": 1.0}, \"18\": {\"effect\": 0.054759869224159985, \"value\": 4.0}, \"19\": {\"effect\": 0.03954942678444706, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.046387908139727874, \"value\": 0.9}, \"21\": {\"effect\": -0.10492190864933257, \"value\": 0.1075886224745157}, \"22\": {\"effect\": -0.0118331640094367, \"value\": 0.0057433033054355}, \"23\": {\"effect\": -0.18196620933903376, \"value\": -0.941312941937396}, \"24\": {\"effect\": -0.025595202322917458, \"value\": 4.0}, \"25\": {\"effect\": 0.16419511324987895, \"value\": 4.0}, \"26\": {\"effect\": 1.0362087006854237, \"value\": -0.8436915914648505}, \"27\": {\"effect\": 0.013617245061153097, \"value\": 0.5247820402373953}, \"28\": {\"effect\": -0.037337404051532866, \"value\": -1.4908807882717507}, \"29\": {\"effect\": 0.195485013143642, \"value\": -0.9283012959153636}, \"30\": {\"effect\": 0.11250283252092118, \"value\": -0.5779350877899657}, \"31\": {\"effect\": 0.04704944345439836, \"value\": -0.3793566741719761}, \"32\": {\"effect\": 0.008458542070280878, \"value\": 0.7751008497015311}, \"33\": {\"effect\": -0.13223293804447322, \"value\": 1.4162650230233202}, \"34\": {\"effect\": -0.010687616163607973, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.030766864989926958, \"value\": -0.6794748654777818}, \"36\": {\"effect\": 0.0004934692215178265, \"value\": -0.0693195215745352}, \"37\": {\"effect\": 0.017070085993466193, \"value\": 0.0}, \"38\": {\"effect\": 0.003345735463212911, \"value\": 0.0}, \"39\": {\"effect\": -0.07889956805678301, \"value\": 3.0}}}, {\"outValue\": 2.252507754243907, \"simIndex\": 6.0, \"features\": {\"0\": {\"effect\": -0.7703978036493153, \"value\": 1.0}, \"1\": {\"effect\": 0.028955532934242773, \"value\": 1.0}, \"2\": {\"effect\": -0.0753957481295934, \"value\": 0.0}, \"3\": {\"effect\": 0.08454347015744573, \"value\": -0.6084223494078528}, \"4\": {\"effect\": 0.010709641492515807, \"value\": 0.0}, \"5\": {\"effect\": -0.23040776195511198, \"value\": 0.0}, \"6\": {\"effect\": 0.1358606552427759, \"value\": 0.9724943033069674}, \"7\": {\"effect\": -0.5512254941842502, \"value\": 0.9}, \"8\": {\"effect\": 0.2900882447889734, \"value\": 1.0}, \"9\": {\"effect\": 0.013468029624352567, \"value\": 0.9903651630412104}, \"10\": {\"effect\": -0.008359742500430327, \"value\": 0.7138169041128101}, \"11\": {\"effect\": -0.01862297260929726, \"value\": 0.0}, \"12\": {\"effect\": -0.32489697113588323, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.6849339830562883, \"value\": 1.0}, \"14\": {\"effect\": 0.03553976209409902, \"value\": 1.0}, \"15\": {\"effect\": -0.13071701135797992, \"value\": 1.0}, \"16\": {\"effect\": 0.36126254238306105, \"value\": 0.0}, \"17\": {\"effect\": -0.00174410192199382, \"value\": 1.0}, \"18\": {\"effect\": 0.07622500901799517, \"value\": 3.0}, \"19\": {\"effect\": 0.026174664649633753, \"value\": 0.5247820402373953}, \"20\": {\"effect\": -0.03208009557363605, \"value\": 0.9}, \"21\": {\"effect\": 0.09321524128050078, \"value\": 0.7138169041128101}, \"22\": {\"effect\": -0.6550153974566253, \"value\": 1.6610289078174356}, \"23\": {\"effect\": -0.03533259745842264, \"value\": -0.5029596538861232}, \"24\": {\"effect\": 0.06008963864846526, \"value\": 6.0}, \"25\": {\"effect\": 0.16785673440506263, \"value\": 3.0}, \"26\": {\"effect\": -0.5806824411408547, \"value\": -0.3799250749875946}, \"27\": {\"effect\": 0.0110095840697664, \"value\": 0.5247820402373953}, \"28\": {\"effect\": 0.004256805341756911, \"value\": -0.2457768425498273}, \"29\": {\"effect\": -0.010946559838791668, \"value\": -0.9864457995552764}, \"30\": {\"effect\": 0.0844364783696726, \"value\": -0.5668619970726538}, \"31\": {\"effect\": -0.03798079561607702, \"value\": -0.4011135364871937}, \"32\": {\"effect\": -0.010612400225414086, \"value\": 0.9903651630412104}, \"33\": {\"effect\": 0.013363505831216718, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.01310193664731019, \"value\": 0.9724943033069674}, \"35\": {\"effect\": 0.43634573838495805, \"value\": 0.6096497732444289}, \"36\": {\"effect\": 0.014591964689697827, \"value\": -0.6084223494078528}, \"37\": {\"effect\": 0.024037612482264315, \"value\": 0.0}, \"38\": {\"effect\": 0.0012840478897562233, \"value\": 0.0}, \"39\": {\"effect\": -0.015330679212063473, \"value\": 3.0}}}, {\"outValue\": 4.15100874075752, \"simIndex\": 45.0, \"features\": {\"0\": {\"effect\": 0.3162062755234518, \"value\": 0.0}, \"1\": {\"effect\": 0.006381242312268766, \"value\": 1.0}, \"2\": {\"effect\": 0.21028301228411342, \"value\": 1.0}, \"3\": {\"effect\": -0.03653169784958845, \"value\": 2.255188427957684}, \"4\": {\"effect\": 0.0058807229075721204, \"value\": 0.0}, \"5\": {\"effect\": 1.0288857923087833, \"value\": 1.0}, \"6\": {\"effect\": -0.027537697141238524, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.2227719409925681, \"value\": 0.3}, \"8\": {\"effect\": -0.20237657108254453, \"value\": 0.0}, \"9\": {\"effect\": -0.24455347570231312, \"value\": 1.6218071488376022}, \"10\": {\"effect\": -0.36266502391915534, \"value\": 0.1185511143371529}, \"11\": {\"effect\": -0.011738376931619507, \"value\": 0.0}, \"12\": {\"effect\": 0.4451855016877724, \"value\": 0.9913256516867326}, \"13\": {\"effect\": -0.3601725145293612, \"value\": 0.0}, \"14\": {\"effect\": 0.045056120886737376, \"value\": 1.0}, \"15\": {\"effect\": 0.36132054243568146, \"value\": 2.0}, \"16\": {\"effect\": -0.34298685877870905, \"value\": 1.0}, \"17\": {\"effect\": 0.0013544552879947713, \"value\": 1.0}, \"18\": {\"effect\": 0.0940468931504397, \"value\": 3.0}, \"19\": {\"effect\": 0.019451614023412306, \"value\": -0.3067639787858137}, \"20\": {\"effect\": 0.16274563408908038, \"value\": 0.3}, \"21\": {\"effect\": 0.003044569016966415, \"value\": 0.1185511143371529}, \"22\": {\"effect\": 0.14777035592723586, \"value\": 0.0208286958620848}, \"23\": {\"effect\": 0.34614931960675016, \"value\": 47.96542129224834}, \"24\": {\"effect\": 0.04428518302468512, \"value\": 19.0}, \"25\": {\"effect\": 0.1544952204588428, \"value\": 3.0}, \"26\": {\"effect\": -0.6340446408326081, \"value\": -0.2554999120302821}, \"27\": {\"effect\": 0.007329351643206962, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.005511660978344832, \"value\": -0.2490525918650297}, \"29\": {\"effect\": 0.03198380618511881, \"value\": -0.5435734871918722}, \"30\": {\"effect\": 0.09057502939527837, \"value\": 0.26600614042487}, \"31\": {\"effect\": 0.05777967304574478, \"value\": 0.9913256516867326}, \"32\": {\"effect\": -0.03828935297921026, \"value\": 1.6218071488376022}, \"33\": {\"effect\": -0.061009548061303154, \"value\": -0.4819151924735424}, \"34\": {\"effect\": 0.012325894173244924, \"value\": -0.6478202303431079}, \"35\": {\"effect\": -0.15493052937569488, \"value\": -0.378853786070493}, \"36\": {\"effect\": -0.06136924520409364, \"value\": 2.255188427957684}, \"37\": {\"effect\": 0.018498870543804245, \"value\": 0.0}, \"38\": {\"effect\": 0.004765487385436373, \"value\": 0.0}, \"39\": {\"effect\": -0.22577540085741202, \"value\": 3.0}}}, {\"outValue\": 5.805572479556602, \"simIndex\": 49.0, \"features\": {\"0\": {\"effect\": 0.3086620321838523, \"value\": 0.0}, \"1\": {\"effect\": 0.04973442019781504, \"value\": 1.0}, \"2\": {\"effect\": 0.20012261856511177, \"value\": 1.0}, \"3\": {\"effect\": 0.03132841394120526, \"value\": -0.3020687129269269}, \"4\": {\"effect\": 0.014567729850142262, \"value\": 0.0}, \"5\": {\"effect\": 0.809613534090322, \"value\": 1.0}, \"6\": {\"effect\": 0.07155417525669579, \"value\": -0.6478202303431079}, \"7\": {\"effect\": -0.0649473571540573, \"value\": 0.8}, \"8\": {\"effect\": 0.27770775046191676, \"value\": 1.0}, \"9\": {\"effect\": 0.11675757543910815, \"value\": -0.6169417098950603}, \"10\": {\"effect\": 0.2291161650517663, \"value\": 0.5237567592219091}, \"11\": {\"effect\": -0.02665419088230116, \"value\": 0.0}, \"12\": {\"effect\": -0.17278204770648137, \"value\": -0.4011135364871937}, \"13\": {\"effect\": 0.5815236572038, \"value\": 1.0}, \"14\": {\"effect\": 0.04444734743530553, \"value\": 1.0}, \"15\": {\"effect\": -0.1329830273941992, \"value\": 1.0}, \"16\": {\"effect\": -0.2807610403166648, \"value\": 1.0}, \"17\": {\"effect\": 0.001864051661294257, \"value\": 1.0}, \"18\": {\"effect\": 0.283148051118524, \"value\": 5.0}, \"19\": {\"effect\": 0.10890424075802078, \"value\": -1.1383099978090228}, \"20\": {\"effect\": -0.03423378340099474, \"value\": 0.8}, \"21\": {\"effect\": 0.07056720025127511, \"value\": 0.5237567592219091}, \"22\": {\"effect\": 0.1195749941213246, \"value\": 0.0196961019721107}, \"23\": {\"effect\": -0.04301670798886286, \"value\": -1.4475018465688156}, \"24\": {\"effect\": 0.055539979407224487, \"value\": 9.0}, \"25\": {\"effect\": 0.18418496707204254, \"value\": 5.0}, \"26\": {\"effect\": -0.10241522572665004, \"value\": 1.9615302643000143}, \"27\": {\"effect\": 0.060308208439399984, \"value\": -1.1383099978090228}, \"28\": {\"effect\": -0.031009345018657063, \"value\": -0.7239059823643473}, \"29\": {\"effect\": -0.24021868511562613, \"value\": 0.7844967114616924}, \"30\": {\"effect\": 0.13003322842742354, \"value\": 0.2444030520155753}, \"31\": {\"effect\": -0.09168791979330645, \"value\": -0.4011135364871937}, \"32\": {\"effect\": 0.008795773892745157, \"value\": -0.6169417098950603}, \"33\": {\"effect\": -0.04484853406936625, \"value\": -0.9770926399944632}, \"34\": {\"effect\": 0.0075720531691735515, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.02653827259318211, \"value\": -0.6682359576202958}, \"36\": {\"effect\": 0.02634271608176847, \"value\": -0.3020687129269269}, \"37\": {\"effect\": 0.048085646512606356, \"value\": 0.0}, \"38\": {\"effect\": 0.0016190707536519256, \"value\": 0.0}, \"39\": {\"effect\": 0.13201096545923563, \"value\": 2.0}}}, {\"outValue\": 4.121080369101623, \"simIndex\": 29.0, \"features\": {\"0\": {\"effect\": 0.2698216636210273, \"value\": 0.0}, \"1\": {\"effect\": 0.00951009706993424, \"value\": 1.0}, \"2\": {\"effect\": 0.29544736725851256, \"value\": 1.0}, \"3\": {\"effect\": -0.31953390621027766, \"value\": 3.156345553450277}, \"4\": {\"effect\": 0.009332134852733081, \"value\": 0.0}, \"5\": {\"effect\": -0.2590709264697329, \"value\": 0.0}, \"6\": {\"effect\": -0.0027569320686589953, \"value\": -0.6478202303431079}, \"7\": {\"effect\": 0.25282992226199796, \"value\": 0.1}, \"8\": {\"effect\": 0.2841099405658421, \"value\": 1.0}, \"9\": {\"effect\": 0.021958481177156305, \"value\": -0.4734321676686074}, \"10\": {\"effect\": 0.003293554460788048, \"value\": 0.429990206102383}, \"11\": {\"effect\": -0.03513504977710852, \"value\": 0.0}, \"12\": {\"effect\": 0.0006959899085833566, \"value\": -0.3684782430143673}, \"13\": {\"effect\": -0.2994953507486416, \"value\": 0.0}, \"14\": {\"effect\": 0.03609284004796806, \"value\": 1.0}, \"15\": {\"effect\": -0.126329381450154, \"value\": 1.0}, \"16\": {\"effect\": -0.3264099839368373, \"value\": 1.0}, \"17\": {\"effect\": 0.0017461794387500988, \"value\": 1.0}, \"18\": {\"effect\": 0.07604731733841778, \"value\": 3.0}, \"19\": {\"effect\": 0.18041972681138874, \"value\": -1.1383099978090228}, \"20\": {\"effect\": 0.01948798867613622, \"value\": 0.1}, \"21\": {\"effect\": 0.02788899086023478, \"value\": 0.429990206102383}, \"22\": {\"effect\": -0.40093350623112567, \"value\": 0.0014794841291957}, \"23\": {\"effect\": 0.3777200817564444, \"value\": 0.0894729701827194}, \"24\": {\"effect\": -0.030897102585440837, \"value\": 7.0}, \"25\": {\"effect\": 0.125959209167259, \"value\": 3.0}, \"26\": {\"effect\": 0.41127935174671854, \"value\": -0.7305778069582027}, \"27\": {\"effect\": 0.030287754105379004, \"value\": -1.1383099978090228}, \"28\": {\"effect\": 0.21611347996588695, \"value\": 1.9192059847381795}, \"29\": {\"effect\": -0.1934840369506551, \"value\": 2.1089877315981087}, \"30\": {\"effect\": -0.01454428838389013, \"value\": 0.7826706341107407}, \"31\": {\"effect\": 0.013775285321014994, \"value\": -0.3684782430143673}, \"32\": {\"effect\": 0.032114138722955515, \"value\": -0.4734321676686074}, \"33\": {\"effect\": 0.14507005552429236, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.0009503389490957321, \"value\": -0.6478202303431079}, \"35\": {\"effect\": 0.17531602511561656, \"value\": 0.3677589325600016}, \"36\": {\"effect\": 0.043218512550693075, \"value\": 3.156345553450277}, \"37\": {\"effect\": 0.04274946138749625, \"value\": 0.0}, \"38\": {\"effect\": 0.002233177356907098, \"value\": 0.0}, \"39\": {\"effect\": -0.04480305893472891, \"value\": 1.0}}}, {\"outValue\": 3.80733168508002, \"simIndex\": 52.0, \"features\": {\"0\": {\"effect\": 0.2661159172953703, \"value\": 0.0}, \"1\": {\"effect\": 0.013626869820439924, \"value\": 1.0}, \"2\": {\"effect\": -0.1229722557454046, \"value\": 0.0}, \"3\": {\"effect\": 0.14677663054046386, \"value\": -1.0410971282039654}, \"4\": {\"effect\": 0.007556674732692332, \"value\": 0.0}, \"5\": {\"effect\": 0.963541578067751, \"value\": 1.0}, \"6\": {\"effect\": -0.14332183333116041, \"value\": 2.01852014148613}, \"7\": {\"effect\": -0.5444817015101114, \"value\": 0.9}, \"8\": {\"effect\": -0.2920942640407061, \"value\": 0.0}, \"9\": {\"effect\": -0.026812790793056415, \"value\": 0.976014208818565}, \"10\": {\"effect\": 0.19030430930078, \"value\": 0.8818652294081765}, \"11\": {\"effect\": 0.042118110987525194, \"value\": 1.0}, \"12\": {\"effect\": 0.09002422927489728, \"value\": -0.3793566741719761}, \"13\": {\"effect\": -0.3312618947946775, \"value\": 0.0}, \"14\": {\"effect\": 0.03265234995324733, \"value\": 1.0}, \"15\": {\"effect\": -0.11002215620224493, \"value\": 1.0}, \"16\": {\"effect\": 0.32783563029392637, \"value\": 0.0}, \"17\": {\"effect\": 0.0013832272270465267, \"value\": 1.0}, \"18\": {\"effect\": 0.07456476553799761, \"value\": 3.0}, \"19\": {\"effect\": 0.0985349515171272, \"value\": -0.3067639787858137}, \"20\": {\"effect\": -0.03981160436038979, \"value\": 0.9}, \"21\": {\"effect\": 0.04259935947136562, \"value\": 0.8818652294081765}, \"22\": {\"effect\": -0.17709705492893893, \"value\": 0.0162885309260045}, \"23\": {\"effect\": 0.6564734852384742, \"value\": 38.12314775259958}, \"24\": {\"effect\": 0.10156187121920049, \"value\": 14.0}, \"25\": {\"effect\": 0.07940085258295435, \"value\": 3.0}, \"26\": {\"effect\": -0.7120216895990427, \"value\": -0.1536975059742991}, \"27\": {\"effect\": -0.003554975021277361, \"value\": -0.3067639787858137}, \"28\": {\"effect\": 0.06000918383652794, \"value\": -1.658707311212152}, \"29\": {\"effect\": 0.06871701532371104, \"value\": -0.6607633823261981}, \"30\": {\"effect\": 0.16441334784324357, \"value\": 0.3218407827586891}, \"31\": {\"effect\": 0.0102971907059769, \"value\": -0.3793566741719761}, \"32\": {\"effect\": -0.08121892196304989, \"value\": 0.976014208818565}, \"33\": {\"effect\": 0.09525462736777819, \"value\": -0.8120334908208229}, \"34\": {\"effect\": -0.050797618653322524, \"value\": 2.01852014148613}, \"35\": {\"effect\": -0.006204873628835229, \"value\": -0.1650233528165174}, \"36\": {\"effect\": -0.19364926870050722, \"value\": -1.0410971282039654}, \"37\": {\"effect\": 0.017871343205354894, \"value\": 0.0}, \"38\": {\"effect\": 0.0014485805085104211, \"value\": 0.0}, \"39\": {\"effect\": 0.01866698177254609, \"value\": 1.0}}}], \"plot_cmap\": \"RdBu\", \"ordering_keys\": null, \"ordering_keys_time_format\": null}),\n",
       "    document.getElementById('i4MMFPTMF44OUZMIOHU0R')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<shap.plots._force.AdditiveForceArrayVisualizer at 0x2df91a478b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar SHAP force plot para una muestra de datos\n",
    "\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][:100, :], features=X_test.iloc[:100, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b1c41",
   "metadata": {},
   "source": [
    "Este gráfico proporciona información sobre cómo cada característica contribuye a la diferencia entre la salida del modelo y la media de las predicciones del modelo para las primeras 100 instancias del \"X_test\".\n",
    "\n",
    "- Eje y (\"f(x)\"): Representa la predicción del modelo. Cada punto en el gráfico indica la contribución de una instancia específica a la predicción final del modelo. La posición vertical del punto muestra si la contribución fue positiva o negativa y en qué medida.\n",
    "- Eje x (\"sample order by similarity\"): Los puntos en el eje x están ordenados por similitud. Las instancias que son similares entre sí (en términos de características relevantes para el modelo) están agrupadas cercanas entre sí en el eje x. Esto proporciona una perspectiva sobre cómo las contribuciones de SHAP varían a medida que pasamos de una instancia a otra en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be1800",
   "metadata": {},
   "source": [
    "##### Bloque 3: Visualizar el resumen de los efectos de todas las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccf37607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar el resumen de los efectos de todas las características\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0811aa3",
   "metadata": {},
   "source": [
    "En el gráfico anterior, indicamos el valor SHAP para cada variable, es decir, la contribución de cada variable en nuestro modelo. Esta clasificado en colores (\"class 0\" en azul, representando los casos dondo no hay fraude bancario y \"class 1\" en rojo representando los casos donde sí hay fraude. \n",
    "\n",
    "Interpretación de las características más relevantes:\n",
    "- Current_address_months_count: Con una media del valor SHAP de aproximadamente 0.5, podemos decir que tiene un impacto positivo en la predicción de ambas clases. Un valor alto contribuye a la predicción de fraude y viceversa.\n",
    "- Phone_home_valid: Similar al anterior, con una media SHAP de 0.4. \n",
    "- Device_os_1: La presencia de esta variable tiene un impacto positivo en la predicción de fraude.\n",
    "- Housing_status:  Un housing_status ligeramente inferior a 0.4 en el valor SHAP indica que el tipo de vivienda tiene un impacto positivo en la predicción de fraude.\n",
    "\n",
    "También encontramos un impacto positivo en las siguientes variables \"has_other_cards\"; \"keep_alive_session\"; \"email_is_free\"; \"name_email_similarity\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd151c9",
   "metadata": {},
   "source": [
    "#### Bloque 4: Visualizar SHAP summary plot para todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c16298a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar SHAP summary plot para todos los datos\n",
    "shap.summary_plot(shap_values[0], features=X_test, max_display=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc3525",
   "metadata": {},
   "source": [
    "El \"SHAP summary plot\" que resume los efectos de cada característica en todas las predicciones. \n",
    "Podemos observar lo siguiente:\n",
    "- current_address_months_count:\n",
    "    - Los valores negativos (en azul) sugieren que tener un current_address_months_count menor contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos (en rojo) indican que un current_address_months_count mayor contribuye a una predicción más alta de fraude.\n",
    "- phone_home_valid:\n",
    "    - Los valores negativos sugieren que tener un número de teléfono de hogar no válido contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que tener un número de teléfono de hogar válido contribuye a una predicción más alta de fraude.\n",
    "- device_os_1:\n",
    "    - Los valores negativos sugieren que ciertos sistemas operativos (probablemente representados por 1) contribuyen a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que otros sistemas operativos tienen un impacto positivo en la predicción de fraude.\n",
    "- housing_status:\n",
    "    - Los valores negativos sugieren que ciertos tipos de vivienda contribuyen a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que otros tipos de vivienda tienen un impacto positivo en la predicción de fraude.\n",
    "- has_other_cards:\n",
    "    - Los valores negativos sugieren que tener otras tarjetas de crédito contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que no tener otras tarjetas de crédito tiene un impacto positivo en la predicción de fraude.\n",
    "- keep_alive_session:\n",
    "    - Los valores negativos sugieren que no mantener la sesión activa contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que mantener la sesión activa tiene un impacto positivo en la predicción de fraude.\n",
    "- email_is_free:\n",
    "    - Los valores negativos sugieren que el uso de un correo electrónico gratuito contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que tener un correo electrónico no gratuito tiene un impacto positivo en la predicción de fraude.\n",
    "- name_email_similarity:\n",
    "    - Los valores negativos sugieren que una mayor similitud entre el nombre y el correo electrónico contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que una menor similitud tiene un impacto positivo en la predicción de fraude.\n",
    "- income:\n",
    "    - Los valores negativos sugieren que un ingreso más bajo contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que un ingreso más alto tiene un impacto positivo en la predicción de fraude.\n",
    "- intended_balcon_amount:\n",
    "    - Los valores negativos sugieren que un saldo previsto más bajo contribuye a una predicción más baja de fraude.\n",
    "    - Los valores positivos indican que un saldo previsto más alto tiene un impacto positivo en la predicción de fraude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97be10e",
   "metadata": {},
   "source": [
    "# Conclusiones del trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a29b3",
   "metadata": {},
   "source": [
    "En este trabajo hemos encontrado la forma de hallar con unos datos que, creemos, no son de una gran calidad, un modelo mediante el cual podemos ordenar por probabilidades la posibilidad de que los clientes de una entidad bancaria cometan fraude.\n",
    "Hemos erradicado el 46% del fraude bancario investigando solo al 3,8% de nuestra clientela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f04e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
